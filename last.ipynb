{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e48af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import io\n",
    "import lmdb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import lmdb\n",
    "import pickle\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e4089369",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_ima_dir = './output/gaf_images'\n",
    "normal_img_dir = './output/normal/gaf_images'\n",
    "undersampled_img_dir = './output/undersampled/gaf_images'\n",
    "meta_data_drop_dataset = './output/final_dataset/gaf_images'\n",
    "\n",
    "input_folder = './data'\n",
    "output_folder = './output/final_dataset'\n",
    "lmdb_path = os.path.join(output_folder, 'gaf_images')\n",
    "pca_components = 32\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "dff0510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAF Creation Function\n",
    "def gaf_transform_torch(x, device='cpu'):\n",
    "    min_x = x.min(dim=1, keepdim=True).values\n",
    "    max_x = x.max(dim=1, keepdim=True).values\n",
    "    scaled_x = (2 * (x - min_x) / (max_x - min_x + 1e-8)) - 1\n",
    "    scaled_x = torch.clamp(scaled_x, -1, 1)\n",
    "    phi = torch.arccos(scaled_x)\n",
    "    gaf = torch.cos(phi.unsqueeze(2) + phi.unsqueeze(1))\n",
    "    return gaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1a605ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple MPS (Metal Performance Shaders)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA:\", torch.cuda.get_device_name(0))\n",
    "elif getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple MPS (Metal Performance Shaders)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "87ae388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dos_attacks = ['DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS slowloris']\n",
    "brute_force_attacks = ['FTP-Patator', 'SSH-Patator']\n",
    "web_attacks = ['Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ Sql Injection', 'Web Attack ÔøΩ XSS']\n",
    "\n",
    "def map_to_broader_category(label):\n",
    "    if label == 'BENIGN':\n",
    "        return 'BENIGN'\n",
    "    elif label == 'DDoS':\n",
    "        return 'DDoS'\n",
    "    elif label == 'PortScan':\n",
    "        return 'PortScan'\n",
    "    elif label in dos_attacks:\n",
    "        return 'DoS'\n",
    "    elif label in brute_force_attacks:\n",
    "        return 'BruteForce'\n",
    "    elif label in web_attacks:\n",
    "        return 'WebAttack'\n",
    "    elif label == 'Bot':\n",
    "        return 'Bot'\n",
    "    elif label == 'Infiltration':\n",
    "        return 'Infiltration'\n",
    "    elif label == 'Heartbleed':\n",
    "        return 'Heartbleed'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1cc47013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDB map_size set to: 35 GB\n",
      "\n",
      "üìÑ Processing Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 288359, 'Infiltration': 36}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Monday-WorkingHours.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 529481}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Monday-WorkingHours.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Friday-WorkingHours-Morning.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 188955, 'Bot': 1956}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Friday-WorkingHours-Morning.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 127292, 'PortScan': 158804}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 97686, 'DDoS': 128025}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Tuesday-WorkingHours.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 431813, 'BruteForce': 13832}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Tuesday-WorkingHours.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Wednesday-workingHours.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 439683, 'DoS': 251712, 'Heartbleed': 11}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Wednesday-workingHours.pcap_ISCX.csv.done\n",
      "\n",
      "üìÑ Processing Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv...\n",
      "After category merging: {'BENIGN': 168051, 'WebAttack': 2180}\n",
      "Generating GAF images and storing (label, data) in LMDB...\n",
      "Checkpoint saved: ./output/final_dataset/checkpoints/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv.done\n",
      "\n",
      "‚úÖ GAF image generation and LMDB (label, data) storage complete.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_folder = os.path.join(output_folder, 'checkpoints')\n",
    "os.makedirs(checkpoint_folder, exist_ok=True)\n",
    "\n",
    "map_size = 35 * 1024 ** 3  \n",
    "print(f\"LMDB map_size set to: {map_size / (1024**3):.0f} GB\")\n",
    "\n",
    "env = lmdb.open(lmdb_path, map_size=map_size)\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "with env.begin(write=True) as txn:\n",
    "    for csv_file in csv_files:\n",
    "        # Check if CSV already done\n",
    "        checkpoint_file = os.path.join(checkpoint_folder, csv_file + '.done')\n",
    "        if os.path.exists(checkpoint_file):\n",
    "            print(f\"‚úÖ Skipping {csv_file} (already processed, found checkpoint)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìÑ Processing {csv_file}...\")\n",
    "        try:\n",
    "            df_path = os.path.join(input_folder, csv_file)\n",
    "            df = pd.read_csv(df_path)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            if 'Label' not in df.columns:\n",
    "                print(f\"‚ö† Skipping {csv_file} ‚Äî 'Label' column not found.\")\n",
    "                continue\n",
    "\n",
    "            df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            labels = df['Label'].values\n",
    "            drop_cols = [\n",
    "                'Flow ID', 'Source IP', 'Source Port', 'Destination IP', 'Destination Port',\n",
    "                'Protocol', 'Timestamp', 'Label'\n",
    "            ]\n",
    "            feature_cols = [col for col in df.columns if col not in drop_cols]\n",
    "            features = df.select_dtypes(include=[np.number])\n",
    "            features = features.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            X_res = features.values\n",
    "            y_res = labels\n",
    "\n",
    "            y_categorized = np.array([map_to_broader_category(label) for label in y_res])\n",
    "            print(f\"After category merging: {dict(zip(*np.unique(y_categorized, return_counts=True)))}\")\n",
    "            y_res = y_categorized\n",
    "\n",
    "            features_scaled = scaler.fit_transform(X_res)\n",
    "            features_reduced = pca.fit_transform(features_scaled)\n",
    "            labels_res = y_res\n",
    "\n",
    "            print(f\"Generating GAF images and storing (label, data) in LMDB...\")\n",
    "\n",
    "            # ‚úÖ BATCHED GAF PROCESSING TO PREVENT OOM\n",
    "            batch_size = 1024\n",
    "            for start_idx in range(0, len(features_reduced), batch_size):\n",
    "                end_idx = min(start_idx + batch_size, len(features_reduced))\n",
    "                batch_features = features_reduced[start_idx:end_idx]\n",
    "                batch_labels = labels_res[start_idx:end_idx]\n",
    "\n",
    "                try:\n",
    "                    flows_torch = torch.tensor(batch_features, dtype=torch.float32, device=device)\n",
    "                    gaf_images = gaf_transform_torch(flows_torch, device=device).cpu().numpy()\n",
    "\n",
    "                    for idx, (gaf_image, label) in enumerate(zip(gaf_images, batch_labels)):\n",
    "                        buf = io.BytesIO()\n",
    "                        plt.imsave(buf, gaf_image, cmap='gray', format='png')\n",
    "                        buf.seek(0)\n",
    "                        image_bytes = buf.read()\n",
    "                        buf.close()\n",
    "                        key = f\"{os.path.splitext(csv_file)[0]}_{start_idx + idx:07d}\".encode('utf-8')\n",
    "                        record = {\"label\": str(label), \"data\": image_bytes}\n",
    "                        txn.put(key, pickle.dumps(record))\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† Error on batch {start_idx}-{end_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "            # === Write checkpoint file to mark as done ===\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                f.write('done')\n",
    "            print(f\"Checkpoint saved: {checkpoint_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {csv_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\n‚úÖ GAF image generation and LMDB (label, data) storage complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b5c59320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDBGAFDataset(Dataset):\n",
    "    def __init__(self, lmdb_path, transform=None):\n",
    "        self.env = lmdb.open(lmdb_path, readonly=True, lock=False)\n",
    "        self.txn = self.env.begin()\n",
    "        self.keys = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        with self.env.begin() as txn:\n",
    "            for key, value in txn.cursor():\n",
    "                record = pickle.loads(value)\n",
    "                label = record['label']\n",
    "                self.keys.append(key)\n",
    "                self.labels.append(label)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        value = self.txn.get(key)\n",
    "        record = pickle.loads(value)\n",
    "        label = record['label']\n",
    "        image = Image.open(io.BytesIO(record['data'])).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8088320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = LMDBGAFDataset(normal_img_dir)\n",
    "features_reduced_dataset = LMDBGAFDataset(meta_data_drop_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "696cb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_images(images):\n",
    "    \"\"\"\n",
    "    Sub plot the images in a grid.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.title(f'Label: {image[1]}')\n",
    "        plt.imshow(image[0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def analyse_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Analyze the dataset to get the distribution of labels.\n",
    "    \"\"\"\n",
    "    label_counts = {}\n",
    "    for _, label in dataset:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    return label_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d26a8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "for i in range(5):\n",
    "    images.append(normal_dataset[random.randint(0, len(normal_dataset) - 1)])\n",
    "       \n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f90dfc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "for i in range(5):\n",
    "    images.append(features_reduced_dataset[random.randint(0, len(features_reduced_dataset) - 1)])\n",
    "\n",
    "show_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03beafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset_analysis = analyse_dataset(normal_dataset)\n",
    "features_reduced_dataset_analysis = analyse_dataset(features_reduced_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Dataset Analysis: {'BENIGN': 2271320, 'DDoS': 128025, 'PortScan': 158804, 'Bot': 1956, 'Infiltration': 36, 'WebAttack': 2180, 'BruteForce': 13832, 'DoS': 251712, 'Heartbleed': 11}\n",
      "Undersampled Dataset Analysis: {'BENIGN': 232899, 'DDoS': 97686, 'PortScan': 127292, 'Bot': 1956, 'Infiltration': 36, 'WebAttack': 63, 'BruteForce': 11794, 'DoS': 44, 'Heartbleed': 11}\n",
      "SMOTE IMA Dataset Analysis: {'BENIGN': 2333171, 'DDoS': 128025, 'PortScan': 158804, 'Bot': 188955, 'Infiltration': 288359, 'WebAttack': 504153, 'BruteForce': 863626, 'DoS': 1758732, 'Heartbleed': 439683}\n",
      "Unique Labels in Dataset: {'WebAttack', 'PortScan', 'Heartbleed', 'BruteForce', 'DoS', 'DDoS', 'Bot', 'BENIGN', 'Infiltration'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal Dataset Analysis:\", normal_dataset_analysis)\n",
    "print(\"Features Reduced Dataset Analysis:\", features_reduced_dataset_analysis)\n",
    "unique_labels = set(normal_dataset_analysis.keys())\n",
    "print(\"Unique Labels in Dataset:\", unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bd91f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAIhCAYAAAAy8fsSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZN9JREFUeJzt3Xd0FdXi9vHnhISEFAihJEEDCSVApDcpUqJCKCIoVVGCCopSVC5FEKU3pQki6BVIBCsiiMilE0SK0ouEIoYiLRQhBIRAst8/eHN+HJJAgAMZyPez1qzFzOzZs2fmnOE8mZk9NmOMEQAAAAAAyHIuWd0AAAAAAABwFSEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAGBZUVFRstls9sHDw0MBAQEKDw/XiBEjFB8ff9t179y5UwMHDtT+/fud1+A7sGbNGg0cOFBnzpy55WV79Oghm82mp556yvkNy0Dqsblb+89ms2ngwIF3XE9MTIzDZyhHjhwqUKCAmjZtqg0bNtx5Q50gODhYHTp0sI8fOXJEAwcO1JYtW7KsTQCArENIBwBY3vTp07V27VotWbJEkyZNUoUKFTRq1CiVLl1aS5cuva06d+7cqUGDBlkqpA8aNOiWQ/rly5c1c+ZMSdLChQt1+PDhu9C6e2/t2rXq2LGj0+obPny41q5dq5iYGL333ntas2aN6tatq7179zptHc5y5MgRDRo0iJAOANkUIR0AYHllypRR9erVVbt2bbVo0ULjxo3Ttm3b5OXlpWeffVbHjx/P6iZmmR9//FEnTpxQkyZNlJycrOjo6KxuklNUr15dDz/8sNPqK1GihP0z1L17d40bN04XLlyw/4EDAACrIKQDAO5LhQsX1pgxY3Tu3Dl9+umn9ukbNmxQ27ZtFRwcrFy5cik4OFjPPfecDhw4YC8TFRWlVq1aSZLCw8Ptt0JHRUVJkpYsWaJmzZrp4YcfloeHh4oXL67XXntNJ0+edGjDiRMn9OqrryooKEju7u4qUKCAatWqlebq/tKlS/XEE08od+7c8vT0VK1atbRs2TL7/IEDB6pXr16SpJCQEHt7YmJibrofpk6dqpw5c2r69OkKCgrS9OnTZYxxKJN6y/fXX3+td999V4UKFVLu3Ln15JNPavfu3Q5lM7vt1xsyZIhcXV116NChNPNefvll5cuXTxcvXpQkLV++XPXq1VO+fPmUK1cuFS5cWC1atNCFCxfsy1x/u/uFCxfUs2dPhYSEyMPDQ35+fqpSpYq+/vrrm+6j9FSpUkWS0vyBZ+/evXr++edVsGBBubu7q3Tp0po0aZJDmZSUFA0dOlQlS5ZUrly55Ovrq3Llyumjjz6yl+nQoYOCg4PTrHfgwIGy2WwZtismJkZVq1aVJL300kv2z0Lqvvjrr7/Utm1bFSpUSO7u7vL399cTTzzBVXcAeIC4ZnUDAAC4XY0bN1aOHDn0yy+/2Kft379fJUuWVNu2beXn56ejR49q8uTJqlq1qnbu3Kn8+fOrSZMmGj58uPr166dJkyapUqVKkqRixYpJkvbt26caNWqoY8eOypMnj/bv36+xY8fqscce0/bt2+Xm5iZJevHFF7Vp0yYNGzZMoaGhOnPmjDZt2qRTp07Z2zNz5ky1b99ezZo1U3R0tNzc3PTpp58qIiJCixYt0hNPPKGOHTvq9OnTmjhxon744QcFBgZKksLCwm64/X///bcWL16sFi1aqECBAoqMjNTQoUP1yy+/qG7dumnK9+vXT7Vq1dLnn3+uhIQE9enTR02bNlVsbKxy5MhxS9t+vddee03Dhg3Tp59+qqFDh9qnnz59Wt988426du0qDw8P7d+/X02aNFHt2rU1bdo0+fr66vDhw1q4cKGSkpLk6emZbv09evTQjBkzNHToUFWsWFHnz5/Xjh07HPb1rYiLi5MkhYaG2qft3LlTNWvWtP8BKCAgQIsWLVL37t118uRJDRgwQJL0wQcfaODAgerfv7/q1Kmjy5cva9euXbfVn8D1KlWqpOnTp+ull15S//791aRJE0my31XQuHFjJScn64MPPlDhwoV18uRJrVmzxinrBgBYhAEAwKKmT59uJJn169dnWMbf39+ULl06w/lXrlwxiYmJxsvLy3z00Uf26bNmzTKSzIoVK27YhpSUFHP58mVz4MABI8n8+OOP9nne3t7mrbfeynDZ8+fPGz8/P9O0aVOH6cnJyaZ8+fKmWrVq9mkffvihkWTi4uJu2J5rDR482EgyCxcuNMYY89dffxmbzWZefPFFh3IrVqwwkkzjxo0dpn/33XdGklm7dm269d9o21OPzbXtjYyMNAULFjSXLl2yTxs1apRxcXGxl/v++++NJLNly5YbbpskM2DAAPt4mTJlTPPmzW+4THpSt/3bb781ly9fNhcuXDCrV682JUuWNGFhYeaff/6xl42IiDAPP/ywOXv2rEMdXbt2NR4eHub06dPGGGOeeuopU6FChRuuNzIy0hQpUiTN9AEDBpjrf34VKVLEREZG2sfXr19vJJnp06c7lDt58qSRZMaPH3/zDQcA3Ley9e3uv/zyi5o2bapChQrJZrNp7ty5t1yHMUajR49WaGio3N3dFRQUpOHDhzu/sQCAdJnrbu1OTExUnz59VLx4cbm6usrV1VXe3t46f/68YmNjM1VnfHy8OnfurKCgILm6usrNzU1FihSRJIc6qlWrpqioKA0dOlTr1q3T5cuXHepZs2aNTp8+rcjISF25csU+pKSkqGHDhlq/fr3Onz9/29udeot7/fr1JV29Vb5evXqaPXu2EhIS0izz9NNPO4yXK1dOkhweBcjstqfnzTffVHx8vGbNmiXp6m3hkydPVpMmTey3fleoUEE5c+bUq6++qujoaP3111+Z2t5q1arpf//7n9555x3FxMTo33//zdRyqdq0aSM3Nzf74wYJCQn6+eef5evrK0m6ePGili1bpmeeeUaenp4Ox6tx48a6ePGi1q1bZ2/L1q1b9cYbb2jRokXp7uu7wc/PT8WKFdOHH36osWPHavPmzUpJSbkn6wYA3DvZOqSfP39e5cuX18cff3zbdbz55pv6/PPPNXr0aO3atUs//fSTqlWr5sRWAgAycv78eZ06dUqFChWyT3v++ef18ccfq2PHjlq0aJF+//13rV+/XgUKFMhUsEtJSVGDBg30ww8/qHfv3lq2bJl+//13e0C7to5vv/1WkZGR+vzzz1WjRg35+fmpffv2OnbsmKT/e965ZcuWcnNzcxhGjRolY4xOnz59W9u+fPlyxcXFqVWrVkpISNCZM2d05swZtW7dWhcuXEj3We18+fI5jLu7uzts061se3oqVqyo2rVr25/hnj9/vvbv36+uXbvayxQrVkxLly5VwYIF1aVLFxUrVkzFihVzeJ47PRMmTFCfPn00d+5chYeHy8/PT82bN8907+yjRo3S+vXrtXLlSr377rs6fvy4mjdvrkuXLkmSTp06pStXrmjixIlpjlXjxo0lyf5cft++fTV69GitW7dOjRo1Ur58+fTEE0/c9Ve62Ww2LVu2TBEREfrggw9UqVIlFShQQN27d9e5c+fu6roBAPdOtn4mvVGjRmrUqFGG85OSktS/f399+eWXOnPmjMqUKaNRo0apXr16kq5eUZg8ebJ27NihkiVL3qNWAwBS/fzzz0pOTrafl8+ePav58+drwIABeuedd+zlLl26lOkwvGPHDm3dulVRUVGKjIy0T//zzz/TlM2fP7/Gjx+v8ePH6+DBg5o3b57eeecdxcfHa+HChcqfP78kaeLEiapevXq66/P398/s5jqYOnWqJGns2LEaO3ZsuvNfe+21W6rzVrY9I927d1erVq20adMmffzxxwoNDbVf6U9Vu3Zt1a5dW8nJydqwYYMmTpyot956S/7+/mrbtm269Xp5eWnQoEEaNGiQjh8/br+q3rRpU+3ateum7SpatKi9s7g6deooV65c6t+/vyZOnKiePXsqb968ypEjh1588UV16dIl3TpCQkIkSa6ururRo4d69OihM2fOaOnSperXr58iIiJ06NAheXp6ysPDw/4HgGvdrAO+mylSpIj92O/Zs0ffffedBg4cqKSkJE2ZMuWO6gYAWEO2Duk389JLL2n//v365ptvVKhQIc2ZM0cNGzbU9u3bVaJECf30008qWrSo5s+fr4YNG8oYoyeffFIffPCB/Pz8srr5APBAO3jwoHr27Kk8efLYw6jNZpMxxn6FONXnn3+u5ORkh2nXX0VOldrz9vV1XNuDfHoKFy6srl27atmyZVq9erUkqVatWvL19dXOnTsdrianJ6P2pOeff/7RnDlzVKtWLYdO2lJ9/vnn+vLLL7Vjxw6VKVPmpvWlut1tv9YzzzyjwoUL6z//+Y9WrlypcePGZdibeY4cOfToo4+qVKlS+vLLL7Vp06YMQ/q1/P391aFDB23dulXjx4/XhQsXMuxwLiO9e/dWVFSURo4cqddee00+Pj4KDw/X5s2bVa5cOeXMmTNT9fj6+qply5Y6fPiw3nrrLe3fv19hYWEKDg5WfHy8jh8/bv9DTFJSkhYtWnTTOjP7WQgNDVX//v01e/Zsbdq0KVPtBQBYHyE9A/v27dPXX3+tv//+234bZc+ePbVw4UJNnz5dw4cP119//aUDBw5o1qxZ+uKLL5ScnKy3335bLVu21PLly7N4CwDgwbFjxw7788Hx8fFatWqVpk+frhw5cmjOnDkqUKCAJCl37tyqU6eOPvzwQ+XPn1/BwcFauXKlpk6dan/2OFVqeP3ss8/k4+MjDw8PhYSEqFSpUipWrJjeeecdGWPk5+enn376SUuWLHFY/uzZswoPD9fzzz+vUqVKycfHR+vXr9fChQv17LPPSpK8vb01ceJERUZG6vTp02rZsqUKFiyoEydOaOvWrTpx4oQmT54sSSpbtqwk6aOPPlJkZKTc3NxUsmRJ+fj4pNkfX375pS5evKju3bvb7yK4Vr58+fTll19q6tSpGjduXKb3c2a3/UZy5MihLl26qE+fPvLy8lKHDh0c5k+ZMkXLly9XkyZNVLhwYV28eFHTpk2TJD355JMZ1vvoo4/qqaeeUrly5ZQ3b17FxsZqxowZqlGjxi0HdElyc3PT8OHD1bp1a3300Ufq37+/PvroIz322GOqXbu2Xn/9dQUHB+vcuXP6888/9dNPP9n/b2/atKnKlCmjKlWqqECBAjpw4IDGjx+vIkWKqESJEpKuPgP//vvvq23bturVq5cuXryoCRMmpPljUXqKFSumXLly6csvv1Tp0qXl7e2tQoUK6eTJk+ratatatWqlEiVKKGfOnFq+fLm2bdvmcOcIAOA+l3V91lmLJDNnzhz7eGqPt15eXg6Dq6urad26tTHGmE6dOhlJZvfu3fblNm7caCSZXbt23etNAIAHTmoP4qlDzpw5TcGCBU3dunXN8OHDTXx8fJpl/v77b9OiRQuTN29e4+PjYxo2bGh27NiRpgdtY4wZP368CQkJMTly5HDoTXvnzp2mfv36xsfHx+TNm9e0atXKHDx40KHH8YsXL5rOnTubcuXKmdy5c5tcuXKZkiVLmgEDBpjz5887rGflypWmSZMmxs/Pz7i5uZmHHnrINGnSxMyaNcuhXN++fU2hQoWMi4vLDXuer1ChQppe1K9XvXp1kz9/fnPp0iV7D+fXry8uLi5NL+KZ2fZrj016vdHv37/fSDKdO3dOM2/t2rXmmWeeMUWKFDHu7u4mX758pm7dumbevHkO5a5f3zvvvGOqVKli8ubNa9zd3U3RokXN22+/bU6ePJnhPjDGZLjtqR599FGTN29ec+bMGfs+efnll81DDz1k3NzcTIECBUzNmjXN0KFD7cuMGTPG1KxZ0+TPn9/kzJnTFC5c2Lzyyitm//79DnUvWLDAVKhQweTKlcsULVrUfPzxx5nq3d0YY77++mtTqlQp4+bmZt8Xx48fNx06dDClSpUyXl5extvb25QrV86MGzfOXLly5Yb7AQBw/7AZc123uNmUzWbTnDlz1Lx5c0lXOwNq166d/vjjD/u7Y1N5e3srICBAAwYM0PDhwx168/3333/l6empxYsXp3kGDwCA7GDixInq3r27duzYoUceeSSrmwMAwH2F290zULFiRSUnJys+Pl61a9dOt0ytWrV05coV7du3T8WKFZN0tRMXSfbX1QAAkF1s3rxZcXFxGjx4sJo1a0ZABwDgNmTrK+mJiYn2HmsrVqyosWPH2l/rUrhwYb3wwgtavXq1xowZo4oVK+rkyZNavny5ypYtq8aNGyslJUVVq1aVt7e3xo8fr5SUFHXp0kW5c+fW4sWLs3jrAAC4t4KDg3Xs2DHVrl1bM2bMUEBAQFY3CQCA+062DukxMTEKDw9PMz0yMlJRUVG6fPmyhg4dqi+++EKHDx9Wvnz5VKNGDQ0aNMjewc+RI0fUrVs3LV68WF5eXmrUqJHGjBlD7+4AAAAAgFuWrUM6AAAAAABW4pLVDQAAAAAAAFcR0gEAAAAAsIhs17t7SkqKjhw5Ih8fH9lstqxuDgAAAADgAWeM0blz51SoUCG5uNz4Wnm2C+lHjhxRUFBQVjcDAAAAAJDNHDp0SA8//PANy2S7kO7j4yPp6s7JnTt3FrcGAAAAAPCgS0hIUFBQkD2P3ki2C+mpt7jnzp2bkA4AAAAAuGcy88g1HccBAAAAAGARhHQAAAAAACyCkA4AAAAAgEVku2fSAQAAAMAYoytXrig5OTmrm4IHhJubm3LkyHHH9RDSAQAAAGQrSUlJOnr0qC5cuJDVTcEDxGaz6eGHH5a3t/cd1UNIBwAAAJBtpKSkKC4uTjly5FChQoWUM2fOTPW4DdyIMUYnTpzQ33//rRIlStzRFXVCOgAAAIBsIykpSSkpKQoKCpKnp2dWNwcPkAIFCmj//v26fPnyHYV0Oo4DAAAAkO24uBCF4FzOuiODTyYAAAAAABZBSAcAAAAAwCJ4Jh0AAAAAJAW/8/M9W9f+kU3u2bqyUkxMjMLDw/XPP//I19c3q5tzX+BKOgAAAADcBzp06CCbzaaRI0c6TJ87dy491D9ACOkAAAAAcJ/w8PDQqFGj9M8//zitzqSkJKfVhTtHSAcAAACA+8STTz6pgIAAjRgxIsMys2fP1iOPPCJ3d3cFBwdrzJgxDvODg4M1dOhQdejQQXny5FGnTp0UFRUlX19fzZ8/XyVLlpSnp6datmyp8+fPKzo6WsHBwcqbN6+6deum5ORke10zZ85UlSpV5OPjo4CAAD3//POKj4+/a9ufHRDSAQAAAOA+kSNHDg0fPlwTJ07U33//nWb+xo0b1bp1a7Vt21bbt2/XwIED9d577ykqKsqh3IcffqgyZcpo48aNeu+99yRJFy5c0IQJE/TNN99o4cKFiomJ0bPPPqsFCxZowYIFmjFjhj777DN9//339nqSkpI0ZMgQbd26VXPnzlVcXJw6dOhwN3fBA4+O4wAAAADgPvLMM8+oQoUKGjBggKZOneowb+zYsXriiSfswTs0NFQ7d+7Uhx9+6BCeH3/8cfXs2dM+/uuvv+ry5cuaPHmyihUrJklq2bKlZsyYoePHj8vb21thYWEKDw/XihUr1KZNG0nSyy+/bK+jaNGimjBhgqpVq6bExER5e3vfrV3wQONKOgAAAADcZ0aNGqXo6Gjt3LnTYXpsbKxq1arlMK1WrVrau3evw23qVapUSVOnp6enPaBLkr+/v4KDgx3Ctr+/v8Pt7Js3b1azZs1UpEgR+fj4qF69epKkgwcP3tH2ZWeEdAAAAAC4z9SpU0cRERHq16+fw3RjTJqe3o0xaZb38vJKM83Nzc1h3GazpTstJSVFknT+/Hk1aNBA3t7emjlzptavX685c+ZIojO6O8Ht7gAAAABwHxo5cqQqVKig0NBQ+7SwsDD9+uuvDuXWrFmj0NBQ5ciRw6nr37Vrl06ePKmRI0cqKChIkrRhwwanriM7IqTjtpWNLuvU+rZHbndqfQAAAMCDrGzZsmrXrp0mTpxon/af//xHVatW1ZAhQ9SmTRutXbtWH3/8sT755BOnr79w4cLKmTOnJk6cqM6dO2vHjh0aMmSI09eT3RDSAQAAAEDS/pFNsroJt2zIkCH67rvv7OOVKlXSd999p/fff19DhgxRYGCgBg8efFd6XC9QoICioqLUr18/TZgwQZUqVdLo0aP19NNPO31d2YnNpPeAwgMsISFBefLk0dmzZ5U7d+6sbs59jSvpAAAAuN9cvHhRcXFxCgkJkYeHR1Y3Bw+QG322biWH0nEcAAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCNesbgBuLPidn51W1/6RTZxWFwAAAADA+QjpAAAAACBJA/Pcw3WdvXfryoR69eqpQoUKGj9+fFY35a4YOHCg5s6dqy1bttx2Hfv371dISIg2b96sChUqOK1t1+N2dwAAAAC4D9SrV09vvfVWmulz586VzWa79w3CXUFIBwAAAADckeTkZKWkpGR1Mx4IhHQAAAAAeEAMHDhQFSpU0IwZMxQcHKw8efKobdu2OnfunL3M+fPn1b59e3l7eyswMFBjxoxJU09SUpJ69+6thx56SF5eXnr00UcVExNjnx8VFSVfX1/Nnz9fYWFhcnd314EDBxQTE6Nq1arJy8tLvr6+qlWrlg4cOCBJ2rdvn5o1ayZ/f395e3uratWqWrp0qcN6g4ODNXToUHv7ihQpoh9//FEnTpxQs2bN5O3trbJly2rDhg1p2jJ37lyFhobKw8ND9evX16FDh264r6ZPn67SpUvLw8NDpUqV0ieffOIw//fff1fFihXl4eGhKlWqaPPmzZk+DneCkA4AAAAAD5B9+/Zp7ty5mj9/vubPn6+VK1dq5MiR9vm9evXSihUrNGfOHC1evFgxMTHauHGjQx0vvfSSVq9erW+++Ubbtm1Tq1at1LBhQ+3du9de5sKFCxoxYoQ+//xz/fHHH/Lz81Pz5s1Vt25dbdu2TWvXrtWrr75qvxU/MTFRjRs31tKlS7V582ZFRESoadOmOnjwoMO6x40bp1q1amnz5s1q0qSJXnzxRbVv314vvPCCNm3apOLFi6t9+/Yyxji0ZdiwYYqOjtbq1auVkJCgtm3bZriP/vvf/+rdd9/VsGHDFBsbq+HDh+u9995TdHS0pKt/yHjqqadUsmRJbdy4UQMHDlTPnj1v/6DcAjqOAwAAAIAHSEpKiqKiouTj4yNJevHFF7Vs2TINGzZMiYmJmjp1qr744gvVr19fkhQdHa2HH37Yvvy+ffv09ddf6++//1ahQoUkST179tTChQs1ffp0DR8+XJJ0+fJlffLJJypfvrwk6fTp0zp79qyeeuopFStWTJJUunRpe73ly5e3l5WkoUOHas6cOZo3b566du1qn964cWO99tprkqT3339fkydPVtWqVdWqVStJUp8+fVSjRg0dP35cAQEB9rZ8/PHHevTRR+3bVLp0af3++++qVq1amn00ZMgQjRkzRs8++6wkKSQkRDt37tSnn36qyMhIffnll0pOTta0adPk6empRx55RH///bdef/312zsot4CQDgAAAAAPkODgYHtAl6TAwEDFx8dLuhrAk5KSVKNGDft8Pz8/lSxZ0j6+adMmGWMUGhrqUO+lS5eUL18++3jOnDlVrlw5h3o6dOigiIgI1a9fX08++aRat26twMBASVevTg8aNEjz58/XkSNHdOXKFf37779prqRfW6e/v78kqWzZsmmmxcfH20O6q6urqlSpYi9TqlQp+fr6KjY2Nk1IP3HihA4dOqRXXnlFnTp1sk+/cuWK8uS52sN/bGysypcvL09PT/v8a/fZ3URIBwAAAID7QO7cuXX2bNpXt505c0a5c+e2j7u5uTnMt9ls9k7drr1FPCMpKSnKkSOHNm7cqBw5cjjM8/b2tv87V65caXqVnz59urp3766FCxfq22+/Vf/+/bVkyRJVr15dvXr10qJFizR69GgVL15cuXLlUsuWLZWUlORQx7XtT60/vWnXd1SXXg/36U1LXe6///2v/cp7qtTtzcx+ult4Jh0AAAAA7gOlSpVy6DAt1fr16x2uhN9I8eLF5ebmpnXr1tmn/fPPP9qzZ499vGLFikpOTlZ8fLyKFy/uMKReub6RihUrqm/fvlqzZo3KlCmjr776SpK0atUqdejQQc8884zKli2rgIAA7d+/P1PtvpkrV6447Jvdu3frzJkzKlWqVJqy/v7+euihh/TXX3+l2b6QkBBJUlhYmLZu3ap///3Xvty1++xuIqQDAAAAwH3gjTfe0L59+9SlSxdt3bpVe/bs0aRJkzR16lT16tUrU3V4e3vrlVdeUa9evbRs2TLt2LFDHTp0kIvL/0XD0NBQtWvXTu3bt9cPP/yguLg4rV+/XqNGjdKCBQsyrDsuLk59+/bV2rVrdeDAAS1evFh79uyxP5devHhx/fDDD9qyZYu2bt2q559/3mmvbXNzc1O3bt3022+/adOmTXrppZdUvXr1dJ9Hl672gj9ixAh99NFH2rNnj7Zv367p06dr7NixkqTnn39eLi4ueuWVV7Rz504tWLBAo0ePdkpbb4bb3QEAAABAkgamvZXcSoKDg7Vq1Sq9++67atCggS5evKjQ0FBFRUXZO1XLjA8//FCJiYl6+umn5ePjo//85z9pbqOfPn26hg4dqv/85z86fPiw8uXLpxo1aqhx48YZ1uvp6aldu3YpOjpap06dUmBgoLp27WrvBG7cuHF6+eWXVbNmTeXPn199+vRRQkLC7e2MdNbdp08fPf/88/r777/12GOPadq0aRmW79ixozw9PfXhhx+qd+/e8vLyUtmyZfXWW29JuvrHjJ9++kmdO3dWxYoVFRYWplGjRqlFixZOae+N2ExW3myfBRISEpQnTx6dPXvW4bkNqwp+52en1bV/ZBOn1SVJZaPL3rzQLdgeud2p9QEAAADXu3jxouLi4hQSEiIPD4+sbg6cICoqSm+99ZbOnDmTpe240WfrVnIot7sDAAAAAGARhHQAAAAAACyCkA4AAAAAuG916NAhy291dyZCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACzCNasbAAAAAABWUDa67D1b1/bI7fdsXbi/cCUdAAAAAO4D8fHxeu2111S4cGG5u7srICBAERERWrt2rSQpODhYNptN33zzTZplH3nkEdlsNkVFRTlMX7NmjRo3bqy8efPKw8NDZcuW1ZgxY5ScnCxJioqKks1mu+EQExOTYTkPD4+7vl8eNFxJBwAAAID7QIsWLXT58mVFR0eraNGiOn78uJYtW6bTp0/bywQFBWn69Olq27atfdq6det07NgxeXl5OdQ3Z84ctW7dWi+99JJWrFghX19fLV26VL1799a6dev03XffqU2bNmrYsKF9mWeffVZlypTR4MGD7dP8/Py0f/9+5c6dW7t373ZYh81mc/ZueOAR0gEAAADA4s6cOaNff/1VMTExqlu3riSpSJEiqlatmkO5du3aady4cTp06JCCgoIkSdOmTVO7du30xRdf2MudP39enTp10tNPP63PPvvMPr1jx47y9/fX008/bQ/puXLlss/PmTOnPD09FRAQkKaNNpst3em4NdzuDgAAAAAW5+3tLW9vb82dO1eXLl3KsJy/v78iIiIUHR0tSbpw4YK+/fZbvfzyyw7lFi9erFOnTqlnz55p6mjatKlCQ0P19ddfO3cjkCmEdAAAAACwOFdXV0VFRSk6Olq+vr6qVauW+vXrp23btqUp+/LLLysqKkrGGH3//fcqVqyYKlSo4FBmz549kqTSpUunu75SpUrZy2TW2bNn7X9MSB0aNGhwS3WAkA4AAAAA94UWLVroyJEjmjdvniIiIhQTE6NKlSql6QyuSZMmSkxM1C+//KJp06aluYp+LWNMhtNv9XlyHx8fbdmyxWGYPn36LdUBQjoAAAAA3Dc8PDxUv359vf/++1qzZo06dOigAQMGOJRxdXXViy++qAEDBui3335Tu3bt0tQTGhoqSYqNjU13Pbt27VKJEiVuqW0uLi4qXry4w/DQQw/dUh0gpAMAAADAfSssLEznz59PM/3ll1/WypUr1axZM+XNmzfN/AYNGsjPz09jxoxJM2/evHnau3evnnvuubvSZtwYvbsDAAAAgMWdOnVKrVq10ssvv6xy5crJx8dHGzZs0AcffKBmzZqlKV+6dGmdPHlSnp6e6dbn5eWlTz/9VG3bttWrr76qrl27Knfu3Fq2bJl69eqlli1bqnXr1rfURmOMjh07lmZ6wYIF5eLC9eHMIqQDAAAAgKTtkduzugkZ8vb21qOPPqpx48Zp3759unz5soKCgtSpUyf169cv3WXy5ct3wzpbtmypFStWaPjw4apTp47+/fdfFS9eXO+++67eeuutW34mPSEhQYGBgWmmHz16lFez3QKbyaingAdUQkKC8uTJo7Nnzyp37txZ3ZybCn7nZ6fVtX9kE6fVJUllo8s6tT4rnxQBAADwYLh48aLi4uIUEhIiDw+PrG4OHiA3+mzdSg7lngMAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAJDtZLP+s3EPOOszRUgHAAAAkG24ublJki5cuJDFLcGDJikpSZKUI0eOO6qH96QDAAAAyDZy5MghX19fxcfHS5I8PT1v+X3gwPVSUlJ04sQJeXp6ytX1zmI2IR0AAABAthIQECBJ9qAOOIOLi4sKFy58x3/0IaQDAAAAyFZsNpsCAwNVsGBBXb58OaubgwdEzpw55eJy50+UE9IBAAAAZEs5cuS44+eHAWej4zgAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFpGlIX3EiBGqWrWqfHx8VLBgQTVv3ly7d+++6XIrV65U5cqV5eHhoaJFi2rKlCn3oLUAAAAAANxdWRrSV65cqS5dumjdunVasmSJrly5ogYNGuj8+fMZLhMXF6fGjRurdu3a2rx5s/r166fu3btr9uzZ97DlAAAAAAA4X5a+gm3hwoUO49OnT1fBggW1ceNG1alTJ91lpkyZosKFC2v8+PGSpNKlS2vDhg0aPXq0WrRocbebDAAAAADAXWOpZ9LPnj0rSfLz88uwzNq1a9WgQQOHaREREdqwYYMuX76cpvylS5eUkJDgMAAAAAAAYEWWCenGGPXo0UOPPfaYypQpk2G5Y8eOyd/f32Gav7+/rly5opMnT6YpP2LECOXJk8c+BAUFOb3tAAAAAAA4g2VCeteuXbVt2zZ9/fXXNy1rs9kcxo0x6U6XpL59++rs2bP24dChQ85pMAAAAAAATpalz6Sn6tatm+bNm6dffvlFDz/88A3LBgQE6NixYw7T4uPj5erqqnz58qUp7+7uLnd3d6e2FwAAAACAuyFLr6QbY9S1a1f98MMPWr58uUJCQm66TI0aNbRkyRKHaYsXL1aVKlXk5uZ2t5oKAAAAAMBdl6UhvUuXLpo5c6a++uor+fj46NixYzp27Jj+/fdfe5m+ffuqffv29vHOnTvrwIED6tGjh2JjYzVt2jRNnTpVPXv2zIpNAAAAAADAabI0pE+ePFlnz55VvXr1FBgYaB++/fZbe5mjR4/q4MGD9vGQkBAtWLBAMTExqlChgoYMGaIJEybw+jUAAAAAwH0vS59JT+3w7UaioqLSTKtbt642bdp0F1oEAAAAAEDWsUzv7gAAAAAAZHeEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiXLO6AQAAAABwL5SNLuvU+rZHbndqfYDElXQAAAAAACyDkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFpGlIf2XX35R06ZNVahQIdlsNs2dO/eG5WNiYmSz2dIMu3btujcNBgAAAADgLnLNypWfP39e5cuX10svvaQWLVpkerndu3crd+7c9vECBQrcjeYBAAAAAHBPZWlIb9SokRo1anTLyxUsWFC+vr7ObxAAAAAAAFnovnwmvWLFigoMDNQTTzyhFStW3LDspUuXlJCQ4DAAAAAAAGBF91VIDwwM1GeffabZs2frhx9+UMmSJfXEE0/ol19+yXCZESNGKE+ePPYhKCjoHrYYAAAAAIDMy9Lb3W9VyZIlVbJkSft4jRo1dOjQIY0ePVp16tRJd5m+ffuqR48e9vGEhASCOgAAAADAku6rK+npqV69uvbu3ZvhfHd3d+XOndthAAAAAADAiu77kL5582YFBgZmdTMAAAAAALhjWXq7e2Jiov7880/7eFxcnLZs2SI/Pz8VLlxYffv21eHDh/XFF19IksaPH6/g4GA98sgjSkpK0syZMzV79mzNnj07qzYBAAAAAACnydKQvmHDBoWHh9vHU58dj4yMVFRUlI4ePaqDBw/a5yclJalnz546fPiwcuXKpUceeUQ///yzGjdufM/bDgAAAACAs2VpSK9Xr56MMRnOj4qKchjv3bu3evfufZdbBQAAAABA1rjvn0kHAAAAAOBBQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwiNsK6Zs2bdL27dvt4z/++KOaN2+ufv36KSkpyWmNAwAAAAAgO7mtkP7aa69pz549kqS//vpLbdu2laenp2bNmqXevXs7tYEAAAAAAGQXtxXS9+zZowoVKkiSZs2apTp16uirr75SVFSUZs+e7cz2AQAAAACQbdxWSDfGKCUlRZK0dOlSNW7cWJIUFBSkkydPOq91AAAAAABkI7cV0qtUqaKhQ4dqxowZWrlypZo0aSJJiouLk7+/v1MbCAAAAABAdnFbIX3cuHHatGmTunbtqnfffVfFixeXJH3//feqWbOmUxsIAAAAAEB24Xo7C5UvX96hd/dUH374oVxdb6tKAAAAAACyvdu6kl60aFGdOnUqzfSLFy8qNDT0jhsFAAAAAEB2dFshff/+/UpOTk4z/dKlS/r777/vuFEAAAAAAGRHt3Rv+rx58+z/XrRokfLkyWMfT05O1rJlyxQSEuK81gEAAAAAkI3cUkhv3ry5JMlmsykyMtJhnpubm4KDgzVmzBinNQ4AAAAAgOzklkJ66rvRQ0JCtH79euXPn/+uNAoAAAAAgOzotrpij4uLc3Y7AAAAAADI9m77fWnLli3TsmXLFB8fb7/CnmratGl33DAAAAAAALKb2wrpgwYN0uDBg1WlShUFBgbKZrM5u10AAAAAAGQ7txXSp0yZoqioKL344ovObg8AAAAAANnWbb0nPSkpSTVr1nR2WwAAAAAAyNZuK6R37NhRX331lbPbAgAAAABAtnZbt7tfvHhRn332mZYuXapy5crJzc3NYf7YsWOd0jgAAAAAALKT2wrp27ZtU4UKFSRJO3bscJhHJ3IAAAAAANye2wrpK1ascHY7AAAAAADI9m7rmXQAAAAAAOB8t3UlPTw8/Ia3tS9fvvy2GwQAAAAAQHZ1WyE99Xn0VJcvX9aWLVu0Y8cORUZGOqNdAAAAAABkO7cV0seNG5fu9IEDByoxMfGOGgQAAAAAQHbl1GfSX3jhBU2bNs2ZVQIAAAAAkG04NaSvXbtWHh4ezqwSAAAAAIBs47Zud3/22Wcdxo0xOnr0qDZs2KD33nvPKQ0DAAAAACC7ua2QnidPHodxFxcXlSxZUoMHD1aDBg2c0jAAAAAAALKb2wrp06dPd3Y7AAAAAADI9m4rpKfauHGjYmNjZbPZFBYWpooVKzqrXQAAAAAAZDu3FdLj4+PVtm1bxcTEyNfXV8YYnT17VuHh4frmm29UoEABZ7cTAAAAAIAH3m317t6tWzclJCTojz/+0OnTp/XPP/9ox44dSkhIUPfu3Z3dRgAAAAAAsoXbupK+cOFCLV26VKVLl7ZPCwsL06RJk+g4DgAAAACA23RbV9JTUlLk5uaWZrqbm5tSUlLuuFEAAAAAAGRHtxXSH3/8cb355ps6cuSIfdrhw4f19ttv64knnnBa4wAAAAAAyE5uK6R//PHHOnfunIKDg1WsWDEVL15cISEhOnfunCZOnOjsNgIAAAAAkC3c1jPpQUFB2rRpk5YsWaJdu3bJGKOwsDA9+eSTzm4fAAAAAADZxi1dSV++fLnCwsKUkJAgSapfv766deum7t27q2rVqnrkkUe0atWqu9JQAAAAAAAedLcU0sePH69OnTopd+7caeblyZNHr732msaOHeu0xgEAAAAAkJ3cUkjfunWrGjZsmOH8Bg0aaOPGjXfcKAAAAAAAsqNbCunHjx9P99VrqVxdXXXixIk7bhQAAAAAANnRLYX0hx56SNu3b89w/rZt2xQYGHjHjQIAAAAAIDu6pZDeuHFjvf/++7p48WKaef/++68GDBigp556ymmNAwAAAAAgO7mlV7D1799fP/zwg0JDQ9W1a1eVLFlSNptNsbGxmjRpkpKTk/Xuu+/erbYCAAAAAPBAu6WQ7u/vrzVr1uj1119X3759ZYyRJNlsNkVEROiTTz6Rv7//XWkoAAAAAAAPulsK6ZJUpEgRLViwQP/884/+/PNPGWNUokQJ5c2b9260DwAAAACAbOOWQ3qqvHnzqmrVqs5sCwAAAAAA2dotdRwHAAAAAADuHkI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAisjSk//LLL2ratKkKFSokm82muXPn3nSZlStXqnLlyvLw8FDRokU1ZcqUu99QAAAAAADugSwN6efPn1f58uX18ccfZ6p8XFycGjdurNq1a2vz5s3q16+funfvrtmzZ9/llgIAAAAAcPe5ZuXKGzVqpEaNGmW6/JQpU1S4cGGNHz9eklS6dGlt2LBBo0ePVosWLe5SKwEAAAAAuDfuq2fS165dqwYNGjhMi4iI0IYNG3T58uV0l7l06ZISEhIcBgAAAAAArOi+CunHjh2Tv7+/wzR/f39duXJFJ0+eTHeZESNGKE+ePPYhKCjoXjQVAAAAAIBbdl+FdEmy2WwO48aYdKen6tu3r86ePWsfDh06dNfbCAAAAADA7cjSZ9JvVUBAgI4dO+YwLT4+Xq6ursqXL1+6y7i7u8vd3f1eNA8AAAAAgDtyX11Jr1GjhpYsWeIwbfHixapSpYrc3NyyqFUAAAAAADhHlob0xMREbdmyRVu2bJF09RVrW7Zs0cGDByVdvVW9ffv29vKdO3fWgQMH1KNHD8XGxmratGmaOnWqevbsmRXNBwAAAADAqbL0dvcNGzYoPDzcPt6jRw9JUmRkpKKionT06FF7YJekkJAQLViwQG+//bYmTZqkQoUKacKECbx+DQAAAADwQMjSkF6vXj17x2/piYqKSjOtbt262rRp011sFQAAAAAAWeO+eiYdAAAAAIAHGSEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARrlndAAAAAOBBVza6rFPr2x653an1AbAOrqQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLyPKQ/sknnygkJEQeHh6qXLmyVq1alWHZmJgY2Wy2NMOuXbvuYYsBAAAAALg7sjSkf/vtt3rrrbf07rvvavPmzapdu7YaNWqkgwcP3nC53bt36+jRo/ahRIkS96jFAAAAAADcPVka0seOHatXXnlFHTt2VOnSpTV+/HgFBQVp8uTJN1yuYMGCCggIsA85cuTIsOylS5eUkJDgMAAAAAAAYEWuWbXipKQkbdy4Ue+8847D9AYNGmjNmjU3XLZixYq6ePGiwsLC1L9/f4WHh2dYdsSIERo0aJBT2gwAAHC/KRtd1ml1bY/c7rS6AADpy7Ir6SdPnlRycrL8/f0dpvv7++vYsWPpLhMYGKjPPvtMs2fP1g8//KCSJUvqiSee0C+//JLhevr27auzZ8/ah0OHDjl1OwAAAAAAcJYsu5KeymazOYwbY9JMS1WyZEmVLFnSPl6jRg0dOnRIo0ePVp06ddJdxt3dXe7u7s5rMAAAAAAAd0mWXUnPnz+/cuTIkeaqeXx8fJqr6zdSvXp17d2719nNAwAAAADgnsuykJ4zZ05VrlxZS5YscZi+ZMkS1axZM9P1bN68WYGBgc5uHgAAAAAA91yW3u7eo0cPvfjii6pSpYpq1Kihzz77TAcPHlTnzp0lXX2e/PDhw/riiy8kSePHj1dwcLAeeeQRJSUlaebMmZo9e7Zmz56dlZsBAAAAAIBTZGlIb9OmjU6dOqXBgwfr6NGjKlOmjBYsWKAiRYpIko4ePerwzvSkpCT17NlThw8fVq5cufTII4/o559/VuPGjbNqEwAAAAAAcJos7zjujTfe0BtvvJHuvKioKIfx3r17q3fv3vegVQAAAAAA3HtZ9kw6AAAAAABwREgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIvI8o7jAAAAAADZR9nosk6tb3vkdqfWl9W4kg4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFuGa1Q0AAAAPnrLRZZ1a3/bI7U6tDwAAq+JKOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCV7ABAAAAcJrgd352Wl37RzZxWl3A/YIr6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgETyTnp0MzOPc+kIKO7c+AAAAAMjmuJIOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEbwnHQDwQCkbXdap9W2P3O7U+gAAAG6EK+kAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARdC7O4D7RvA7Pzu1vv0jmzi1Pmf2Kk6P4gAAANkTV9IBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAi6B3dyATrNyruDN7FJeyWa/iA/M4t76Qws6tDwAAANkOV9IBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQdxwFZwZkdltFZGQAAAPDA4Eo6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALCLLQ/onn3yikJAQeXh4qHLlylq1atUNy69cuVKVK1eWh4eHihYtqilTptyjlgIAAAAAcHe5ZuXKv/32W7311lv65JNPVKtWLX366adq1KiRdu7cqcKFC6cpHxcXp8aNG6tTp06aOXOmVq9erTfeeEMFChRQixYtsmALAAAAYBXB7/zstLr2ezzvtLokSSFpf9sCQHqy9Er62LFj9corr6hjx44qXbq0xo8fr6CgIE2ePDnd8lOmTFHhwoU1fvx4lS5dWh07dtTLL7+s0aNH3+OWAwAAAADgfFl2JT0pKUkbN27UO++84zC9QYMGWrNmTbrLrF27Vg0aNHCYFhERoalTp+ry5ctyc3NLs8ylS5d06dIl+/jZs2clSQkJCXe6CfdEyqULTqsrwWacVpckJf+b7NT6rHxMnHkcJOceC47D7bPyd8LKx0GSygxY5LS6dni84rS6JCm5yMNOrc/qx8KqstO5yZnfB0naMSjCqfVlp3MTv5uswanHwcnbmZ2Og5Vlx+OQ2kZjMnFuMVnk8OHDRpJZvXq1w/Rhw4aZ0NDQdJcpUaKEGTZsmMO01atXG0nmyJEj6S4zYMAAI4mBgYGBgYGBgYGBgYGBIUuHQ4cO3TQrZ+kz6ZJks9kcxo0xaabdrHx601P17dtXPXr0sI+npKTo9OnTypcv3w3Xk10lJCQoKChIhw4dUu7cubO6OdkWx8E6OBbWwHGwBo6DdXAsrIHjYA0cB+vgWGTMGKNz586pUKFCNy2bZSE9f/78ypEjh44dO+YwPT4+Xv7+/ukuExAQkG55V1dX5cuXL91l3N3d5e7u7jDN19f39hueTeTOnZsvlgVwHKyDY2ENHAdr4DhYB8fCGjgO1sBxsA6ORfry5MmTqXJZ1nFczpw5VblyZS1ZssRh+pIlS1SzZs10l6lRo0aa8osXL1aVKlXSfR4dAAAAAID7SZb27t6jRw99/vnnmjZtmmJjY/X222/r4MGD6ty5s6Srt6q3b9/eXr5z5846cOCAevToodjYWE2bNk1Tp05Vz549s2oTAAAAAABwmix9Jr1NmzY6deqUBg8erKNHj6pMmTJasGCBihQpIkk6evSoDh48aC8fEhKiBQsW6O2339akSZNUqFAhTZgwgXekO5G7u7sGDBiQ5hEB3FscB+vgWFgDx8EaOA7WwbGwBo6DNXAcrINj4Rw2YzLTBzwAAAAAALjbsvR2dwAAAAAA8H8I6QAAAAAAWAQhHQAAAAAAiyCkAwDwADp27Jjq168vLy8v+fr6SpJsNpvmzp0rSdq/f79sNpu2bNlyT9sVHBys8ePH39N1WlVUVJT92NxPrv0cAcD1bnaOuFf//8TExMhms+nMmTN3dT13AyH9PtOhQwfZbDb7kC9fPjVs2FDbtm2zl7l2/rXDN998I+n/PrBlypRRcnKyQ/2+vr6Kioqyj6f3Y2rz5s1q06aNAgMD5e7uriJFiuipp57STz/9pNR+CFO/fAULFtS5c+cclq9QoYIGDhzovJ1iMdceIzc3N/n7+6t+/fqaNm2aUlJS7OWCg4Pt5XLlyqXg4GC1bt1ay5cvv+V1xsfH67XXXlPhwoXl7u6ugIAARUREaO3atc7ctCx3/b4tWrSoevbsqfPnz992nQMHDlSFChXSTN+8ebOeeuopFSxYUB4eHgoODlabNm108uTJO9gCpCcz57XM1NG8efO710gLuNVtHDdunI4ePaotW7Zoz549kq6+NaVRo0bplnf2j5mMAuj69ev16quvOmUd99KUKVPk4+OjK1eu2KclJibKzc1NtWvXdii7atUq2Ww2+353hn///Vd58+aVn5+f/v33X4d5GR27evXq6a233nJaG6zCGeeMG9V9O+eSgQMHpvvba+nSpXfcpuwqs7+nbiY5OVkjRoxQqVKllCtXLvn5+al69eqaPn36XWz9vZHR5/VehdOMfkPhzhHS70MNGzbU0aNHdfToUS1btkyurq566qmnHMpMnz7dXiZ1uP5LvG/fPn3xxRe3tO4ff/xR1atXV2JioqKjo7Vz507NmjVLzZs3V//+/XX27FmH8ufOndPo0aNvazvvZ6nHaP/+/frf//6n8PBwvfnmm3rqqaccfuClvn5w9+7d+uKLL+Tr66snn3xSw4YNu6X1tWjRQlu3blV0dLT27NmjefPmqV69ejp9+rSzNy3Lpe7bv/76S0OHDtUnn3yinj173nI9xhiHY3Gt+Ph4Pfnkk8qfP78WLVqk2NhYTZs2TYGBgbpw4cKdbgLSkZnzGm7Nvn37VLlyZZUoUUIFCxaUJAUEBNzxa3GSkpLuaPkCBQrI09PzjurICuHh4UpMTNSGDRvs01atWqWAgACtX7/e4dwQExOjQoUKKTQ01Gnrnz17tsqUKaOwsDD98MMPTqv3fnWr54zLly/f9TY98sgjaX571alT57bqutPv2YMis7+nbmTgwIEaP368hgwZop07d2rFihXq1KmT/vnnn7vc+gfXjX5DwUkM7iuRkZGmWbNmDtN++eUXI8nEx8cbY4yRZObMmZNhHStWrDCSTK9evUxQUJD5999/7fPy5Mljpk+fbh8vUqSIGTdunDHGmMTERJMvXz7zzDPPZFh3SkqKMcaYuLg4+zq8vb3N8ePH7WXKly9vBgwYkLkNvg+ld4yMMWbZsmVGkvnvf/9rjHHct9d6//33jYuLi9m1a5d9WkxMjKlatarJmTOnCQgIMH369DGXL182xhjzzz//GEkmJibmrmyPlaS3bzt27GgCAgLMxYsXTbdu3UyBAgWMu7u7qVWrlvn999/t5VI/9wsXLjSVK1c2bm5uZtq0aUaSwzB9+nQzZ84c4+rqat/HGdmxY4dp3Lix8fHxMd7e3uaxxx4zf/75pzHGmN9//908+eSTJl++fCZ37tymTp06ZuPGjQ7Lp34emjdvbnLlymWKFy9ufvzxR+fsrPtIZs5r27ZtM+Hh4cbDw8P4+fmZTp06mXPnzhljjBkwYECa47hixYp7vBV337X7qW7duqZbt26mV69eJm/evMbf39/hvFqkSBGH/REZGWmMcfz/IfU8vXnzZvu/01umbt26pkuXLubtt982+fLlM3Xq1DHGGDNmzBhTpkwZ4+npaR5++GHz+uuv249J6vft2iG1fdef+w4cOGCefvpp4+XlZXx8fEyrVq3MsWPH7PMHDBhgypcvb7744gtTpEgRkzt3btOmTRuTkJDg9H18M4UKFTIjRoywj/fu3dt06dLFhIWFmSVLltinP/7446Zdu3bm0qVLplevXqZQoULG09PTVKtWzeGzOX36dJMnTx4zZ84cU6JECePu7m6efPJJc/DgwTTrrlevnpkyZYqZPHmyCQ8Pt0/P6NhFRkammR4XF2euXLliXn75ZRMcHGw8PDxMaGioGT9+fJr1TZ061YSFhdn/3+nSpYt93vW/MwYNGmQKFixoNm/efJt79tbc7JyRuk++/fZbU7duXePu7m6mTZtm/yxda9y4caZIkSLGmBufS/7++2/TunVr4+vra/z8/MzTTz9t4uLi7PWkV/e1bnQOu3abhg8fbgIDA+1tOnTokGnTpo3Jmzev8fT0NJUrVzbr1q2zLzdv3jxTqVIl4+7ubkJCQszAgQNv+n/X/SKzv6dudg4pX768GThw4L1q9j2V0T5KPQf/888/xhhjVq9ebWrXrm08PDzMww8/bLp162YSExPt5WfMmGEqV65svL29jb+/v3nuueccfrvfym8oY66eIz755BPTsGFD4+HhYYKDg813331nr+/a/39S/fHHH6ZRo0bGy8vLFCxY0LzwwgvmxIkT9vkpKSlm1KhRJiQkxHh4eJhy5cqZWbNmOWz3zz//bEqUKGE8PDxMvXr1zPTp0x32w/2EK+n3ucTERH355ZcqXry48uXLd0vLvvXWW7py5Yo+/vjjTJVfvHixTp06pd69e2dYxmazOYw/99xzKl68uAYPHnxLbXsQPf744ypfvvxNr4C8+eabMsboxx9/lCQdPnxYjRs3VtWqVbV161ZNnjxZU6dO1dChQyVJ3t7e8vb21ty5c3Xp0qW7vh1WkytXLl2+fFm9e/fW7NmzFR0drU2bNql48eKKiIhIczdB7969NWLECMXGxqpBgwb6z3/+43D1o02bNgoICNCVK1c0Z84c+yMc1zt8+LDq1KkjDw8PLV++XBs3btTLL79s/8vyuXPnFBkZqVWrVmndunUqUaKEGjdunObxj0GDBql169batm2bGjdurHbt2j2Qd0DciuvPaxcuXFDDhg2VN29erV+/XrNmzdLSpUvVtWtXSVLPnj3VunVrhytrNWvWzOKtuPuio6Pl5eWl3377TR988IEGDx6sJUuWSLp6S3nDhg3VunVrHT16VB999NEN6woKCtLs2bMlSbt3706zTHR0tFxdXbV69Wp9+umnkiQXFxdNmDBBO3bsUHR0tJYvX27//6FmzZoaP368cufObT8m6d3xYoxR8+bNdfr0aa1cuVJLlizRvn371KZNG4dy+/bt09y5czV//nzNnz9fK1eu1MiRI29/592mevXqacWKFfbxFStWqF69eqpbt659elJSktauXavw8HC99NJLWr16tb755htt27ZNrVq1UsOGDbV37157HRcuXNCwYcMUHR2t1atXKyEhQW3btnVY7759+7R27Vq1bt1arVu31po1a/TXX39JyvjYffTRR6pRo4Y6depkPwZBQUFKSUnRww8/rO+++047d+7U+++/r379+um7776zr2/y5Mnq0qWLXn31VW3fvl3z5s1T8eLF0+wPY4zefPNNTZ06Vb/++muW3faa0W+hPn36qHv37oqNjVVERMRN68noXHLhwgWFh4fL29tbv/zyi3799Vd5e3urYcOGmbrifbNzWKply5YpNjZWS5Ys0fz585WYmKi6devqyJEjmjdvnrZu3arevXvbb/VetGiRXnjhBXXv3l07d+7Up59+qqioqFu+G+9+c+3vqcycQwICArR8+XKdOHEiC1uddbZv366IiAg9++yz2rZtm7799lv9+uuvDp+/pKQkDRkyRFu3btXcuXMVFxenDh06pKkrM7+hUr333nv2Oz1feOEFPffcc4qNjU23jUePHlXdunVVoUIFbdiwQQsXLtTx48fVunVre5n+/ftr+vTpmjx5sv744w+9/fbbeuGFF7Ry5UpJ0qFDh/Tss8+qcePG2rJlizp27Kh33nnHSXsxC2TpnwhwyyIjI02OHDmMl5eX8fLyMpJMYGCgwxU6ScbDw8NeJnXYt2+fMcbxr2tTpkwxfn5+5syZM8aYG19JHzlypJFkTp8+bZ//+++/O6zjp59+MsY4/oVs4cKFxs3NzX6FMbteSTfGmDZt2pjSpUsbYzK+km6MMf7+/ub11183xhjTr18/U7JkSftdCsYYM2nSJOPt7W2Sk5ONMcZ8//33Jm/evMbDw8PUrFnT9O3b12zdutV5G2UR1+/b3377zeTLl8+0bNnSuLm5mS+//NI+LykpyRQqVMh88MEHxpj/+9zPnTvXoc6Mrn7069fPuLq6Gj8/P9OwYUPzwQcfOPxlvm/fviYkJMQkJSVlqu1XrlwxPj4+9u+IMVe/q/3797ePJyYmGpvNZv73v/9lqs4Hxc3Oa5999pnJmzevw1/9f/75Z+Pi4mI/Jjf63j0orr+S/thjjznMr1q1qunTp499vFmzZvar4amUwZV0Y9JeeUlVt25dU6FChZu277vvvjP58uWzj6deJb7etee+xYsXmxw5cjhcOf7jjz+MJPudMAMGDDCenp4OV8579eplHn300Zu2ydk+++wz4+XlZS5fvmwSEhKMq6urOX78uPnmm29MzZo1jTHGrFy50kgyf/75p7HZbObw4cMOdTzxxBOmb9++xhhjv8pz7ZXR2NhYI8n89ttv9mn9+vUzzZs3t483a9bMvPvuu/bxGx27N99886bb9cYbb5gWLVrYxwsVKuRQ//UkmVmzZpkXXnjBlCpVyhw6dOim63Cmm50zUj/b198hcLMr6al1X38umTp1apr/hy9dumRy5cplFi1aZK/bxcXF4TdR1apVjTGZP4f5+/ubS5cu2ct8+umnxsfHx5w6dSrd/VC7dm0zfPhwh2kzZswwgYGBGe26+0pmfk9l5hzyxx9/mNKlSxsXFxdTtmxZ89prr5kFCxbci024667/LqQOHh4e9nPCiy++aF599VWH5VatWmVcXFwc7qa91u+//24kpbk7KrO/oSSZzp07O0x79NFH7b9tr///57333jMNGjRwKH/o0CEjyezevdskJiYaDw8Ps2bNGocyr7zyinnuueeMMVd/l5UuXdrhe9qnTx+upOPeCQ8P15YtW7Rlyxb99ttvatCggRo1aqQDBw7Yy4wbN85eJnUICgpKU9crr7yi/Pnza9SoUbfVlnLlytnrP3/+fLrPp0REROixxx7Te++9d1vreJAYY9LcbXCzcrGxsapRo4bDcrVq1VJiYqL+/vtvSVefSU/9S3tERIRiYmJUqVIlh04AHxTz58+Xt7e3PDw8VKNGDdWpU0fdunXT5cuXVatWLXs5Nzc3VatWLc1fbatUqZKp9QwbNkzHjh3TlClTFBYWpilTpqhUqVLavn27JGnLli2qXbu23Nzc0l0+Pj5enTt3VmhoqPLkyaM8efIoMTFRBw8edChXrlw5+7+9vLzk4+Oj+Pj4TLXxQXKj81psbKzKly8vLy8ve/latWopJSVFu3fvzsJWZ61rPzuSFBgYeNc+O+l9b1asWKH69evroYceko+Pj9q3b69Tp07dUkeOsbGxCgoKcvj/KSwsTL6+vg7f3eDgYPn4+NjH7+a23kh4eLjOnz+v9evXa9WqVQoNDVXBggVVt25drV+/XufPn1dMTIwKFy6sTZs2yRij0NBQ+x1P3t7eWrlypfbt22ev09XV1WH/lipVymH7k5OTFR0drRdeeMFe5oUXXlB0dHSazl8za8qUKapSpYoKFCggb29v/fe//7Wfm+Lj43XkyBE98cQTN6zj7bff1tq1a7Vq1So9/PDDt9WOO5GZ30KZPd/fzMaNG/Xnn3/Kx8fHfhz9/Px08eJFh2NZsmRJh99dqXc4ZPYcVrZsWeXMmdM+vmXLFlWsWFF+fn4Ztmvw4MEOn6/UOyce9P5TUn8nZeYcEhYWph07dmjdunV66aWXdPz4cTVt2lQdO3bMquY71bXfhdTh888/t8/fuHGjoqKiHD4nERERSklJUVxcnKSrneU2a9ZMRYoUkY+Pj+rVqydJaX6z3Mp3qkaNGmnGM7qSvnHjRq1YscKhjaVKlZJ09U6inTt36uLFi6pfv75DmS+++ML+HYyNjVX16tUdfi9f34b7iWtWNwC3zsvLy+G2s8qVKytPnjz673//a78FOiAgIN1b067n6uqqoUOHqkOHDmluu7peiRIlJF29na569eqSJHd390ytZ+TIkapRo4Z69ep107IPstjYWIWEhNywzKlTp3TixAl7ufSCvfn/t2BfO93Dw0P169dX/fr19f7776tjx44aMGBAurcr3c/Cw8M1efJkubm5qVChQnJzc9PWrVslpX3cIr19d+2PpJvJly+fWrVqpVatWmnEiBGqWLGiRo8erejoaOXKleuGy3bo0EEnTpzQ+PHjVaRIEbm7u6tGjRppbo28PuTbbLZb6rX2QXGj89qN/riVmT96Paju5Wfn+u/NgQMH1LhxY3Xu3FlDhgyRn5+ffv31V73yyiu31EFXRsf2+ulW+Z4UL15cDz/8sFasWKF//vlHdevWlXT1/9yQkBCtXr1aK1as0OOPP66UlBTlyJFDGzduVI4cORzq8fb2dhhPbx+kTlu0aJEOHz6c5hGA5ORkLV68OMPe+jPy3Xff6e2339aYMWNUo0YN+fj46MMPP9Rvv/0mSTc9t6WqX7++vv76ay1atEjt2rW7pTY4w43OGanh6/rPrYuLS5pHmDLzeU1JSVHlypX15ZdfpplXoEAB+79z5syZ4WMBmTmHXd/emx2LlJQUDRo0SM8++2yaeR4eHjdc9n6X+nsqs+cQFxcXVa1aVVWrVtXbb7+tmTNn6sUXX9S77757099lVnf9d0GS/SKOdPVz8tprr6l79+5pli1cuLDOnz+vBg0aqEGDBpo5c6YKFCiggwcPKiIiIs1vllv5DZWejL4HKSkpatq0aboXDQMDA7Vjxw5J0s8//6yHHnrIYX5qZ6jXf7fvd1xJfwDYbDa5uLikeSVLZrVq1UqPPPKIBg0adMNyDRo0kJ+f321dda9WrZqeffbZ+/vZkDu0fPlybd++XS1atLhhuY8++kguLi723vjDwsK0Zs0ah5PPmjVr5OPjk+ZEda2wsLA7ejWZVaX+Z1SkSBH7D/fixYsrZ86c+vXXX+3lLl++rA0bNqh06dI3rC9nzpyZuhqVM2dOFStWzL5Py5Urp1WrVmX4A2/VqlXq3r27GjdurEceeUTu7u68vu0WXHteCwsLs9+tk2r16tVycXGx956d2eOIjKVewcvMftywYYOuXLmiMWPGqHr16goNDdWRI0fS1HezusLCwnTw4EEdOnTIPm3nzp06e/bsTb+7WSU8PFwxMTGKiYmxX22SpLp162rRokVat26dwsPDVbFiRSUnJys+Pl7Fixd3GAICAuzLXblyxaHH+N27d+vMmTP2q0hTp05V27Zt01wpa9eunaZOnSop42OX3jFYtWqVatasqTfeeEMVK1ZU8eLFHa4G+/j4KDg4WMuWLbvhfnj66af11VdfqWPHjvZXvGalzPwWKlCggI4dO+bw/+n172lOb59VqlRJe/fuVcGCBdMcyzx58ty0bZk5h6Un9W7FjPopqVSpknbv3p2mTcWLF5eLy4P7E//a31O3ew4JCwuTpAfyd9L1KlWqpD/++CPdz0nOnDm1a9cunTx5UiNHjlTt2rVVqlSpTN+pdKPz/Lp169KMp57XMmpjcHBwmjZ6eXkpLCxM7u7uOnjwYJr5qXdRhIWFpbvO+9WD+w1+gF26dEnHjh3TsWPHFBsbq27duikxMVFNmza1lzlz5oy9TOpwoxPRyJEjNW3atBuW8fb21ueff66ff/5ZTZo00aJFi/TXX39p27Zt+uCDDyQpzdWCaw0bNkzLly/PFrenph6jw4cPa9OmTRo+fLiaNWump556Su3bt7eXO3funI4dO6ZDhw7pl19+0auvvqqhQ4dq2LBh9r+KvvHGGzp06JC6deumXbt26ccff9SAAQPUo0cPubi46NSpU3r88cc1c+ZMbdu2TXFxcZo1a5Y++OADNWvWLKt2wT3l5eWl119/Xb169dLChQu1c+dOderUSRcuXNArr7xyw2WDg4MVFxenLVu26OTJk7p06ZLmz5+vF154QfPnz9eePXu0e/dujR49WgsWLLDv065du9o7eNqwYYP27t2rGTNm2D/fxYsX14wZMxQbG6vffvtN7dq1y/QVquzoRue1du3aycPDQ5GRkdqxY4dWrFihbt266cUXX5S/v7+kq8dx27Zt2r17t06ePHlPXrf0oClSpIhsNpvmz5+vEydOKDExMcOyxYoV05UrVzRx4kT99ddfmjFjhqZMmeJQJjg4WImJiVq2bJlOnjyZ7u23Tz75pMqVK6d27dpp06ZN+v3339W+fXvVrVvXabcqO1t4eLh+/fVXbdmyxX4lXboa0v/73//q4sWLCg8PV2hoqNq1a6f27dvrhx9+UFxcnNavX69Ro0ZpwYIF9uXc3NzUrVs3/fbbb9q0aZNeeuklVa9eXdWqVdOJEyf0008/KTIyUmXKlHEYIiMjNW/ePJ04cSLDYxccHKzffvtN+/fv18mTJ5WSkqLixYtrw4YNWrRokfbs2aP33ntP69evd9jGgQMHasyYMZowYYL27t2rTZs2aeLEiWn2xTPPPKMZM2bopZde0vfff3+X9nj6MvNb6Hr16tXTiRMn9MEHH2jfvn2aNGmS/ve//zmUSe9c0q5dO+XPn1/NmjXTqlWrFBcXp5UrV+rNN990uGKZkcycw9Lz3HPPKSAgQM2bN9fq1av1119/afbs2Vq7dq0k6f3339cXX3yhgQMH6o8//lBsbKy+/fZb9e/fP5N70fpu9nsqM+eQli1baty4cfrtt9904MABxcTEqEuXLgoNDc0wND5I+vTpo7Vr16pLly7asmWL9u7dq3nz5qlbt26Srl5Nz5kzp/18Pm/ePA0ZMiRTdaf3GyrVrFmzNG3aNO3Zs0cDBgzQ77//nuFdu126dNHp06f13HPP6ffff9dff/2lxYsX6+WXX1ZycrJ8fHzUs2dPvf3224qOjta+ffu0efNmTZo0SdHR0ZKkzp07a9++ferRo4d2796tr7766v5+7POePwWPO3L9K1V8fHxM1apVzffff28vc+38a4fU18Zk1MFMgwYNHF6fYEz6nZutX7/etGzZ0hQsWNC4urqafPnymYiICPPNN9+keQXb9a9jefXVVx1exfMguvYYubq6mgIFCpgnn3zSTJs2zd7RmzGOr0jKmTOnKVy4sGndurVZvnx5mjpv9Aq2ixcvmnfeecdUqlTJ5MmTx3h6epqSJUua/v37mwsXLtyz7b4XbtSJzL///mu6detm8ufPf8NXsF3/ub948aJp0aKF8fX1tX/+9+3bZzp16mRCQ0NNrly5jK+vr6latarDd8MYY7Zu3WoaNGhgPD09jY+Pj6ldu7a9g8ZNmzaZKlWqGHd3d1OiRAkza9asNN8npfO6xOs7b8wOMnNeu9nri+Lj4039+vWNt7d3tnkF2/Udgl3fUdytdhxnjDGDBw82AQEBxmazObyCLb3Ox8aOHWsCAwNNrly5TEREhPniiy/SfMc6d+5s8uXL55RXsF3r+s6+7qXU/VaqVCmH6amdHBUrVsw+LSkpybz//vsmODjYuLm5mYCAAPPMM8+Ybdu2GWP+r3O92bNnm6JFi5qcOXOaxx9/3Ozfv98YY8zo0aONr69vuh1UXr582fj5+ZkxY8YYY9I/drt37zbVq1c3uXLlsr+C7eLFi6ZDhw4mT548xtfX17z++uvmnXfeSbOPp0yZYkqWLGnc3NxMYGCg6datm33e9eeub7/91nh4eJjZs2ff9n69FTc7Z2T0G8QYYyZPnmyCgoKMl5eXad++vRk2bJjDZymjc8nRo0dN+/bt7f/HFC1a1HTq1MmcPXvWGOO8V7Bdb//+/aZFixYmd+7cxtPT01SpUsWhU8GFCxeamjVrmly5cpncuXObatWqmc8++yzzO9PCMvt76mbnkM8++8yEh4ebAgUK2H9vdejQwf49u59l9hVsv//+u/1z7eXlZcqVK2eGDRtmL//VV1+Z4OBg4+7ubmrUqGHmzZuXqY5F0/sNZczVc8SkSZNM/fr1jbu7uylSpIj5+uuv7cul9x3ds2ePeeaZZ4yvr6/JlSuXKVWqlHnrrbfs2SIlJcV89NFH9vNSgQIFTEREhFm5cqW9jp9++skUL17cuLu7m9q1a9tfE3c/dhxnM+YBu4EfAAAAAID7FLe7AwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwCANKKiouTr63vH9dhsNs2dO/eO6wEAILsgpAMA8IDq0KGDmjdvntXNAAAAt4CQDgAAAACARRDSAQDIhsaOHauyZcvKy8tLQUFBeuONN5SYmJim3Ny5cxUaGioPDw/Vr19fhw4dcpj/008/qXLlyvLw8FDRokU1aNAgXblyJd11JiUlqWvXrgoMDJSHh4eCg4M1YsSIu7J9AADcrwjpAABkQy4uLpowYYJ27Nih6OhoLV++XL1793Yoc+HCBQ0bNkzR0dFavXq1EhIS1LZtW/v8RYsW6YUXXlD37t21c+dOffrpp4qKitKwYcPSXeeECRM0b948fffdd9q9e7dmzpyp4ODgu7mZAADcd2zGGJPVjQAAAM7XoUMHnTlzJlMdt82aNUuvv/66Tp48Kelqx3EvvfSS1q1bp0cffVSStGvXLpUuXVq//fabqlWrpjp16qhRo0bq27evvZ6ZM2eqd+/eOnLkiKSrHcfNmTNHzZs3V/fu3fXHH39o6dKlstlszt9gAAAeAFxJBwAgG1qxYoXq16+vhx56SD4+Pmrfvr1OnTql8+fP28u4urqqSpUq9vFSpUrJ19dXsbGxkqSNGzdq8ODB8vb2tg+dOnXS0aNHdeHChTTr7NChg7Zs2aKSJUuqe/fuWrx48d3fUAAA7jOEdAAAspkDBw6ocePGKlOmjGbPnq2NGzdq0qRJkqTLly87lE3vinfqtJSUFA0aNEhbtmyxD9u3b9fevXvl4eGRZrlKlSopLi5OQ4YM0b///qvWrVurZcuWd2ELAQC4f7lmdQMAAMC9tWHDBl25ckVjxoyRi8vVv9d/9913acpduXJFGzZsULVq1SRJu3fv1pkzZ1SqVClJV0P37t27Vbx48UyvO3fu3GrTpo3atGmjli1bqmHDhjp9+rT8/PycsGUAANz/COkAADzAzp49qy1btjhMK1CggK5cuaKJEyeqadOmWr16taZMmZJmWTc3N3Xr1k0TJkyQm5ubunbtqurVq9tD+/vvv6+nnnpKQUFBatWqlVxcXLRt2zZt375dQ4cOTVPfuHHjFBgYqAoVKsjFxUWzZs1SQECAfH1978amAwBwX+J2dwAAHmAxMTGqWLGiwzBt2jSNHTtWo0aNUpkyZfTll1+m+yo0T09P9enTR88//7xq1KihXLly6ZtvvrHPj4iI0Pz587VkyRJVrVpV1atX19ixY1WkSJF02+Lt7a1Ro0apSpUqqlq1qvbv368FCxbYr+YDAAB6dwcAAAAAwDL40zUAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWMT/A78s+/+hciltAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the analysis results in single bar chart\n",
    "def plot_analysis_results(normal_analysis, undersampled_analysis, smote_ima_analysis):\n",
    "    labels = list(normal_analysis.keys())\n",
    "    normal_counts = [normal_analysis[label] for label in labels]\n",
    "    undersampled_counts = [undersampled_analysis.get(label, 0) for label in labels]\n",
    "    smote_ima_counts = [smote_ima_analysis.get(label, 0) for label in labels]\n",
    "\n",
    "    x = range(len(labels))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x, normal_counts, width=0.2, label='Normal', align='center')\n",
    "    plt.bar([i + 0.2 for i in x], undersampled_counts, width=0.2, label='Undersampled', align='center')\n",
    "    plt.bar([i + 0.4 for i in x], smote_ima_counts, width=0.2, label='SMOTE', align='center')\n",
    "\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Dataset Analysis Results')\n",
    "    plt.xticks([i + 0.2 for i in x], labels)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_analysis_results(normal_dataset_analysis, undersampled_dataset_analysis, smote_ima_dataset_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "df437536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input: (batch, 1, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # (batch, 16, 32, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                         # (batch, 16, 16, 16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # (batch, 32, 16, 16)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                         # (batch, 32, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # (batch, 64, 8, 8)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)                         # (batch, 64, 4, 4)\n",
    "        self.fc1 = nn.Linear(64*4*4, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa325ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_indices(dataset):\n",
    "    \n",
    "    all_indices = list(range(len(dataset)))\n",
    "    all_labels = []\n",
    "    for idx in all_indices:\n",
    "        _, label = dataset[idx]\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    return all_labels, all_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2b06a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'WebAttack': 0, 'PortScan': 1, 'Heartbleed': 2, 'BruteForce': 3, 'DoS': 4, 'DDoS': 5, 'Bot': 6, 'BENIGN': 7, 'Infiltration': 8}\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_indices = get_labels_indices(normal_dataset)\n",
    "\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "print(\"Label mapping:\", label_to_idx)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train (70%) and temp (30%)\n",
    "train_keys, temp_keys, train_labels, temp_labels = train_test_split(\n",
    "    all_indices, all_labels, test_size=0.3, stratify=all_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into validation (15%) and test (15%)\n",
    "val_keys, test_keys, val_labels, test_labels = train_test_split(\n",
    "    temp_keys, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "train_labels_encoded = [label_to_idx[label] for label in train_labels]\n",
    "val_labels_encoded = [label_to_idx[label] for label in val_labels]\n",
    "test_labels_encoded = [label_to_idx[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingLMDBDataset(Dataset):\n",
    "    def __init__(self, lmdb_path, keys, labels, lmdb_dataset, transform=None):\n",
    "        self.keys = keys\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.original_dataset = lmdb_dataset  # Store the original dataset for reference\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        image, label = self.original_dataset.get_[key]\n",
    "        image = image.convert('L')\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "# Add this transform\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),   \n",
    "])\n",
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            y = label_to_idx[y] \n",
    "        return x, y\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(\n",
    "    normal_dataset,\n",
    "    train_keys\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.Subset(\n",
    "    normal_dataset,\n",
    "    val_keys\n",
    ")\n",
    "\n",
    "test_dataset = torch.utils.data.Subset(\n",
    "    normal_dataset,\n",
    "    test_keys,\n",
    ")\n",
    "# Create transformed datasets\n",
    "transformed_train_subset = TransformDataset(train_dataset, transform)\n",
    "transformed_val_subset = TransformDataset(val_dataset, transform)\n",
    "transformed_test_subset = TransformDataset(test_dataset, transform)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    transformed_train_subset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    transformed_val_subset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    transformed_test_subset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "62cd58c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_train_subset[10000][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f217dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_verbose(model, train_dataloader, val_dataloader, num_epochs=5, learning_rate=0.001):\n",
    "    from torch.optim import Adam\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % 500 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_dataloader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "    # Plot learning curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Model analysis: check for overfitting\n",
    "    if val_losses[-1] > train_losses[-1]:\n",
    "        print(\"Warning: Possible overfitting detected (validation loss > training loss).\")\n",
    "    else:\n",
    "        print(\"No overfitting detected (validation loss <= training loss).\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c0f0a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [10/30930], Loss: 1.0344\n",
      "Epoch [1/5], Step [20/30930], Loss: 0.7780\n",
      "Epoch [1/5], Step [30/30930], Loss: 0.9980\n",
      "Epoch [1/5], Step [40/30930], Loss: 0.7318\n",
      "Epoch [1/5], Step [50/30930], Loss: 0.9007\n",
      "Epoch [1/5], Step [60/30930], Loss: 0.5973\n",
      "Epoch [1/5], Step [70/30930], Loss: 0.6378\n",
      "Epoch [1/5], Step [80/30930], Loss: 0.7216\n",
      "Epoch [1/5], Step [90/30930], Loss: 0.6400\n",
      "Epoch [1/5], Step [100/30930], Loss: 0.5154\n",
      "Epoch [1/5], Step [110/30930], Loss: 0.5674\n",
      "Epoch [1/5], Step [120/30930], Loss: 0.5804\n",
      "Epoch [1/5], Step [130/30930], Loss: 0.6110\n",
      "Epoch [1/5], Step [140/30930], Loss: 0.3353\n",
      "Epoch [1/5], Step [150/30930], Loss: 0.3233\n",
      "Epoch [1/5], Step [160/30930], Loss: 0.5457\n",
      "Epoch [1/5], Step [170/30930], Loss: 0.3494\n",
      "Epoch [1/5], Step [180/30930], Loss: 0.4006\n",
      "Epoch [1/5], Step [190/30930], Loss: 0.4020\n",
      "Epoch [1/5], Step [200/30930], Loss: 0.5700\n",
      "Epoch [1/5], Step [210/30930], Loss: 0.4430\n",
      "Epoch [1/5], Step [220/30930], Loss: 0.2426\n",
      "Epoch [1/5], Step [230/30930], Loss: 0.2846\n",
      "Epoch [1/5], Step [240/30930], Loss: 0.2151\n",
      "Epoch [1/5], Step [250/30930], Loss: 0.4150\n",
      "Epoch [1/5], Step [260/30930], Loss: 0.2185\n",
      "Epoch [1/5], Step [270/30930], Loss: 0.1824\n",
      "Epoch [1/5], Step [280/30930], Loss: 0.0885\n",
      "Epoch [1/5], Step [290/30930], Loss: 0.4102\n",
      "Epoch [1/5], Step [300/30930], Loss: 0.1087\n",
      "Epoch [1/5], Step [310/30930], Loss: 0.2288\n",
      "Epoch [1/5], Step [320/30930], Loss: 0.0941\n",
      "Epoch [1/5], Step [330/30930], Loss: 0.2112\n",
      "Epoch [1/5], Step [340/30930], Loss: 0.0963\n",
      "Epoch [1/5], Step [350/30930], Loss: 0.4798\n",
      "Epoch [1/5], Step [360/30930], Loss: 0.1472\n",
      "Epoch [1/5], Step [370/30930], Loss: 0.1442\n",
      "Epoch [1/5], Step [380/30930], Loss: 0.0700\n",
      "Epoch [1/5], Step [390/30930], Loss: 0.1267\n",
      "Epoch [1/5], Step [400/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [410/30930], Loss: 0.1438\n",
      "Epoch [1/5], Step [420/30930], Loss: 0.1279\n",
      "Epoch [1/5], Step [430/30930], Loss: 0.0985\n",
      "Epoch [1/5], Step [440/30930], Loss: 0.0852\n",
      "Epoch [1/5], Step [450/30930], Loss: 0.1632\n",
      "Epoch [1/5], Step [460/30930], Loss: 0.1917\n",
      "Epoch [1/5], Step [470/30930], Loss: 0.1853\n",
      "Epoch [1/5], Step [480/30930], Loss: 0.1524\n",
      "Epoch [1/5], Step [490/30930], Loss: 0.1605\n",
      "Epoch [1/5], Step [500/30930], Loss: 0.1359\n",
      "Epoch [1/5], Step [510/30930], Loss: 0.0863\n",
      "Epoch [1/5], Step [520/30930], Loss: 0.2731\n",
      "Epoch [1/5], Step [530/30930], Loss: 0.1116\n",
      "Epoch [1/5], Step [540/30930], Loss: 0.0701\n",
      "Epoch [1/5], Step [550/30930], Loss: 0.0926\n",
      "Epoch [1/5], Step [560/30930], Loss: 0.2152\n",
      "Epoch [1/5], Step [570/30930], Loss: 0.1230\n",
      "Epoch [1/5], Step [580/30930], Loss: 0.0585\n",
      "Epoch [1/5], Step [590/30930], Loss: 0.0478\n",
      "Epoch [1/5], Step [600/30930], Loss: 0.0686\n",
      "Epoch [1/5], Step [610/30930], Loss: 0.1761\n",
      "Epoch [1/5], Step [620/30930], Loss: 0.0580\n",
      "Epoch [1/5], Step [630/30930], Loss: 0.0413\n",
      "Epoch [1/5], Step [640/30930], Loss: 0.1715\n",
      "Epoch [1/5], Step [650/30930], Loss: 0.0432\n",
      "Epoch [1/5], Step [660/30930], Loss: 0.1030\n",
      "Epoch [1/5], Step [670/30930], Loss: 0.2117\n",
      "Epoch [1/5], Step [680/30930], Loss: 0.2596\n",
      "Epoch [1/5], Step [690/30930], Loss: 0.3201\n",
      "Epoch [1/5], Step [700/30930], Loss: 0.1680\n",
      "Epoch [1/5], Step [710/30930], Loss: 0.0888\n",
      "Epoch [1/5], Step [720/30930], Loss: 0.0939\n",
      "Epoch [1/5], Step [730/30930], Loss: 0.1645\n",
      "Epoch [1/5], Step [740/30930], Loss: 0.2553\n",
      "Epoch [1/5], Step [750/30930], Loss: 0.0342\n",
      "Epoch [1/5], Step [760/30930], Loss: 0.0243\n",
      "Epoch [1/5], Step [770/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [780/30930], Loss: 0.0253\n",
      "Epoch [1/5], Step [790/30930], Loss: 0.3264\n",
      "Epoch [1/5], Step [800/30930], Loss: 0.1298\n",
      "Epoch [1/5], Step [810/30930], Loss: 0.0219\n",
      "Epoch [1/5], Step [820/30930], Loss: 0.0882\n",
      "Epoch [1/5], Step [830/30930], Loss: 0.3376\n",
      "Epoch [1/5], Step [840/30930], Loss: 0.0409\n",
      "Epoch [1/5], Step [850/30930], Loss: 0.2061\n",
      "Epoch [1/5], Step [860/30930], Loss: 0.0454\n",
      "Epoch [1/5], Step [870/30930], Loss: 0.0296\n",
      "Epoch [1/5], Step [880/30930], Loss: 0.1244\n",
      "Epoch [1/5], Step [890/30930], Loss: 0.1572\n",
      "Epoch [1/5], Step [900/30930], Loss: 0.0965\n",
      "Epoch [1/5], Step [910/30930], Loss: 0.1124\n",
      "Epoch [1/5], Step [920/30930], Loss: 0.0178\n",
      "Epoch [1/5], Step [930/30930], Loss: 0.0163\n",
      "Epoch [1/5], Step [940/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [950/30930], Loss: 0.0624\n",
      "Epoch [1/5], Step [960/30930], Loss: 0.0511\n",
      "Epoch [1/5], Step [970/30930], Loss: 0.0405\n",
      "Epoch [1/5], Step [980/30930], Loss: 0.0819\n",
      "Epoch [1/5], Step [990/30930], Loss: 0.0316\n",
      "Epoch [1/5], Step [1000/30930], Loss: 0.0772\n",
      "Epoch [1/5], Step [1010/30930], Loss: 0.0574\n",
      "Epoch [1/5], Step [1020/30930], Loss: 0.0593\n",
      "Epoch [1/5], Step [1030/30930], Loss: 0.0456\n",
      "Epoch [1/5], Step [1040/30930], Loss: 0.0279\n",
      "Epoch [1/5], Step [1050/30930], Loss: 0.2261\n",
      "Epoch [1/5], Step [1060/30930], Loss: 0.0944\n",
      "Epoch [1/5], Step [1070/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [1080/30930], Loss: 0.1768\n",
      "Epoch [1/5], Step [1090/30930], Loss: 0.0602\n",
      "Epoch [1/5], Step [1100/30930], Loss: 0.0515\n",
      "Epoch [1/5], Step [1110/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [1120/30930], Loss: 0.0786\n",
      "Epoch [1/5], Step [1130/30930], Loss: 0.0542\n",
      "Epoch [1/5], Step [1140/30930], Loss: 0.0791\n",
      "Epoch [1/5], Step [1150/30930], Loss: 0.1170\n",
      "Epoch [1/5], Step [1160/30930], Loss: 0.0441\n",
      "Epoch [1/5], Step [1170/30930], Loss: 0.0289\n",
      "Epoch [1/5], Step [1180/30930], Loss: 0.0898\n",
      "Epoch [1/5], Step [1190/30930], Loss: 0.5089\n",
      "Epoch [1/5], Step [1200/30930], Loss: 0.2199\n",
      "Epoch [1/5], Step [1210/30930], Loss: 0.0197\n",
      "Epoch [1/5], Step [1220/30930], Loss: 0.0886\n",
      "Epoch [1/5], Step [1230/30930], Loss: 0.0697\n",
      "Epoch [1/5], Step [1240/30930], Loss: 0.0852\n",
      "Epoch [1/5], Step [1250/30930], Loss: 0.1055\n",
      "Epoch [1/5], Step [1260/30930], Loss: 0.0191\n",
      "Epoch [1/5], Step [1270/30930], Loss: 0.1356\n",
      "Epoch [1/5], Step [1280/30930], Loss: 0.0545\n",
      "Epoch [1/5], Step [1290/30930], Loss: 0.0186\n",
      "Epoch [1/5], Step [1300/30930], Loss: 0.0334\n",
      "Epoch [1/5], Step [1310/30930], Loss: 0.0708\n",
      "Epoch [1/5], Step [1320/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [1330/30930], Loss: 0.0760\n",
      "Epoch [1/5], Step [1340/30930], Loss: 0.2595\n",
      "Epoch [1/5], Step [1350/30930], Loss: 0.0288\n",
      "Epoch [1/5], Step [1360/30930], Loss: 0.0507\n",
      "Epoch [1/5], Step [1370/30930], Loss: 0.0198\n",
      "Epoch [1/5], Step [1380/30930], Loss: 0.0155\n",
      "Epoch [1/5], Step [1390/30930], Loss: 0.0463\n",
      "Epoch [1/5], Step [1400/30930], Loss: 0.0481\n",
      "Epoch [1/5], Step [1410/30930], Loss: 0.0367\n",
      "Epoch [1/5], Step [1420/30930], Loss: 0.0228\n",
      "Epoch [1/5], Step [1430/30930], Loss: 0.0332\n",
      "Epoch [1/5], Step [1440/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [1450/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [1460/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [1470/30930], Loss: 0.1383\n",
      "Epoch [1/5], Step [1480/30930], Loss: 0.0523\n",
      "Epoch [1/5], Step [1490/30930], Loss: 0.0252\n",
      "Epoch [1/5], Step [1500/30930], Loss: 0.0403\n",
      "Epoch [1/5], Step [1510/30930], Loss: 0.0330\n",
      "Epoch [1/5], Step [1520/30930], Loss: 0.0454\n",
      "Epoch [1/5], Step [1530/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [1540/30930], Loss: 0.0797\n",
      "Epoch [1/5], Step [1550/30930], Loss: 0.0195\n",
      "Epoch [1/5], Step [1560/30930], Loss: 0.0710\n",
      "Epoch [1/5], Step [1570/30930], Loss: 0.0141\n",
      "Epoch [1/5], Step [1580/30930], Loss: 0.0244\n",
      "Epoch [1/5], Step [1590/30930], Loss: 0.0152\n",
      "Epoch [1/5], Step [1600/30930], Loss: 0.1569\n",
      "Epoch [1/5], Step [1610/30930], Loss: 0.1088\n",
      "Epoch [1/5], Step [1620/30930], Loss: 0.0201\n",
      "Epoch [1/5], Step [1630/30930], Loss: 0.0411\n",
      "Epoch [1/5], Step [1640/30930], Loss: 0.0251\n",
      "Epoch [1/5], Step [1650/30930], Loss: 0.0606\n",
      "Epoch [1/5], Step [1660/30930], Loss: 0.0691\n",
      "Epoch [1/5], Step [1670/30930], Loss: 0.0460\n",
      "Epoch [1/5], Step [1680/30930], Loss: 0.0756\n",
      "Epoch [1/5], Step [1690/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [1700/30930], Loss: 0.0694\n",
      "Epoch [1/5], Step [1710/30930], Loss: 0.0177\n",
      "Epoch [1/5], Step [1720/30930], Loss: 0.0927\n",
      "Epoch [1/5], Step [1730/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [1740/30930], Loss: 0.0387\n",
      "Epoch [1/5], Step [1750/30930], Loss: 0.0250\n",
      "Epoch [1/5], Step [1760/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [1770/30930], Loss: 0.0549\n",
      "Epoch [1/5], Step [1780/30930], Loss: 0.0157\n",
      "Epoch [1/5], Step [1790/30930], Loss: 0.0112\n",
      "Epoch [1/5], Step [1800/30930], Loss: 0.0809\n",
      "Epoch [1/5], Step [1810/30930], Loss: 0.0375\n",
      "Epoch [1/5], Step [1820/30930], Loss: 0.0800\n",
      "Epoch [1/5], Step [1830/30930], Loss: 0.1322\n",
      "Epoch [1/5], Step [1840/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [1850/30930], Loss: 0.0596\n",
      "Epoch [1/5], Step [1860/30930], Loss: 0.0312\n",
      "Epoch [1/5], Step [1870/30930], Loss: 0.0242\n",
      "Epoch [1/5], Step [1880/30930], Loss: 0.1270\n",
      "Epoch [1/5], Step [1890/30930], Loss: 0.0509\n",
      "Epoch [1/5], Step [1900/30930], Loss: 0.0918\n",
      "Epoch [1/5], Step [1910/30930], Loss: 0.0139\n",
      "Epoch [1/5], Step [1920/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [1930/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [1940/30930], Loss: 0.1021\n",
      "Epoch [1/5], Step [1950/30930], Loss: 0.0357\n",
      "Epoch [1/5], Step [1960/30930], Loss: 0.0988\n",
      "Epoch [1/5], Step [1970/30930], Loss: 0.0267\n",
      "Epoch [1/5], Step [1980/30930], Loss: 0.0145\n",
      "Epoch [1/5], Step [1990/30930], Loss: 0.0515\n",
      "Epoch [1/5], Step [2000/30930], Loss: 0.1211\n",
      "Epoch [1/5], Step [2010/30930], Loss: 0.0213\n",
      "Epoch [1/5], Step [2020/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [2030/30930], Loss: 0.0213\n",
      "Epoch [1/5], Step [2040/30930], Loss: 0.0234\n",
      "Epoch [1/5], Step [2050/30930], Loss: 0.0824\n",
      "Epoch [1/5], Step [2060/30930], Loss: 0.0588\n",
      "Epoch [1/5], Step [2070/30930], Loss: 0.0551\n",
      "Epoch [1/5], Step [2080/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [2090/30930], Loss: 0.0491\n",
      "Epoch [1/5], Step [2100/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [2110/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [2120/30930], Loss: 0.0118\n",
      "Epoch [1/5], Step [2130/30930], Loss: 0.0405\n",
      "Epoch [1/5], Step [2140/30930], Loss: 0.0813\n",
      "Epoch [1/5], Step [2150/30930], Loss: 0.0638\n",
      "Epoch [1/5], Step [2160/30930], Loss: 0.1327\n",
      "Epoch [1/5], Step [2170/30930], Loss: 0.0245\n",
      "Epoch [1/5], Step [2180/30930], Loss: 0.0162\n",
      "Epoch [1/5], Step [2190/30930], Loss: 0.0706\n",
      "Epoch [1/5], Step [2200/30930], Loss: 0.1189\n",
      "Epoch [1/5], Step [2210/30930], Loss: 0.0332\n",
      "Epoch [1/5], Step [2220/30930], Loss: 0.0267\n",
      "Epoch [1/5], Step [2230/30930], Loss: 0.0370\n",
      "Epoch [1/5], Step [2240/30930], Loss: 0.0406\n",
      "Epoch [1/5], Step [2250/30930], Loss: 0.1883\n",
      "Epoch [1/5], Step [2260/30930], Loss: 0.0468\n",
      "Epoch [1/5], Step [2270/30930], Loss: 0.0813\n",
      "Epoch [1/5], Step [2280/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [2290/30930], Loss: 0.0361\n",
      "Epoch [1/5], Step [2300/30930], Loss: 0.0581\n",
      "Epoch [1/5], Step [2310/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [2320/30930], Loss: 0.0650\n",
      "Epoch [1/5], Step [2330/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [2340/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [2350/30930], Loss: 0.0345\n",
      "Epoch [1/5], Step [2360/30930], Loss: 0.0916\n",
      "Epoch [1/5], Step [2370/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [2380/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [2390/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [2400/30930], Loss: 0.0333\n",
      "Epoch [1/5], Step [2410/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [2420/30930], Loss: 0.0193\n",
      "Epoch [1/5], Step [2430/30930], Loss: 0.0122\n",
      "Epoch [1/5], Step [2440/30930], Loss: 0.0162\n",
      "Epoch [1/5], Step [2450/30930], Loss: 0.0438\n",
      "Epoch [1/5], Step [2460/30930], Loss: 0.1287\n",
      "Epoch [1/5], Step [2470/30930], Loss: 0.0425\n",
      "Epoch [1/5], Step [2480/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [2490/30930], Loss: 0.0475\n",
      "Epoch [1/5], Step [2500/30930], Loss: 0.0604\n",
      "Epoch [1/5], Step [2510/30930], Loss: 0.0173\n",
      "Epoch [1/5], Step [2520/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [2530/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [2540/30930], Loss: 0.0390\n",
      "Epoch [1/5], Step [2550/30930], Loss: 0.0151\n",
      "Epoch [1/5], Step [2560/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [2570/30930], Loss: 0.0391\n",
      "Epoch [1/5], Step [2580/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [2590/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [2600/30930], Loss: 0.0727\n",
      "Epoch [1/5], Step [2610/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [2620/30930], Loss: 0.1454\n",
      "Epoch [1/5], Step [2630/30930], Loss: 0.0777\n",
      "Epoch [1/5], Step [2640/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [2650/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [2660/30930], Loss: 0.1031\n",
      "Epoch [1/5], Step [2670/30930], Loss: 0.0280\n",
      "Epoch [1/5], Step [2680/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [2690/30930], Loss: 0.0252\n",
      "Epoch [1/5], Step [2700/30930], Loss: 0.1577\n",
      "Epoch [1/5], Step [2710/30930], Loss: 0.0113\n",
      "Epoch [1/5], Step [2720/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [2730/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [2740/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [2750/30930], Loss: 0.0573\n",
      "Epoch [1/5], Step [2760/30930], Loss: 0.0614\n",
      "Epoch [1/5], Step [2770/30930], Loss: 0.0692\n",
      "Epoch [1/5], Step [2780/30930], Loss: 0.0126\n",
      "Epoch [1/5], Step [2790/30930], Loss: 0.0386\n",
      "Epoch [1/5], Step [2800/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [2810/30930], Loss: 0.0509\n",
      "Epoch [1/5], Step [2820/30930], Loss: 0.0259\n",
      "Epoch [1/5], Step [2830/30930], Loss: 0.1247\n",
      "Epoch [1/5], Step [2840/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [2850/30930], Loss: 0.0496\n",
      "Epoch [1/5], Step [2860/30930], Loss: 0.0198\n",
      "Epoch [1/5], Step [2870/30930], Loss: 0.0509\n",
      "Epoch [1/5], Step [2880/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [2890/30930], Loss: 0.0123\n",
      "Epoch [1/5], Step [2900/30930], Loss: 0.0654\n",
      "Epoch [1/5], Step [2910/30930], Loss: 0.0171\n",
      "Epoch [1/5], Step [2920/30930], Loss: 0.0173\n",
      "Epoch [1/5], Step [2930/30930], Loss: 0.0156\n",
      "Epoch [1/5], Step [2940/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [2950/30930], Loss: 0.0693\n",
      "Epoch [1/5], Step [2960/30930], Loss: 0.0705\n",
      "Epoch [1/5], Step [2970/30930], Loss: 0.0282\n",
      "Epoch [1/5], Step [2980/30930], Loss: 0.0280\n",
      "Epoch [1/5], Step [2990/30930], Loss: 0.0314\n",
      "Epoch [1/5], Step [3000/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [3010/30930], Loss: 0.0315\n",
      "Epoch [1/5], Step [3020/30930], Loss: 0.0359\n",
      "Epoch [1/5], Step [3030/30930], Loss: 0.0080\n",
      "Epoch [1/5], Step [3040/30930], Loss: 0.0278\n",
      "Epoch [1/5], Step [3050/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [3060/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [3070/30930], Loss: 0.0709\n",
      "Epoch [1/5], Step [3080/30930], Loss: 0.1535\n",
      "Epoch [1/5], Step [3090/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [3100/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [3110/30930], Loss: 0.0151\n",
      "Epoch [1/5], Step [3120/30930], Loss: 0.0143\n",
      "Epoch [1/5], Step [3130/30930], Loss: 0.0541\n",
      "Epoch [1/5], Step [3140/30930], Loss: 0.0110\n",
      "Epoch [1/5], Step [3150/30930], Loss: 0.1596\n",
      "Epoch [1/5], Step [3160/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [3170/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [3180/30930], Loss: 0.0180\n",
      "Epoch [1/5], Step [3190/30930], Loss: 0.0543\n",
      "Epoch [1/5], Step [3200/30930], Loss: 0.0801\n",
      "Epoch [1/5], Step [3210/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [3220/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [3230/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [3240/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [3250/30930], Loss: 0.0159\n",
      "Epoch [1/5], Step [3260/30930], Loss: 0.0228\n",
      "Epoch [1/5], Step [3270/30930], Loss: 0.0546\n",
      "Epoch [1/5], Step [3280/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [3290/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [3300/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [3310/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [3320/30930], Loss: 0.1009\n",
      "Epoch [1/5], Step [3330/30930], Loss: 0.0383\n",
      "Epoch [1/5], Step [3340/30930], Loss: 0.0648\n",
      "Epoch [1/5], Step [3350/30930], Loss: 0.0493\n",
      "Epoch [1/5], Step [3360/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [3370/30930], Loss: 0.0862\n",
      "Epoch [1/5], Step [3380/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [3390/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [3400/30930], Loss: 0.0413\n",
      "Epoch [1/5], Step [3410/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [3420/30930], Loss: 0.0937\n",
      "Epoch [1/5], Step [3430/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [3440/30930], Loss: 0.0091\n",
      "Epoch [1/5], Step [3450/30930], Loss: 0.0266\n",
      "Epoch [1/5], Step [3460/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [3470/30930], Loss: 0.0364\n",
      "Epoch [1/5], Step [3480/30930], Loss: 0.1521\n",
      "Epoch [1/5], Step [3490/30930], Loss: 0.0147\n",
      "Epoch [1/5], Step [3500/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [3510/30930], Loss: 0.0228\n",
      "Epoch [1/5], Step [3520/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [3530/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [3540/30930], Loss: 0.0271\n",
      "Epoch [1/5], Step [3550/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [3560/30930], Loss: 0.0653\n",
      "Epoch [1/5], Step [3570/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [3580/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [3590/30930], Loss: 0.0388\n",
      "Epoch [1/5], Step [3600/30930], Loss: 0.0932\n",
      "Epoch [1/5], Step [3610/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [3620/30930], Loss: 0.0827\n",
      "Epoch [1/5], Step [3630/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [3640/30930], Loss: 0.0399\n",
      "Epoch [1/5], Step [3650/30930], Loss: 0.0225\n",
      "Epoch [1/5], Step [3660/30930], Loss: 0.0480\n",
      "Epoch [1/5], Step [3670/30930], Loss: 0.0130\n",
      "Epoch [1/5], Step [3680/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [3690/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [3700/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [3710/30930], Loss: 0.0377\n",
      "Epoch [1/5], Step [3720/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [3730/30930], Loss: 0.0156\n",
      "Epoch [1/5], Step [3740/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [3750/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [3760/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [3770/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [3780/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [3790/30930], Loss: 0.0845\n",
      "Epoch [1/5], Step [3800/30930], Loss: 0.0433\n",
      "Epoch [1/5], Step [3810/30930], Loss: 0.0428\n",
      "Epoch [1/5], Step [3820/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [3830/30930], Loss: 0.0395\n",
      "Epoch [1/5], Step [3840/30930], Loss: 0.0169\n",
      "Epoch [1/5], Step [3850/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [3860/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [3870/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [3880/30930], Loss: 0.0113\n",
      "Epoch [1/5], Step [3890/30930], Loss: 0.1239\n",
      "Epoch [1/5], Step [3900/30930], Loss: 0.0158\n",
      "Epoch [1/5], Step [3910/30930], Loss: 0.1140\n",
      "Epoch [1/5], Step [3920/30930], Loss: 0.0511\n",
      "Epoch [1/5], Step [3930/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [3940/30930], Loss: 0.0524\n",
      "Epoch [1/5], Step [3950/30930], Loss: 0.3440\n",
      "Epoch [1/5], Step [3960/30930], Loss: 0.0303\n",
      "Epoch [1/5], Step [3970/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [3980/30930], Loss: 0.0206\n",
      "Epoch [1/5], Step [3990/30930], Loss: 0.0245\n",
      "Epoch [1/5], Step [4000/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [4010/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [4020/30930], Loss: 0.0552\n",
      "Epoch [1/5], Step [4030/30930], Loss: 0.0128\n",
      "Epoch [1/5], Step [4040/30930], Loss: 0.0722\n",
      "Epoch [1/5], Step [4050/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [4060/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [4070/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [4080/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [4090/30930], Loss: 0.1441\n",
      "Epoch [1/5], Step [4100/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [4110/30930], Loss: 0.0349\n",
      "Epoch [1/5], Step [4120/30930], Loss: 0.0132\n",
      "Epoch [1/5], Step [4130/30930], Loss: 0.0198\n",
      "Epoch [1/5], Step [4140/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [4150/30930], Loss: 0.0302\n",
      "Epoch [1/5], Step [4160/30930], Loss: 0.0082\n",
      "Epoch [1/5], Step [4170/30930], Loss: 0.0411\n",
      "Epoch [1/5], Step [4180/30930], Loss: 0.0288\n",
      "Epoch [1/5], Step [4190/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [4200/30930], Loss: 0.0626\n",
      "Epoch [1/5], Step [4210/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [4220/30930], Loss: 0.0501\n",
      "Epoch [1/5], Step [4230/30930], Loss: 0.0462\n",
      "Epoch [1/5], Step [4240/30930], Loss: 0.0148\n",
      "Epoch [1/5], Step [4250/30930], Loss: 0.0725\n",
      "Epoch [1/5], Step [4260/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [4270/30930], Loss: 0.0866\n",
      "Epoch [1/5], Step [4280/30930], Loss: 0.0185\n",
      "Epoch [1/5], Step [4290/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [4300/30930], Loss: 0.0328\n",
      "Epoch [1/5], Step [4310/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [4320/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [4330/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [4340/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [4350/30930], Loss: 0.0787\n",
      "Epoch [1/5], Step [4360/30930], Loss: 0.0636\n",
      "Epoch [1/5], Step [4370/30930], Loss: 0.0421\n",
      "Epoch [1/5], Step [4380/30930], Loss: 0.0093\n",
      "Epoch [1/5], Step [4390/30930], Loss: 0.0684\n",
      "Epoch [1/5], Step [4400/30930], Loss: 0.0518\n",
      "Epoch [1/5], Step [4410/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [4420/30930], Loss: 0.0646\n",
      "Epoch [1/5], Step [4430/30930], Loss: 0.0368\n",
      "Epoch [1/5], Step [4440/30930], Loss: 0.0125\n",
      "Epoch [1/5], Step [4450/30930], Loss: 0.0553\n",
      "Epoch [1/5], Step [4460/30930], Loss: 0.0444\n",
      "Epoch [1/5], Step [4470/30930], Loss: 0.2207\n",
      "Epoch [1/5], Step [4480/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [4490/30930], Loss: 0.0563\n",
      "Epoch [1/5], Step [4500/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [4510/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [4520/30930], Loss: 0.0132\n",
      "Epoch [1/5], Step [4530/30930], Loss: 0.0099\n",
      "Epoch [1/5], Step [4540/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [4550/30930], Loss: 0.0376\n",
      "Epoch [1/5], Step [4560/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [4570/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [4580/30930], Loss: 0.0651\n",
      "Epoch [1/5], Step [4590/30930], Loss: 0.0517\n",
      "Epoch [1/5], Step [4600/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [4610/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [4620/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [4630/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [4640/30930], Loss: 0.0430\n",
      "Epoch [1/5], Step [4650/30930], Loss: 0.0733\n",
      "Epoch [1/5], Step [4660/30930], Loss: 0.0230\n",
      "Epoch [1/5], Step [4670/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [4680/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [4690/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [4700/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [4710/30930], Loss: 0.0825\n",
      "Epoch [1/5], Step [4720/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [4730/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [4740/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [4750/30930], Loss: 0.0207\n",
      "Epoch [1/5], Step [4760/30930], Loss: 0.0263\n",
      "Epoch [1/5], Step [4770/30930], Loss: 0.0489\n",
      "Epoch [1/5], Step [4780/30930], Loss: 0.0338\n",
      "Epoch [1/5], Step [4790/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [4800/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [4810/30930], Loss: 0.0269\n",
      "Epoch [1/5], Step [4820/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [4830/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [4840/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [4850/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [4860/30930], Loss: 0.0590\n",
      "Epoch [1/5], Step [4870/30930], Loss: 0.0344\n",
      "Epoch [1/5], Step [4880/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [4890/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [4900/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [4910/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [4920/30930], Loss: 0.0400\n",
      "Epoch [1/5], Step [4930/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [4940/30930], Loss: 0.0972\n",
      "Epoch [1/5], Step [4950/30930], Loss: 0.0280\n",
      "Epoch [1/5], Step [4960/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [4970/30930], Loss: 0.0723\n",
      "Epoch [1/5], Step [4980/30930], Loss: 0.0290\n",
      "Epoch [1/5], Step [4990/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [5000/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [5010/30930], Loss: 0.0604\n",
      "Epoch [1/5], Step [5020/30930], Loss: 0.0510\n",
      "Epoch [1/5], Step [5030/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [5040/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [5050/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [5060/30930], Loss: 0.0447\n",
      "Epoch [1/5], Step [5070/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [5080/30930], Loss: 0.0740\n",
      "Epoch [1/5], Step [5090/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [5100/30930], Loss: 0.0172\n",
      "Epoch [1/5], Step [5110/30930], Loss: 0.0534\n",
      "Epoch [1/5], Step [5120/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [5130/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [5140/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [5150/30930], Loss: 0.0195\n",
      "Epoch [1/5], Step [5160/30930], Loss: 0.0711\n",
      "Epoch [1/5], Step [5170/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [5180/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [5190/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [5200/30930], Loss: 0.0457\n",
      "Epoch [1/5], Step [5210/30930], Loss: 0.0845\n",
      "Epoch [1/5], Step [5220/30930], Loss: 0.0413\n",
      "Epoch [1/5], Step [5230/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [5240/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [5250/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [5260/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [5270/30930], Loss: 0.0451\n",
      "Epoch [1/5], Step [5280/30930], Loss: 0.0317\n",
      "Epoch [1/5], Step [5290/30930], Loss: 0.0146\n",
      "Epoch [1/5], Step [5300/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [5310/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [5320/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [5330/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [5340/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [5350/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [5360/30930], Loss: 0.0813\n",
      "Epoch [1/5], Step [5370/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [5380/30930], Loss: 0.0178\n",
      "Epoch [1/5], Step [5390/30930], Loss: 0.0213\n",
      "Epoch [1/5], Step [5400/30930], Loss: 0.0839\n",
      "Epoch [1/5], Step [5410/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [5420/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [5430/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [5440/30930], Loss: 0.0518\n",
      "Epoch [1/5], Step [5450/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [5460/30930], Loss: 0.0747\n",
      "Epoch [1/5], Step [5470/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [5480/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [5490/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [5500/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [5510/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [5520/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [5530/30930], Loss: 0.0829\n",
      "Epoch [1/5], Step [5540/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [5550/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [5560/30930], Loss: 0.0193\n",
      "Epoch [1/5], Step [5570/30930], Loss: 0.0917\n",
      "Epoch [1/5], Step [5580/30930], Loss: 0.0195\n",
      "Epoch [1/5], Step [5590/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [5600/30930], Loss: 0.0415\n",
      "Epoch [1/5], Step [5610/30930], Loss: 0.0236\n",
      "Epoch [1/5], Step [5620/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [5630/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [5640/30930], Loss: 0.0918\n",
      "Epoch [1/5], Step [5650/30930], Loss: 0.0240\n",
      "Epoch [1/5], Step [5660/30930], Loss: 0.0377\n",
      "Epoch [1/5], Step [5670/30930], Loss: 0.0290\n",
      "Epoch [1/5], Step [5680/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [5690/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [5700/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [5710/30930], Loss: 0.0404\n",
      "Epoch [1/5], Step [5720/30930], Loss: 0.0264\n",
      "Epoch [1/5], Step [5730/30930], Loss: 0.0148\n",
      "Epoch [1/5], Step [5740/30930], Loss: 0.0188\n",
      "Epoch [1/5], Step [5750/30930], Loss: 0.0463\n",
      "Epoch [1/5], Step [5760/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [5770/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [5780/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [5790/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [5800/30930], Loss: 0.0334\n",
      "Epoch [1/5], Step [5810/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [5820/30930], Loss: 0.0184\n",
      "Epoch [1/5], Step [5830/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [5840/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [5850/30930], Loss: 0.0232\n",
      "Epoch [1/5], Step [5860/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [5870/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [5880/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [5890/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [5900/30930], Loss: 0.0534\n",
      "Epoch [1/5], Step [5910/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [5920/30930], Loss: 0.0613\n",
      "Epoch [1/5], Step [5930/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [5940/30930], Loss: 0.0230\n",
      "Epoch [1/5], Step [5950/30930], Loss: 0.0267\n",
      "Epoch [1/5], Step [5960/30930], Loss: 0.0332\n",
      "Epoch [1/5], Step [5970/30930], Loss: 0.0150\n",
      "Epoch [1/5], Step [5980/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [5990/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [6000/30930], Loss: 0.1159\n",
      "Epoch [1/5], Step [6010/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [6020/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [6030/30930], Loss: 0.0156\n",
      "Epoch [1/5], Step [6040/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [6050/30930], Loss: 0.0456\n",
      "Epoch [1/5], Step [6060/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [6070/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [6080/30930], Loss: 0.0113\n",
      "Epoch [1/5], Step [6090/30930], Loss: 0.0325\n",
      "Epoch [1/5], Step [6100/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [6110/30930], Loss: 0.0418\n",
      "Epoch [1/5], Step [6120/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [6130/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [6140/30930], Loss: 0.0367\n",
      "Epoch [1/5], Step [6150/30930], Loss: 0.0470\n",
      "Epoch [1/5], Step [6160/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [6170/30930], Loss: 0.0437\n",
      "Epoch [1/5], Step [6180/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [6190/30930], Loss: 0.0620\n",
      "Epoch [1/5], Step [6200/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [6210/30930], Loss: 0.0184\n",
      "Epoch [1/5], Step [6220/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [6230/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [6240/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [6250/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [6260/30930], Loss: 0.0594\n",
      "Epoch [1/5], Step [6270/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [6280/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [6290/30930], Loss: 0.0344\n",
      "Epoch [1/5], Step [6300/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [6310/30930], Loss: 0.0208\n",
      "Epoch [1/5], Step [6320/30930], Loss: 0.0226\n",
      "Epoch [1/5], Step [6330/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [6340/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [6350/30930], Loss: 0.0231\n",
      "Epoch [1/5], Step [6360/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [6370/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [6380/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [6390/30930], Loss: 0.0456\n",
      "Epoch [1/5], Step [6400/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [6410/30930], Loss: 0.0599\n",
      "Epoch [1/5], Step [6420/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [6430/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [6440/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [6450/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [6460/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [6470/30930], Loss: 0.0146\n",
      "Epoch [1/5], Step [6480/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [6490/30930], Loss: 0.0254\n",
      "Epoch [1/5], Step [6500/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [6510/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [6520/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [6530/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [6540/30930], Loss: 0.0413\n",
      "Epoch [1/5], Step [6550/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [6560/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [6570/30930], Loss: 0.0405\n",
      "Epoch [1/5], Step [6580/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [6590/30930], Loss: 0.0137\n",
      "Epoch [1/5], Step [6600/30930], Loss: 0.0189\n",
      "Epoch [1/5], Step [6610/30930], Loss: 0.0440\n",
      "Epoch [1/5], Step [6620/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [6630/30930], Loss: 0.0512\n",
      "Epoch [1/5], Step [6640/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [6650/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [6660/30930], Loss: 0.0351\n",
      "Epoch [1/5], Step [6670/30930], Loss: 0.0260\n",
      "Epoch [1/5], Step [6680/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [6690/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [6700/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [6710/30930], Loss: 0.1074\n",
      "Epoch [1/5], Step [6720/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [6730/30930], Loss: 0.0134\n",
      "Epoch [1/5], Step [6740/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [6750/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [6760/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [6770/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [6780/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [6790/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [6800/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [6810/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [6820/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [6830/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [6840/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [6850/30930], Loss: 0.0125\n",
      "Epoch [1/5], Step [6860/30930], Loss: 0.0751\n",
      "Epoch [1/5], Step [6870/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [6880/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [6890/30930], Loss: 0.0336\n",
      "Epoch [1/5], Step [6900/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [6910/30930], Loss: 0.1026\n",
      "Epoch [1/5], Step [6920/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [6930/30930], Loss: 0.0154\n",
      "Epoch [1/5], Step [6940/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [6950/30930], Loss: 0.1359\n",
      "Epoch [1/5], Step [6960/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [6970/30930], Loss: 0.0367\n",
      "Epoch [1/5], Step [6980/30930], Loss: 0.0408\n",
      "Epoch [1/5], Step [6990/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [7000/30930], Loss: 0.0328\n",
      "Epoch [1/5], Step [7010/30930], Loss: 0.0226\n",
      "Epoch [1/5], Step [7020/30930], Loss: 0.0208\n",
      "Epoch [1/5], Step [7030/30930], Loss: 0.0205\n",
      "Epoch [1/5], Step [7040/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [7050/30930], Loss: 0.0149\n",
      "Epoch [1/5], Step [7060/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [7070/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [7080/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [7090/30930], Loss: 0.0396\n",
      "Epoch [1/5], Step [7100/30930], Loss: 0.0406\n",
      "Epoch [1/5], Step [7110/30930], Loss: 0.0355\n",
      "Epoch [1/5], Step [7120/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [7130/30930], Loss: 0.0716\n",
      "Epoch [1/5], Step [7140/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [7150/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [7160/30930], Loss: 0.0172\n",
      "Epoch [1/5], Step [7170/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [7180/30930], Loss: 0.0482\n",
      "Epoch [1/5], Step [7190/30930], Loss: 0.0165\n",
      "Epoch [1/5], Step [7200/30930], Loss: 0.1575\n",
      "Epoch [1/5], Step [7210/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [7220/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [7230/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [7240/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [7250/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [7260/30930], Loss: 0.0083\n",
      "Epoch [1/5], Step [7270/30930], Loss: 0.0333\n",
      "Epoch [1/5], Step [7280/30930], Loss: 0.0093\n",
      "Epoch [1/5], Step [7290/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [7300/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [7310/30930], Loss: 0.0181\n",
      "Epoch [1/5], Step [7320/30930], Loss: 0.0311\n",
      "Epoch [1/5], Step [7330/30930], Loss: 0.0768\n",
      "Epoch [1/5], Step [7340/30930], Loss: 0.0364\n",
      "Epoch [1/5], Step [7350/30930], Loss: 0.0130\n",
      "Epoch [1/5], Step [7360/30930], Loss: 0.0107\n",
      "Epoch [1/5], Step [7370/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [7380/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [7390/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [7400/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [7410/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [7420/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [7430/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [7440/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [7450/30930], Loss: 0.0118\n",
      "Epoch [1/5], Step [7460/30930], Loss: 0.0475\n",
      "Epoch [1/5], Step [7470/30930], Loss: 0.0846\n",
      "Epoch [1/5], Step [7480/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [7490/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [7500/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [7510/30930], Loss: 0.0133\n",
      "Epoch [1/5], Step [7520/30930], Loss: 0.0401\n",
      "Epoch [1/5], Step [7530/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [7540/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [7550/30930], Loss: 0.1705\n",
      "Epoch [1/5], Step [7560/30930], Loss: 0.1663\n",
      "Epoch [1/5], Step [7570/30930], Loss: 0.0134\n",
      "Epoch [1/5], Step [7580/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [7590/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [7600/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [7610/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [7620/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [7630/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [7640/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [7650/30930], Loss: 0.0711\n",
      "Epoch [1/5], Step [7660/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [7670/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [7680/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [7690/30930], Loss: 0.0344\n",
      "Epoch [1/5], Step [7700/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [7710/30930], Loss: 0.0428\n",
      "Epoch [1/5], Step [7720/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [7730/30930], Loss: 0.0296\n",
      "Epoch [1/5], Step [7740/30930], Loss: 0.0390\n",
      "Epoch [1/5], Step [7750/30930], Loss: 0.0177\n",
      "Epoch [1/5], Step [7760/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [7770/30930], Loss: 0.0318\n",
      "Epoch [1/5], Step [7780/30930], Loss: 0.0173\n",
      "Epoch [1/5], Step [7790/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [7800/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [7810/30930], Loss: 0.0175\n",
      "Epoch [1/5], Step [7820/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [7830/30930], Loss: 0.0377\n",
      "Epoch [1/5], Step [7840/30930], Loss: 0.0260\n",
      "Epoch [1/5], Step [7850/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [7860/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [7870/30930], Loss: 0.0272\n",
      "Epoch [1/5], Step [7880/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [7890/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [7900/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [7910/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [7920/30930], Loss: 0.0886\n",
      "Epoch [1/5], Step [7930/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [7940/30930], Loss: 0.0386\n",
      "Epoch [1/5], Step [7950/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [7960/30930], Loss: 0.0443\n",
      "Epoch [1/5], Step [7970/30930], Loss: 0.0191\n",
      "Epoch [1/5], Step [7980/30930], Loss: 0.1366\n",
      "Epoch [1/5], Step [7990/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [8000/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [8010/30930], Loss: 0.0132\n",
      "Epoch [1/5], Step [8020/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [8030/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [8040/30930], Loss: 0.1111\n",
      "Epoch [1/5], Step [8050/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [8060/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [8070/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [8080/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [8090/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [8100/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [8110/30930], Loss: 0.0966\n",
      "Epoch [1/5], Step [8120/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [8130/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [8140/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [8150/30930], Loss: 0.0523\n",
      "Epoch [1/5], Step [8160/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [8170/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [8180/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [8190/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [8200/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [8210/30930], Loss: 0.0113\n",
      "Epoch [1/5], Step [8220/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [8230/30930], Loss: 0.1212\n",
      "Epoch [1/5], Step [8240/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [8250/30930], Loss: 0.0336\n",
      "Epoch [1/5], Step [8260/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [8270/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [8280/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [8290/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [8300/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [8310/30930], Loss: 0.0336\n",
      "Epoch [1/5], Step [8320/30930], Loss: 0.0231\n",
      "Epoch [1/5], Step [8330/30930], Loss: 0.0762\n",
      "Epoch [1/5], Step [8340/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [8350/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [8360/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [8370/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [8380/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [8390/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [8400/30930], Loss: 0.0544\n",
      "Epoch [1/5], Step [8410/30930], Loss: 0.0534\n",
      "Epoch [1/5], Step [8420/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [8430/30930], Loss: 0.0900\n",
      "Epoch [1/5], Step [8440/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [8450/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [8460/30930], Loss: 0.0214\n",
      "Epoch [1/5], Step [8470/30930], Loss: 0.0182\n",
      "Epoch [1/5], Step [8480/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [8490/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [8500/30930], Loss: 0.0313\n",
      "Epoch [1/5], Step [8510/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [8520/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [8530/30930], Loss: 0.0304\n",
      "Epoch [1/5], Step [8540/30930], Loss: 0.0080\n",
      "Epoch [1/5], Step [8550/30930], Loss: 0.2126\n",
      "Epoch [1/5], Step [8560/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [8570/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [8580/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [8590/30930], Loss: 0.0230\n",
      "Epoch [1/5], Step [8600/30930], Loss: 0.0457\n",
      "Epoch [1/5], Step [8610/30930], Loss: 0.0428\n",
      "Epoch [1/5], Step [8620/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [8630/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [8640/30930], Loss: 0.0093\n",
      "Epoch [1/5], Step [8650/30930], Loss: 0.1181\n",
      "Epoch [1/5], Step [8660/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [8670/30930], Loss: 0.0152\n",
      "Epoch [1/5], Step [8680/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [8690/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [8700/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [8710/30930], Loss: 0.0642\n",
      "Epoch [1/5], Step [8720/30930], Loss: 0.0171\n",
      "Epoch [1/5], Step [8730/30930], Loss: 0.0397\n",
      "Epoch [1/5], Step [8740/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [8750/30930], Loss: 0.0257\n",
      "Epoch [1/5], Step [8760/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [8770/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [8780/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [8790/30930], Loss: 0.0173\n",
      "Epoch [1/5], Step [8800/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [8810/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [8820/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [8830/30930], Loss: 0.0372\n",
      "Epoch [1/5], Step [8840/30930], Loss: 0.0114\n",
      "Epoch [1/5], Step [8850/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [8860/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [8870/30930], Loss: 0.0157\n",
      "Epoch [1/5], Step [8880/30930], Loss: 0.0521\n",
      "Epoch [1/5], Step [8890/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [8900/30930], Loss: 0.0091\n",
      "Epoch [1/5], Step [8910/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [8920/30930], Loss: 0.0460\n",
      "Epoch [1/5], Step [8930/30930], Loss: 0.0631\n",
      "Epoch [1/5], Step [8940/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [8950/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [8960/30930], Loss: 0.0279\n",
      "Epoch [1/5], Step [8970/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [8980/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [8990/30930], Loss: 0.0304\n",
      "Epoch [1/5], Step [9000/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [9010/30930], Loss: 0.0371\n",
      "Epoch [1/5], Step [9020/30930], Loss: 0.0148\n",
      "Epoch [1/5], Step [9030/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [9040/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [9050/30930], Loss: 0.0510\n",
      "Epoch [1/5], Step [9060/30930], Loss: 0.0203\n",
      "Epoch [1/5], Step [9070/30930], Loss: 0.0197\n",
      "Epoch [1/5], Step [9080/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [9090/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [9100/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [9110/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [9120/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [9130/30930], Loss: 0.0544\n",
      "Epoch [1/5], Step [9140/30930], Loss: 0.0152\n",
      "Epoch [1/5], Step [9150/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [9160/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [9170/30930], Loss: 0.0676\n",
      "Epoch [1/5], Step [9180/30930], Loss: 0.0592\n",
      "Epoch [1/5], Step [9190/30930], Loss: 0.0360\n",
      "Epoch [1/5], Step [9200/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [9210/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [9220/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [9230/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [9240/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [9250/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [9260/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [9270/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [9280/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [9290/30930], Loss: 0.0099\n",
      "Epoch [1/5], Step [9300/30930], Loss: 0.0170\n",
      "Epoch [1/5], Step [9310/30930], Loss: 0.0571\n",
      "Epoch [1/5], Step [9320/30930], Loss: 0.1610\n",
      "Epoch [1/5], Step [9330/30930], Loss: 0.0114\n",
      "Epoch [1/5], Step [9340/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [9350/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [9360/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [9370/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [9380/30930], Loss: 0.0359\n",
      "Epoch [1/5], Step [9390/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [9400/30930], Loss: 0.0165\n",
      "Epoch [1/5], Step [9410/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [9420/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [9430/30930], Loss: 0.0213\n",
      "Epoch [1/5], Step [9440/30930], Loss: 0.1725\n",
      "Epoch [1/5], Step [9450/30930], Loss: 0.0294\n",
      "Epoch [1/5], Step [9460/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [9470/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [9480/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [9490/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [9500/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [9510/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [9520/30930], Loss: 0.0251\n",
      "Epoch [1/5], Step [9530/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [9540/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [9550/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [9560/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [9570/30930], Loss: 0.0209\n",
      "Epoch [1/5], Step [9580/30930], Loss: 0.0222\n",
      "Epoch [1/5], Step [9590/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [9600/30930], Loss: 0.0288\n",
      "Epoch [1/5], Step [9610/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [9620/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [9630/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [9640/30930], Loss: 0.0150\n",
      "Epoch [1/5], Step [9650/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [9660/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [9670/30930], Loss: 0.0182\n",
      "Epoch [1/5], Step [9680/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [9690/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [9700/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [9710/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [9720/30930], Loss: 0.0399\n",
      "Epoch [1/5], Step [9730/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [9740/30930], Loss: 0.0400\n",
      "Epoch [1/5], Step [9750/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [9760/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [9770/30930], Loss: 0.0151\n",
      "Epoch [1/5], Step [9780/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [9790/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [9800/30930], Loss: 0.0224\n",
      "Epoch [1/5], Step [9810/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [9820/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [9830/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [9840/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [9850/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [9860/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [9870/30930], Loss: 0.0222\n",
      "Epoch [1/5], Step [9880/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [9890/30930], Loss: 0.0247\n",
      "Epoch [1/5], Step [9900/30930], Loss: 0.0983\n",
      "Epoch [1/5], Step [9910/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [9920/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [9930/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [9940/30930], Loss: 0.0322\n",
      "Epoch [1/5], Step [9950/30930], Loss: 0.0254\n",
      "Epoch [1/5], Step [9960/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [9970/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [9980/30930], Loss: 0.0334\n",
      "Epoch [1/5], Step [9990/30930], Loss: 0.0133\n",
      "Epoch [1/5], Step [10000/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [10010/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [10020/30930], Loss: 0.1236\n",
      "Epoch [1/5], Step [10030/30930], Loss: 0.0355\n",
      "Epoch [1/5], Step [10040/30930], Loss: 0.0275\n",
      "Epoch [1/5], Step [10050/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [10060/30930], Loss: 0.0232\n",
      "Epoch [1/5], Step [10070/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [10080/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [10090/30930], Loss: 0.0648\n",
      "Epoch [1/5], Step [10100/30930], Loss: 0.0319\n",
      "Epoch [1/5], Step [10110/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [10120/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [10130/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [10140/30930], Loss: 0.0125\n",
      "Epoch [1/5], Step [10150/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [10160/30930], Loss: 0.0523\n",
      "Epoch [1/5], Step [10170/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [10180/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [10190/30930], Loss: 0.0156\n",
      "Epoch [1/5], Step [10200/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [10210/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [10220/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [10230/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [10240/30930], Loss: 0.0114\n",
      "Epoch [1/5], Step [10250/30930], Loss: 0.0583\n",
      "Epoch [1/5], Step [10260/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [10270/30930], Loss: 0.0578\n",
      "Epoch [1/5], Step [10280/30930], Loss: 0.0158\n",
      "Epoch [1/5], Step [10290/30930], Loss: 0.0175\n",
      "Epoch [1/5], Step [10300/30930], Loss: 0.0286\n",
      "Epoch [1/5], Step [10310/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [10320/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [10330/30930], Loss: 0.0152\n",
      "Epoch [1/5], Step [10340/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [10350/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [10360/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [10370/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [10380/30930], Loss: 0.0227\n",
      "Epoch [1/5], Step [10390/30930], Loss: 0.0406\n",
      "Epoch [1/5], Step [10400/30930], Loss: 0.0151\n",
      "Epoch [1/5], Step [10410/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [10420/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [10430/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [10440/30930], Loss: 0.0450\n",
      "Epoch [1/5], Step [10450/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [10460/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [10470/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [10480/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [10490/30930], Loss: 0.0644\n",
      "Epoch [1/5], Step [10500/30930], Loss: 0.0283\n",
      "Epoch [1/5], Step [10510/30930], Loss: 0.0189\n",
      "Epoch [1/5], Step [10520/30930], Loss: 0.0898\n",
      "Epoch [1/5], Step [10530/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [10540/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [10550/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [10560/30930], Loss: 0.0256\n",
      "Epoch [1/5], Step [10570/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [10580/30930], Loss: 0.0302\n",
      "Epoch [1/5], Step [10590/30930], Loss: 0.0324\n",
      "Epoch [1/5], Step [10600/30930], Loss: 0.0305\n",
      "Epoch [1/5], Step [10610/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [10620/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [10630/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [10640/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [10650/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [10660/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [10670/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [10680/30930], Loss: 0.1190\n",
      "Epoch [1/5], Step [10690/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [10700/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [10710/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [10720/30930], Loss: 0.0574\n",
      "Epoch [1/5], Step [10730/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [10740/30930], Loss: 0.0410\n",
      "Epoch [1/5], Step [10750/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [10760/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [10770/30930], Loss: 0.0346\n",
      "Epoch [1/5], Step [10780/30930], Loss: 0.1068\n",
      "Epoch [1/5], Step [10790/30930], Loss: 0.0733\n",
      "Epoch [1/5], Step [10800/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [10810/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [10820/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [10830/30930], Loss: 0.0833\n",
      "Epoch [1/5], Step [10840/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [10850/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [10860/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [10870/30930], Loss: 0.0195\n",
      "Epoch [1/5], Step [10880/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [10890/30930], Loss: 0.0222\n",
      "Epoch [1/5], Step [10900/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [10910/30930], Loss: 0.0297\n",
      "Epoch [1/5], Step [10920/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [10930/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [10940/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [10950/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [10960/30930], Loss: 0.0150\n",
      "Epoch [1/5], Step [10970/30930], Loss: 0.0876\n",
      "Epoch [1/5], Step [10980/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [10990/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [11000/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [11010/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [11020/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [11030/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [11040/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [11050/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [11060/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [11070/30930], Loss: 0.0318\n",
      "Epoch [1/5], Step [11080/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [11090/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [11100/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [11110/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [11120/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [11130/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [11140/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [11150/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [11160/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [11170/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [11180/30930], Loss: 0.0265\n",
      "Epoch [1/5], Step [11190/30930], Loss: 0.0847\n",
      "Epoch [1/5], Step [11200/30930], Loss: 0.0112\n",
      "Epoch [1/5], Step [11210/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [11220/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [11230/30930], Loss: 0.0178\n",
      "Epoch [1/5], Step [11240/30930], Loss: 0.0185\n",
      "Epoch [1/5], Step [11250/30930], Loss: 0.0113\n",
      "Epoch [1/5], Step [11260/30930], Loss: 0.0422\n",
      "Epoch [1/5], Step [11270/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [11280/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [11290/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [11300/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [11310/30930], Loss: 0.0144\n",
      "Epoch [1/5], Step [11320/30930], Loss: 0.0930\n",
      "Epoch [1/5], Step [11330/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [11340/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [11350/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [11360/30930], Loss: 0.0295\n",
      "Epoch [1/5], Step [11370/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [11380/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [11390/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [11400/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [11410/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [11420/30930], Loss: 0.0858\n",
      "Epoch [1/5], Step [11430/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [11440/30930], Loss: 0.0450\n",
      "Epoch [1/5], Step [11450/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [11460/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [11470/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [11480/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [11490/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [11500/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [11510/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [11520/30930], Loss: 0.0408\n",
      "Epoch [1/5], Step [11530/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [11540/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [11550/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [11560/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [11570/30930], Loss: 0.0143\n",
      "Epoch [1/5], Step [11580/30930], Loss: 0.0378\n",
      "Epoch [1/5], Step [11590/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [11600/30930], Loss: 0.0619\n",
      "Epoch [1/5], Step [11610/30930], Loss: 0.0338\n",
      "Epoch [1/5], Step [11620/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [11630/30930], Loss: 0.0394\n",
      "Epoch [1/5], Step [11640/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [11650/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [11660/30930], Loss: 0.0291\n",
      "Epoch [1/5], Step [11670/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [11680/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [11690/30930], Loss: 0.0107\n",
      "Epoch [1/5], Step [11700/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [11710/30930], Loss: 0.0191\n",
      "Epoch [1/5], Step [11720/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [11730/30930], Loss: 0.0262\n",
      "Epoch [1/5], Step [11740/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [11750/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [11760/30930], Loss: 0.0256\n",
      "Epoch [1/5], Step [11770/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [11780/30930], Loss: 0.0389\n",
      "Epoch [1/5], Step [11790/30930], Loss: 0.0252\n",
      "Epoch [1/5], Step [11800/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [11810/30930], Loss: 0.0099\n",
      "Epoch [1/5], Step [11820/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [11830/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [11840/30930], Loss: 0.0133\n",
      "Epoch [1/5], Step [11850/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [11860/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [11870/30930], Loss: 0.0129\n",
      "Epoch [1/5], Step [11880/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [11890/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [11900/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [11910/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [11920/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [11930/30930], Loss: 0.0439\n",
      "Epoch [1/5], Step [11940/30930], Loss: 0.0258\n",
      "Epoch [1/5], Step [11950/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [11960/30930], Loss: 0.0428\n",
      "Epoch [1/5], Step [11970/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [11980/30930], Loss: 0.0507\n",
      "Epoch [1/5], Step [11990/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [12000/30930], Loss: 0.0209\n",
      "Epoch [1/5], Step [12010/30930], Loss: 0.0128\n",
      "Epoch [1/5], Step [12020/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [12030/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [12040/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [12050/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [12060/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [12070/30930], Loss: 0.1143\n",
      "Epoch [1/5], Step [12080/30930], Loss: 0.0343\n",
      "Epoch [1/5], Step [12090/30930], Loss: 0.0555\n",
      "Epoch [1/5], Step [12100/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [12110/30930], Loss: 0.0363\n",
      "Epoch [1/5], Step [12120/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [12130/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [12140/30930], Loss: 0.0107\n",
      "Epoch [1/5], Step [12150/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [12160/30930], Loss: 0.0262\n",
      "Epoch [1/5], Step [12170/30930], Loss: 0.0180\n",
      "Epoch [1/5], Step [12180/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [12190/30930], Loss: 0.0266\n",
      "Epoch [1/5], Step [12200/30930], Loss: 0.0370\n",
      "Epoch [1/5], Step [12210/30930], Loss: 0.0273\n",
      "Epoch [1/5], Step [12220/30930], Loss: 0.0198\n",
      "Epoch [1/5], Step [12230/30930], Loss: 0.0161\n",
      "Epoch [1/5], Step [12240/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [12250/30930], Loss: 0.0264\n",
      "Epoch [1/5], Step [12260/30930], Loss: 0.0249\n",
      "Epoch [1/5], Step [12270/30930], Loss: 0.2155\n",
      "Epoch [1/5], Step [12280/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [12290/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [12300/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [12310/30930], Loss: 0.0110\n",
      "Epoch [1/5], Step [12320/30930], Loss: 0.4204\n",
      "Epoch [1/5], Step [12330/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [12340/30930], Loss: 0.0282\n",
      "Epoch [1/5], Step [12350/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [12360/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [12370/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [12380/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [12390/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [12400/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [12410/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [12420/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [12430/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [12440/30930], Loss: 0.2100\n",
      "Epoch [1/5], Step [12450/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [12460/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [12470/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [12480/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [12490/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [12500/30930], Loss: 0.0492\n",
      "Epoch [1/5], Step [12510/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [12520/30930], Loss: 0.0852\n",
      "Epoch [1/5], Step [12530/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [12540/30930], Loss: 0.0568\n",
      "Epoch [1/5], Step [12550/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [12560/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [12570/30930], Loss: 0.0370\n",
      "Epoch [1/5], Step [12580/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [12590/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [12600/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [12610/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [12620/30930], Loss: 0.0132\n",
      "Epoch [1/5], Step [12630/30930], Loss: 0.0533\n",
      "Epoch [1/5], Step [12640/30930], Loss: 0.0552\n",
      "Epoch [1/5], Step [12650/30930], Loss: 0.0214\n",
      "Epoch [1/5], Step [12660/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [12670/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [12680/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [12690/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [12700/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [12710/30930], Loss: 0.0304\n",
      "Epoch [1/5], Step [12720/30930], Loss: 0.0268\n",
      "Epoch [1/5], Step [12730/30930], Loss: 0.0418\n",
      "Epoch [1/5], Step [12740/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [12750/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [12760/30930], Loss: 0.0340\n",
      "Epoch [1/5], Step [12770/30930], Loss: 0.0253\n",
      "Epoch [1/5], Step [12780/30930], Loss: 0.0308\n",
      "Epoch [1/5], Step [12790/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [12800/30930], Loss: 0.0239\n",
      "Epoch [1/5], Step [12810/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [12820/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [12830/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [12840/30930], Loss: 0.0319\n",
      "Epoch [1/5], Step [12850/30930], Loss: 0.0465\n",
      "Epoch [1/5], Step [12860/30930], Loss: 0.0342\n",
      "Epoch [1/5], Step [12870/30930], Loss: 0.0441\n",
      "Epoch [1/5], Step [12880/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [12890/30930], Loss: 0.0191\n",
      "Epoch [1/5], Step [12900/30930], Loss: 0.0580\n",
      "Epoch [1/5], Step [12910/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [12920/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [12930/30930], Loss: 0.0177\n",
      "Epoch [1/5], Step [12940/30930], Loss: 0.0942\n",
      "Epoch [1/5], Step [12950/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [12960/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [12970/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [12980/30930], Loss: 0.0133\n",
      "Epoch [1/5], Step [12990/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [13000/30930], Loss: 0.0536\n",
      "Epoch [1/5], Step [13010/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [13020/30930], Loss: 0.0107\n",
      "Epoch [1/5], Step [13030/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [13040/30930], Loss: 0.0319\n",
      "Epoch [1/5], Step [13050/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [13060/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [13070/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [13080/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [13090/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [13100/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [13110/30930], Loss: 0.0157\n",
      "Epoch [1/5], Step [13120/30930], Loss: 0.0176\n",
      "Epoch [1/5], Step [13130/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [13140/30930], Loss: 0.0240\n",
      "Epoch [1/5], Step [13150/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [13160/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [13170/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [13180/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [13190/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [13200/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [13210/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [13220/30930], Loss: 0.0114\n",
      "Epoch [1/5], Step [13230/30930], Loss: 0.0141\n",
      "Epoch [1/5], Step [13240/30930], Loss: 0.0234\n",
      "Epoch [1/5], Step [13250/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [13260/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [13270/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [13280/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [13290/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [13300/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [13310/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [13320/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [13330/30930], Loss: 0.0352\n",
      "Epoch [1/5], Step [13340/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [13350/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [13360/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [13370/30930], Loss: 0.0245\n",
      "Epoch [1/5], Step [13380/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [13390/30930], Loss: 0.0485\n",
      "Epoch [1/5], Step [13400/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [13410/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [13420/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [13430/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [13440/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [13450/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [13460/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [13470/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [13480/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [13490/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [13500/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [13510/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [13520/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [13530/30930], Loss: 0.0190\n",
      "Epoch [1/5], Step [13540/30930], Loss: 0.0259\n",
      "Epoch [1/5], Step [13550/30930], Loss: 0.0094\n",
      "Epoch [1/5], Step [13560/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [13570/30930], Loss: 0.0216\n",
      "Epoch [1/5], Step [13580/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [13590/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [13600/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [13610/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [13620/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [13630/30930], Loss: 0.0335\n",
      "Epoch [1/5], Step [13640/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [13650/30930], Loss: 0.0250\n",
      "Epoch [1/5], Step [13660/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [13670/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [13680/30930], Loss: 0.0188\n",
      "Epoch [1/5], Step [13690/30930], Loss: 0.0505\n",
      "Epoch [1/5], Step [13700/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [13710/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [13720/30930], Loss: 0.0341\n",
      "Epoch [1/5], Step [13730/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [13740/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [13750/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [13760/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [13770/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [13780/30930], Loss: 0.0224\n",
      "Epoch [1/5], Step [13790/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [13800/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [13810/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [13820/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [13830/30930], Loss: 0.0501\n",
      "Epoch [1/5], Step [13840/30930], Loss: 0.0644\n",
      "Epoch [1/5], Step [13850/30930], Loss: 0.0404\n",
      "Epoch [1/5], Step [13860/30930], Loss: 0.0365\n",
      "Epoch [1/5], Step [13870/30930], Loss: 0.0228\n",
      "Epoch [1/5], Step [13880/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [13890/30930], Loss: 0.0243\n",
      "Epoch [1/5], Step [13900/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [13910/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [13920/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [13930/30930], Loss: 0.0158\n",
      "Epoch [1/5], Step [13940/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [13950/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [13960/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [13970/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [13980/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [13990/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [14000/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [14010/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [14020/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [14030/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [14040/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [14050/30930], Loss: 0.0195\n",
      "Epoch [1/5], Step [14060/30930], Loss: 0.0148\n",
      "Epoch [1/5], Step [14070/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [14080/30930], Loss: 0.0528\n",
      "Epoch [1/5], Step [14090/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [14100/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [14110/30930], Loss: 0.0363\n",
      "Epoch [1/5], Step [14120/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [14130/30930], Loss: 0.0270\n",
      "Epoch [1/5], Step [14140/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [14150/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [14160/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [14170/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [14180/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [14190/30930], Loss: 0.0294\n",
      "Epoch [1/5], Step [14200/30930], Loss: 0.0564\n",
      "Epoch [1/5], Step [14210/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [14220/30930], Loss: 0.0442\n",
      "Epoch [1/5], Step [14230/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [14240/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [14250/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [14260/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [14270/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [14280/30930], Loss: 0.0339\n",
      "Epoch [1/5], Step [14290/30930], Loss: 0.0281\n",
      "Epoch [1/5], Step [14300/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [14310/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [14320/30930], Loss: 0.0783\n",
      "Epoch [1/5], Step [14330/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [14340/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [14350/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [14360/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [14370/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [14380/30930], Loss: 0.0352\n",
      "Epoch [1/5], Step [14390/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [14400/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [14410/30930], Loss: 0.0211\n",
      "Epoch [1/5], Step [14420/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [14430/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [14440/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [14450/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [14460/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [14470/30930], Loss: 0.0259\n",
      "Epoch [1/5], Step [14480/30930], Loss: 0.1120\n",
      "Epoch [1/5], Step [14490/30930], Loss: 0.0427\n",
      "Epoch [1/5], Step [14500/30930], Loss: 0.0080\n",
      "Epoch [1/5], Step [14510/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [14520/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [14530/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [14540/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [14550/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [14560/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [14570/30930], Loss: 0.1805\n",
      "Epoch [1/5], Step [14580/30930], Loss: 0.0636\n",
      "Epoch [1/5], Step [14590/30930], Loss: 0.0127\n",
      "Epoch [1/5], Step [14600/30930], Loss: 0.0265\n",
      "Epoch [1/5], Step [14610/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [14620/30930], Loss: 0.0120\n",
      "Epoch [1/5], Step [14630/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [14640/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [14650/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [14660/30930], Loss: 0.0320\n",
      "Epoch [1/5], Step [14670/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [14680/30930], Loss: 0.0281\n",
      "Epoch [1/5], Step [14690/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [14700/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [14710/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [14720/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [14730/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [14740/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [14750/30930], Loss: 0.0862\n",
      "Epoch [1/5], Step [14760/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [14770/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [14780/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [14790/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [14800/30930], Loss: 0.0404\n",
      "Epoch [1/5], Step [14810/30930], Loss: 0.0410\n",
      "Epoch [1/5], Step [14820/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [14830/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [14840/30930], Loss: 0.0146\n",
      "Epoch [1/5], Step [14850/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [14860/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [14870/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [14880/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [14890/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [14900/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [14910/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [14920/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [14930/30930], Loss: 0.0242\n",
      "Epoch [1/5], Step [14940/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [14950/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [14960/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [14970/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [14980/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [14990/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [15000/30930], Loss: 0.0454\n",
      "Epoch [1/5], Step [15010/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [15020/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [15030/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [15040/30930], Loss: 0.0247\n",
      "Epoch [1/5], Step [15050/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [15060/30930], Loss: 0.0475\n",
      "Epoch [1/5], Step [15070/30930], Loss: 0.0153\n",
      "Epoch [1/5], Step [15080/30930], Loss: 0.0267\n",
      "Epoch [1/5], Step [15090/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [15100/30930], Loss: 0.0218\n",
      "Epoch [1/5], Step [15110/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [15120/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [15130/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [15140/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [15150/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [15160/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [15170/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [15180/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [15190/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [15200/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [15210/30930], Loss: 0.0229\n",
      "Epoch [1/5], Step [15220/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [15230/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [15240/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [15250/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [15260/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [15270/30930], Loss: 0.0344\n",
      "Epoch [1/5], Step [15280/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [15290/30930], Loss: 0.0129\n",
      "Epoch [1/5], Step [15300/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [15310/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [15320/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [15330/30930], Loss: 0.0171\n",
      "Epoch [1/5], Step [15340/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [15350/30930], Loss: 0.0272\n",
      "Epoch [1/5], Step [15360/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [15370/30930], Loss: 0.0437\n",
      "Epoch [1/5], Step [15380/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [15390/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [15400/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [15410/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [15420/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [15430/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [15440/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [15450/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [15460/30930], Loss: 0.0320\n",
      "Epoch [1/5], Step [15470/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [15480/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [15490/30930], Loss: 0.0545\n",
      "Epoch [1/5], Step [15500/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [15510/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [15520/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [15530/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [15540/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [15550/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [15560/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [15570/30930], Loss: 0.0349\n",
      "Epoch [1/5], Step [15580/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [15590/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [15600/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [15610/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [15620/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [15630/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [15640/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [15650/30930], Loss: 0.0636\n",
      "Epoch [1/5], Step [15660/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [15670/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [15680/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [15690/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [15700/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [15710/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [15720/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [15730/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [15740/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [15750/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [15760/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [15770/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [15780/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [15790/30930], Loss: 0.0330\n",
      "Epoch [1/5], Step [15800/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [15810/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [15820/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [15830/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [15840/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [15850/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [15860/30930], Loss: 0.0218\n",
      "Epoch [1/5], Step [15870/30930], Loss: 0.0323\n",
      "Epoch [1/5], Step [15880/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [15890/30930], Loss: 0.0372\n",
      "Epoch [1/5], Step [15900/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [15910/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [15920/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [15930/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [15940/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [15950/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [15960/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [15970/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [15980/30930], Loss: 0.0216\n",
      "Epoch [1/5], Step [15990/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [16000/30930], Loss: 0.0297\n",
      "Epoch [1/5], Step [16010/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [16020/30930], Loss: 0.0192\n",
      "Epoch [1/5], Step [16030/30930], Loss: 0.0232\n",
      "Epoch [1/5], Step [16040/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [16050/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [16060/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [16070/30930], Loss: 0.0339\n",
      "Epoch [1/5], Step [16080/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [16090/30930], Loss: 0.0561\n",
      "Epoch [1/5], Step [16100/30930], Loss: 0.0293\n",
      "Epoch [1/5], Step [16110/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [16120/30930], Loss: 0.0533\n",
      "Epoch [1/5], Step [16130/30930], Loss: 0.0650\n",
      "Epoch [1/5], Step [16140/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [16150/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [16160/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [16170/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [16180/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [16190/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [16200/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [16210/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [16220/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [16230/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [16240/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [16250/30930], Loss: 0.0202\n",
      "Epoch [1/5], Step [16260/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [16270/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [16280/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [16290/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [16300/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [16310/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [16320/30930], Loss: 0.0169\n",
      "Epoch [1/5], Step [16330/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [16340/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [16350/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [16360/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [16370/30930], Loss: 0.0238\n",
      "Epoch [1/5], Step [16380/30930], Loss: 0.0168\n",
      "Epoch [1/5], Step [16390/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [16400/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [16410/30930], Loss: 0.0643\n",
      "Epoch [1/5], Step [16420/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [16430/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [16440/30930], Loss: 0.0572\n",
      "Epoch [1/5], Step [16450/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [16460/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [16470/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [16480/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [16490/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [16500/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [16510/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [16520/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [16530/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [16540/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [16550/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [16560/30930], Loss: 0.0334\n",
      "Epoch [1/5], Step [16570/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [16580/30930], Loss: 0.1099\n",
      "Epoch [1/5], Step [16590/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [16600/30930], Loss: 0.0126\n",
      "Epoch [1/5], Step [16610/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [16620/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [16630/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [16640/30930], Loss: 0.0381\n",
      "Epoch [1/5], Step [16650/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [16660/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [16670/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [16680/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [16690/30930], Loss: 0.0251\n",
      "Epoch [1/5], Step [16700/30930], Loss: 0.0128\n",
      "Epoch [1/5], Step [16710/30930], Loss: 0.0141\n",
      "Epoch [1/5], Step [16720/30930], Loss: 0.0420\n",
      "Epoch [1/5], Step [16730/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [16740/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [16750/30930], Loss: 0.0336\n",
      "Epoch [1/5], Step [16760/30930], Loss: 0.0405\n",
      "Epoch [1/5], Step [16770/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [16780/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [16790/30930], Loss: 0.0327\n",
      "Epoch [1/5], Step [16800/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [16810/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [16820/30930], Loss: 0.0120\n",
      "Epoch [1/5], Step [16830/30930], Loss: 0.0903\n",
      "Epoch [1/5], Step [16840/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [16850/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [16860/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [16870/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [16880/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [16890/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [16900/30930], Loss: 0.0272\n",
      "Epoch [1/5], Step [16910/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [16920/30930], Loss: 0.0476\n",
      "Epoch [1/5], Step [16930/30930], Loss: 0.0320\n",
      "Epoch [1/5], Step [16940/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [16950/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [16960/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [16970/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [16980/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [16990/30930], Loss: 0.0180\n",
      "Epoch [1/5], Step [17000/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [17010/30930], Loss: 0.0242\n",
      "Epoch [1/5], Step [17020/30930], Loss: 0.0279\n",
      "Epoch [1/5], Step [17030/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [17040/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [17050/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [17060/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [17070/30930], Loss: 0.0357\n",
      "Epoch [1/5], Step [17080/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [17090/30930], Loss: 0.0178\n",
      "Epoch [1/5], Step [17100/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [17110/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [17120/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [17130/30930], Loss: 0.0641\n",
      "Epoch [1/5], Step [17140/30930], Loss: 0.0129\n",
      "Epoch [1/5], Step [17150/30930], Loss: 0.0244\n",
      "Epoch [1/5], Step [17160/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [17170/30930], Loss: 0.0289\n",
      "Epoch [1/5], Step [17180/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [17190/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [17200/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [17210/30930], Loss: 0.0125\n",
      "Epoch [1/5], Step [17220/30930], Loss: 0.0286\n",
      "Epoch [1/5], Step [17230/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [17240/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17250/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [17260/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17270/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [17280/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [17290/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [17300/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [17310/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [17320/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [17330/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [17340/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [17350/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [17360/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [17370/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [17380/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [17390/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [17400/30930], Loss: 0.0252\n",
      "Epoch [1/5], Step [17410/30930], Loss: 0.0144\n",
      "Epoch [1/5], Step [17420/30930], Loss: 0.0306\n",
      "Epoch [1/5], Step [17430/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [17440/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [17450/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [17460/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [17470/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17480/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [17490/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [17500/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [17510/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17520/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17530/30930], Loss: 0.0214\n",
      "Epoch [1/5], Step [17540/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [17550/30930], Loss: 0.0186\n",
      "Epoch [1/5], Step [17560/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [17570/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [17580/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [17590/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [17600/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [17610/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [17620/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [17630/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [17640/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [17650/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [17660/30930], Loss: 0.0179\n",
      "Epoch [1/5], Step [17670/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [17680/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [17690/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [17700/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [17710/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [17720/30930], Loss: 0.0368\n",
      "Epoch [1/5], Step [17730/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [17740/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [17750/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [17760/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [17770/30930], Loss: 0.0276\n",
      "Epoch [1/5], Step [17780/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [17790/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [17800/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [17810/30930], Loss: 0.0387\n",
      "Epoch [1/5], Step [17820/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [17830/30930], Loss: 0.0328\n",
      "Epoch [1/5], Step [17840/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [17850/30930], Loss: 0.0289\n",
      "Epoch [1/5], Step [17860/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [17870/30930], Loss: 0.0143\n",
      "Epoch [1/5], Step [17880/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [17890/30930], Loss: 0.0203\n",
      "Epoch [1/5], Step [17900/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [17910/30930], Loss: 0.0188\n",
      "Epoch [1/5], Step [17920/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [17930/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [17940/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [17950/30930], Loss: 0.0227\n",
      "Epoch [1/5], Step [17960/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [17970/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [17980/30930], Loss: 0.0255\n",
      "Epoch [1/5], Step [17990/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [18000/30930], Loss: 0.0162\n",
      "Epoch [1/5], Step [18010/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [18020/30930], Loss: 0.0533\n",
      "Epoch [1/5], Step [18030/30930], Loss: 0.0293\n",
      "Epoch [1/5], Step [18040/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [18050/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [18060/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [18070/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [18080/30930], Loss: 0.0284\n",
      "Epoch [1/5], Step [18090/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [18100/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [18110/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [18120/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [18130/30930], Loss: 0.0255\n",
      "Epoch [1/5], Step [18140/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [18150/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [18160/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [18170/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [18180/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [18190/30930], Loss: 0.0344\n",
      "Epoch [1/5], Step [18200/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [18210/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [18220/30930], Loss: 0.0413\n",
      "Epoch [1/5], Step [18230/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [18240/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [18250/30930], Loss: 0.0720\n",
      "Epoch [1/5], Step [18260/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [18270/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [18280/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [18290/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [18300/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [18310/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [18320/30930], Loss: 0.0144\n",
      "Epoch [1/5], Step [18330/30930], Loss: 0.0258\n",
      "Epoch [1/5], Step [18340/30930], Loss: 0.1985\n",
      "Epoch [1/5], Step [18350/30930], Loss: 0.0331\n",
      "Epoch [1/5], Step [18360/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [18370/30930], Loss: 0.0127\n",
      "Epoch [1/5], Step [18380/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [18390/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [18400/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [18410/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [18420/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [18430/30930], Loss: 0.0490\n",
      "Epoch [1/5], Step [18440/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [18450/30930], Loss: 0.0206\n",
      "Epoch [1/5], Step [18460/30930], Loss: 0.0138\n",
      "Epoch [1/5], Step [18470/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [18480/30930], Loss: 0.0122\n",
      "Epoch [1/5], Step [18490/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [18500/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [18510/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [18520/30930], Loss: 0.0807\n",
      "Epoch [1/5], Step [18530/30930], Loss: 0.0110\n",
      "Epoch [1/5], Step [18540/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [18550/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [18560/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [18570/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [18580/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [18590/30930], Loss: 0.0216\n",
      "Epoch [1/5], Step [18600/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [18610/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [18620/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [18630/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [18640/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [18650/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [18660/30930], Loss: 0.0335\n",
      "Epoch [1/5], Step [18670/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [18680/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [18690/30930], Loss: 0.0658\n",
      "Epoch [1/5], Step [18700/30930], Loss: 0.0276\n",
      "Epoch [1/5], Step [18710/30930], Loss: 0.0458\n",
      "Epoch [1/5], Step [18720/30930], Loss: 0.0231\n",
      "Epoch [1/5], Step [18730/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [18740/30930], Loss: 0.0217\n",
      "Epoch [1/5], Step [18750/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [18760/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [18770/30930], Loss: 0.0338\n",
      "Epoch [1/5], Step [18780/30930], Loss: 0.0251\n",
      "Epoch [1/5], Step [18790/30930], Loss: 0.0468\n",
      "Epoch [1/5], Step [18800/30930], Loss: 0.0110\n",
      "Epoch [1/5], Step [18810/30930], Loss: 0.0330\n",
      "Epoch [1/5], Step [18820/30930], Loss: 0.0555\n",
      "Epoch [1/5], Step [18830/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [18840/30930], Loss: 0.0190\n",
      "Epoch [1/5], Step [18850/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [18860/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [18870/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [18880/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [18890/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [18900/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [18910/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [18920/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [18930/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [18940/30930], Loss: 0.0150\n",
      "Epoch [1/5], Step [18950/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [18960/30930], Loss: 0.0374\n",
      "Epoch [1/5], Step [18970/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [18980/30930], Loss: 0.0411\n",
      "Epoch [1/5], Step [18990/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [19000/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [19010/30930], Loss: 0.0631\n",
      "Epoch [1/5], Step [19020/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [19030/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [19040/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [19050/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [19060/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [19070/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [19080/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [19090/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [19100/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [19110/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [19120/30930], Loss: 0.0619\n",
      "Epoch [1/5], Step [19130/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [19140/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [19150/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [19160/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [19170/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [19180/30930], Loss: 0.0140\n",
      "Epoch [1/5], Step [19190/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [19200/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [19210/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [19220/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [19230/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [19240/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [19250/30930], Loss: 0.0720\n",
      "Epoch [1/5], Step [19260/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [19270/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [19280/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [19290/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [19300/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [19310/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [19320/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [19330/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [19340/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [19350/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [19360/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [19370/30930], Loss: 0.0223\n",
      "Epoch [1/5], Step [19380/30930], Loss: 0.0204\n",
      "Epoch [1/5], Step [19390/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [19400/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [19410/30930], Loss: 0.2410\n",
      "Epoch [1/5], Step [19420/30930], Loss: 0.0152\n",
      "Epoch [1/5], Step [19430/30930], Loss: 0.0537\n",
      "Epoch [1/5], Step [19440/30930], Loss: 0.0202\n",
      "Epoch [1/5], Step [19450/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [19460/30930], Loss: 0.0647\n",
      "Epoch [1/5], Step [19470/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [19480/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [19490/30930], Loss: 0.0297\n",
      "Epoch [1/5], Step [19500/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [19510/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [19520/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [19530/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [19540/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [19550/30930], Loss: 0.0080\n",
      "Epoch [1/5], Step [19560/30930], Loss: 0.0349\n",
      "Epoch [1/5], Step [19570/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [19580/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [19590/30930], Loss: 0.0372\n",
      "Epoch [1/5], Step [19600/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [19610/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [19620/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [19630/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [19640/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [19650/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [19660/30930], Loss: 0.0253\n",
      "Epoch [1/5], Step [19670/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [19680/30930], Loss: 0.0106\n",
      "Epoch [1/5], Step [19690/30930], Loss: 0.0096\n",
      "Epoch [1/5], Step [19700/30930], Loss: 0.0384\n",
      "Epoch [1/5], Step [19710/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [19720/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [19730/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [19740/30930], Loss: 0.0207\n",
      "Epoch [1/5], Step [19750/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [19760/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [19770/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [19780/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [19790/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [19800/30930], Loss: 0.0323\n",
      "Epoch [1/5], Step [19810/30930], Loss: 0.0300\n",
      "Epoch [1/5], Step [19820/30930], Loss: 0.0224\n",
      "Epoch [1/5], Step [19830/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [19840/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [19850/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [19860/30930], Loss: 0.0253\n",
      "Epoch [1/5], Step [19870/30930], Loss: 0.0326\n",
      "Epoch [1/5], Step [19880/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [19890/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [19900/30930], Loss: 0.0461\n",
      "Epoch [1/5], Step [19910/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [19920/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [19930/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [19940/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [19950/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [19960/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [19970/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [19980/30930], Loss: 0.0084\n",
      "Epoch [1/5], Step [19990/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [20000/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [20010/30930], Loss: 0.0302\n",
      "Epoch [1/5], Step [20020/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [20030/30930], Loss: 0.0459\n",
      "Epoch [1/5], Step [20040/30930], Loss: 0.0124\n",
      "Epoch [1/5], Step [20050/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [20060/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [20070/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [20080/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [20090/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [20100/30930], Loss: 0.0393\n",
      "Epoch [1/5], Step [20110/30930], Loss: 0.0112\n",
      "Epoch [1/5], Step [20120/30930], Loss: 0.0177\n",
      "Epoch [1/5], Step [20130/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [20140/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [20150/30930], Loss: 0.0395\n",
      "Epoch [1/5], Step [20160/30930], Loss: 0.0224\n",
      "Epoch [1/5], Step [20170/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [20180/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [20190/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [20200/30930], Loss: 0.0208\n",
      "Epoch [1/5], Step [20210/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [20220/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [20230/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [20240/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [20250/30930], Loss: 0.0255\n",
      "Epoch [1/5], Step [20260/30930], Loss: 0.0223\n",
      "Epoch [1/5], Step [20270/30930], Loss: 0.0247\n",
      "Epoch [1/5], Step [20280/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [20290/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [20300/30930], Loss: 0.0208\n",
      "Epoch [1/5], Step [20310/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [20320/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [20330/30930], Loss: 0.0392\n",
      "Epoch [1/5], Step [20340/30930], Loss: 0.0268\n",
      "Epoch [1/5], Step [20350/30930], Loss: 0.0304\n",
      "Epoch [1/5], Step [20360/30930], Loss: 0.0159\n",
      "Epoch [1/5], Step [20370/30930], Loss: 0.0259\n",
      "Epoch [1/5], Step [20380/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [20390/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [20400/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [20410/30930], Loss: 0.0161\n",
      "Epoch [1/5], Step [20420/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [20430/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [20440/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [20450/30930], Loss: 0.0135\n",
      "Epoch [1/5], Step [20460/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [20470/30930], Loss: 0.0182\n",
      "Epoch [1/5], Step [20480/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [20490/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [20500/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [20510/30930], Loss: 0.0283\n",
      "Epoch [1/5], Step [20520/30930], Loss: 0.0201\n",
      "Epoch [1/5], Step [20530/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [20540/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [20550/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [20560/30930], Loss: 0.0266\n",
      "Epoch [1/5], Step [20570/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [20580/30930], Loss: 0.0248\n",
      "Epoch [1/5], Step [20590/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [20600/30930], Loss: 0.0099\n",
      "Epoch [1/5], Step [20610/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [20620/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [20630/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [20640/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [20650/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [20660/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [20670/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [20680/30930], Loss: 0.0271\n",
      "Epoch [1/5], Step [20690/30930], Loss: 0.0485\n",
      "Epoch [1/5], Step [20700/30930], Loss: 0.0336\n",
      "Epoch [1/5], Step [20710/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [20720/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [20730/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [20740/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [20750/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [20760/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [20770/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [20780/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [20790/30930], Loss: 0.0358\n",
      "Epoch [1/5], Step [20800/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [20810/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [20820/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [20830/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [20840/30930], Loss: 0.0136\n",
      "Epoch [1/5], Step [20850/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [20860/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [20870/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [20880/30930], Loss: 0.0145\n",
      "Epoch [1/5], Step [20890/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [20900/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [20910/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [20920/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [20930/30930], Loss: 0.1154\n",
      "Epoch [1/5], Step [20940/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [20950/30930], Loss: 0.0340\n",
      "Epoch [1/5], Step [20960/30930], Loss: 0.0651\n",
      "Epoch [1/5], Step [20970/30930], Loss: 0.0339\n",
      "Epoch [1/5], Step [20980/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [20990/30930], Loss: 0.0300\n",
      "Epoch [1/5], Step [21000/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [21010/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [21020/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [21030/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [21040/30930], Loss: 0.0120\n",
      "Epoch [1/5], Step [21050/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [21060/30930], Loss: 0.0456\n",
      "Epoch [1/5], Step [21070/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [21080/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [21090/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [21100/30930], Loss: 0.0492\n",
      "Epoch [1/5], Step [21110/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [21120/30930], Loss: 0.0331\n",
      "Epoch [1/5], Step [21130/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [21140/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [21150/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [21160/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [21170/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [21180/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [21190/30930], Loss: 0.0236\n",
      "Epoch [1/5], Step [21200/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [21210/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [21220/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [21230/30930], Loss: 0.0604\n",
      "Epoch [1/5], Step [21240/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [21250/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [21260/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [21270/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [21280/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [21290/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [21300/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [21310/30930], Loss: 0.1322\n",
      "Epoch [1/5], Step [21320/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [21330/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [21340/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [21350/30930], Loss: 0.0284\n",
      "Epoch [1/5], Step [21360/30930], Loss: 0.0090\n",
      "Epoch [1/5], Step [21370/30930], Loss: 0.1163\n",
      "Epoch [1/5], Step [21380/30930], Loss: 0.0100\n",
      "Epoch [1/5], Step [21390/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [21400/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [21410/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [21420/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [21430/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [21440/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [21450/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [21460/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [21470/30930], Loss: 0.0153\n",
      "Epoch [1/5], Step [21480/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [21490/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [21500/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [21510/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [21520/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [21530/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [21540/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [21550/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [21560/30930], Loss: 0.0131\n",
      "Epoch [1/5], Step [21570/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [21580/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [21590/30930], Loss: 0.0465\n",
      "Epoch [1/5], Step [21600/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [21610/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [21620/30930], Loss: 0.0319\n",
      "Epoch [1/5], Step [21630/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [21640/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [21650/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [21660/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [21670/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [21680/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [21690/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [21700/30930], Loss: 0.0191\n",
      "Epoch [1/5], Step [21710/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [21720/30930], Loss: 0.0411\n",
      "Epoch [1/5], Step [21730/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [21740/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [21750/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [21760/30930], Loss: 0.0091\n",
      "Epoch [1/5], Step [21770/30930], Loss: 0.1156\n",
      "Epoch [1/5], Step [21780/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [21790/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [21800/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [21810/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [21820/30930], Loss: 0.0280\n",
      "Epoch [1/5], Step [21830/30930], Loss: 0.0146\n",
      "Epoch [1/5], Step [21840/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [21850/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [21860/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [21870/30930], Loss: 0.0114\n",
      "Epoch [1/5], Step [21880/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [21890/30930], Loss: 0.0227\n",
      "Epoch [1/5], Step [21900/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [21910/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [21920/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [21930/30930], Loss: 0.0201\n",
      "Epoch [1/5], Step [21940/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [21950/30930], Loss: 0.0587\n",
      "Epoch [1/5], Step [21960/30930], Loss: 0.0185\n",
      "Epoch [1/5], Step [21970/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [21980/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [21990/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22000/30930], Loss: 0.0466\n",
      "Epoch [1/5], Step [22010/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [22020/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22030/30930], Loss: 0.0204\n",
      "Epoch [1/5], Step [22040/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [22050/30930], Loss: 0.0237\n",
      "Epoch [1/5], Step [22060/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [22070/30930], Loss: 0.0229\n",
      "Epoch [1/5], Step [22080/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [22090/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22100/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [22110/30930], Loss: 0.0226\n",
      "Epoch [1/5], Step [22120/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [22130/30930], Loss: 0.0286\n",
      "Epoch [1/5], Step [22140/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [22150/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [22160/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [22170/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [22180/30930], Loss: 0.0323\n",
      "Epoch [1/5], Step [22190/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [22200/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [22210/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [22220/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [22230/30930], Loss: 0.0233\n",
      "Epoch [1/5], Step [22240/30930], Loss: 0.0524\n",
      "Epoch [1/5], Step [22250/30930], Loss: 0.0168\n",
      "Epoch [1/5], Step [22260/30930], Loss: 0.0264\n",
      "Epoch [1/5], Step [22270/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [22280/30930], Loss: 0.0441\n",
      "Epoch [1/5], Step [22290/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [22300/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [22310/30930], Loss: 0.0145\n",
      "Epoch [1/5], Step [22320/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22330/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22340/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22350/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22360/30930], Loss: 0.0856\n",
      "Epoch [1/5], Step [22370/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [22380/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [22390/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [22400/30930], Loss: 0.1090\n",
      "Epoch [1/5], Step [22410/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [22420/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [22430/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [22440/30930], Loss: 0.0153\n",
      "Epoch [1/5], Step [22450/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [22460/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [22470/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [22480/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [22490/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [22500/30930], Loss: 0.0107\n",
      "Epoch [1/5], Step [22510/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22520/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22530/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [22540/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [22550/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [22560/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [22570/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [22580/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [22590/30930], Loss: 0.0889\n",
      "Epoch [1/5], Step [22600/30930], Loss: 0.0139\n",
      "Epoch [1/5], Step [22610/30930], Loss: 0.0208\n",
      "Epoch [1/5], Step [22620/30930], Loss: 0.0321\n",
      "Epoch [1/5], Step [22630/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [22640/30930], Loss: 0.0332\n",
      "Epoch [1/5], Step [22650/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [22660/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [22670/30930], Loss: 0.0135\n",
      "Epoch [1/5], Step [22680/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22690/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [22700/30930], Loss: 0.0141\n",
      "Epoch [1/5], Step [22710/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [22720/30930], Loss: 0.0435\n",
      "Epoch [1/5], Step [22730/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [22740/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [22750/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [22760/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [22770/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [22780/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22790/30930], Loss: 0.0602\n",
      "Epoch [1/5], Step [22800/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [22810/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22820/30930], Loss: 0.0268\n",
      "Epoch [1/5], Step [22830/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22840/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [22850/30930], Loss: 0.0145\n",
      "Epoch [1/5], Step [22860/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22870/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [22880/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22890/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [22900/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [22910/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [22920/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [22930/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [22940/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [22950/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [22960/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [22970/30930], Loss: 0.0642\n",
      "Epoch [1/5], Step [22980/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [22990/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [23000/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [23010/30930], Loss: 0.0320\n",
      "Epoch [1/5], Step [23020/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [23030/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [23040/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [23050/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [23060/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23070/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [23080/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [23090/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [23100/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23110/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [23120/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [23130/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [23140/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [23150/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23160/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [23170/30930], Loss: 0.0276\n",
      "Epoch [1/5], Step [23180/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [23190/30930], Loss: 0.0267\n",
      "Epoch [1/5], Step [23200/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [23210/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [23220/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [23230/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23240/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [23250/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [23260/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [23270/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [23280/30930], Loss: 0.0202\n",
      "Epoch [1/5], Step [23290/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [23300/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [23310/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [23320/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [23330/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [23340/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23350/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [23360/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [23370/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [23380/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [23390/30930], Loss: 0.0391\n",
      "Epoch [1/5], Step [23400/30930], Loss: 0.0154\n",
      "Epoch [1/5], Step [23410/30930], Loss: 0.0174\n",
      "Epoch [1/5], Step [23420/30930], Loss: 0.0318\n",
      "Epoch [1/5], Step [23430/30930], Loss: 0.0385\n",
      "Epoch [1/5], Step [23440/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [23450/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [23460/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [23470/30930], Loss: 0.0384\n",
      "Epoch [1/5], Step [23480/30930], Loss: 0.0066\n",
      "Epoch [1/5], Step [23490/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [23500/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23510/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [23520/30930], Loss: 0.0350\n",
      "Epoch [1/5], Step [23530/30930], Loss: 0.0197\n",
      "Epoch [1/5], Step [23540/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [23550/30930], Loss: 0.2389\n",
      "Epoch [1/5], Step [23560/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [23570/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [23580/30930], Loss: 0.0300\n",
      "Epoch [1/5], Step [23590/30930], Loss: 0.0265\n",
      "Epoch [1/5], Step [23600/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23610/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [23620/30930], Loss: 0.0322\n",
      "Epoch [1/5], Step [23630/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [23640/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [23650/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [23660/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [23670/30930], Loss: 0.0062\n",
      "Epoch [1/5], Step [23680/30930], Loss: 0.1048\n",
      "Epoch [1/5], Step [23690/30930], Loss: 0.0090\n",
      "Epoch [1/5], Step [23700/30930], Loss: 0.0091\n",
      "Epoch [1/5], Step [23710/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [23720/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [23730/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [23740/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [23750/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [23760/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [23770/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [23780/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [23790/30930], Loss: 0.0149\n",
      "Epoch [1/5], Step [23800/30930], Loss: 0.0249\n",
      "Epoch [1/5], Step [23810/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [23820/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [23830/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [23840/30930], Loss: 0.0588\n",
      "Epoch [1/5], Step [23850/30930], Loss: 0.0412\n",
      "Epoch [1/5], Step [23860/30930], Loss: 0.0175\n",
      "Epoch [1/5], Step [23870/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [23880/30930], Loss: 0.0187\n",
      "Epoch [1/5], Step [23890/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [23900/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [23910/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [23920/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [23930/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [23940/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [23950/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [23960/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [23970/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [23980/30930], Loss: 0.0149\n",
      "Epoch [1/5], Step [23990/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [24000/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24010/30930], Loss: 0.0189\n",
      "Epoch [1/5], Step [24020/30930], Loss: 0.0287\n",
      "Epoch [1/5], Step [24030/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [24040/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [24050/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [24060/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [24070/30930], Loss: 0.0351\n",
      "Epoch [1/5], Step [24080/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [24090/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [24100/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24110/30930], Loss: 0.0135\n",
      "Epoch [1/5], Step [24120/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [24130/30930], Loss: 0.0248\n",
      "Epoch [1/5], Step [24140/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [24150/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [24160/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24170/30930], Loss: 0.0468\n",
      "Epoch [1/5], Step [24180/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [24190/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24200/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24210/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [24220/30930], Loss: 0.0416\n",
      "Epoch [1/5], Step [24230/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [24240/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [24250/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [24260/30930], Loss: 0.0271\n",
      "Epoch [1/5], Step [24270/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24280/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [24290/30930], Loss: 0.0547\n",
      "Epoch [1/5], Step [24300/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [24310/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [24320/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [24330/30930], Loss: 0.0253\n",
      "Epoch [1/5], Step [24340/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24350/30930], Loss: 0.0091\n",
      "Epoch [1/5], Step [24360/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [24370/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [24380/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [24390/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [24400/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [24410/30930], Loss: 0.0275\n",
      "Epoch [1/5], Step [24420/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24430/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [24440/30930], Loss: 0.0071\n",
      "Epoch [1/5], Step [24450/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [24460/30930], Loss: 0.0197\n",
      "Epoch [1/5], Step [24470/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [24480/30930], Loss: 0.0118\n",
      "Epoch [1/5], Step [24490/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24500/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [24510/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [24520/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [24530/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [24540/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24550/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [24560/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [24570/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [24580/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [24590/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [24600/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24610/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [24620/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [24630/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [24640/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [24650/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [24660/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [24670/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [24680/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [24690/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [24700/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [24710/30930], Loss: 0.0345\n",
      "Epoch [1/5], Step [24720/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24730/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [24740/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [24750/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [24760/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24770/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [24780/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [24790/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [24800/30930], Loss: 0.0317\n",
      "Epoch [1/5], Step [24810/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [24820/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [24830/30930], Loss: 0.0508\n",
      "Epoch [1/5], Step [24840/30930], Loss: 0.0258\n",
      "Epoch [1/5], Step [24850/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [24860/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [24870/30930], Loss: 0.0459\n",
      "Epoch [1/5], Step [24880/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [24890/30930], Loss: 0.0098\n",
      "Epoch [1/5], Step [24900/30930], Loss: 0.0302\n",
      "Epoch [1/5], Step [24910/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [24920/30930], Loss: 0.0176\n",
      "Epoch [1/5], Step [24930/30930], Loss: 0.0374\n",
      "Epoch [1/5], Step [24940/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [24950/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [24960/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [24970/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [24980/30930], Loss: 0.0220\n",
      "Epoch [1/5], Step [24990/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [25000/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [25010/30930], Loss: 0.0406\n",
      "Epoch [1/5], Step [25020/30930], Loss: 0.0574\n",
      "Epoch [1/5], Step [25030/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [25040/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [25050/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [25060/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [25070/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [25080/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [25090/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25100/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [25110/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [25120/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [25130/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [25140/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25150/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25160/30930], Loss: 0.0182\n",
      "Epoch [1/5], Step [25170/30930], Loss: 0.0549\n",
      "Epoch [1/5], Step [25180/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [25190/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25200/30930], Loss: 0.0095\n",
      "Epoch [1/5], Step [25210/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [25220/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [25230/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25240/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [25250/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [25260/30930], Loss: 0.1577\n",
      "Epoch [1/5], Step [25270/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [25280/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [25290/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25300/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [25310/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [25320/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [25330/30930], Loss: 0.0239\n",
      "Epoch [1/5], Step [25340/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [25350/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [25360/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [25370/30930], Loss: 0.0140\n",
      "Epoch [1/5], Step [25380/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [25390/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [25400/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [25410/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [25420/30930], Loss: 0.0380\n",
      "Epoch [1/5], Step [25430/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [25440/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25450/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [25460/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [25470/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [25480/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25490/30930], Loss: 0.0308\n",
      "Epoch [1/5], Step [25500/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [25510/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [25520/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [25530/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [25540/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25550/30930], Loss: 0.0175\n",
      "Epoch [1/5], Step [25560/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [25570/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25580/30930], Loss: 0.0151\n",
      "Epoch [1/5], Step [25590/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [25600/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25610/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25620/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25630/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [25640/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [25650/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [25660/30930], Loss: 0.0300\n",
      "Epoch [1/5], Step [25670/30930], Loss: 0.0478\n",
      "Epoch [1/5], Step [25680/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [25690/30930], Loss: 0.0315\n",
      "Epoch [1/5], Step [25700/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [25710/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [25720/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [25730/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [25740/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [25750/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [25760/30930], Loss: 0.0222\n",
      "Epoch [1/5], Step [25770/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [25780/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [25790/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [25800/30930], Loss: 0.0080\n",
      "Epoch [1/5], Step [25810/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [25820/30930], Loss: 0.0284\n",
      "Epoch [1/5], Step [25830/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [25840/30930], Loss: 0.0129\n",
      "Epoch [1/5], Step [25850/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [25860/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [25870/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [25880/30930], Loss: 0.0379\n",
      "Epoch [1/5], Step [25890/30930], Loss: 0.0368\n",
      "Epoch [1/5], Step [25900/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [25910/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [25920/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [25930/30930], Loss: 0.0340\n",
      "Epoch [1/5], Step [25940/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [25950/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [25960/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [25970/30930], Loss: 0.0121\n",
      "Epoch [1/5], Step [25980/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [25990/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [26000/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [26010/30930], Loss: 0.0135\n",
      "Epoch [1/5], Step [26020/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [26030/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [26040/30930], Loss: 0.0471\n",
      "Epoch [1/5], Step [26050/30930], Loss: 0.0104\n",
      "Epoch [1/5], Step [26060/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [26070/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26080/30930], Loss: 0.1037\n",
      "Epoch [1/5], Step [26090/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26100/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [26110/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [26120/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [26130/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [26140/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [26150/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [26160/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [26170/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [26180/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [26190/30930], Loss: 0.0289\n",
      "Epoch [1/5], Step [26200/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [26210/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [26220/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [26230/30930], Loss: 0.0129\n",
      "Epoch [1/5], Step [26240/30930], Loss: 0.0275\n",
      "Epoch [1/5], Step [26250/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [26260/30930], Loss: 0.0373\n",
      "Epoch [1/5], Step [26270/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [26280/30930], Loss: 0.0072\n",
      "Epoch [1/5], Step [26290/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [26300/30930], Loss: 0.0402\n",
      "Epoch [1/5], Step [26310/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [26320/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [26330/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26340/30930], Loss: 0.0439\n",
      "Epoch [1/5], Step [26350/30930], Loss: 0.0058\n",
      "Epoch [1/5], Step [26360/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [26370/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [26380/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26390/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26400/30930], Loss: 0.0089\n",
      "Epoch [1/5], Step [26410/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [26420/30930], Loss: 0.0375\n",
      "Epoch [1/5], Step [26430/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [26440/30930], Loss: 0.0155\n",
      "Epoch [1/5], Step [26450/30930], Loss: 0.0137\n",
      "Epoch [1/5], Step [26460/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [26470/30930], Loss: 0.0085\n",
      "Epoch [1/5], Step [26480/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [26490/30930], Loss: 0.0362\n",
      "Epoch [1/5], Step [26500/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [26510/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [26520/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [26530/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [26540/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [26550/30930], Loss: 0.0419\n",
      "Epoch [1/5], Step [26560/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [26570/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [26580/30930], Loss: 0.0611\n",
      "Epoch [1/5], Step [26590/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [26600/30930], Loss: 0.0528\n",
      "Epoch [1/5], Step [26610/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [26620/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [26630/30930], Loss: 0.0088\n",
      "Epoch [1/5], Step [26640/30930], Loss: 0.0076\n",
      "Epoch [1/5], Step [26650/30930], Loss: 0.0329\n",
      "Epoch [1/5], Step [26660/30930], Loss: 0.0647\n",
      "Epoch [1/5], Step [26670/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [26680/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [26690/30930], Loss: 0.0397\n",
      "Epoch [1/5], Step [26700/30930], Loss: 0.0233\n",
      "Epoch [1/5], Step [26710/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [26720/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [26730/30930], Loss: 0.0963\n",
      "Epoch [1/5], Step [26740/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [26750/30930], Loss: 0.0232\n",
      "Epoch [1/5], Step [26760/30930], Loss: 0.0165\n",
      "Epoch [1/5], Step [26770/30930], Loss: 0.0068\n",
      "Epoch [1/5], Step [26780/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [26790/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [26800/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [26810/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [26820/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [26830/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [26840/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [26850/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [26860/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [26870/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [26880/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [26890/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [26900/30930], Loss: 0.0012\n",
      "Epoch [1/5], Step [26910/30930], Loss: 0.0314\n",
      "Epoch [1/5], Step [26920/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [26930/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [26940/30930], Loss: 0.0086\n",
      "Epoch [1/5], Step [26950/30930], Loss: 0.0243\n",
      "Epoch [1/5], Step [26960/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [26970/30930], Loss: 0.0247\n",
      "Epoch [1/5], Step [26980/30930], Loss: 0.0083\n",
      "Epoch [1/5], Step [26990/30930], Loss: 0.0235\n",
      "Epoch [1/5], Step [27000/30930], Loss: 0.0302\n",
      "Epoch [1/5], Step [27010/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [27020/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [27030/30930], Loss: 0.0684\n",
      "Epoch [1/5], Step [27040/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [27050/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [27060/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [27070/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [27080/30930], Loss: 0.0321\n",
      "Epoch [1/5], Step [27090/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [27100/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [27110/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [27120/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [27130/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [27140/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [27150/30930], Loss: 0.0409\n",
      "Epoch [1/5], Step [27160/30930], Loss: 0.0221\n",
      "Epoch [1/5], Step [27170/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [27180/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [27190/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [27200/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [27210/30930], Loss: 0.0111\n",
      "Epoch [1/5], Step [27220/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [27230/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [27240/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [27250/30930], Loss: 0.0133\n",
      "Epoch [1/5], Step [27260/30930], Loss: 0.1958\n",
      "Epoch [1/5], Step [27270/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [27280/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [27290/30930], Loss: 0.0285\n",
      "Epoch [1/5], Step [27300/30930], Loss: 0.0083\n",
      "Epoch [1/5], Step [27310/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27320/30930], Loss: 0.0118\n",
      "Epoch [1/5], Step [27330/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [27340/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [27350/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [27360/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27370/30930], Loss: 0.0296\n",
      "Epoch [1/5], Step [27380/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [27390/30930], Loss: 0.0202\n",
      "Epoch [1/5], Step [27400/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [27410/30930], Loss: 0.0049\n",
      "Epoch [1/5], Step [27420/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [27430/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [27440/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [27450/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27460/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [27470/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [27480/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [27490/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [27500/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [27510/30930], Loss: 0.0097\n",
      "Epoch [1/5], Step [27520/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [27530/30930], Loss: 0.0425\n",
      "Epoch [1/5], Step [27540/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [27550/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [27560/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [27570/30930], Loss: 0.0310\n",
      "Epoch [1/5], Step [27580/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [27590/30930], Loss: 0.0300\n",
      "Epoch [1/5], Step [27600/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [27610/30930], Loss: 0.0144\n",
      "Epoch [1/5], Step [27620/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [27630/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [27640/30930], Loss: 0.0231\n",
      "Epoch [1/5], Step [27650/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [27660/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [27670/30930], Loss: 0.0319\n",
      "Epoch [1/5], Step [27680/30930], Loss: 0.0075\n",
      "Epoch [1/5], Step [27690/30930], Loss: 0.0160\n",
      "Epoch [1/5], Step [27700/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [27710/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [27720/30930], Loss: 0.0074\n",
      "Epoch [1/5], Step [27730/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [27740/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27750/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27760/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [27770/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [27780/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [27790/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [27800/30930], Loss: 0.0067\n",
      "Epoch [1/5], Step [27810/30930], Loss: 0.0532\n",
      "Epoch [1/5], Step [27820/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [27830/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [27840/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [27850/30930], Loss: 0.0073\n",
      "Epoch [1/5], Step [27860/30930], Loss: 0.0638\n",
      "Epoch [1/5], Step [27870/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [27880/30930], Loss: 0.0082\n",
      "Epoch [1/5], Step [27890/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [27900/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [27910/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [27920/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27930/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [27940/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [27950/30930], Loss: 0.0059\n",
      "Epoch [1/5], Step [27960/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [27970/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [27980/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [27990/30930], Loss: 0.0286\n",
      "Epoch [1/5], Step [28000/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [28010/30930], Loss: 0.0181\n",
      "Epoch [1/5], Step [28020/30930], Loss: 0.0204\n",
      "Epoch [1/5], Step [28030/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [28040/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [28050/30930], Loss: 0.0102\n",
      "Epoch [1/5], Step [28060/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28070/30930], Loss: 0.0288\n",
      "Epoch [1/5], Step [28080/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28090/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [28100/30930], Loss: 0.0324\n",
      "Epoch [1/5], Step [28110/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [28120/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [28130/30930], Loss: 0.0087\n",
      "Epoch [1/5], Step [28140/30930], Loss: 0.0115\n",
      "Epoch [1/5], Step [28150/30930], Loss: 0.0077\n",
      "Epoch [1/5], Step [28160/30930], Loss: 0.0045\n",
      "Epoch [1/5], Step [28170/30930], Loss: 0.0309\n",
      "Epoch [1/5], Step [28180/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [28190/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [28200/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [28210/30930], Loss: 0.0440\n",
      "Epoch [1/5], Step [28220/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28230/30930], Loss: 0.0040\n",
      "Epoch [1/5], Step [28240/30930], Loss: 0.0323\n",
      "Epoch [1/5], Step [28250/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [28260/30930], Loss: 0.0063\n",
      "Epoch [1/5], Step [28270/30930], Loss: 0.0021\n",
      "Epoch [1/5], Step [28280/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [28290/30930], Loss: 0.0938\n",
      "Epoch [1/5], Step [28300/30930], Loss: 0.0033\n",
      "Epoch [1/5], Step [28310/30930], Loss: 0.0136\n",
      "Epoch [1/5], Step [28320/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [28330/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [28340/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28350/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [28360/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28370/30930], Loss: 0.1191\n",
      "Epoch [1/5], Step [28380/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [28390/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [28400/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28410/30930], Loss: 0.0157\n",
      "Epoch [1/5], Step [28420/30930], Loss: 0.0558\n",
      "Epoch [1/5], Step [28430/30930], Loss: 0.0044\n",
      "Epoch [1/5], Step [28440/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [28450/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [28460/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [28470/30930], Loss: 0.0780\n",
      "Epoch [1/5], Step [28480/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [28490/30930], Loss: 0.0028\n",
      "Epoch [1/5], Step [28500/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [28510/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28520/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [28530/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [28540/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [28550/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [28560/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28570/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [28580/30930], Loss: 0.0278\n",
      "Epoch [1/5], Step [28590/30930], Loss: 0.0290\n",
      "Epoch [1/5], Step [28600/30930], Loss: 0.0228\n",
      "Epoch [1/5], Step [28610/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [28620/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [28630/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [28640/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [28650/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [28660/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [28670/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [28680/30930], Loss: 0.0693\n",
      "Epoch [1/5], Step [28690/30930], Loss: 0.0206\n",
      "Epoch [1/5], Step [28700/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28710/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [28720/30930], Loss: 0.0019\n",
      "Epoch [1/5], Step [28730/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [28740/30930], Loss: 0.0346\n",
      "Epoch [1/5], Step [28750/30930], Loss: 0.0305\n",
      "Epoch [1/5], Step [28760/30930], Loss: 0.0057\n",
      "Epoch [1/5], Step [28770/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [28780/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [28790/30930], Loss: 0.0213\n",
      "Epoch [1/5], Step [28800/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [28810/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [28820/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28830/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28840/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28850/30930], Loss: 0.0048\n",
      "Epoch [1/5], Step [28860/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [28870/30930], Loss: 0.0262\n",
      "Epoch [1/5], Step [28880/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [28890/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [28900/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [28910/30930], Loss: 0.0061\n",
      "Epoch [1/5], Step [28920/30930], Loss: 0.0233\n",
      "Epoch [1/5], Step [28930/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [28940/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [28950/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [28960/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [28970/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [28980/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [28990/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [29000/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [29010/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [29020/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29030/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [29040/30930], Loss: 0.0261\n",
      "Epoch [1/5], Step [29050/30930], Loss: 0.0215\n",
      "Epoch [1/5], Step [29060/30930], Loss: 0.0140\n",
      "Epoch [1/5], Step [29070/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [29080/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29090/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [29100/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29110/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [29120/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29130/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29140/30930], Loss: 0.0357\n",
      "Epoch [1/5], Step [29150/30930], Loss: 0.0353\n",
      "Epoch [1/5], Step [29160/30930], Loss: 0.0081\n",
      "Epoch [1/5], Step [29170/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [29180/30930], Loss: 0.0333\n",
      "Epoch [1/5], Step [29190/30930], Loss: 0.0199\n",
      "Epoch [1/5], Step [29200/30930], Loss: 0.0219\n",
      "Epoch [1/5], Step [29210/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29220/30930], Loss: 0.0116\n",
      "Epoch [1/5], Step [29230/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [29240/30930], Loss: 0.0064\n",
      "Epoch [1/5], Step [29250/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [29260/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29270/30930], Loss: 0.0070\n",
      "Epoch [1/5], Step [29280/30930], Loss: 0.0051\n",
      "Epoch [1/5], Step [29290/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29300/30930], Loss: 0.0117\n",
      "Epoch [1/5], Step [29310/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29320/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [29330/30930], Loss: 0.0451\n",
      "Epoch [1/5], Step [29340/30930], Loss: 0.0039\n",
      "Epoch [1/5], Step [29350/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29360/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [29370/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [29380/30930], Loss: 0.0027\n",
      "Epoch [1/5], Step [29390/30930], Loss: 0.0307\n",
      "Epoch [1/5], Step [29400/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [29410/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [29420/30930], Loss: 0.0369\n",
      "Epoch [1/5], Step [29430/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29440/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29450/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [29460/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29470/30930], Loss: 0.0055\n",
      "Epoch [1/5], Step [29480/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29490/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [29500/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [29510/30930], Loss: 0.0023\n",
      "Epoch [1/5], Step [29520/30930], Loss: 0.0887\n",
      "Epoch [1/5], Step [29530/30930], Loss: 0.0258\n",
      "Epoch [1/5], Step [29540/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [29550/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [29560/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [29570/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29580/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [29590/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [29600/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [29610/30930], Loss: 0.0136\n",
      "Epoch [1/5], Step [29620/30930], Loss: 0.0241\n",
      "Epoch [1/5], Step [29630/30930], Loss: 0.0079\n",
      "Epoch [1/5], Step [29640/30930], Loss: 0.0038\n",
      "Epoch [1/5], Step [29650/30930], Loss: 0.0833\n",
      "Epoch [1/5], Step [29660/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [29670/30930], Loss: 0.0109\n",
      "Epoch [1/5], Step [29680/30930], Loss: 0.0239\n",
      "Epoch [1/5], Step [29690/30930], Loss: 0.0036\n",
      "Epoch [1/5], Step [29700/30930], Loss: 0.0119\n",
      "Epoch [1/5], Step [29710/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [29720/30930], Loss: 0.0014\n",
      "Epoch [1/5], Step [29730/30930], Loss: 0.0402\n",
      "Epoch [1/5], Step [29740/30930], Loss: 0.0020\n",
      "Epoch [1/5], Step [29750/30930], Loss: 0.0034\n",
      "Epoch [1/5], Step [29760/30930], Loss: 0.0491\n",
      "Epoch [1/5], Step [29770/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [29780/30930], Loss: 0.0069\n",
      "Epoch [1/5], Step [29790/30930], Loss: 0.0010\n",
      "Epoch [1/5], Step [29800/30930], Loss: 0.0868\n",
      "Epoch [1/5], Step [29810/30930], Loss: 0.0041\n",
      "Epoch [1/5], Step [29820/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [29830/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [29840/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [29850/30930], Loss: 0.0101\n",
      "Epoch [1/5], Step [29860/30930], Loss: 0.0245\n",
      "Epoch [1/5], Step [29870/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [29880/30930], Loss: 0.0175\n",
      "Epoch [1/5], Step [29890/30930], Loss: 0.0352\n",
      "Epoch [1/5], Step [29900/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [29910/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [29920/30930], Loss: 0.0025\n",
      "Epoch [1/5], Step [29930/30930], Loss: 0.0122\n",
      "Epoch [1/5], Step [29940/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [29950/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [29960/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [29970/30930], Loss: 0.0105\n",
      "Epoch [1/5], Step [29980/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [29990/30930], Loss: 0.0378\n",
      "Epoch [1/5], Step [30000/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [30010/30930], Loss: 0.0332\n",
      "Epoch [1/5], Step [30020/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [30030/30930], Loss: 0.0385\n",
      "Epoch [1/5], Step [30040/30930], Loss: 0.0167\n",
      "Epoch [1/5], Step [30050/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [30060/30930], Loss: 0.0285\n",
      "Epoch [1/5], Step [30070/30930], Loss: 0.0275\n",
      "Epoch [1/5], Step [30080/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [30090/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [30100/30930], Loss: 0.0026\n",
      "Epoch [1/5], Step [30110/30930], Loss: 0.0056\n",
      "Epoch [1/5], Step [30120/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [30130/30930], Loss: 0.0301\n",
      "Epoch [1/5], Step [30140/30930], Loss: 0.0022\n",
      "Epoch [1/5], Step [30150/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [30160/30930], Loss: 0.0275\n",
      "Epoch [1/5], Step [30170/30930], Loss: 0.0231\n",
      "Epoch [1/5], Step [30180/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [30190/30930], Loss: 0.0230\n",
      "Epoch [1/5], Step [30200/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [30210/30930], Loss: 0.0139\n",
      "Epoch [1/5], Step [30220/30930], Loss: 0.0017\n",
      "Epoch [1/5], Step [30230/30930], Loss: 0.0266\n",
      "Epoch [1/5], Step [30240/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [30250/30930], Loss: 0.2157\n",
      "Epoch [1/5], Step [30260/30930], Loss: 0.0018\n",
      "Epoch [1/5], Step [30270/30930], Loss: 0.0030\n",
      "Epoch [1/5], Step [30280/30930], Loss: 0.0008\n",
      "Epoch [1/5], Step [30290/30930], Loss: 0.0000\n",
      "Epoch [1/5], Step [30300/30930], Loss: 0.0108\n",
      "Epoch [1/5], Step [30310/30930], Loss: 0.0132\n",
      "Epoch [1/5], Step [30320/30930], Loss: 0.0013\n",
      "Epoch [1/5], Step [30330/30930], Loss: 0.0052\n",
      "Epoch [1/5], Step [30340/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [30350/30930], Loss: 0.0047\n",
      "Epoch [1/5], Step [30360/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [30370/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [30380/30930], Loss: 0.0164\n",
      "Epoch [1/5], Step [30390/30930], Loss: 0.0037\n",
      "Epoch [1/5], Step [30400/30930], Loss: 0.0532\n",
      "Epoch [1/5], Step [30410/30930], Loss: 0.0240\n",
      "Epoch [1/5], Step [30420/30930], Loss: 0.0078\n",
      "Epoch [1/5], Step [30430/30930], Loss: 0.0005\n",
      "Epoch [1/5], Step [30440/30930], Loss: 0.0411\n",
      "Epoch [1/5], Step [30450/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [30460/30930], Loss: 0.0093\n",
      "Epoch [1/5], Step [30470/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [30480/30930], Loss: 0.0487\n",
      "Epoch [1/5], Step [30490/30930], Loss: 0.0009\n",
      "Epoch [1/5], Step [30500/30930], Loss: 0.0403\n",
      "Epoch [1/5], Step [30510/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [30520/30930], Loss: 0.0050\n",
      "Epoch [1/5], Step [30530/30930], Loss: 0.0385\n",
      "Epoch [1/5], Step [30540/30930], Loss: 0.0015\n",
      "Epoch [1/5], Step [30550/30930], Loss: 0.0004\n",
      "Epoch [1/5], Step [30560/30930], Loss: 0.0016\n",
      "Epoch [1/5], Step [30570/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [30580/30930], Loss: 0.0065\n",
      "Epoch [1/5], Step [30590/30930], Loss: 0.0011\n",
      "Epoch [1/5], Step [30600/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [30610/30930], Loss: 0.0341\n",
      "Epoch [1/5], Step [30620/30930], Loss: 0.0060\n",
      "Epoch [1/5], Step [30630/30930], Loss: 0.0002\n",
      "Epoch [1/5], Step [30640/30930], Loss: 0.0157\n",
      "Epoch [1/5], Step [30650/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [30660/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [30670/30930], Loss: 0.0054\n",
      "Epoch [1/5], Step [30680/30930], Loss: 0.0222\n",
      "Epoch [1/5], Step [30690/30930], Loss: 0.0103\n",
      "Epoch [1/5], Step [30700/30930], Loss: 0.0083\n",
      "Epoch [1/5], Step [30710/30930], Loss: 0.0671\n",
      "Epoch [1/5], Step [30720/30930], Loss: 0.0024\n",
      "Epoch [1/5], Step [30730/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [30740/30930], Loss: 0.0094\n",
      "Epoch [1/5], Step [30750/30930], Loss: 0.0043\n",
      "Epoch [1/5], Step [30760/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [30770/30930], Loss: 0.0092\n",
      "Epoch [1/5], Step [30780/30930], Loss: 0.0046\n",
      "Epoch [1/5], Step [30790/30930], Loss: 0.0142\n",
      "Epoch [1/5], Step [30800/30930], Loss: 0.0053\n",
      "Epoch [1/5], Step [30810/30930], Loss: 0.0042\n",
      "Epoch [1/5], Step [30820/30930], Loss: 0.0006\n",
      "Epoch [1/5], Step [30830/30930], Loss: 0.0032\n",
      "Epoch [1/5], Step [30840/30930], Loss: 0.0029\n",
      "Epoch [1/5], Step [30850/30930], Loss: 0.0290\n",
      "Epoch [1/5], Step [30860/30930], Loss: 0.0001\n",
      "Epoch [1/5], Step [30870/30930], Loss: 0.0007\n",
      "Epoch [1/5], Step [30880/30930], Loss: 0.0194\n",
      "Epoch [1/5], Step [30890/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [30900/30930], Loss: 0.0031\n",
      "Epoch [1/5], Step [30910/30930], Loss: 0.0003\n",
      "Epoch [1/5], Step [30920/30930], Loss: 0.0035\n",
      "Epoch [1/5], Step [30930/30930], Loss: 0.0003\n",
      "Epoch [1/5], Average Train Loss: 0.0256\n",
      "Epoch [1/5], Validation Loss: 0.0124\n",
      "Epoch [2/5], Step [10/30930], Loss: 0.0131\n",
      "Epoch [2/5], Step [20/30930], Loss: 0.0332\n",
      "Epoch [2/5], Step [30/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [40/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [50/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [60/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [70/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [80/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [90/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [100/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [110/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [120/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [130/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [140/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [150/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [160/30930], Loss: 0.0263\n",
      "Epoch [2/5], Step [170/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [180/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [190/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [200/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [210/30930], Loss: 0.0101\n",
      "Epoch [2/5], Step [220/30930], Loss: 0.0287\n",
      "Epoch [2/5], Step [230/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [240/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [250/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [260/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [270/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [280/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [290/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [300/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [310/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [320/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [330/30930], Loss: 0.0913\n",
      "Epoch [2/5], Step [340/30930], Loss: 0.0136\n",
      "Epoch [2/5], Step [350/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [360/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [370/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [380/30930], Loss: 0.0580\n",
      "Epoch [2/5], Step [390/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [400/30930], Loss: 0.0720\n",
      "Epoch [2/5], Step [410/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [420/30930], Loss: 0.0278\n",
      "Epoch [2/5], Step [430/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [440/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [450/30930], Loss: 0.0337\n",
      "Epoch [2/5], Step [460/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [470/30930], Loss: 0.0230\n",
      "Epoch [2/5], Step [480/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [490/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [500/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [510/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [520/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [530/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [540/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [550/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [560/30930], Loss: 0.0182\n",
      "Epoch [2/5], Step [570/30930], Loss: 0.0328\n",
      "Epoch [2/5], Step [580/30930], Loss: 0.0210\n",
      "Epoch [2/5], Step [590/30930], Loss: 0.0238\n",
      "Epoch [2/5], Step [600/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [610/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [620/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [630/30930], Loss: 0.0689\n",
      "Epoch [2/5], Step [640/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [650/30930], Loss: 0.0312\n",
      "Epoch [2/5], Step [660/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [670/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [680/30930], Loss: 0.0333\n",
      "Epoch [2/5], Step [690/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [700/30930], Loss: 0.0104\n",
      "Epoch [2/5], Step [710/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [720/30930], Loss: 0.0170\n",
      "Epoch [2/5], Step [730/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [740/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [750/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [760/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [770/30930], Loss: 0.0243\n",
      "Epoch [2/5], Step [780/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [790/30930], Loss: 0.0140\n",
      "Epoch [2/5], Step [800/30930], Loss: 0.0357\n",
      "Epoch [2/5], Step [810/30930], Loss: 0.0242\n",
      "Epoch [2/5], Step [820/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [830/30930], Loss: 0.0324\n",
      "Epoch [2/5], Step [840/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [850/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [860/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [870/30930], Loss: 0.0527\n",
      "Epoch [2/5], Step [880/30930], Loss: 0.0978\n",
      "Epoch [2/5], Step [890/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [900/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [910/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [920/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [930/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [940/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [950/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [960/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [970/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [980/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [990/30930], Loss: 0.0248\n",
      "Epoch [2/5], Step [1000/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [1010/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [1020/30930], Loss: 0.0091\n",
      "Epoch [2/5], Step [1030/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [1040/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [1050/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [1060/30930], Loss: 0.0749\n",
      "Epoch [2/5], Step [1070/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [1080/30930], Loss: 0.0243\n",
      "Epoch [2/5], Step [1090/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [1100/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [1110/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [1120/30930], Loss: 0.0212\n",
      "Epoch [2/5], Step [1130/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [1140/30930], Loss: 0.0419\n",
      "Epoch [2/5], Step [1150/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [1160/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [1170/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [1180/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [1190/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [1200/30930], Loss: 0.0250\n",
      "Epoch [2/5], Step [1210/30930], Loss: 0.0158\n",
      "Epoch [2/5], Step [1220/30930], Loss: 0.0585\n",
      "Epoch [2/5], Step [1230/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [1240/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1250/30930], Loss: 0.0384\n",
      "Epoch [2/5], Step [1260/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [1270/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [1280/30930], Loss: 0.0194\n",
      "Epoch [2/5], Step [1290/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [1300/30930], Loss: 0.0288\n",
      "Epoch [2/5], Step [1310/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1320/30930], Loss: 0.0159\n",
      "Epoch [2/5], Step [1330/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [1340/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1350/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1360/30930], Loss: 0.0379\n",
      "Epoch [2/5], Step [1370/30930], Loss: 0.0333\n",
      "Epoch [2/5], Step [1380/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [1390/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [1400/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [1410/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [1420/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1430/30930], Loss: 0.0164\n",
      "Epoch [2/5], Step [1440/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1450/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [1460/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [1470/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [1480/30930], Loss: 0.0275\n",
      "Epoch [2/5], Step [1490/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1500/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1510/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1520/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [1530/30930], Loss: 0.0209\n",
      "Epoch [2/5], Step [1540/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [1550/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1560/30930], Loss: 0.0249\n",
      "Epoch [2/5], Step [1570/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [1580/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [1590/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [1600/30930], Loss: 0.1857\n",
      "Epoch [2/5], Step [1610/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [1620/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [1630/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1640/30930], Loss: 0.0307\n",
      "Epoch [2/5], Step [1650/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [1660/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [1670/30930], Loss: 0.0310\n",
      "Epoch [2/5], Step [1680/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1690/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [1700/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1710/30930], Loss: 0.0223\n",
      "Epoch [2/5], Step [1720/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [1730/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [1740/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [1750/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [1760/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [1770/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [1780/30930], Loss: 0.0352\n",
      "Epoch [2/5], Step [1790/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [1800/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [1810/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [1820/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1830/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [1840/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [1850/30930], Loss: 0.0183\n",
      "Epoch [2/5], Step [1860/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [1870/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [1880/30930], Loss: 0.0407\n",
      "Epoch [2/5], Step [1890/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [1900/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [1910/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [1920/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [1930/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [1940/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [1950/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [1960/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1970/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [1980/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [1990/30930], Loss: 0.1336\n",
      "Epoch [2/5], Step [2000/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [2010/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [2020/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [2030/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2040/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2050/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [2060/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [2070/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2080/30930], Loss: 0.0337\n",
      "Epoch [2/5], Step [2090/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [2100/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2110/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [2120/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2130/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [2140/30930], Loss: 0.0101\n",
      "Epoch [2/5], Step [2150/30930], Loss: 0.0100\n",
      "Epoch [2/5], Step [2160/30930], Loss: 0.0278\n",
      "Epoch [2/5], Step [2170/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [2180/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [2190/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2200/30930], Loss: 0.0264\n",
      "Epoch [2/5], Step [2210/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [2220/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [2230/30930], Loss: 0.0509\n",
      "Epoch [2/5], Step [2240/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [2250/30930], Loss: 0.0140\n",
      "Epoch [2/5], Step [2260/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [2270/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [2280/30930], Loss: 0.1285\n",
      "Epoch [2/5], Step [2290/30930], Loss: 0.0232\n",
      "Epoch [2/5], Step [2300/30930], Loss: 0.0705\n",
      "Epoch [2/5], Step [2310/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [2320/30930], Loss: 0.0156\n",
      "Epoch [2/5], Step [2330/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [2340/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [2350/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [2360/30930], Loss: 0.0116\n",
      "Epoch [2/5], Step [2370/30930], Loss: 0.0276\n",
      "Epoch [2/5], Step [2380/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2390/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [2400/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [2410/30930], Loss: 0.0248\n",
      "Epoch [2/5], Step [2420/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [2430/30930], Loss: 0.0347\n",
      "Epoch [2/5], Step [2440/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [2450/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [2460/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2470/30930], Loss: 0.0162\n",
      "Epoch [2/5], Step [2480/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [2490/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [2500/30930], Loss: 0.0292\n",
      "Epoch [2/5], Step [2510/30930], Loss: 0.0059\n",
      "Epoch [2/5], Step [2520/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [2530/30930], Loss: 0.0487\n",
      "Epoch [2/5], Step [2540/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [2550/30930], Loss: 0.0107\n",
      "Epoch [2/5], Step [2560/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2570/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [2580/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [2590/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [2600/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [2610/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [2620/30930], Loss: 0.0327\n",
      "Epoch [2/5], Step [2630/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [2640/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [2650/30930], Loss: 0.0076\n",
      "Epoch [2/5], Step [2660/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [2670/30930], Loss: 0.0442\n",
      "Epoch [2/5], Step [2680/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [2690/30930], Loss: 0.0294\n",
      "Epoch [2/5], Step [2700/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2710/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [2720/30930], Loss: 0.0309\n",
      "Epoch [2/5], Step [2730/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [2740/30930], Loss: 0.0146\n",
      "Epoch [2/5], Step [2750/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [2760/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2770/30930], Loss: 0.0166\n",
      "Epoch [2/5], Step [2780/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [2790/30930], Loss: 0.0887\n",
      "Epoch [2/5], Step [2800/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [2810/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [2820/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [2830/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [2840/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [2850/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [2860/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [2870/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [2880/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [2890/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [2900/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [2910/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [2920/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2930/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [2940/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [2950/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [2960/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [2970/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [2980/30930], Loss: 0.0678\n",
      "Epoch [2/5], Step [2990/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [3000/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [3010/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [3020/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [3030/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [3040/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [3050/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [3060/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [3070/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [3080/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [3090/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [3100/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [3110/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [3120/30930], Loss: 0.0202\n",
      "Epoch [2/5], Step [3130/30930], Loss: 0.0190\n",
      "Epoch [2/5], Step [3140/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3150/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [3160/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [3170/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [3180/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3190/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [3200/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [3210/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [3220/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [3230/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [3240/30930], Loss: 0.0545\n",
      "Epoch [2/5], Step [3250/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [3260/30930], Loss: 0.0246\n",
      "Epoch [2/5], Step [3270/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [3280/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [3290/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [3300/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [3310/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [3320/30930], Loss: 0.0136\n",
      "Epoch [2/5], Step [3330/30930], Loss: 0.0299\n",
      "Epoch [2/5], Step [3340/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [3350/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [3360/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3370/30930], Loss: 0.0339\n",
      "Epoch [2/5], Step [3380/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [3390/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [3400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3410/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [3420/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [3430/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [3440/30930], Loss: 0.0617\n",
      "Epoch [2/5], Step [3450/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [3460/30930], Loss: 0.0264\n",
      "Epoch [2/5], Step [3470/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [3480/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [3490/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [3500/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [3510/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3520/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [3530/30930], Loss: 0.0268\n",
      "Epoch [2/5], Step [3540/30930], Loss: 0.0333\n",
      "Epoch [2/5], Step [3550/30930], Loss: 0.0334\n",
      "Epoch [2/5], Step [3560/30930], Loss: 0.0132\n",
      "Epoch [2/5], Step [3570/30930], Loss: 0.0334\n",
      "Epoch [2/5], Step [3580/30930], Loss: 0.0104\n",
      "Epoch [2/5], Step [3590/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [3600/30930], Loss: 0.0482\n",
      "Epoch [2/5], Step [3610/30930], Loss: 0.0219\n",
      "Epoch [2/5], Step [3620/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [3630/30930], Loss: 0.0317\n",
      "Epoch [2/5], Step [3640/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [3650/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [3660/30930], Loss: 0.0240\n",
      "Epoch [2/5], Step [3670/30930], Loss: 0.0143\n",
      "Epoch [2/5], Step [3680/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [3690/30930], Loss: 0.0574\n",
      "Epoch [2/5], Step [3700/30930], Loss: 0.0211\n",
      "Epoch [2/5], Step [3710/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [3720/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [3730/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [3740/30930], Loss: 0.0105\n",
      "Epoch [2/5], Step [3750/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [3760/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [3770/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [3780/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [3790/30930], Loss: 0.0192\n",
      "Epoch [2/5], Step [3800/30930], Loss: 0.0107\n",
      "Epoch [2/5], Step [3810/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [3820/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [3830/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [3840/30930], Loss: 0.0343\n",
      "Epoch [2/5], Step [3850/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [3860/30930], Loss: 0.0211\n",
      "Epoch [2/5], Step [3870/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [3880/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [3890/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [3900/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [3910/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [3920/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [3930/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [3940/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [3950/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [3960/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [3970/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [3980/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [3990/30930], Loss: 0.0116\n",
      "Epoch [2/5], Step [4000/30930], Loss: 0.0116\n",
      "Epoch [2/5], Step [4010/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4020/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4030/30930], Loss: 0.0335\n",
      "Epoch [2/5], Step [4040/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [4050/30930], Loss: 0.0265\n",
      "Epoch [2/5], Step [4060/30930], Loss: 0.0102\n",
      "Epoch [2/5], Step [4070/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4080/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [4090/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [4100/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [4110/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [4120/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [4130/30930], Loss: 0.0366\n",
      "Epoch [2/5], Step [4140/30930], Loss: 0.0800\n",
      "Epoch [2/5], Step [4150/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [4160/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [4170/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [4180/30930], Loss: 0.0067\n",
      "Epoch [2/5], Step [4190/30930], Loss: 0.0187\n",
      "Epoch [2/5], Step [4200/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4210/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [4220/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [4230/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4240/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [4250/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4260/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [4270/30930], Loss: 0.0320\n",
      "Epoch [2/5], Step [4280/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [4290/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [4300/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [4310/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [4320/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [4330/30930], Loss: 0.0356\n",
      "Epoch [2/5], Step [4340/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [4350/30930], Loss: 0.0520\n",
      "Epoch [2/5], Step [4360/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [4370/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4380/30930], Loss: 0.0413\n",
      "Epoch [2/5], Step [4390/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [4400/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [4410/30930], Loss: 0.0131\n",
      "Epoch [2/5], Step [4420/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [4430/30930], Loss: 0.0312\n",
      "Epoch [2/5], Step [4440/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4450/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [4460/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [4470/30930], Loss: 0.0255\n",
      "Epoch [2/5], Step [4480/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4490/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [4500/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [4510/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [4520/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [4530/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [4540/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [4550/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [4560/30930], Loss: 0.0165\n",
      "Epoch [2/5], Step [4570/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [4580/30930], Loss: 0.0217\n",
      "Epoch [2/5], Step [4590/30930], Loss: 0.2451\n",
      "Epoch [2/5], Step [4600/30930], Loss: 0.0126\n",
      "Epoch [2/5], Step [4610/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [4620/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [4630/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [4640/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [4650/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [4660/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [4670/30930], Loss: 0.0155\n",
      "Epoch [2/5], Step [4680/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [4690/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [4700/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [4710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4720/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [4730/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4740/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [4750/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [4760/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [4770/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [4780/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [4790/30930], Loss: 0.0299\n",
      "Epoch [2/5], Step [4800/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [4810/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [4820/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [4830/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [4840/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4850/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [4860/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [4870/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4880/30930], Loss: 0.0278\n",
      "Epoch [2/5], Step [4890/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [4900/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [4910/30930], Loss: 0.0155\n",
      "Epoch [2/5], Step [4920/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [4930/30930], Loss: 0.0122\n",
      "Epoch [2/5], Step [4940/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [4950/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [4960/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [4970/30930], Loss: 0.0293\n",
      "Epoch [2/5], Step [4980/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [4990/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [5000/30930], Loss: 0.0147\n",
      "Epoch [2/5], Step [5010/30930], Loss: 0.0168\n",
      "Epoch [2/5], Step [5020/30930], Loss: 0.0226\n",
      "Epoch [2/5], Step [5030/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [5040/30930], Loss: 0.0281\n",
      "Epoch [2/5], Step [5050/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [5060/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [5070/30930], Loss: 0.0287\n",
      "Epoch [2/5], Step [5080/30930], Loss: 0.0272\n",
      "Epoch [2/5], Step [5090/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5100/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5110/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5120/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [5130/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [5140/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [5150/30930], Loss: 0.0172\n",
      "Epoch [2/5], Step [5160/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5170/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [5180/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [5190/30930], Loss: 0.0136\n",
      "Epoch [2/5], Step [5200/30930], Loss: 0.0143\n",
      "Epoch [2/5], Step [5210/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [5220/30930], Loss: 0.0326\n",
      "Epoch [2/5], Step [5230/30930], Loss: 0.0340\n",
      "Epoch [2/5], Step [5240/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [5250/30930], Loss: 0.0188\n",
      "Epoch [2/5], Step [5260/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [5270/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [5280/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [5290/30930], Loss: 0.0251\n",
      "Epoch [2/5], Step [5300/30930], Loss: 0.0252\n",
      "Epoch [2/5], Step [5310/30930], Loss: 0.0290\n",
      "Epoch [2/5], Step [5320/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [5330/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [5340/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5350/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [5360/30930], Loss: 0.0364\n",
      "Epoch [2/5], Step [5370/30930], Loss: 0.0360\n",
      "Epoch [2/5], Step [5380/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5390/30930], Loss: 0.0217\n",
      "Epoch [2/5], Step [5400/30930], Loss: 0.0099\n",
      "Epoch [2/5], Step [5410/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5420/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5430/30930], Loss: 0.0401\n",
      "Epoch [2/5], Step [5440/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [5450/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [5460/30930], Loss: 0.0173\n",
      "Epoch [2/5], Step [5470/30930], Loss: 0.0691\n",
      "Epoch [2/5], Step [5480/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5490/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [5500/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [5510/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [5520/30930], Loss: 0.0370\n",
      "Epoch [2/5], Step [5530/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5540/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [5550/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [5560/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5570/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [5580/30930], Loss: 0.0279\n",
      "Epoch [2/5], Step [5590/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [5600/30930], Loss: 0.0316\n",
      "Epoch [2/5], Step [5610/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5620/30930], Loss: 0.0256\n",
      "Epoch [2/5], Step [5630/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [5640/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [5650/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [5660/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [5670/30930], Loss: 0.0267\n",
      "Epoch [2/5], Step [5680/30930], Loss: 0.0450\n",
      "Epoch [2/5], Step [5690/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [5700/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5710/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [5720/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [5730/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [5740/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [5750/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [5760/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [5770/30930], Loss: 0.0167\n",
      "Epoch [2/5], Step [5780/30930], Loss: 0.0332\n",
      "Epoch [2/5], Step [5790/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [5800/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [5810/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [5820/30930], Loss: 0.0092\n",
      "Epoch [2/5], Step [5830/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [5840/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [5850/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5860/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5870/30930], Loss: 0.0226\n",
      "Epoch [2/5], Step [5880/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [5890/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [5900/30930], Loss: 0.0521\n",
      "Epoch [2/5], Step [5910/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [5920/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5930/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [5940/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [5950/30930], Loss: 0.0151\n",
      "Epoch [2/5], Step [5960/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [5970/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [5980/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [5990/30930], Loss: 0.0210\n",
      "Epoch [2/5], Step [6000/30930], Loss: 0.0413\n",
      "Epoch [2/5], Step [6010/30930], Loss: 0.0312\n",
      "Epoch [2/5], Step [6020/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [6030/30930], Loss: 0.0108\n",
      "Epoch [2/5], Step [6040/30930], Loss: 0.0749\n",
      "Epoch [2/5], Step [6050/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6060/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [6070/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [6080/30930], Loss: 0.0460\n",
      "Epoch [2/5], Step [6090/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [6100/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [6110/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [6120/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [6130/30930], Loss: 0.0490\n",
      "Epoch [2/5], Step [6140/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [6150/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [6160/30930], Loss: 0.1190\n",
      "Epoch [2/5], Step [6170/30930], Loss: 0.0152\n",
      "Epoch [2/5], Step [6180/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [6190/30930], Loss: 0.0198\n",
      "Epoch [2/5], Step [6200/30930], Loss: 0.0183\n",
      "Epoch [2/5], Step [6210/30930], Loss: 0.0091\n",
      "Epoch [2/5], Step [6220/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [6230/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [6240/30930], Loss: 0.0446\n",
      "Epoch [2/5], Step [6250/30930], Loss: 0.0224\n",
      "Epoch [2/5], Step [6260/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [6270/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [6280/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [6290/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [6300/30930], Loss: 0.0283\n",
      "Epoch [2/5], Step [6310/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [6320/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6330/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [6340/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [6350/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [6360/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [6370/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [6380/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [6390/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6400/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [6410/30930], Loss: 0.0320\n",
      "Epoch [2/5], Step [6420/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6430/30930], Loss: 0.0253\n",
      "Epoch [2/5], Step [6440/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6450/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [6460/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [6470/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [6480/30930], Loss: 0.0186\n",
      "Epoch [2/5], Step [6490/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [6500/30930], Loss: 0.0592\n",
      "Epoch [2/5], Step [6510/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [6520/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6530/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [6540/30930], Loss: 0.0263\n",
      "Epoch [2/5], Step [6550/30930], Loss: 0.0720\n",
      "Epoch [2/5], Step [6560/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [6570/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [6580/30930], Loss: 0.0195\n",
      "Epoch [2/5], Step [6590/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [6600/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [6610/30930], Loss: 0.0222\n",
      "Epoch [2/5], Step [6620/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [6630/30930], Loss: 0.1073\n",
      "Epoch [2/5], Step [6640/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [6650/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [6660/30930], Loss: 0.0281\n",
      "Epoch [2/5], Step [6670/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [6680/30930], Loss: 0.0123\n",
      "Epoch [2/5], Step [6690/30930], Loss: 0.0910\n",
      "Epoch [2/5], Step [6700/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [6720/30930], Loss: 0.0424\n",
      "Epoch [2/5], Step [6730/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [6740/30930], Loss: 0.0136\n",
      "Epoch [2/5], Step [6750/30930], Loss: 0.0135\n",
      "Epoch [2/5], Step [6760/30930], Loss: 0.0564\n",
      "Epoch [2/5], Step [6770/30930], Loss: 0.0113\n",
      "Epoch [2/5], Step [6780/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [6790/30930], Loss: 0.0454\n",
      "Epoch [2/5], Step [6800/30930], Loss: 0.0230\n",
      "Epoch [2/5], Step [6810/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [6820/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [6830/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [6840/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [6850/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [6860/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [6870/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [6880/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [6890/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [6900/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [6910/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [6920/30930], Loss: 0.0237\n",
      "Epoch [2/5], Step [6930/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [6940/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [6950/30930], Loss: 0.0578\n",
      "Epoch [2/5], Step [6960/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [6970/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [6980/30930], Loss: 0.0745\n",
      "Epoch [2/5], Step [6990/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [7000/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [7010/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [7020/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [7030/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [7040/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [7050/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [7060/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [7070/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7080/30930], Loss: 0.0269\n",
      "Epoch [2/5], Step [7090/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [7100/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [7110/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [7120/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [7130/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [7140/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [7150/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [7160/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7170/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [7180/30930], Loss: 0.0420\n",
      "Epoch [2/5], Step [7190/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [7200/30930], Loss: 0.0505\n",
      "Epoch [2/5], Step [7210/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [7220/30930], Loss: 0.0164\n",
      "Epoch [2/5], Step [7230/30930], Loss: 0.0338\n",
      "Epoch [2/5], Step [7240/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7250/30930], Loss: 0.0303\n",
      "Epoch [2/5], Step [7260/30930], Loss: 0.0389\n",
      "Epoch [2/5], Step [7270/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7280/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7290/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [7300/30930], Loss: 0.0659\n",
      "Epoch [2/5], Step [7310/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [7320/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [7330/30930], Loss: 0.0185\n",
      "Epoch [2/5], Step [7340/30930], Loss: 0.0304\n",
      "Epoch [2/5], Step [7350/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [7360/30930], Loss: 0.0117\n",
      "Epoch [2/5], Step [7370/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [7380/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [7390/30930], Loss: 0.0243\n",
      "Epoch [2/5], Step [7400/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [7410/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [7420/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [7430/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [7440/30930], Loss: 0.0179\n",
      "Epoch [2/5], Step [7450/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7460/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [7470/30930], Loss: 0.0315\n",
      "Epoch [2/5], Step [7480/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [7490/30930], Loss: 0.0496\n",
      "Epoch [2/5], Step [7500/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [7510/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [7520/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [7530/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [7540/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [7550/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7560/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [7570/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [7580/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [7590/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [7600/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [7610/30930], Loss: 0.0545\n",
      "Epoch [2/5], Step [7620/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [7630/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [7640/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [7650/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [7660/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [7670/30930], Loss: 0.0300\n",
      "Epoch [2/5], Step [7680/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [7690/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7700/30930], Loss: 0.0411\n",
      "Epoch [2/5], Step [7710/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [7720/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7730/30930], Loss: 0.0268\n",
      "Epoch [2/5], Step [7740/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7750/30930], Loss: 0.0290\n",
      "Epoch [2/5], Step [7760/30930], Loss: 0.0254\n",
      "Epoch [2/5], Step [7770/30930], Loss: 0.0260\n",
      "Epoch [2/5], Step [7780/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [7790/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [7800/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [7810/30930], Loss: 0.0433\n",
      "Epoch [2/5], Step [7820/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [7830/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7840/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [7850/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [7860/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [7870/30930], Loss: 0.0339\n",
      "Epoch [2/5], Step [7880/30930], Loss: 0.0298\n",
      "Epoch [2/5], Step [7890/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [7900/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [7910/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [7920/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [7930/30930], Loss: 0.0257\n",
      "Epoch [2/5], Step [7940/30930], Loss: 0.0323\n",
      "Epoch [2/5], Step [7950/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7960/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [7970/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [7980/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [7990/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [8000/30930], Loss: 0.0380\n",
      "Epoch [2/5], Step [8010/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [8020/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [8030/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [8040/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [8050/30930], Loss: 0.0294\n",
      "Epoch [2/5], Step [8060/30930], Loss: 0.0305\n",
      "Epoch [2/5], Step [8070/30930], Loss: 0.0655\n",
      "Epoch [2/5], Step [8080/30930], Loss: 0.0104\n",
      "Epoch [2/5], Step [8090/30930], Loss: 0.0129\n",
      "Epoch [2/5], Step [8100/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [8110/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8120/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [8130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8140/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [8150/30930], Loss: 0.0587\n",
      "Epoch [2/5], Step [8160/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [8170/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [8180/30930], Loss: 0.0082\n",
      "Epoch [2/5], Step [8190/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8200/30930], Loss: 0.0255\n",
      "Epoch [2/5], Step [8210/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [8220/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [8230/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [8240/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [8250/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8260/30930], Loss: 0.0404\n",
      "Epoch [2/5], Step [8270/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [8280/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [8290/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8300/30930], Loss: 0.0137\n",
      "Epoch [2/5], Step [8310/30930], Loss: 0.0208\n",
      "Epoch [2/5], Step [8320/30930], Loss: 0.0140\n",
      "Epoch [2/5], Step [8330/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [8340/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8350/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [8360/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [8370/30930], Loss: 0.0265\n",
      "Epoch [2/5], Step [8380/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [8390/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [8400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8410/30930], Loss: 0.0471\n",
      "Epoch [2/5], Step [8420/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [8430/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [8440/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [8450/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [8460/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [8470/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [8480/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [8490/30930], Loss: 0.0233\n",
      "Epoch [2/5], Step [8500/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [8510/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [8520/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [8530/30930], Loss: 0.0221\n",
      "Epoch [2/5], Step [8540/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [8550/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [8560/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [8570/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [8580/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [8590/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [8600/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [8610/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [8620/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [8630/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [8640/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8650/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [8660/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [8670/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [8680/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [8690/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [8700/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [8710/30930], Loss: 0.0384\n",
      "Epoch [2/5], Step [8720/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [8730/30930], Loss: 0.0498\n",
      "Epoch [2/5], Step [8740/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [8750/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [8760/30930], Loss: 0.0246\n",
      "Epoch [2/5], Step [8770/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [8780/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [8790/30930], Loss: 0.0333\n",
      "Epoch [2/5], Step [8800/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [8810/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [8820/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8830/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [8840/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [8850/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [8860/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [8870/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [8880/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [8890/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [8900/30930], Loss: 0.0237\n",
      "Epoch [2/5], Step [8910/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [8920/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [8930/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [8940/30930], Loss: 0.0433\n",
      "Epoch [2/5], Step [8950/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [8960/30930], Loss: 0.0610\n",
      "Epoch [2/5], Step [8970/30930], Loss: 0.0099\n",
      "Epoch [2/5], Step [8980/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [8990/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9000/30930], Loss: 0.0380\n",
      "Epoch [2/5], Step [9010/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [9020/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [9030/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [9040/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [9050/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [9060/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [9070/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [9080/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [9090/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [9100/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [9110/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [9120/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [9130/30930], Loss: 0.0158\n",
      "Epoch [2/5], Step [9140/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [9150/30930], Loss: 0.0244\n",
      "Epoch [2/5], Step [9160/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [9170/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9180/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9190/30930], Loss: 0.0059\n",
      "Epoch [2/5], Step [9200/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9210/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [9220/30930], Loss: 0.0590\n",
      "Epoch [2/5], Step [9230/30930], Loss: 0.0206\n",
      "Epoch [2/5], Step [9240/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [9250/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [9260/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [9270/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9280/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [9290/30930], Loss: 0.0245\n",
      "Epoch [2/5], Step [9300/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9310/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [9320/30930], Loss: 0.0210\n",
      "Epoch [2/5], Step [9330/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [9340/30930], Loss: 0.1127\n",
      "Epoch [2/5], Step [9350/30930], Loss: 0.0308\n",
      "Epoch [2/5], Step [9360/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [9370/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [9380/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [9390/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [9400/30930], Loss: 0.0184\n",
      "Epoch [2/5], Step [9410/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [9420/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [9430/30930], Loss: 0.0373\n",
      "Epoch [2/5], Step [9440/30930], Loss: 0.0233\n",
      "Epoch [2/5], Step [9450/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [9460/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [9470/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9480/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [9490/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9500/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [9510/30930], Loss: 0.0356\n",
      "Epoch [2/5], Step [9520/30930], Loss: 0.0329\n",
      "Epoch [2/5], Step [9530/30930], Loss: 0.0386\n",
      "Epoch [2/5], Step [9540/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9550/30930], Loss: 0.0305\n",
      "Epoch [2/5], Step [9560/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9570/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9580/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [9590/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [9600/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [9610/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [9620/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [9630/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [9640/30930], Loss: 0.0091\n",
      "Epoch [2/5], Step [9650/30930], Loss: 0.0135\n",
      "Epoch [2/5], Step [9660/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [9670/30930], Loss: 0.0269\n",
      "Epoch [2/5], Step [9680/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [9690/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [9700/30930], Loss: 0.0221\n",
      "Epoch [2/5], Step [9710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9720/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9730/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [9740/30930], Loss: 0.0228\n",
      "Epoch [2/5], Step [9750/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [9760/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9770/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [9780/30930], Loss: 0.0308\n",
      "Epoch [2/5], Step [9790/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [9800/30930], Loss: 0.0245\n",
      "Epoch [2/5], Step [9810/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [9820/30930], Loss: 0.0099\n",
      "Epoch [2/5], Step [9830/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [9840/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [9850/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [9860/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9870/30930], Loss: 0.0256\n",
      "Epoch [2/5], Step [9880/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [9890/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [9900/30930], Loss: 0.0811\n",
      "Epoch [2/5], Step [9910/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [9920/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [9930/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [9940/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [9950/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [9960/30930], Loss: 0.0231\n",
      "Epoch [2/5], Step [9970/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [9980/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [9990/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [10000/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [10010/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [10020/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [10030/30930], Loss: 0.0326\n",
      "Epoch [2/5], Step [10040/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [10050/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [10060/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [10070/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [10080/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [10090/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [10100/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [10110/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [10120/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [10130/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [10140/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [10150/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [10160/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [10170/30930], Loss: 0.0079\n",
      "Epoch [2/5], Step [10180/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [10190/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [10200/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [10210/30930], Loss: 0.0353\n",
      "Epoch [2/5], Step [10220/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [10230/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [10240/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [10250/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10260/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [10270/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [10280/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10290/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [10300/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [10310/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10320/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [10330/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [10340/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [10350/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [10360/30930], Loss: 0.0287\n",
      "Epoch [2/5], Step [10370/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [10380/30930], Loss: 0.0405\n",
      "Epoch [2/5], Step [10390/30930], Loss: 0.0428\n",
      "Epoch [2/5], Step [10400/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [10410/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [10420/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10430/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [10440/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [10450/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [10460/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [10470/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [10480/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [10490/30930], Loss: 0.0260\n",
      "Epoch [2/5], Step [10500/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10510/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [10520/30930], Loss: 0.0192\n",
      "Epoch [2/5], Step [10530/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [10540/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [10550/30930], Loss: 0.0217\n",
      "Epoch [2/5], Step [10560/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [10570/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [10580/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [10590/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10600/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [10610/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [10620/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [10630/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [10640/30930], Loss: 0.0308\n",
      "Epoch [2/5], Step [10650/30930], Loss: 0.0692\n",
      "Epoch [2/5], Step [10660/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [10670/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [10680/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10690/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [10700/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10720/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [10730/30930], Loss: 0.0404\n",
      "Epoch [2/5], Step [10740/30930], Loss: 0.0309\n",
      "Epoch [2/5], Step [10750/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [10760/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [10770/30930], Loss: 0.0400\n",
      "Epoch [2/5], Step [10780/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [10790/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10800/30930], Loss: 0.0124\n",
      "Epoch [2/5], Step [10810/30930], Loss: 0.0278\n",
      "Epoch [2/5], Step [10820/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [10830/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [10840/30930], Loss: 0.0420\n",
      "Epoch [2/5], Step [10850/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [10860/30930], Loss: 0.0303\n",
      "Epoch [2/5], Step [10870/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [10880/30930], Loss: 0.0165\n",
      "Epoch [2/5], Step [10890/30930], Loss: 0.0537\n",
      "Epoch [2/5], Step [10900/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [10910/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [10920/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [10930/30930], Loss: 0.0140\n",
      "Epoch [2/5], Step [10940/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10950/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [10960/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [10970/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [10980/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [10990/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11000/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [11010/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [11020/30930], Loss: 0.1305\n",
      "Epoch [2/5], Step [11030/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [11040/30930], Loss: 0.0108\n",
      "Epoch [2/5], Step [11050/30930], Loss: 0.0275\n",
      "Epoch [2/5], Step [11060/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [11070/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [11080/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [11090/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [11100/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [11110/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [11120/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [11130/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [11140/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [11150/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [11160/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [11170/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [11180/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [11190/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [11200/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [11210/30930], Loss: 0.0124\n",
      "Epoch [2/5], Step [11220/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [11230/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [11240/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [11250/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [11260/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [11270/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [11280/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11290/30930], Loss: 0.0102\n",
      "Epoch [2/5], Step [11300/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11310/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [11320/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [11330/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [11340/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11350/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11360/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11370/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [11380/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [11390/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [11400/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11410/30930], Loss: 0.0287\n",
      "Epoch [2/5], Step [11420/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [11430/30930], Loss: 0.0143\n",
      "Epoch [2/5], Step [11440/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [11450/30930], Loss: 0.0700\n",
      "Epoch [2/5], Step [11460/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11470/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [11480/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [11490/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [11500/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [11510/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [11520/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [11530/30930], Loss: 0.0482\n",
      "Epoch [2/5], Step [11540/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [11550/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11560/30930], Loss: 0.0289\n",
      "Epoch [2/5], Step [11570/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [11580/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [11590/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [11600/30930], Loss: 0.0347\n",
      "Epoch [2/5], Step [11610/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [11620/30930], Loss: 0.0162\n",
      "Epoch [2/5], Step [11630/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [11640/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [11650/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [11660/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [11670/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [11680/30930], Loss: 0.0217\n",
      "Epoch [2/5], Step [11690/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [11700/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [11710/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11720/30930], Loss: 0.0371\n",
      "Epoch [2/5], Step [11730/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [11740/30930], Loss: 0.0258\n",
      "Epoch [2/5], Step [11750/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11760/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [11770/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [11780/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11790/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [11800/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [11810/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [11820/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [11830/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [11840/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [11850/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [11860/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [11870/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [11880/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [11890/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [11900/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [11910/30930], Loss: 0.0133\n",
      "Epoch [2/5], Step [11920/30930], Loss: 0.0145\n",
      "Epoch [2/5], Step [11930/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [11940/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [11950/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [11960/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [11970/30930], Loss: 0.0108\n",
      "Epoch [2/5], Step [11980/30930], Loss: 0.0157\n",
      "Epoch [2/5], Step [11990/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [12000/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12010/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [12020/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [12030/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [12040/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [12050/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12060/30930], Loss: 0.0079\n",
      "Epoch [2/5], Step [12070/30930], Loss: 0.0273\n",
      "Epoch [2/5], Step [12080/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12090/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [12100/30930], Loss: 0.0283\n",
      "Epoch [2/5], Step [12110/30930], Loss: 0.0229\n",
      "Epoch [2/5], Step [12120/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [12130/30930], Loss: 0.0352\n",
      "Epoch [2/5], Step [12140/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [12150/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [12160/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [12170/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [12180/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [12190/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [12200/30930], Loss: 0.0361\n",
      "Epoch [2/5], Step [12210/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [12220/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [12230/30930], Loss: 0.0205\n",
      "Epoch [2/5], Step [12240/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [12250/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [12260/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [12270/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [12280/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [12290/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [12300/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [12310/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [12320/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [12330/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [12340/30930], Loss: 0.0299\n",
      "Epoch [2/5], Step [12350/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [12360/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12370/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12380/30930], Loss: 0.0137\n",
      "Epoch [2/5], Step [12390/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [12400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [12410/30930], Loss: 0.0236\n",
      "Epoch [2/5], Step [12420/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [12430/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12440/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [12450/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [12460/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12470/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [12480/30930], Loss: 0.0110\n",
      "Epoch [2/5], Step [12490/30930], Loss: 0.0260\n",
      "Epoch [2/5], Step [12500/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [12510/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [12520/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [12530/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [12540/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [12550/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [12560/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [12570/30930], Loss: 0.0421\n",
      "Epoch [2/5], Step [12580/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [12590/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [12600/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [12610/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [12620/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [12630/30930], Loss: 0.0354\n",
      "Epoch [2/5], Step [12640/30930], Loss: 0.0088\n",
      "Epoch [2/5], Step [12650/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [12660/30930], Loss: 0.0303\n",
      "Epoch [2/5], Step [12670/30930], Loss: 0.0181\n",
      "Epoch [2/5], Step [12680/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [12690/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [12700/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [12710/30930], Loss: 0.0126\n",
      "Epoch [2/5], Step [12720/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12730/30930], Loss: 0.0117\n",
      "Epoch [2/5], Step [12740/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [12750/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [12760/30930], Loss: 0.0226\n",
      "Epoch [2/5], Step [12770/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [12780/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12790/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [12800/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [12810/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [12820/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12830/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [12840/30930], Loss: 0.0478\n",
      "Epoch [2/5], Step [12850/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [12860/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [12870/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [12880/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [12890/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [12900/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [12910/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [12920/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [12930/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [12940/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [12950/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [12960/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [12970/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [12980/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [12990/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [13000/30930], Loss: 0.0363\n",
      "Epoch [2/5], Step [13010/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [13020/30930], Loss: 0.0929\n",
      "Epoch [2/5], Step [13030/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [13040/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [13050/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [13060/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [13070/30930], Loss: 0.0680\n",
      "Epoch [2/5], Step [13080/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13090/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [13100/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [13110/30930], Loss: 0.0094\n",
      "Epoch [2/5], Step [13120/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13140/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [13150/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [13160/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [13170/30930], Loss: 0.0321\n",
      "Epoch [2/5], Step [13180/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [13190/30930], Loss: 0.0079\n",
      "Epoch [2/5], Step [13200/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [13210/30930], Loss: 0.1238\n",
      "Epoch [2/5], Step [13220/30930], Loss: 0.0147\n",
      "Epoch [2/5], Step [13230/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [13240/30930], Loss: 0.0123\n",
      "Epoch [2/5], Step [13250/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [13260/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [13270/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [13280/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [13290/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [13300/30930], Loss: 0.0240\n",
      "Epoch [2/5], Step [13310/30930], Loss: 0.0259\n",
      "Epoch [2/5], Step [13320/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [13330/30930], Loss: 0.0303\n",
      "Epoch [2/5], Step [13340/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [13350/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [13360/30930], Loss: 0.0124\n",
      "Epoch [2/5], Step [13370/30930], Loss: 0.0221\n",
      "Epoch [2/5], Step [13380/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13390/30930], Loss: 0.0366\n",
      "Epoch [2/5], Step [13400/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [13410/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [13420/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13430/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13440/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [13450/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13460/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [13470/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [13480/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [13490/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [13500/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [13510/30930], Loss: 0.0112\n",
      "Epoch [2/5], Step [13520/30930], Loss: 0.0123\n",
      "Epoch [2/5], Step [13530/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [13540/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [13550/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [13560/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [13570/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [13580/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13590/30930], Loss: 0.0186\n",
      "Epoch [2/5], Step [13600/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13610/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13620/30930], Loss: 0.0715\n",
      "Epoch [2/5], Step [13630/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [13640/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [13650/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [13660/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13670/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [13680/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [13690/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [13700/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [13710/30930], Loss: 0.0339\n",
      "Epoch [2/5], Step [13720/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [13730/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [13740/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [13750/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [13760/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [13770/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [13780/30930], Loss: 0.0765\n",
      "Epoch [2/5], Step [13790/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [13800/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [13810/30930], Loss: 0.0210\n",
      "Epoch [2/5], Step [13820/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [13830/30930], Loss: 0.1607\n",
      "Epoch [2/5], Step [13840/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [13850/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [13860/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [13870/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [13880/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [13890/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13900/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [13910/30930], Loss: 0.0516\n",
      "Epoch [2/5], Step [13920/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [13930/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [13940/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [13950/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [13960/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [13970/30930], Loss: 0.0191\n",
      "Epoch [2/5], Step [13980/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [13990/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [14000/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [14010/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [14020/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [14030/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [14040/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14050/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [14060/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14070/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14080/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [14090/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [14100/30930], Loss: 0.0299\n",
      "Epoch [2/5], Step [14110/30930], Loss: 0.0374\n",
      "Epoch [2/5], Step [14120/30930], Loss: 0.0129\n",
      "Epoch [2/5], Step [14130/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [14140/30930], Loss: 0.0322\n",
      "Epoch [2/5], Step [14150/30930], Loss: 0.0346\n",
      "Epoch [2/5], Step [14160/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [14170/30930], Loss: 0.0254\n",
      "Epoch [2/5], Step [14180/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14190/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14200/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [14210/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [14220/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [14230/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14240/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [14250/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14260/30930], Loss: 0.0059\n",
      "Epoch [2/5], Step [14270/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [14280/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [14290/30930], Loss: 0.0334\n",
      "Epoch [2/5], Step [14300/30930], Loss: 0.0095\n",
      "Epoch [2/5], Step [14310/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [14320/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [14330/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [14340/30930], Loss: 0.0229\n",
      "Epoch [2/5], Step [14350/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [14360/30930], Loss: 0.0094\n",
      "Epoch [2/5], Step [14370/30930], Loss: 0.0197\n",
      "Epoch [2/5], Step [14380/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [14390/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14400/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [14410/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14420/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14430/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [14440/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [14450/30930], Loss: 0.0257\n",
      "Epoch [2/5], Step [14460/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14470/30930], Loss: 0.0102\n",
      "Epoch [2/5], Step [14480/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14490/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [14500/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14510/30930], Loss: 0.0342\n",
      "Epoch [2/5], Step [14520/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14530/30930], Loss: 0.0302\n",
      "Epoch [2/5], Step [14540/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [14550/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14560/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [14570/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [14580/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [14590/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [14600/30930], Loss: 0.0476\n",
      "Epoch [2/5], Step [14610/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [14620/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [14630/30930], Loss: 0.0125\n",
      "Epoch [2/5], Step [14640/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [14650/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14660/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14670/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [14680/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14690/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [14700/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [14710/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [14720/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [14730/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [14740/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [14750/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [14760/30930], Loss: 0.0776\n",
      "Epoch [2/5], Step [14770/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [14780/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14790/30930], Loss: 0.0214\n",
      "Epoch [2/5], Step [14800/30930], Loss: 0.0192\n",
      "Epoch [2/5], Step [14810/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14820/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14830/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [14840/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14850/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [14860/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [14870/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [14880/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14890/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [14900/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14910/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [14920/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [14930/30930], Loss: 0.0296\n",
      "Epoch [2/5], Step [14940/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [14950/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [14960/30930], Loss: 0.0129\n",
      "Epoch [2/5], Step [14970/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [14980/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [14990/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [15000/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [15010/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [15020/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [15030/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [15040/30930], Loss: 0.0307\n",
      "Epoch [2/5], Step [15050/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [15060/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [15070/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [15080/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [15090/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [15100/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [15110/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [15120/30930], Loss: 0.0181\n",
      "Epoch [2/5], Step [15130/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [15140/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [15150/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [15160/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [15170/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [15180/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [15190/30930], Loss: 0.0508\n",
      "Epoch [2/5], Step [15200/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [15210/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [15220/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [15230/30930], Loss: 0.0319\n",
      "Epoch [2/5], Step [15240/30930], Loss: 0.0263\n",
      "Epoch [2/5], Step [15250/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [15260/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [15270/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [15280/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [15290/30930], Loss: 0.0881\n",
      "Epoch [2/5], Step [15300/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [15310/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [15320/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [15330/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [15340/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [15350/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [15360/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [15370/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [15380/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [15390/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [15400/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [15410/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [15420/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [15430/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [15440/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [15450/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [15460/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [15470/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [15480/30930], Loss: 0.0279\n",
      "Epoch [2/5], Step [15490/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [15500/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [15510/30930], Loss: 0.0215\n",
      "Epoch [2/5], Step [15520/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [15530/30930], Loss: 0.0231\n",
      "Epoch [2/5], Step [15540/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [15550/30930], Loss: 0.0238\n",
      "Epoch [2/5], Step [15560/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [15570/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [15580/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [15590/30930], Loss: 0.0305\n",
      "Epoch [2/5], Step [15600/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [15610/30930], Loss: 0.0179\n",
      "Epoch [2/5], Step [15620/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [15630/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [15640/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [15650/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [15660/30930], Loss: 0.0285\n",
      "Epoch [2/5], Step [15670/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15680/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [15690/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15700/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [15710/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [15720/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [15730/30930], Loss: 0.0144\n",
      "Epoch [2/5], Step [15740/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [15750/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [15760/30930], Loss: 0.0193\n",
      "Epoch [2/5], Step [15770/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [15780/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [15790/30930], Loss: 0.0126\n",
      "Epoch [2/5], Step [15800/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [15810/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [15820/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [15830/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15840/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [15850/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [15860/30930], Loss: 0.0470\n",
      "Epoch [2/5], Step [15870/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [15880/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [15890/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [15900/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [15910/30930], Loss: 0.0256\n",
      "Epoch [2/5], Step [15920/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [15930/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15940/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15950/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [15960/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [15970/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [15980/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [15990/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [16000/30930], Loss: 0.0205\n",
      "Epoch [2/5], Step [16010/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [16020/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [16030/30930], Loss: 0.0220\n",
      "Epoch [2/5], Step [16040/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [16050/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [16060/30930], Loss: 0.0269\n",
      "Epoch [2/5], Step [16070/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16080/30930], Loss: 0.0607\n",
      "Epoch [2/5], Step [16090/30930], Loss: 0.0076\n",
      "Epoch [2/5], Step [16100/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [16110/30930], Loss: 0.0128\n",
      "Epoch [2/5], Step [16120/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [16130/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [16140/30930], Loss: 0.0418\n",
      "Epoch [2/5], Step [16150/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [16160/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16170/30930], Loss: 0.0273\n",
      "Epoch [2/5], Step [16180/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [16190/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16200/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [16210/30930], Loss: 0.0095\n",
      "Epoch [2/5], Step [16220/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [16230/30930], Loss: 0.0328\n",
      "Epoch [2/5], Step [16240/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [16250/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [16260/30930], Loss: 0.0157\n",
      "Epoch [2/5], Step [16270/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [16280/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [16290/30930], Loss: 0.0067\n",
      "Epoch [2/5], Step [16300/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16310/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16320/30930], Loss: 0.0388\n",
      "Epoch [2/5], Step [16330/30930], Loss: 0.0156\n",
      "Epoch [2/5], Step [16340/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [16350/30930], Loss: 0.0297\n",
      "Epoch [2/5], Step [16360/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [16370/30930], Loss: 0.0104\n",
      "Epoch [2/5], Step [16380/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [16390/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [16400/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [16410/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [16420/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [16430/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16440/30930], Loss: 0.0135\n",
      "Epoch [2/5], Step [16450/30930], Loss: 0.0457\n",
      "Epoch [2/5], Step [16460/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [16470/30930], Loss: 0.0227\n",
      "Epoch [2/5], Step [16480/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [16490/30930], Loss: 0.0415\n",
      "Epoch [2/5], Step [16500/30930], Loss: 0.0281\n",
      "Epoch [2/5], Step [16510/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [16520/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [16530/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [16540/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [16550/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [16560/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [16570/30930], Loss: 0.0300\n",
      "Epoch [2/5], Step [16580/30930], Loss: 0.0326\n",
      "Epoch [2/5], Step [16590/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [16600/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [16610/30930], Loss: 0.0523\n",
      "Epoch [2/5], Step [16620/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16630/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [16640/30930], Loss: 0.0324\n",
      "Epoch [2/5], Step [16650/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [16660/30930], Loss: 0.0823\n",
      "Epoch [2/5], Step [16670/30930], Loss: 0.0324\n",
      "Epoch [2/5], Step [16680/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [16690/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [16700/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [16710/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [16720/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [16730/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [16740/30930], Loss: 0.0108\n",
      "Epoch [2/5], Step [16750/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [16760/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [16770/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [16780/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [16790/30930], Loss: 0.0112\n",
      "Epoch [2/5], Step [16800/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [16810/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [16820/30930], Loss: 0.0346\n",
      "Epoch [2/5], Step [16830/30930], Loss: 0.0264\n",
      "Epoch [2/5], Step [16840/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [16850/30930], Loss: 0.0155\n",
      "Epoch [2/5], Step [16860/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [16870/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [16880/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [16890/30930], Loss: 0.0678\n",
      "Epoch [2/5], Step [16900/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [16910/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [16920/30930], Loss: 0.1379\n",
      "Epoch [2/5], Step [16930/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [16940/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [16950/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [16960/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [16970/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [16980/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [16990/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17000/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [17010/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17020/30930], Loss: 0.0906\n",
      "Epoch [2/5], Step [17030/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [17040/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [17050/30930], Loss: 0.0145\n",
      "Epoch [2/5], Step [17060/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [17070/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17080/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [17090/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17100/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [17110/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [17120/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [17130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17140/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17150/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17160/30930], Loss: 0.0162\n",
      "Epoch [2/5], Step [17170/30930], Loss: 0.0129\n",
      "Epoch [2/5], Step [17180/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [17190/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [17200/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [17210/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [17220/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17230/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [17240/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [17250/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [17260/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [17270/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17280/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [17290/30930], Loss: 0.0341\n",
      "Epoch [2/5], Step [17300/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [17310/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17320/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [17330/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [17340/30930], Loss: 0.0282\n",
      "Epoch [2/5], Step [17350/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [17360/30930], Loss: 0.0188\n",
      "Epoch [2/5], Step [17370/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17380/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [17390/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [17400/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [17410/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [17420/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [17430/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [17440/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [17450/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [17460/30930], Loss: 0.0240\n",
      "Epoch [2/5], Step [17470/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [17480/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [17490/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [17500/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [17510/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [17520/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [17530/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17540/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [17550/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [17560/30930], Loss: 0.0493\n",
      "Epoch [2/5], Step [17570/30930], Loss: 0.0241\n",
      "Epoch [2/5], Step [17580/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [17590/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [17600/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [17610/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [17620/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [17630/30930], Loss: 0.0771\n",
      "Epoch [2/5], Step [17640/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [17650/30930], Loss: 0.0266\n",
      "Epoch [2/5], Step [17660/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [17670/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17680/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [17690/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [17700/30930], Loss: 0.0559\n",
      "Epoch [2/5], Step [17710/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [17720/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [17730/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [17740/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [17750/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [17760/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [17770/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [17780/30930], Loss: 0.0315\n",
      "Epoch [2/5], Step [17790/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [17800/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [17810/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [17820/30930], Loss: 0.0518\n",
      "Epoch [2/5], Step [17830/30930], Loss: 0.0313\n",
      "Epoch [2/5], Step [17840/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [17850/30930], Loss: 0.0544\n",
      "Epoch [2/5], Step [17860/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [17870/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [17880/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [17890/30930], Loss: 0.0108\n",
      "Epoch [2/5], Step [17900/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [17910/30930], Loss: 0.0336\n",
      "Epoch [2/5], Step [17920/30930], Loss: 0.0244\n",
      "Epoch [2/5], Step [17930/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [17940/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [17950/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [17960/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [17970/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [17980/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [17990/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [18000/30930], Loss: 0.0287\n",
      "Epoch [2/5], Step [18010/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [18020/30930], Loss: 0.0781\n",
      "Epoch [2/5], Step [18030/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [18040/30930], Loss: 0.0197\n",
      "Epoch [2/5], Step [18050/30930], Loss: 0.0325\n",
      "Epoch [2/5], Step [18060/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [18070/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [18080/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [18090/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [18100/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [18110/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [18120/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [18130/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [18140/30930], Loss: 0.0151\n",
      "Epoch [2/5], Step [18150/30930], Loss: 0.0148\n",
      "Epoch [2/5], Step [18160/30930], Loss: 0.0450\n",
      "Epoch [2/5], Step [18170/30930], Loss: 0.0622\n",
      "Epoch [2/5], Step [18180/30930], Loss: 0.0124\n",
      "Epoch [2/5], Step [18190/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [18200/30930], Loss: 0.0483\n",
      "Epoch [2/5], Step [18210/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [18220/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [18230/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [18240/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [18250/30930], Loss: 0.0285\n",
      "Epoch [2/5], Step [18260/30930], Loss: 0.0150\n",
      "Epoch [2/5], Step [18270/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [18280/30930], Loss: 0.0253\n",
      "Epoch [2/5], Step [18290/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [18300/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [18310/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [18320/30930], Loss: 0.0148\n",
      "Epoch [2/5], Step [18330/30930], Loss: 0.0208\n",
      "Epoch [2/5], Step [18340/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [18350/30930], Loss: 0.0153\n",
      "Epoch [2/5], Step [18360/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [18370/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [18380/30930], Loss: 0.0116\n",
      "Epoch [2/5], Step [18390/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [18400/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [18410/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [18420/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [18430/30930], Loss: 0.0147\n",
      "Epoch [2/5], Step [18440/30930], Loss: 0.0301\n",
      "Epoch [2/5], Step [18450/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [18460/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [18470/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [18480/30930], Loss: 0.0310\n",
      "Epoch [2/5], Step [18490/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18500/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18510/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [18520/30930], Loss: 0.0241\n",
      "Epoch [2/5], Step [18530/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [18540/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18550/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [18560/30930], Loss: 0.0262\n",
      "Epoch [2/5], Step [18570/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [18580/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [18590/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [18600/30930], Loss: 0.0325\n",
      "Epoch [2/5], Step [18610/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18620/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [18630/30930], Loss: 0.0144\n",
      "Epoch [2/5], Step [18640/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18650/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18660/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [18670/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18680/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [18690/30930], Loss: 0.0416\n",
      "Epoch [2/5], Step [18700/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18710/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [18720/30930], Loss: 0.0470\n",
      "Epoch [2/5], Step [18730/30930], Loss: 0.0223\n",
      "Epoch [2/5], Step [18740/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [18750/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [18760/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [18770/30930], Loss: 0.0112\n",
      "Epoch [2/5], Step [18780/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18790/30930], Loss: 0.0356\n",
      "Epoch [2/5], Step [18800/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [18810/30930], Loss: 0.0138\n",
      "Epoch [2/5], Step [18820/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [18830/30930], Loss: 0.0308\n",
      "Epoch [2/5], Step [18840/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [18850/30930], Loss: 0.0977\n",
      "Epoch [2/5], Step [18860/30930], Loss: 0.0326\n",
      "Epoch [2/5], Step [18870/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [18880/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18890/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [18900/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18910/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [18920/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [18930/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [18940/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [18950/30930], Loss: 0.0392\n",
      "Epoch [2/5], Step [18960/30930], Loss: 0.0442\n",
      "Epoch [2/5], Step [18970/30930], Loss: 0.0206\n",
      "Epoch [2/5], Step [18980/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [18990/30930], Loss: 0.0452\n",
      "Epoch [2/5], Step [19000/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [19010/30930], Loss: 0.0137\n",
      "Epoch [2/5], Step [19020/30930], Loss: 0.0392\n",
      "Epoch [2/5], Step [19030/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [19040/30930], Loss: 0.0298\n",
      "Epoch [2/5], Step [19050/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [19060/30930], Loss: 0.0067\n",
      "Epoch [2/5], Step [19070/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [19080/30930], Loss: 0.0793\n",
      "Epoch [2/5], Step [19090/30930], Loss: 0.0244\n",
      "Epoch [2/5], Step [19100/30930], Loss: 0.0076\n",
      "Epoch [2/5], Step [19110/30930], Loss: 0.0124\n",
      "Epoch [2/5], Step [19120/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [19130/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [19140/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [19150/30930], Loss: 0.0533\n",
      "Epoch [2/5], Step [19160/30930], Loss: 0.0178\n",
      "Epoch [2/5], Step [19170/30930], Loss: 0.0852\n",
      "Epoch [2/5], Step [19180/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [19190/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [19200/30930], Loss: 0.0741\n",
      "Epoch [2/5], Step [19210/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [19220/30930], Loss: 0.0432\n",
      "Epoch [2/5], Step [19230/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [19240/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [19250/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [19260/30930], Loss: 0.0649\n",
      "Epoch [2/5], Step [19270/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [19280/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [19290/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [19300/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [19310/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [19320/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19330/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [19340/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [19350/30930], Loss: 0.0193\n",
      "Epoch [2/5], Step [19360/30930], Loss: 0.0446\n",
      "Epoch [2/5], Step [19370/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [19380/30930], Loss: 0.0250\n",
      "Epoch [2/5], Step [19390/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [19400/30930], Loss: 0.0538\n",
      "Epoch [2/5], Step [19410/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [19420/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [19430/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [19440/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19450/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19460/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [19470/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [19480/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [19490/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [19500/30930], Loss: 0.0029\n",
      "Epoch [2/5], Step [19510/30930], Loss: 0.1499\n",
      "Epoch [2/5], Step [19520/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [19530/30930], Loss: 0.0178\n",
      "Epoch [2/5], Step [19540/30930], Loss: 0.0357\n",
      "Epoch [2/5], Step [19550/30930], Loss: 0.0152\n",
      "Epoch [2/5], Step [19560/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [19570/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [19580/30930], Loss: 0.0302\n",
      "Epoch [2/5], Step [19590/30930], Loss: 0.0448\n",
      "Epoch [2/5], Step [19600/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [19610/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [19620/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [19630/30930], Loss: 0.0173\n",
      "Epoch [2/5], Step [19640/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19650/30930], Loss: 0.0092\n",
      "Epoch [2/5], Step [19660/30930], Loss: 0.0152\n",
      "Epoch [2/5], Step [19670/30930], Loss: 0.0067\n",
      "Epoch [2/5], Step [19680/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [19690/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [19700/30930], Loss: 0.0123\n",
      "Epoch [2/5], Step [19710/30930], Loss: 0.1044\n",
      "Epoch [2/5], Step [19720/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [19730/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [19740/30930], Loss: 0.0168\n",
      "Epoch [2/5], Step [19750/30930], Loss: 0.0369\n",
      "Epoch [2/5], Step [19760/30930], Loss: 0.0232\n",
      "Epoch [2/5], Step [19770/30930], Loss: 0.0092\n",
      "Epoch [2/5], Step [19780/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [19790/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19800/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [19810/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [19820/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [19830/30930], Loss: 0.0277\n",
      "Epoch [2/5], Step [19840/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [19850/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [19860/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [19870/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [19880/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [19890/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [19900/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [19910/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [19920/30930], Loss: 0.0132\n",
      "Epoch [2/5], Step [19930/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [19940/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [19950/30930], Loss: 0.0176\n",
      "Epoch [2/5], Step [19960/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [19970/30930], Loss: 0.0662\n",
      "Epoch [2/5], Step [19980/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [19990/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [20000/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20010/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [20020/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [20030/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20040/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [20050/30930], Loss: 0.0924\n",
      "Epoch [2/5], Step [20060/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [20070/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [20080/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [20090/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [20100/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [20110/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20120/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [20130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20140/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20150/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [20160/30930], Loss: 0.0148\n",
      "Epoch [2/5], Step [20170/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [20180/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [20190/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [20200/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [20210/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [20220/30930], Loss: 0.0104\n",
      "Epoch [2/5], Step [20230/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [20240/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [20250/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [20260/30930], Loss: 0.0128\n",
      "Epoch [2/5], Step [20270/30930], Loss: 0.0136\n",
      "Epoch [2/5], Step [20280/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [20290/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20300/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [20310/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20320/30930], Loss: 0.0169\n",
      "Epoch [2/5], Step [20330/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20340/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [20350/30930], Loss: 0.0195\n",
      "Epoch [2/5], Step [20360/30930], Loss: 0.0353\n",
      "Epoch [2/5], Step [20370/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [20380/30930], Loss: 0.0091\n",
      "Epoch [2/5], Step [20390/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [20400/30930], Loss: 0.0495\n",
      "Epoch [2/5], Step [20410/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [20420/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [20430/30930], Loss: 0.1395\n",
      "Epoch [2/5], Step [20440/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [20450/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [20460/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20470/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [20480/30930], Loss: 0.0122\n",
      "Epoch [2/5], Step [20490/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [20500/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20510/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [20520/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [20530/30930], Loss: 0.0241\n",
      "Epoch [2/5], Step [20540/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [20550/30930], Loss: 0.0091\n",
      "Epoch [2/5], Step [20560/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [20570/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [20580/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20590/30930], Loss: 0.0094\n",
      "Epoch [2/5], Step [20600/30930], Loss: 0.0284\n",
      "Epoch [2/5], Step [20610/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [20620/30930], Loss: 0.0196\n",
      "Epoch [2/5], Step [20630/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20640/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [20650/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [20660/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20670/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [20680/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [20690/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [20700/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [20710/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [20720/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [20730/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [20740/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [20750/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [20760/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [20770/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [20780/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [20790/30930], Loss: 0.1234\n",
      "Epoch [2/5], Step [20800/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20810/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [20820/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [20830/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [20840/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [20850/30930], Loss: 0.0240\n",
      "Epoch [2/5], Step [20860/30930], Loss: 0.0598\n",
      "Epoch [2/5], Step [20870/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [20880/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20890/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [20900/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [20910/30930], Loss: 0.1641\n",
      "Epoch [2/5], Step [20920/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [20930/30930], Loss: 0.0149\n",
      "Epoch [2/5], Step [20940/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [20950/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20960/30930], Loss: 0.0215\n",
      "Epoch [2/5], Step [20970/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [20980/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [20990/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [21000/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [21010/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [21020/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [21030/30930], Loss: 0.0100\n",
      "Epoch [2/5], Step [21040/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21050/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [21060/30930], Loss: 0.0161\n",
      "Epoch [2/5], Step [21070/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [21080/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [21090/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [21100/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [21110/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [21120/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [21130/30930], Loss: 0.0130\n",
      "Epoch [2/5], Step [21140/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [21150/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [21160/30930], Loss: 0.0532\n",
      "Epoch [2/5], Step [21170/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [21180/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [21190/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21200/30930], Loss: 0.0237\n",
      "Epoch [2/5], Step [21210/30930], Loss: 0.0142\n",
      "Epoch [2/5], Step [21220/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [21230/30930], Loss: 0.0319\n",
      "Epoch [2/5], Step [21240/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [21250/30930], Loss: 0.0606\n",
      "Epoch [2/5], Step [21260/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [21270/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [21280/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [21290/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [21300/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21310/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [21320/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21330/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [21340/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21350/30930], Loss: 0.0578\n",
      "Epoch [2/5], Step [21360/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21370/30930], Loss: 0.0059\n",
      "Epoch [2/5], Step [21380/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [21390/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21410/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21420/30930], Loss: 0.0313\n",
      "Epoch [2/5], Step [21430/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [21440/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [21450/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21460/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21470/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [21480/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [21490/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [21500/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [21510/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [21520/30930], Loss: 0.0149\n",
      "Epoch [2/5], Step [21530/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [21540/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [21550/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [21560/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [21570/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [21580/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [21590/30930], Loss: 0.0272\n",
      "Epoch [2/5], Step [21600/30930], Loss: 0.0101\n",
      "Epoch [2/5], Step [21610/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21620/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [21630/30930], Loss: 0.1162\n",
      "Epoch [2/5], Step [21640/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [21650/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [21660/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [21670/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21680/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21690/30930], Loss: 0.0323\n",
      "Epoch [2/5], Step [21700/30930], Loss: 0.0132\n",
      "Epoch [2/5], Step [21710/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [21720/30930], Loss: 0.0243\n",
      "Epoch [2/5], Step [21730/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [21740/30930], Loss: 0.0577\n",
      "Epoch [2/5], Step [21750/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [21760/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [21770/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [21780/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [21790/30930], Loss: 0.0294\n",
      "Epoch [2/5], Step [21800/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21810/30930], Loss: 0.0327\n",
      "Epoch [2/5], Step [21820/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [21830/30930], Loss: 0.0735\n",
      "Epoch [2/5], Step [21840/30930], Loss: 0.0260\n",
      "Epoch [2/5], Step [21850/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [21860/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [21870/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [21880/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [21890/30930], Loss: 0.0206\n",
      "Epoch [2/5], Step [21900/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [21910/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [21920/30930], Loss: 0.0151\n",
      "Epoch [2/5], Step [21930/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [21940/30930], Loss: 0.0121\n",
      "Epoch [2/5], Step [21950/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [21960/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [21970/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [21980/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [21990/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [22000/30930], Loss: 0.0280\n",
      "Epoch [2/5], Step [22010/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [22020/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [22030/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [22040/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [22050/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [22060/30930], Loss: 0.0110\n",
      "Epoch [2/5], Step [22070/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [22080/30930], Loss: 0.0470\n",
      "Epoch [2/5], Step [22090/30930], Loss: 0.0235\n",
      "Epoch [2/5], Step [22100/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22110/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [22120/30930], Loss: 0.0317\n",
      "Epoch [2/5], Step [22130/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [22140/30930], Loss: 0.0260\n",
      "Epoch [2/5], Step [22150/30930], Loss: 0.0551\n",
      "Epoch [2/5], Step [22160/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [22170/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22180/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22190/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [22200/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [22210/30930], Loss: 0.0202\n",
      "Epoch [2/5], Step [22220/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [22230/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [22240/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22250/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [22260/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [22270/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [22280/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [22290/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [22300/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [22310/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22320/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [22330/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [22340/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [22350/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22360/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [22370/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [22380/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [22390/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22410/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [22420/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22430/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22440/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [22450/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22460/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22470/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22480/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [22490/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [22500/30930], Loss: 0.0349\n",
      "Epoch [2/5], Step [22510/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [22520/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [22530/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [22540/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22550/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [22560/30930], Loss: 0.0489\n",
      "Epoch [2/5], Step [22570/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [22580/30930], Loss: 0.0302\n",
      "Epoch [2/5], Step [22590/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22600/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [22610/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [22620/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [22630/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [22640/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22650/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22660/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [22670/30930], Loss: 0.0178\n",
      "Epoch [2/5], Step [22680/30930], Loss: 0.0326\n",
      "Epoch [2/5], Step [22690/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [22700/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [22710/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [22720/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [22730/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [22740/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [22750/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [22760/30930], Loss: 0.0745\n",
      "Epoch [2/5], Step [22770/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [22780/30930], Loss: 0.0079\n",
      "Epoch [2/5], Step [22790/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [22800/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [22810/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [22820/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [22830/30930], Loss: 0.0079\n",
      "Epoch [2/5], Step [22840/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [22850/30930], Loss: 0.0227\n",
      "Epoch [2/5], Step [22860/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [22870/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [22880/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [22890/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [22900/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [22910/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [22920/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [22930/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [22940/30930], Loss: 0.0300\n",
      "Epoch [2/5], Step [22950/30930], Loss: 0.0164\n",
      "Epoch [2/5], Step [22960/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [22970/30930], Loss: 0.0194\n",
      "Epoch [2/5], Step [22980/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [22990/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [23000/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [23010/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [23020/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23030/30930], Loss: 0.0276\n",
      "Epoch [2/5], Step [23040/30930], Loss: 0.0268\n",
      "Epoch [2/5], Step [23050/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [23060/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [23070/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23080/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [23090/30930], Loss: 0.0103\n",
      "Epoch [2/5], Step [23100/30930], Loss: 0.0103\n",
      "Epoch [2/5], Step [23110/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [23120/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [23130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23140/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [23150/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23160/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [23170/30930], Loss: 0.0208\n",
      "Epoch [2/5], Step [23180/30930], Loss: 0.0115\n",
      "Epoch [2/5], Step [23190/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23200/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [23210/30930], Loss: 0.0166\n",
      "Epoch [2/5], Step [23220/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [23230/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [23240/30930], Loss: 0.0216\n",
      "Epoch [2/5], Step [23250/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [23260/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [23270/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23280/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23290/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [23300/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [23310/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [23320/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23330/30930], Loss: 0.0193\n",
      "Epoch [2/5], Step [23340/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [23350/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [23360/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [23370/30930], Loss: 0.0527\n",
      "Epoch [2/5], Step [23380/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [23390/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [23400/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [23410/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23420/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [23430/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23440/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [23450/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [23460/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [23470/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [23480/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23490/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [23500/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [23510/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23520/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [23530/30930], Loss: 0.0094\n",
      "Epoch [2/5], Step [23540/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23550/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23560/30930], Loss: 0.0301\n",
      "Epoch [2/5], Step [23570/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [23580/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23590/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [23600/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [23610/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [23620/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23630/30930], Loss: 0.0204\n",
      "Epoch [2/5], Step [23640/30930], Loss: 0.0323\n",
      "Epoch [2/5], Step [23650/30930], Loss: 0.0115\n",
      "Epoch [2/5], Step [23660/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [23670/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [23680/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [23690/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [23700/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [23710/30930], Loss: 0.0470\n",
      "Epoch [2/5], Step [23720/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23730/30930], Loss: 0.0381\n",
      "Epoch [2/5], Step [23740/30930], Loss: 0.0316\n",
      "Epoch [2/5], Step [23750/30930], Loss: 0.0129\n",
      "Epoch [2/5], Step [23760/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [23770/30930], Loss: 0.0227\n",
      "Epoch [2/5], Step [23780/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [23790/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [23800/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [23810/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [23820/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [23830/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [23840/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [23850/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [23860/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [23870/30930], Loss: 0.0042\n",
      "Epoch [2/5], Step [23880/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [23890/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [23900/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [23910/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [23920/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [23930/30930], Loss: 0.0391\n",
      "Epoch [2/5], Step [23940/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [23950/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [23960/30930], Loss: 0.0165\n",
      "Epoch [2/5], Step [23970/30930], Loss: 0.0530\n",
      "Epoch [2/5], Step [23980/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [23990/30930], Loss: 0.0112\n",
      "Epoch [2/5], Step [24000/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24010/30930], Loss: 0.0103\n",
      "Epoch [2/5], Step [24020/30930], Loss: 0.0537\n",
      "Epoch [2/5], Step [24030/30930], Loss: 0.0274\n",
      "Epoch [2/5], Step [24040/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [24050/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24060/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24070/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [24080/30930], Loss: 0.0099\n",
      "Epoch [2/5], Step [24090/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [24100/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24110/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [24120/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24130/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24140/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [24150/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [24160/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24170/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24180/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [24190/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [24200/30930], Loss: 0.0217\n",
      "Epoch [2/5], Step [24210/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [24220/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [24230/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [24240/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [24250/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [24260/30930], Loss: 0.0541\n",
      "Epoch [2/5], Step [24270/30930], Loss: 0.0093\n",
      "Epoch [2/5], Step [24280/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [24290/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [24300/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [24310/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [24320/30930], Loss: 0.0471\n",
      "Epoch [2/5], Step [24330/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [24340/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [24350/30930], Loss: 0.0333\n",
      "Epoch [2/5], Step [24360/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [24370/30930], Loss: 0.0231\n",
      "Epoch [2/5], Step [24380/30930], Loss: 0.0455\n",
      "Epoch [2/5], Step [24390/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [24400/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [24410/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [24420/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [24430/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [24440/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [24450/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [24460/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [24470/30930], Loss: 0.0236\n",
      "Epoch [2/5], Step [24480/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [24490/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24500/30930], Loss: 0.0346\n",
      "Epoch [2/5], Step [24510/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24520/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24530/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [24540/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [24550/30930], Loss: 0.0192\n",
      "Epoch [2/5], Step [24560/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24570/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [24580/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [24590/30930], Loss: 0.0779\n",
      "Epoch [2/5], Step [24600/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [24610/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [24620/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [24630/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [24640/30930], Loss: 0.0167\n",
      "Epoch [2/5], Step [24650/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [24660/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [24670/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [24680/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [24690/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [24700/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [24710/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [24720/30930], Loss: 0.0163\n",
      "Epoch [2/5], Step [24730/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [24740/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [24750/30930], Loss: 0.0143\n",
      "Epoch [2/5], Step [24760/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [24770/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [24780/30930], Loss: 0.0198\n",
      "Epoch [2/5], Step [24790/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [24800/30930], Loss: 0.0176\n",
      "Epoch [2/5], Step [24810/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [24820/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [24830/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [24840/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [24850/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [24860/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [24870/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [24880/30930], Loss: 0.0158\n",
      "Epoch [2/5], Step [24890/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [24900/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [24910/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [24920/30930], Loss: 0.0551\n",
      "Epoch [2/5], Step [24930/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [24940/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [24950/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [24960/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [24970/30930], Loss: 0.0781\n",
      "Epoch [2/5], Step [24980/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [24990/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [25000/30930], Loss: 0.0048\n",
      "Epoch [2/5], Step [25010/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [25020/30930], Loss: 0.0492\n",
      "Epoch [2/5], Step [25030/30930], Loss: 0.0405\n",
      "Epoch [2/5], Step [25040/30930], Loss: 0.0390\n",
      "Epoch [2/5], Step [25050/30930], Loss: 0.0467\n",
      "Epoch [2/5], Step [25060/30930], Loss: 0.0110\n",
      "Epoch [2/5], Step [25070/30930], Loss: 0.0139\n",
      "Epoch [2/5], Step [25080/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [25090/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25100/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [25110/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25120/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [25130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25140/30930], Loss: 0.0875\n",
      "Epoch [2/5], Step [25150/30930], Loss: 0.0159\n",
      "Epoch [2/5], Step [25160/30930], Loss: 0.0356\n",
      "Epoch [2/5], Step [25170/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [25180/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25190/30930], Loss: 0.0111\n",
      "Epoch [2/5], Step [25200/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25210/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [25220/30930], Loss: 0.0067\n",
      "Epoch [2/5], Step [25230/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [25240/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [25250/30930], Loss: 0.0161\n",
      "Epoch [2/5], Step [25260/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [25270/30930], Loss: 0.0163\n",
      "Epoch [2/5], Step [25280/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [25290/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25300/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [25310/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [25320/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [25330/30930], Loss: 0.0481\n",
      "Epoch [2/5], Step [25340/30930], Loss: 0.0227\n",
      "Epoch [2/5], Step [25350/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [25360/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [25370/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [25380/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25390/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [25400/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [25410/30930], Loss: 0.0232\n",
      "Epoch [2/5], Step [25420/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [25430/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [25440/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [25450/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [25460/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25470/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [25480/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25490/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [25500/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25510/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25520/30930], Loss: 0.0088\n",
      "Epoch [2/5], Step [25530/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [25540/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [25550/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [25560/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [25570/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [25580/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [25590/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [25600/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [25610/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25620/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [25630/30930], Loss: 0.0568\n",
      "Epoch [2/5], Step [25640/30930], Loss: 0.0228\n",
      "Epoch [2/5], Step [25650/30930], Loss: 0.0364\n",
      "Epoch [2/5], Step [25660/30930], Loss: 0.0529\n",
      "Epoch [2/5], Step [25670/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25680/30930], Loss: 0.0060\n",
      "Epoch [2/5], Step [25690/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [25700/30930], Loss: 0.0316\n",
      "Epoch [2/5], Step [25710/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [25720/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [25730/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [25740/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [25750/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25760/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [25770/30930], Loss: 0.0754\n",
      "Epoch [2/5], Step [25780/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25790/30930], Loss: 0.0373\n",
      "Epoch [2/5], Step [25800/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [25810/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [25820/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [25830/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [25840/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [25850/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [25860/30930], Loss: 0.0633\n",
      "Epoch [2/5], Step [25870/30930], Loss: 0.0243\n",
      "Epoch [2/5], Step [25880/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [25890/30930], Loss: 0.0182\n",
      "Epoch [2/5], Step [25900/30930], Loss: 0.0180\n",
      "Epoch [2/5], Step [25910/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [25920/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [25930/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [25940/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [25950/30930], Loss: 0.0401\n",
      "Epoch [2/5], Step [25960/30930], Loss: 0.0077\n",
      "Epoch [2/5], Step [25970/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [25980/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [25990/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [26000/30930], Loss: 0.0491\n",
      "Epoch [2/5], Step [26010/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [26020/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [26030/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [26040/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [26050/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [26060/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [26070/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [26080/30930], Loss: 0.0612\n",
      "Epoch [2/5], Step [26090/30930], Loss: 0.0452\n",
      "Epoch [2/5], Step [26100/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26110/30930], Loss: 0.0238\n",
      "Epoch [2/5], Step [26120/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [26130/30930], Loss: 0.0254\n",
      "Epoch [2/5], Step [26140/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [26150/30930], Loss: 0.0061\n",
      "Epoch [2/5], Step [26160/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [26170/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [26180/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [26190/30930], Loss: 0.0792\n",
      "Epoch [2/5], Step [26200/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [26210/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [26220/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [26230/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26240/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [26250/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26260/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [26270/30930], Loss: 0.0374\n",
      "Epoch [2/5], Step [26280/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [26290/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [26300/30930], Loss: 0.0357\n",
      "Epoch [2/5], Step [26310/30930], Loss: 0.1042\n",
      "Epoch [2/5], Step [26320/30930], Loss: 0.0215\n",
      "Epoch [2/5], Step [26330/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [26340/30930], Loss: 0.0056\n",
      "Epoch [2/5], Step [26350/30930], Loss: 0.0335\n",
      "Epoch [2/5], Step [26360/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [26370/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26380/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [26390/30930], Loss: 0.0038\n",
      "Epoch [2/5], Step [26400/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [26410/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [26420/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [26430/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [26440/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [26450/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [26460/30930], Loss: 0.0190\n",
      "Epoch [2/5], Step [26470/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [26480/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [26490/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [26500/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [26510/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [26520/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [26530/30930], Loss: 0.0188\n",
      "Epoch [2/5], Step [26540/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26550/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26560/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [26570/30930], Loss: 0.0169\n",
      "Epoch [2/5], Step [26580/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [26590/30930], Loss: 0.0074\n",
      "Epoch [2/5], Step [26600/30930], Loss: 0.0194\n",
      "Epoch [2/5], Step [26610/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [26620/30930], Loss: 0.0165\n",
      "Epoch [2/5], Step [26630/30930], Loss: 0.0331\n",
      "Epoch [2/5], Step [26640/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [26650/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [26660/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26670/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26680/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [26690/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [26700/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26710/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [26720/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [26730/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [26740/30930], Loss: 0.0500\n",
      "Epoch [2/5], Step [26750/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [26760/30930], Loss: 0.0247\n",
      "Epoch [2/5], Step [26770/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [26780/30930], Loss: 0.0414\n",
      "Epoch [2/5], Step [26790/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26800/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [26810/30930], Loss: 0.0315\n",
      "Epoch [2/5], Step [26820/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [26830/30930], Loss: 0.0185\n",
      "Epoch [2/5], Step [26840/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [26850/30930], Loss: 0.0152\n",
      "Epoch [2/5], Step [26860/30930], Loss: 0.0406\n",
      "Epoch [2/5], Step [26870/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [26880/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26890/30930], Loss: 0.0128\n",
      "Epoch [2/5], Step [26900/30930], Loss: 0.0090\n",
      "Epoch [2/5], Step [26910/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [26920/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [26930/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [26940/30930], Loss: 0.0252\n",
      "Epoch [2/5], Step [26950/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [26960/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [26970/30930], Loss: 0.0240\n",
      "Epoch [2/5], Step [26980/30930], Loss: 0.0097\n",
      "Epoch [2/5], Step [26990/30930], Loss: 0.0575\n",
      "Epoch [2/5], Step [27000/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [27010/30930], Loss: 0.0465\n",
      "Epoch [2/5], Step [27020/30930], Loss: 0.0098\n",
      "Epoch [2/5], Step [27030/30930], Loss: 0.0341\n",
      "Epoch [2/5], Step [27040/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [27050/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [27060/30930], Loss: 0.0094\n",
      "Epoch [2/5], Step [27070/30930], Loss: 0.1052\n",
      "Epoch [2/5], Step [27080/30930], Loss: 0.0052\n",
      "Epoch [2/5], Step [27090/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [27100/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [27110/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [27120/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [27130/30930], Loss: 0.0289\n",
      "Epoch [2/5], Step [27140/30930], Loss: 0.0218\n",
      "Epoch [2/5], Step [27150/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27160/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [27170/30930], Loss: 0.0638\n",
      "Epoch [2/5], Step [27180/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [27190/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [27200/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27210/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [27220/30930], Loss: 0.0238\n",
      "Epoch [2/5], Step [27230/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [27240/30930], Loss: 0.0370\n",
      "Epoch [2/5], Step [27250/30930], Loss: 0.0203\n",
      "Epoch [2/5], Step [27260/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27270/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [27280/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [27290/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [27300/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [27310/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [27320/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [27330/30930], Loss: 0.0195\n",
      "Epoch [2/5], Step [27340/30930], Loss: 0.1230\n",
      "Epoch [2/5], Step [27350/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [27360/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [27370/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [27380/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [27390/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27400/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27410/30930], Loss: 0.0426\n",
      "Epoch [2/5], Step [27420/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [27430/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [27440/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [27450/30930], Loss: 0.0121\n",
      "Epoch [2/5], Step [27460/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [27470/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27480/30930], Loss: 0.0109\n",
      "Epoch [2/5], Step [27490/30930], Loss: 0.0225\n",
      "Epoch [2/5], Step [27500/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [27510/30930], Loss: 0.0187\n",
      "Epoch [2/5], Step [27520/30930], Loss: 0.0296\n",
      "Epoch [2/5], Step [27530/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [27540/30930], Loss: 0.0290\n",
      "Epoch [2/5], Step [27550/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27560/30930], Loss: 0.0209\n",
      "Epoch [2/5], Step [27570/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [27580/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [27590/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [27600/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [27610/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [27620/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27630/30930], Loss: 0.0252\n",
      "Epoch [2/5], Step [27640/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [27650/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [27660/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [27670/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [27680/30930], Loss: 0.0204\n",
      "Epoch [2/5], Step [27690/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [27700/30930], Loss: 0.0089\n",
      "Epoch [2/5], Step [27710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27720/30930], Loss: 0.0072\n",
      "Epoch [2/5], Step [27730/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [27740/30930], Loss: 0.0181\n",
      "Epoch [2/5], Step [27750/30930], Loss: 0.0051\n",
      "Epoch [2/5], Step [27760/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [27770/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27780/30930], Loss: 0.0368\n",
      "Epoch [2/5], Step [27790/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [27800/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [27810/30930], Loss: 0.0370\n",
      "Epoch [2/5], Step [27820/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [27830/30930], Loss: 0.0037\n",
      "Epoch [2/5], Step [27840/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27850/30930], Loss: 0.0119\n",
      "Epoch [2/5], Step [27860/30930], Loss: 0.0032\n",
      "Epoch [2/5], Step [27870/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27880/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [27890/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [27900/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27910/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [27920/30930], Loss: 0.0796\n",
      "Epoch [2/5], Step [27930/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [27940/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [27950/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [27960/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [27970/30930], Loss: 0.1053\n",
      "Epoch [2/5], Step [27980/30930], Loss: 0.0789\n",
      "Epoch [2/5], Step [27990/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [28000/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [28010/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [28020/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28030/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [28040/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [28050/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28060/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [28070/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [28080/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [28090/30930], Loss: 0.0230\n",
      "Epoch [2/5], Step [28100/30930], Loss: 0.0126\n",
      "Epoch [2/5], Step [28110/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [28120/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [28130/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [28140/30930], Loss: 0.0390\n",
      "Epoch [2/5], Step [28150/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [28160/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28170/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [28180/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [28190/30930], Loss: 0.0117\n",
      "Epoch [2/5], Step [28200/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [28210/30930], Loss: 0.0071\n",
      "Epoch [2/5], Step [28220/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [28230/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [28240/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [28250/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [28260/30930], Loss: 0.0040\n",
      "Epoch [2/5], Step [28270/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [28280/30930], Loss: 0.0080\n",
      "Epoch [2/5], Step [28290/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [28300/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [28310/30930], Loss: 0.0134\n",
      "Epoch [2/5], Step [28320/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28330/30930], Loss: 0.0150\n",
      "Epoch [2/5], Step [28340/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [28350/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28360/30930], Loss: 0.0821\n",
      "Epoch [2/5], Step [28370/30930], Loss: 0.0086\n",
      "Epoch [2/5], Step [28380/30930], Loss: 0.0127\n",
      "Epoch [2/5], Step [28390/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [28400/30930], Loss: 0.1042\n",
      "Epoch [2/5], Step [28410/30930], Loss: 0.0143\n",
      "Epoch [2/5], Step [28420/30930], Loss: 0.0231\n",
      "Epoch [2/5], Step [28430/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [28440/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [28450/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [28460/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [28470/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [28480/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [28490/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [28500/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [28510/30930], Loss: 0.0185\n",
      "Epoch [2/5], Step [28520/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [28530/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [28540/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [28550/30930], Loss: 0.0057\n",
      "Epoch [2/5], Step [28560/30930], Loss: 0.0027\n",
      "Epoch [2/5], Step [28570/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [28580/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [28590/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [28600/30930], Loss: 0.0114\n",
      "Epoch [2/5], Step [28610/30930], Loss: 0.0110\n",
      "Epoch [2/5], Step [28620/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [28630/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [28640/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [28650/30930], Loss: 0.0054\n",
      "Epoch [2/5], Step [28660/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [28670/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [28680/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [28690/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28700/30930], Loss: 0.0395\n",
      "Epoch [2/5], Step [28710/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [28720/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [28730/30930], Loss: 0.0021\n",
      "Epoch [2/5], Step [28740/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [28750/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [28760/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [28770/30930], Loss: 0.0735\n",
      "Epoch [2/5], Step [28780/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [28790/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [28800/30930], Loss: 0.0289\n",
      "Epoch [2/5], Step [28810/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [28820/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [28830/30930], Loss: 0.0095\n",
      "Epoch [2/5], Step [28840/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [28850/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [28860/30930], Loss: 0.1032\n",
      "Epoch [2/5], Step [28870/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [28880/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [28890/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [28900/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [28910/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [28920/30930], Loss: 0.0221\n",
      "Epoch [2/5], Step [28930/30930], Loss: 0.0133\n",
      "Epoch [2/5], Step [28940/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [28950/30930], Loss: 0.0117\n",
      "Epoch [2/5], Step [28960/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [28970/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [28980/30930], Loss: 0.0246\n",
      "Epoch [2/5], Step [28990/30930], Loss: 0.0130\n",
      "Epoch [2/5], Step [29000/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29010/30930], Loss: 0.0084\n",
      "Epoch [2/5], Step [29020/30930], Loss: 0.0036\n",
      "Epoch [2/5], Step [29030/30930], Loss: 0.0106\n",
      "Epoch [2/5], Step [29040/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [29050/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [29060/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [29070/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29080/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [29090/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [29100/30930], Loss: 0.0096\n",
      "Epoch [2/5], Step [29110/30930], Loss: 0.0049\n",
      "Epoch [2/5], Step [29120/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [29130/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29140/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [29150/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [29160/30930], Loss: 0.0065\n",
      "Epoch [2/5], Step [29170/30930], Loss: 0.0020\n",
      "Epoch [2/5], Step [29180/30930], Loss: 0.0387\n",
      "Epoch [2/5], Step [29190/30930], Loss: 0.0407\n",
      "Epoch [2/5], Step [29200/30930], Loss: 0.0058\n",
      "Epoch [2/5], Step [29210/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [29220/30930], Loss: 0.0044\n",
      "Epoch [2/5], Step [29230/30930], Loss: 0.0073\n",
      "Epoch [2/5], Step [29240/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29250/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [29260/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [29270/30930], Loss: 0.0081\n",
      "Epoch [2/5], Step [29280/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29290/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29300/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [29310/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [29320/30930], Loss: 0.0088\n",
      "Epoch [2/5], Step [29330/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [29340/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [29350/30930], Loss: 0.0154\n",
      "Epoch [2/5], Step [29360/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29370/30930], Loss: 0.0087\n",
      "Epoch [2/5], Step [29380/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [29390/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29400/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29410/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29420/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29430/30930], Loss: 0.0075\n",
      "Epoch [2/5], Step [29440/30930], Loss: 0.0275\n",
      "Epoch [2/5], Step [29450/30930], Loss: 0.0017\n",
      "Epoch [2/5], Step [29460/30930], Loss: 0.0050\n",
      "Epoch [2/5], Step [29470/30930], Loss: 0.0262\n",
      "Epoch [2/5], Step [29480/30930], Loss: 0.0068\n",
      "Epoch [2/5], Step [29490/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29500/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [29510/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29520/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [29530/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29540/30930], Loss: 0.0399\n",
      "Epoch [2/5], Step [29550/30930], Loss: 0.0480\n",
      "Epoch [2/5], Step [29560/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [29570/30930], Loss: 0.0841\n",
      "Epoch [2/5], Step [29580/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [29590/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29600/30930], Loss: 0.0431\n",
      "Epoch [2/5], Step [29610/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29620/30930], Loss: 0.0025\n",
      "Epoch [2/5], Step [29630/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29640/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [29650/30930], Loss: 0.0026\n",
      "Epoch [2/5], Step [29660/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [29670/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [29680/30930], Loss: 0.0005\n",
      "Epoch [2/5], Step [29690/30930], Loss: 0.0274\n",
      "Epoch [2/5], Step [29700/30930], Loss: 0.0031\n",
      "Epoch [2/5], Step [29710/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29720/30930], Loss: 0.0066\n",
      "Epoch [2/5], Step [29730/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [29740/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [29750/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [29760/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29770/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [29780/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [29790/30930], Loss: 0.0285\n",
      "Epoch [2/5], Step [29800/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29810/30930], Loss: 0.0310\n",
      "Epoch [2/5], Step [29820/30930], Loss: 0.0634\n",
      "Epoch [2/5], Step [29830/30930], Loss: 0.0070\n",
      "Epoch [2/5], Step [29840/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29850/30930], Loss: 0.0008\n",
      "Epoch [2/5], Step [29860/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29870/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29880/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [29890/30930], Loss: 0.0166\n",
      "Epoch [2/5], Step [29900/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [29910/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29920/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [29930/30930], Loss: 0.0016\n",
      "Epoch [2/5], Step [29940/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [29950/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [29960/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [29970/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [29980/30930], Loss: 0.0439\n",
      "Epoch [2/5], Step [29990/30930], Loss: 0.0033\n",
      "Epoch [2/5], Step [30000/30930], Loss: 0.0015\n",
      "Epoch [2/5], Step [30010/30930], Loss: 0.0053\n",
      "Epoch [2/5], Step [30020/30930], Loss: 0.0140\n",
      "Epoch [2/5], Step [30030/30930], Loss: 0.0490\n",
      "Epoch [2/5], Step [30040/30930], Loss: 0.0562\n",
      "Epoch [2/5], Step [30050/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [30060/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [30070/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [30080/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30090/30930], Loss: 0.0340\n",
      "Epoch [2/5], Step [30100/30930], Loss: 0.0063\n",
      "Epoch [2/5], Step [30110/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30120/30930], Loss: 0.0078\n",
      "Epoch [2/5], Step [30130/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [30140/30930], Loss: 0.0014\n",
      "Epoch [2/5], Step [30150/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [30160/30930], Loss: 0.0023\n",
      "Epoch [2/5], Step [30170/30930], Loss: 0.0142\n",
      "Epoch [2/5], Step [30180/30930], Loss: 0.0045\n",
      "Epoch [2/5], Step [30190/30930], Loss: 0.0258\n",
      "Epoch [2/5], Step [30200/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [30210/30930], Loss: 0.0256\n",
      "Epoch [2/5], Step [30220/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30230/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30240/30930], Loss: 0.0120\n",
      "Epoch [2/5], Step [30250/30930], Loss: 0.0039\n",
      "Epoch [2/5], Step [30260/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [30270/30930], Loss: 0.0046\n",
      "Epoch [2/5], Step [30280/30930], Loss: 0.0019\n",
      "Epoch [2/5], Step [30290/30930], Loss: 0.0022\n",
      "Epoch [2/5], Step [30300/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30310/30930], Loss: 0.0092\n",
      "Epoch [2/5], Step [30320/30930], Loss: 0.0041\n",
      "Epoch [2/5], Step [30330/30930], Loss: 0.0034\n",
      "Epoch [2/5], Step [30340/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [30350/30930], Loss: 0.0003\n",
      "Epoch [2/5], Step [30360/30930], Loss: 0.0028\n",
      "Epoch [2/5], Step [30370/30930], Loss: 0.0152\n",
      "Epoch [2/5], Step [30380/30930], Loss: 0.0239\n",
      "Epoch [2/5], Step [30390/30930], Loss: 0.2395\n",
      "Epoch [2/5], Step [30400/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30410/30930], Loss: 0.0047\n",
      "Epoch [2/5], Step [30420/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [30430/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [30440/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [30450/30930], Loss: 0.0135\n",
      "Epoch [2/5], Step [30460/30930], Loss: 0.0195\n",
      "Epoch [2/5], Step [30470/30930], Loss: 0.0013\n",
      "Epoch [2/5], Step [30480/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [30490/30930], Loss: 0.0417\n",
      "Epoch [2/5], Step [30500/30930], Loss: 0.0012\n",
      "Epoch [2/5], Step [30510/30930], Loss: 0.0083\n",
      "Epoch [2/5], Step [30520/30930], Loss: 0.0010\n",
      "Epoch [2/5], Step [30530/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30540/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [30550/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30560/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [30570/30930], Loss: 0.0007\n",
      "Epoch [2/5], Step [30580/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30590/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30600/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30610/30930], Loss: 0.0099\n",
      "Epoch [2/5], Step [30620/30930], Loss: 0.0064\n",
      "Epoch [2/5], Step [30630/30930], Loss: 0.0635\n",
      "Epoch [2/5], Step [30640/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30650/30930], Loss: 0.0281\n",
      "Epoch [2/5], Step [30660/30930], Loss: 0.0337\n",
      "Epoch [2/5], Step [30670/30930], Loss: 0.0004\n",
      "Epoch [2/5], Step [30680/30930], Loss: 0.0365\n",
      "Epoch [2/5], Step [30690/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [30700/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [30710/30930], Loss: 0.0043\n",
      "Epoch [2/5], Step [30720/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [30730/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [30740/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [30750/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30760/30930], Loss: 0.0000\n",
      "Epoch [2/5], Step [30770/30930], Loss: 0.0568\n",
      "Epoch [2/5], Step [30780/30930], Loss: 0.0085\n",
      "Epoch [2/5], Step [30790/30930], Loss: 0.0011\n",
      "Epoch [2/5], Step [30800/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30810/30930], Loss: 0.0055\n",
      "Epoch [2/5], Step [30820/30930], Loss: 0.0024\n",
      "Epoch [2/5], Step [30830/30930], Loss: 0.0002\n",
      "Epoch [2/5], Step [30840/30930], Loss: 0.0030\n",
      "Epoch [2/5], Step [30850/30930], Loss: 0.0035\n",
      "Epoch [2/5], Step [30860/30930], Loss: 0.0006\n",
      "Epoch [2/5], Step [30870/30930], Loss: 0.0162\n",
      "Epoch [2/5], Step [30880/30930], Loss: 0.0001\n",
      "Epoch [2/5], Step [30890/30930], Loss: 0.0062\n",
      "Epoch [2/5], Step [30900/30930], Loss: 0.0069\n",
      "Epoch [2/5], Step [30910/30930], Loss: 0.0018\n",
      "Epoch [2/5], Step [30920/30930], Loss: 0.0009\n",
      "Epoch [2/5], Step [30930/30930], Loss: 0.0606\n",
      "Epoch [2/5], Average Train Loss: 0.0110\n",
      "Epoch [2/5], Validation Loss: 0.0107\n",
      "Epoch [3/5], Step [10/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [20/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [30/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [40/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [50/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [60/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [70/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [80/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [90/30930], Loss: 0.0132\n",
      "Epoch [3/5], Step [100/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [110/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [120/30930], Loss: 0.0117\n",
      "Epoch [3/5], Step [130/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [140/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [150/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [160/30930], Loss: 0.0427\n",
      "Epoch [3/5], Step [170/30930], Loss: 0.0406\n",
      "Epoch [3/5], Step [180/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [190/30930], Loss: 0.0802\n",
      "Epoch [3/5], Step [200/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [210/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [220/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [230/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [240/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [250/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [260/30930], Loss: 0.0400\n",
      "Epoch [3/5], Step [270/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [280/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [290/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [300/30930], Loss: 0.0210\n",
      "Epoch [3/5], Step [310/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [320/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [330/30930], Loss: 0.0116\n",
      "Epoch [3/5], Step [340/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [350/30930], Loss: 0.0119\n",
      "Epoch [3/5], Step [360/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [370/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [380/30930], Loss: 0.0290\n",
      "Epoch [3/5], Step [390/30930], Loss: 0.0402\n",
      "Epoch [3/5], Step [400/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [410/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [420/30930], Loss: 0.0080\n",
      "Epoch [3/5], Step [430/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [440/30930], Loss: 0.0582\n",
      "Epoch [3/5], Step [450/30930], Loss: 0.0398\n",
      "Epoch [3/5], Step [460/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [470/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [480/30930], Loss: 0.0184\n",
      "Epoch [3/5], Step [490/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [500/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [510/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [520/30930], Loss: 0.1386\n",
      "Epoch [3/5], Step [530/30930], Loss: 0.0176\n",
      "Epoch [3/5], Step [540/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [550/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [560/30930], Loss: 0.0539\n",
      "Epoch [3/5], Step [570/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [580/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [590/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [600/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [610/30930], Loss: 0.0238\n",
      "Epoch [3/5], Step [620/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [630/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [640/30930], Loss: 0.0105\n",
      "Epoch [3/5], Step [650/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [660/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [670/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [680/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [690/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [700/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [710/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [720/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [730/30930], Loss: 0.0081\n",
      "Epoch [3/5], Step [740/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [750/30930], Loss: 0.0958\n",
      "Epoch [3/5], Step [760/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [770/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [780/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [790/30930], Loss: 0.0367\n",
      "Epoch [3/5], Step [800/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [810/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [820/30930], Loss: 0.0275\n",
      "Epoch [3/5], Step [830/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [840/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [850/30930], Loss: 0.0615\n",
      "Epoch [3/5], Step [860/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [870/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [880/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [890/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [900/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [910/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [920/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [930/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [940/30930], Loss: 0.0430\n",
      "Epoch [3/5], Step [950/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [960/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [970/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [980/30930], Loss: 0.0430\n",
      "Epoch [3/5], Step [990/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [1000/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [1010/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [1020/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [1030/30930], Loss: 0.0215\n",
      "Epoch [3/5], Step [1040/30930], Loss: 0.0213\n",
      "Epoch [3/5], Step [1050/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [1060/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [1070/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1080/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1090/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [1100/30930], Loss: 0.0306\n",
      "Epoch [3/5], Step [1110/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [1120/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1130/30930], Loss: 0.0645\n",
      "Epoch [3/5], Step [1140/30930], Loss: 0.0279\n",
      "Epoch [3/5], Step [1150/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [1160/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [1170/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [1180/30930], Loss: 0.0154\n",
      "Epoch [3/5], Step [1190/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [1200/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [1210/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [1220/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [1230/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [1240/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [1250/30930], Loss: 0.0066\n",
      "Epoch [3/5], Step [1260/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1270/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [1280/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [1290/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [1300/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [1310/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [1320/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1330/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [1340/30930], Loss: 0.0421\n",
      "Epoch [3/5], Step [1350/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [1360/30930], Loss: 0.0081\n",
      "Epoch [3/5], Step [1370/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [1380/30930], Loss: 0.0183\n",
      "Epoch [3/5], Step [1390/30930], Loss: 0.0148\n",
      "Epoch [3/5], Step [1400/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [1410/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [1420/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [1430/30930], Loss: 0.0151\n",
      "Epoch [3/5], Step [1440/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [1450/30930], Loss: 0.0131\n",
      "Epoch [3/5], Step [1460/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [1470/30930], Loss: 0.0097\n",
      "Epoch [3/5], Step [1480/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1490/30930], Loss: 0.1134\n",
      "Epoch [3/5], Step [1500/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [1510/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [1520/30930], Loss: 0.0093\n",
      "Epoch [3/5], Step [1530/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [1540/30930], Loss: 0.0398\n",
      "Epoch [3/5], Step [1550/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [1560/30930], Loss: 0.0080\n",
      "Epoch [3/5], Step [1570/30930], Loss: 0.0262\n",
      "Epoch [3/5], Step [1580/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [1590/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [1600/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [1610/30930], Loss: 0.0300\n",
      "Epoch [3/5], Step [1620/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [1630/30930], Loss: 0.0249\n",
      "Epoch [3/5], Step [1640/30930], Loss: 0.0253\n",
      "Epoch [3/5], Step [1650/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [1660/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [1670/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [1680/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1690/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1700/30930], Loss: 0.0263\n",
      "Epoch [3/5], Step [1710/30930], Loss: 0.0168\n",
      "Epoch [3/5], Step [1720/30930], Loss: 0.0130\n",
      "Epoch [3/5], Step [1730/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [1740/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1750/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [1760/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [1770/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [1780/30930], Loss: 0.0284\n",
      "Epoch [3/5], Step [1790/30930], Loss: 0.0327\n",
      "Epoch [3/5], Step [1800/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [1810/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [1820/30930], Loss: 0.0353\n",
      "Epoch [3/5], Step [1830/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [1840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1850/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [1860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1870/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [1880/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [1890/30930], Loss: 0.0313\n",
      "Epoch [3/5], Step [1900/30930], Loss: 0.0337\n",
      "Epoch [3/5], Step [1910/30930], Loss: 0.0316\n",
      "Epoch [3/5], Step [1920/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [1930/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [1940/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [1950/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [1960/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [1970/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [1980/30930], Loss: 0.0356\n",
      "Epoch [3/5], Step [1990/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [2000/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [2010/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [2020/30930], Loss: 0.0158\n",
      "Epoch [3/5], Step [2030/30930], Loss: 0.0206\n",
      "Epoch [3/5], Step [2040/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [2050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2060/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [2070/30930], Loss: 0.0254\n",
      "Epoch [3/5], Step [2080/30930], Loss: 0.0514\n",
      "Epoch [3/5], Step [2090/30930], Loss: 0.0106\n",
      "Epoch [3/5], Step [2100/30930], Loss: 0.0825\n",
      "Epoch [3/5], Step [2110/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [2120/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [2130/30930], Loss: 0.0191\n",
      "Epoch [3/5], Step [2140/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [2150/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [2160/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [2170/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [2180/30930], Loss: 0.0500\n",
      "Epoch [3/5], Step [2190/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2200/30930], Loss: 0.0242\n",
      "Epoch [3/5], Step [2210/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [2220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2230/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [2240/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [2250/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [2260/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [2270/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [2280/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [2290/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [2300/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [2310/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [2320/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2330/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [2340/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [2350/30930], Loss: 0.0305\n",
      "Epoch [3/5], Step [2360/30930], Loss: 0.0102\n",
      "Epoch [3/5], Step [2370/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [2380/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [2390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2400/30930], Loss: 0.0495\n",
      "Epoch [3/5], Step [2410/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [2420/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [2430/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [2440/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2450/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [2460/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [2470/30930], Loss: 0.0360\n",
      "Epoch [3/5], Step [2480/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2490/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2500/30930], Loss: 0.0126\n",
      "Epoch [3/5], Step [2510/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2520/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [2530/30930], Loss: 0.0403\n",
      "Epoch [3/5], Step [2540/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [2550/30930], Loss: 0.0186\n",
      "Epoch [3/5], Step [2560/30930], Loss: 0.0106\n",
      "Epoch [3/5], Step [2570/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [2580/30930], Loss: 0.0470\n",
      "Epoch [3/5], Step [2590/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2600/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [2610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2620/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [2630/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [2640/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [2650/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [2660/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [2670/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [2680/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [2690/30930], Loss: 0.0490\n",
      "Epoch [3/5], Step [2700/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [2710/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [2720/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2730/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2740/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [2750/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2760/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2780/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2790/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [2800/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [2810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2820/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2830/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [2840/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [2850/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [2860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2870/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2880/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [2890/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [2900/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [2910/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [2920/30930], Loss: 0.0106\n",
      "Epoch [3/5], Step [2930/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [2940/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [2950/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [2960/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [2970/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [2980/30930], Loss: 0.0343\n",
      "Epoch [3/5], Step [2990/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3000/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3010/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [3020/30930], Loss: 0.0409\n",
      "Epoch [3/5], Step [3030/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [3040/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [3050/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [3060/30930], Loss: 0.0109\n",
      "Epoch [3/5], Step [3070/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3080/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [3090/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3100/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [3110/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [3120/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [3130/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [3140/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3150/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [3160/30930], Loss: 0.0226\n",
      "Epoch [3/5], Step [3170/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [3180/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [3190/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [3200/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [3210/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [3220/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [3230/30930], Loss: 0.0097\n",
      "Epoch [3/5], Step [3240/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3250/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [3260/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3270/30930], Loss: 0.0172\n",
      "Epoch [3/5], Step [3280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3290/30930], Loss: 0.0214\n",
      "Epoch [3/5], Step [3300/30930], Loss: 0.0248\n",
      "Epoch [3/5], Step [3310/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3320/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [3330/30930], Loss: 0.0141\n",
      "Epoch [3/5], Step [3340/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3350/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [3360/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3370/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [3380/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [3390/30930], Loss: 0.0386\n",
      "Epoch [3/5], Step [3400/30930], Loss: 0.0152\n",
      "Epoch [3/5], Step [3410/30930], Loss: 0.0081\n",
      "Epoch [3/5], Step [3420/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3430/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [3440/30930], Loss: 0.0488\n",
      "Epoch [3/5], Step [3450/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [3460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3470/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [3480/30930], Loss: 0.0212\n",
      "Epoch [3/5], Step [3490/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [3500/30930], Loss: 0.0397\n",
      "Epoch [3/5], Step [3510/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [3520/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [3530/30930], Loss: 0.0456\n",
      "Epoch [3/5], Step [3540/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [3550/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [3560/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [3570/30930], Loss: 0.0234\n",
      "Epoch [3/5], Step [3580/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [3590/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [3600/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [3610/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3620/30930], Loss: 0.0246\n",
      "Epoch [3/5], Step [3630/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [3640/30930], Loss: 0.0532\n",
      "Epoch [3/5], Step [3650/30930], Loss: 0.0133\n",
      "Epoch [3/5], Step [3660/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [3670/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [3680/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [3690/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3700/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [3710/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [3720/30930], Loss: 0.0322\n",
      "Epoch [3/5], Step [3730/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [3740/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [3750/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3760/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3770/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [3780/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [3790/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [3800/30930], Loss: 0.0230\n",
      "Epoch [3/5], Step [3810/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [3820/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [3830/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [3840/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [3850/30930], Loss: 0.0116\n",
      "Epoch [3/5], Step [3860/30930], Loss: 0.0143\n",
      "Epoch [3/5], Step [3870/30930], Loss: 0.0076\n",
      "Epoch [3/5], Step [3880/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [3890/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [3900/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3910/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [3920/30930], Loss: 0.0301\n",
      "Epoch [3/5], Step [3930/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [3940/30930], Loss: 0.0626\n",
      "Epoch [3/5], Step [3950/30930], Loss: 0.0205\n",
      "Epoch [3/5], Step [3960/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [3970/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [3980/30930], Loss: 0.0259\n",
      "Epoch [3/5], Step [3990/30930], Loss: 0.0297\n",
      "Epoch [3/5], Step [4000/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [4010/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4020/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [4030/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [4040/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [4050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4060/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [4070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4080/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4090/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [4100/30930], Loss: 0.0293\n",
      "Epoch [3/5], Step [4110/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [4120/30930], Loss: 0.0108\n",
      "Epoch [3/5], Step [4130/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [4140/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4150/30930], Loss: 0.0305\n",
      "Epoch [3/5], Step [4160/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [4170/30930], Loss: 0.0127\n",
      "Epoch [3/5], Step [4180/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4190/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [4200/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4210/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [4220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4230/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4240/30930], Loss: 0.0102\n",
      "Epoch [3/5], Step [4250/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [4260/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4270/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4290/30930], Loss: 0.0137\n",
      "Epoch [3/5], Step [4300/30930], Loss: 0.0149\n",
      "Epoch [3/5], Step [4310/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [4320/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [4330/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [4340/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [4350/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [4360/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [4370/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4380/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [4390/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [4400/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [4410/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4420/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [4430/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [4440/30930], Loss: 0.0997\n",
      "Epoch [3/5], Step [4450/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [4460/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [4470/30930], Loss: 0.0946\n",
      "Epoch [3/5], Step [4480/30930], Loss: 0.0748\n",
      "Epoch [3/5], Step [4490/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [4500/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [4510/30930], Loss: 0.1083\n",
      "Epoch [3/5], Step [4520/30930], Loss: 0.0151\n",
      "Epoch [3/5], Step [4530/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [4540/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4550/30930], Loss: 0.0126\n",
      "Epoch [3/5], Step [4560/30930], Loss: 0.1258\n",
      "Epoch [3/5], Step [4570/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [4580/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4590/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [4600/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [4610/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [4620/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [4630/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [4640/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [4650/30930], Loss: 0.0130\n",
      "Epoch [3/5], Step [4660/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [4670/30930], Loss: 0.0404\n",
      "Epoch [3/5], Step [4680/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4690/30930], Loss: 0.0288\n",
      "Epoch [3/5], Step [4700/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [4710/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [4720/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4730/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [4740/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [4750/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [4760/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [4770/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [4780/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [4790/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [4800/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [4810/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [4820/30930], Loss: 0.0117\n",
      "Epoch [3/5], Step [4830/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [4840/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [4850/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [4860/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [4870/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [4880/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [4890/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [4900/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4910/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [4920/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [4930/30930], Loss: 0.0402\n",
      "Epoch [3/5], Step [4940/30930], Loss: 0.0221\n",
      "Epoch [3/5], Step [4950/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [4960/30930], Loss: 0.0247\n",
      "Epoch [3/5], Step [4970/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [4980/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [4990/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [5000/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [5010/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [5020/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [5030/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [5040/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [5050/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [5060/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [5070/30930], Loss: 0.0603\n",
      "Epoch [3/5], Step [5080/30930], Loss: 0.0560\n",
      "Epoch [3/5], Step [5090/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [5100/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [5110/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [5120/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [5130/30930], Loss: 0.0867\n",
      "Epoch [3/5], Step [5140/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [5150/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [5160/30930], Loss: 0.0417\n",
      "Epoch [3/5], Step [5170/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [5180/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [5190/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5200/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [5210/30930], Loss: 0.0411\n",
      "Epoch [3/5], Step [5220/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [5230/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5240/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [5250/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5260/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [5270/30930], Loss: 0.0080\n",
      "Epoch [3/5], Step [5280/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [5290/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [5300/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [5310/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [5320/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [5330/30930], Loss: 0.0200\n",
      "Epoch [3/5], Step [5340/30930], Loss: 0.0091\n",
      "Epoch [3/5], Step [5350/30930], Loss: 0.0109\n",
      "Epoch [3/5], Step [5360/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [5370/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [5380/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [5390/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [5400/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [5410/30930], Loss: 0.0418\n",
      "Epoch [3/5], Step [5420/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [5430/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [5440/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [5450/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [5460/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5470/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [5480/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [5490/30930], Loss: 0.0225\n",
      "Epoch [3/5], Step [5500/30930], Loss: 0.0229\n",
      "Epoch [3/5], Step [5510/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [5520/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [5530/30930], Loss: 0.0268\n",
      "Epoch [3/5], Step [5540/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [5550/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [5560/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [5570/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [5580/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [5590/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [5600/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [5610/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [5620/30930], Loss: 0.0132\n",
      "Epoch [3/5], Step [5630/30930], Loss: 0.0666\n",
      "Epoch [3/5], Step [5640/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [5650/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [5660/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [5670/30930], Loss: 0.0381\n",
      "Epoch [3/5], Step [5680/30930], Loss: 0.0184\n",
      "Epoch [3/5], Step [5690/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [5700/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [5710/30930], Loss: 0.0473\n",
      "Epoch [3/5], Step [5720/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [5730/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [5740/30930], Loss: 0.0282\n",
      "Epoch [3/5], Step [5750/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [5760/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5770/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [5780/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [5790/30930], Loss: 0.0175\n",
      "Epoch [3/5], Step [5800/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [5810/30930], Loss: 0.0076\n",
      "Epoch [3/5], Step [5820/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [5830/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [5840/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [5850/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [5860/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [5870/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [5880/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [5890/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [5900/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [5910/30930], Loss: 0.0209\n",
      "Epoch [3/5], Step [5920/30930], Loss: 0.0088\n",
      "Epoch [3/5], Step [5930/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [5940/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [5950/30930], Loss: 0.0891\n",
      "Epoch [3/5], Step [5960/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [5970/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [5980/30930], Loss: 0.0621\n",
      "Epoch [3/5], Step [5990/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [6000/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [6010/30930], Loss: 0.0307\n",
      "Epoch [3/5], Step [6020/30930], Loss: 0.0189\n",
      "Epoch [3/5], Step [6030/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6040/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [6050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6080/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [6090/30930], Loss: 0.0327\n",
      "Epoch [3/5], Step [6100/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6110/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [6120/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [6130/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [6140/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [6150/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [6160/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [6170/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [6180/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6190/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [6200/30930], Loss: 0.0622\n",
      "Epoch [3/5], Step [6210/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [6220/30930], Loss: 0.0066\n",
      "Epoch [3/5], Step [6230/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6240/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [6250/30930], Loss: 0.0377\n",
      "Epoch [3/5], Step [6260/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [6270/30930], Loss: 0.0242\n",
      "Epoch [3/5], Step [6280/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [6290/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [6300/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [6310/30930], Loss: 0.0263\n",
      "Epoch [3/5], Step [6320/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [6330/30930], Loss: 0.0175\n",
      "Epoch [3/5], Step [6340/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6350/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [6360/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6370/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [6380/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [6390/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [6400/30930], Loss: 0.0081\n",
      "Epoch [3/5], Step [6410/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6420/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [6430/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [6440/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [6450/30930], Loss: 0.0381\n",
      "Epoch [3/5], Step [6460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6470/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [6480/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6490/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [6500/30930], Loss: 0.0436\n",
      "Epoch [3/5], Step [6510/30930], Loss: 0.0467\n",
      "Epoch [3/5], Step [6520/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [6530/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [6540/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [6550/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [6560/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6570/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [6580/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6590/30930], Loss: 0.0574\n",
      "Epoch [3/5], Step [6600/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [6610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6620/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [6630/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6640/30930], Loss: 0.0176\n",
      "Epoch [3/5], Step [6650/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [6660/30930], Loss: 0.0216\n",
      "Epoch [3/5], Step [6670/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6680/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6690/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [6700/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6710/30930], Loss: 0.0364\n",
      "Epoch [3/5], Step [6720/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [6730/30930], Loss: 0.0200\n",
      "Epoch [3/5], Step [6740/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [6750/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [6760/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [6770/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [6780/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [6790/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [6800/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [6810/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [6820/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [6830/30930], Loss: 0.0119\n",
      "Epoch [3/5], Step [6840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6850/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [6860/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [6870/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [6880/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6900/30930], Loss: 0.0699\n",
      "Epoch [3/5], Step [6910/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [6920/30930], Loss: 0.0069\n",
      "Epoch [3/5], Step [6930/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [6940/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [6950/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [6960/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [6970/30930], Loss: 0.0404\n",
      "Epoch [3/5], Step [6980/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [6990/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [7000/30930], Loss: 0.0119\n",
      "Epoch [3/5], Step [7010/30930], Loss: 0.0460\n",
      "Epoch [3/5], Step [7020/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [7030/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [7040/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [7050/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [7060/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [7070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7080/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [7090/30930], Loss: 0.0327\n",
      "Epoch [3/5], Step [7100/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [7110/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7120/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7130/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [7140/30930], Loss: 0.0326\n",
      "Epoch [3/5], Step [7150/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [7160/30930], Loss: 0.0248\n",
      "Epoch [3/5], Step [7170/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [7180/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [7190/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7210/30930], Loss: 0.0266\n",
      "Epoch [3/5], Step [7220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7230/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7240/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [7250/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [7260/30930], Loss: 0.0767\n",
      "Epoch [3/5], Step [7270/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [7280/30930], Loss: 0.0118\n",
      "Epoch [3/5], Step [7290/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [7300/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [7310/30930], Loss: 0.0663\n",
      "Epoch [3/5], Step [7320/30930], Loss: 0.0352\n",
      "Epoch [3/5], Step [7330/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [7340/30930], Loss: 0.0091\n",
      "Epoch [3/5], Step [7350/30930], Loss: 0.0535\n",
      "Epoch [3/5], Step [7360/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [7370/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [7380/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [7390/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [7400/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [7410/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [7420/30930], Loss: 0.2413\n",
      "Epoch [3/5], Step [7430/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [7440/30930], Loss: 0.0284\n",
      "Epoch [3/5], Step [7450/30930], Loss: 0.0182\n",
      "Epoch [3/5], Step [7460/30930], Loss: 0.0132\n",
      "Epoch [3/5], Step [7470/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [7480/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [7490/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7500/30930], Loss: 0.0098\n",
      "Epoch [3/5], Step [7510/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [7520/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [7530/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [7540/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [7550/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [7560/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [7570/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [7580/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [7590/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [7600/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [7610/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [7620/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [7630/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7640/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [7650/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [7660/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7670/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [7680/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [7690/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [7700/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [7710/30930], Loss: 0.0523\n",
      "Epoch [3/5], Step [7720/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [7730/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [7740/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [7750/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7760/30930], Loss: 0.0218\n",
      "Epoch [3/5], Step [7770/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [7780/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [7790/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [7800/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [7810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7820/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [7830/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [7840/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [7850/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [7860/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7870/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [7880/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [7890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7900/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [7910/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [7920/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [7930/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [7940/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7950/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [7960/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [7970/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [7980/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [7990/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [8000/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [8010/30930], Loss: 0.0291\n",
      "Epoch [3/5], Step [8020/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8030/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [8040/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [8050/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [8060/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8070/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [8080/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [8090/30930], Loss: 0.1247\n",
      "Epoch [3/5], Step [8100/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [8110/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [8120/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [8130/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [8140/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8150/30930], Loss: 0.0105\n",
      "Epoch [3/5], Step [8160/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8180/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [8190/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8200/30930], Loss: 0.0170\n",
      "Epoch [3/5], Step [8210/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [8220/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [8230/30930], Loss: 0.0085\n",
      "Epoch [3/5], Step [8240/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [8250/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8260/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [8270/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8280/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8290/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [8300/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [8310/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [8320/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8330/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8340/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [8350/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [8360/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8370/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8380/30930], Loss: 0.0208\n",
      "Epoch [3/5], Step [8390/30930], Loss: 0.0087\n",
      "Epoch [3/5], Step [8400/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [8410/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [8420/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [8430/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [8440/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [8450/30930], Loss: 0.0166\n",
      "Epoch [3/5], Step [8460/30930], Loss: 0.0123\n",
      "Epoch [3/5], Step [8470/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8480/30930], Loss: 0.0206\n",
      "Epoch [3/5], Step [8490/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [8500/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8510/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8520/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [8530/30930], Loss: 0.0158\n",
      "Epoch [3/5], Step [8540/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [8550/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [8560/30930], Loss: 0.0196\n",
      "Epoch [3/5], Step [8570/30930], Loss: 0.0268\n",
      "Epoch [3/5], Step [8580/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [8590/30930], Loss: 0.0091\n",
      "Epoch [3/5], Step [8600/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [8610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8620/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [8630/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [8640/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8650/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [8660/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8670/30930], Loss: 0.0470\n",
      "Epoch [3/5], Step [8680/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [8690/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [8700/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [8710/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [8720/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [8730/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [8740/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [8750/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [8760/30930], Loss: 0.0256\n",
      "Epoch [3/5], Step [8770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8780/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8790/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [8800/30930], Loss: 0.0156\n",
      "Epoch [3/5], Step [8810/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [8820/30930], Loss: 0.0210\n",
      "Epoch [3/5], Step [8830/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8840/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [8850/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [8860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [8870/30930], Loss: 0.0293\n",
      "Epoch [3/5], Step [8880/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [8890/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [8900/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [8910/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [8920/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [8930/30930], Loss: 0.0082\n",
      "Epoch [3/5], Step [8940/30930], Loss: 0.0428\n",
      "Epoch [3/5], Step [8950/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [8960/30930], Loss: 0.0316\n",
      "Epoch [3/5], Step [8970/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8980/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [8990/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [9000/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [9010/30930], Loss: 0.0126\n",
      "Epoch [3/5], Step [9020/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [9030/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [9040/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [9050/30930], Loss: 0.0241\n",
      "Epoch [3/5], Step [9060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9070/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [9080/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [9090/30930], Loss: 0.0083\n",
      "Epoch [3/5], Step [9100/30930], Loss: 0.0346\n",
      "Epoch [3/5], Step [9110/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [9120/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9130/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [9140/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [9150/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [9160/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9170/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [9180/30930], Loss: 0.0178\n",
      "Epoch [3/5], Step [9190/30930], Loss: 0.0299\n",
      "Epoch [3/5], Step [9200/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [9210/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9220/30930], Loss: 0.0222\n",
      "Epoch [3/5], Step [9230/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9240/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [9250/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9260/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [9270/30930], Loss: 0.0205\n",
      "Epoch [3/5], Step [9280/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [9290/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [9300/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9310/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [9320/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9330/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [9340/30930], Loss: 0.2082\n",
      "Epoch [3/5], Step [9350/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [9360/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [9370/30930], Loss: 0.0243\n",
      "Epoch [3/5], Step [9380/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [9390/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [9400/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9410/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [9420/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9430/30930], Loss: 0.0118\n",
      "Epoch [3/5], Step [9440/30930], Loss: 0.0171\n",
      "Epoch [3/5], Step [9450/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [9460/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [9470/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [9480/30930], Loss: 0.0572\n",
      "Epoch [3/5], Step [9490/30930], Loss: 0.0201\n",
      "Epoch [3/5], Step [9500/30930], Loss: 0.0269\n",
      "Epoch [3/5], Step [9510/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [9520/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [9530/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [9540/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [9550/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [9560/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9570/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9580/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9590/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [9600/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9620/30930], Loss: 0.0255\n",
      "Epoch [3/5], Step [9630/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9640/30930], Loss: 0.0130\n",
      "Epoch [3/5], Step [9650/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [9660/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [9670/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [9680/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [9690/30930], Loss: 0.0099\n",
      "Epoch [3/5], Step [9700/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9710/30930], Loss: 0.0325\n",
      "Epoch [3/5], Step [9720/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [9730/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [9740/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9750/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [9760/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9770/30930], Loss: 0.0382\n",
      "Epoch [3/5], Step [9780/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [9790/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9800/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [9810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9820/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [9830/30930], Loss: 0.0141\n",
      "Epoch [3/5], Step [9840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9850/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [9860/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9870/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [9880/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [9890/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [9900/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [9910/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9920/30930], Loss: 0.0087\n",
      "Epoch [3/5], Step [9930/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [9940/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [9950/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [9960/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9970/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [9980/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [9990/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [10000/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [10010/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [10020/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [10030/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [10040/30930], Loss: 0.0164\n",
      "Epoch [3/5], Step [10050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10060/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [10070/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [10080/30930], Loss: 0.0232\n",
      "Epoch [3/5], Step [10090/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [10100/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [10110/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [10120/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [10130/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [10140/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [10150/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [10160/30930], Loss: 0.0169\n",
      "Epoch [3/5], Step [10170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10180/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [10190/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [10200/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [10210/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [10220/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [10230/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [10240/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [10250/30930], Loss: 0.0398\n",
      "Epoch [3/5], Step [10260/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [10270/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10280/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [10290/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [10300/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [10310/30930], Loss: 0.0202\n",
      "Epoch [3/5], Step [10320/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10330/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10340/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10350/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [10360/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [10370/30930], Loss: 0.0108\n",
      "Epoch [3/5], Step [10380/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [10390/30930], Loss: 0.0167\n",
      "Epoch [3/5], Step [10400/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [10410/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [10420/30930], Loss: 0.0251\n",
      "Epoch [3/5], Step [10430/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [10440/30930], Loss: 0.0127\n",
      "Epoch [3/5], Step [10450/30930], Loss: 0.0408\n",
      "Epoch [3/5], Step [10460/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [10470/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10480/30930], Loss: 0.0080\n",
      "Epoch [3/5], Step [10490/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10500/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [10510/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10520/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [10530/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [10540/30930], Loss: 0.0070\n",
      "Epoch [3/5], Step [10550/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [10560/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [10570/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [10580/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [10590/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [10600/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [10610/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [10620/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [10630/30930], Loss: 0.0567\n",
      "Epoch [3/5], Step [10640/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [10650/30930], Loss: 0.0364\n",
      "Epoch [3/5], Step [10660/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [10670/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [10680/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [10690/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [10700/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10710/30930], Loss: 0.0533\n",
      "Epoch [3/5], Step [10720/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10730/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [10740/30930], Loss: 0.0343\n",
      "Epoch [3/5], Step [10750/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [10760/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [10770/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [10780/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [10790/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10800/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [10810/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [10820/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [10830/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [10840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10850/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [10860/30930], Loss: 0.0268\n",
      "Epoch [3/5], Step [10870/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [10880/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [10890/30930], Loss: 0.0180\n",
      "Epoch [3/5], Step [10900/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [10910/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [10920/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10930/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10940/30930], Loss: 0.0269\n",
      "Epoch [3/5], Step [10950/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [10960/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [10970/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [10980/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [10990/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [11000/30930], Loss: 0.0082\n",
      "Epoch [3/5], Step [11010/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11020/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [11030/30930], Loss: 0.0331\n",
      "Epoch [3/5], Step [11040/30930], Loss: 0.0116\n",
      "Epoch [3/5], Step [11050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11060/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [11070/30930], Loss: 0.0149\n",
      "Epoch [3/5], Step [11080/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [11090/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [11100/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [11110/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [11120/30930], Loss: 0.0359\n",
      "Epoch [3/5], Step [11130/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [11140/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [11150/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [11160/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [11170/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [11180/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [11190/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [11200/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [11210/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [11220/30930], Loss: 0.0349\n",
      "Epoch [3/5], Step [11230/30930], Loss: 0.0258\n",
      "Epoch [3/5], Step [11240/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [11250/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [11260/30930], Loss: 0.0088\n",
      "Epoch [3/5], Step [11270/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [11280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11290/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [11300/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [11310/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11320/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [11330/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [11340/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [11350/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [11360/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [11370/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11380/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11390/30930], Loss: 0.0642\n",
      "Epoch [3/5], Step [11400/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [11410/30930], Loss: 0.0278\n",
      "Epoch [3/5], Step [11420/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11430/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [11440/30930], Loss: 0.0100\n",
      "Epoch [3/5], Step [11450/30930], Loss: 0.0102\n",
      "Epoch [3/5], Step [11460/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [11470/30930], Loss: 0.0351\n",
      "Epoch [3/5], Step [11480/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [11490/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [11500/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [11510/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [11520/30930], Loss: 0.0382\n",
      "Epoch [3/5], Step [11530/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [11540/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [11550/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [11560/30930], Loss: 0.1034\n",
      "Epoch [3/5], Step [11570/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [11580/30930], Loss: 0.0589\n",
      "Epoch [3/5], Step [11590/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [11600/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [11610/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [11620/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [11630/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [11640/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11650/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [11660/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11670/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [11680/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [11690/30930], Loss: 0.0243\n",
      "Epoch [3/5], Step [11700/30930], Loss: 0.0090\n",
      "Epoch [3/5], Step [11710/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11720/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [11730/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [11740/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [11750/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [11760/30930], Loss: 0.0228\n",
      "Epoch [3/5], Step [11770/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [11780/30930], Loss: 0.0157\n",
      "Epoch [3/5], Step [11790/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [11800/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [11810/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [11820/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [11830/30930], Loss: 0.0525\n",
      "Epoch [3/5], Step [11840/30930], Loss: 0.0715\n",
      "Epoch [3/5], Step [11850/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [11860/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [11870/30930], Loss: 0.0102\n",
      "Epoch [3/5], Step [11880/30930], Loss: 0.0319\n",
      "Epoch [3/5], Step [11890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [11900/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [11910/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [11920/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [11930/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [11940/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [11950/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [11960/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [11970/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [11980/30930], Loss: 0.0420\n",
      "Epoch [3/5], Step [11990/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [12000/30930], Loss: 0.0192\n",
      "Epoch [3/5], Step [12010/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [12020/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [12030/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [12040/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [12050/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [12060/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [12070/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [12080/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [12090/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12100/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [12110/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [12120/30930], Loss: 0.0111\n",
      "Epoch [3/5], Step [12130/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [12140/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12150/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [12160/30930], Loss: 0.0289\n",
      "Epoch [3/5], Step [12170/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [12180/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [12190/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [12200/30930], Loss: 0.0237\n",
      "Epoch [3/5], Step [12210/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [12220/30930], Loss: 0.0221\n",
      "Epoch [3/5], Step [12230/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [12240/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [12250/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12260/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [12270/30930], Loss: 0.0296\n",
      "Epoch [3/5], Step [12280/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [12290/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [12300/30930], Loss: 0.0791\n",
      "Epoch [3/5], Step [12310/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [12320/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [12330/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [12340/30930], Loss: 0.0738\n",
      "Epoch [3/5], Step [12350/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [12360/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [12370/30930], Loss: 0.0424\n",
      "Epoch [3/5], Step [12380/30930], Loss: 0.0179\n",
      "Epoch [3/5], Step [12390/30930], Loss: 0.0228\n",
      "Epoch [3/5], Step [12400/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [12410/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [12420/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [12430/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [12440/30930], Loss: 0.0559\n",
      "Epoch [3/5], Step [12450/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [12460/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [12470/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [12480/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [12490/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12500/30930], Loss: 0.0289\n",
      "Epoch [3/5], Step [12510/30930], Loss: 0.0205\n",
      "Epoch [3/5], Step [12520/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [12530/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [12540/30930], Loss: 0.0381\n",
      "Epoch [3/5], Step [12550/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [12560/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [12570/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [12580/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [12590/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [12600/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [12610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12620/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [12630/30930], Loss: 0.1291\n",
      "Epoch [3/5], Step [12640/30930], Loss: 0.0422\n",
      "Epoch [3/5], Step [12650/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [12660/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [12670/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12680/30930], Loss: 0.0392\n",
      "Epoch [3/5], Step [12690/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [12700/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [12710/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [12720/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [12730/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [12740/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [12750/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [12760/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [12770/30930], Loss: 0.0083\n",
      "Epoch [3/5], Step [12780/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [12790/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [12800/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [12810/30930], Loss: 0.0076\n",
      "Epoch [3/5], Step [12820/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [12830/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [12840/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [12850/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [12860/30930], Loss: 0.0147\n",
      "Epoch [3/5], Step [12870/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [12880/30930], Loss: 0.3359\n",
      "Epoch [3/5], Step [12890/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [12900/30930], Loss: 0.0613\n",
      "Epoch [3/5], Step [12910/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [12920/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [12930/30930], Loss: 0.0279\n",
      "Epoch [3/5], Step [12940/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [12950/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [12960/30930], Loss: 0.0791\n",
      "Epoch [3/5], Step [12970/30930], Loss: 0.0183\n",
      "Epoch [3/5], Step [12980/30930], Loss: 0.0179\n",
      "Epoch [3/5], Step [12990/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [13000/30930], Loss: 0.1110\n",
      "Epoch [3/5], Step [13010/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [13020/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [13030/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [13040/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [13050/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [13060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13070/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [13080/30930], Loss: 0.0116\n",
      "Epoch [3/5], Step [13090/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [13100/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13110/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [13120/30930], Loss: 0.0352\n",
      "Epoch [3/5], Step [13130/30930], Loss: 0.0203\n",
      "Epoch [3/5], Step [13140/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [13150/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [13160/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [13170/30930], Loss: 0.0082\n",
      "Epoch [3/5], Step [13180/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [13190/30930], Loss: 0.0234\n",
      "Epoch [3/5], Step [13200/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13210/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [13220/30930], Loss: 0.0260\n",
      "Epoch [3/5], Step [13230/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13240/30930], Loss: 0.0160\n",
      "Epoch [3/5], Step [13250/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [13260/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [13270/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [13280/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [13290/30930], Loss: 0.0168\n",
      "Epoch [3/5], Step [13300/30930], Loss: 0.0123\n",
      "Epoch [3/5], Step [13310/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [13320/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13330/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13340/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13350/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [13360/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13370/30930], Loss: 0.0224\n",
      "Epoch [3/5], Step [13380/30930], Loss: 0.1233\n",
      "Epoch [3/5], Step [13390/30930], Loss: 0.0177\n",
      "Epoch [3/5], Step [13400/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [13410/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [13420/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13430/30930], Loss: 0.0111\n",
      "Epoch [3/5], Step [13440/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [13450/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [13460/30930], Loss: 0.0155\n",
      "Epoch [3/5], Step [13470/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [13480/30930], Loss: 0.0194\n",
      "Epoch [3/5], Step [13490/30930], Loss: 0.0091\n",
      "Epoch [3/5], Step [13500/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13510/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [13520/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13530/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [13540/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13550/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [13560/30930], Loss: 0.0275\n",
      "Epoch [3/5], Step [13570/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13580/30930], Loss: 0.0209\n",
      "Epoch [3/5], Step [13590/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [13600/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13610/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [13620/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [13630/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13640/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [13650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13660/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [13670/30930], Loss: 0.0313\n",
      "Epoch [3/5], Step [13680/30930], Loss: 0.0106\n",
      "Epoch [3/5], Step [13690/30930], Loss: 0.0296\n",
      "Epoch [3/5], Step [13700/30930], Loss: 0.0156\n",
      "Epoch [3/5], Step [13710/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13720/30930], Loss: 0.0127\n",
      "Epoch [3/5], Step [13730/30930], Loss: 0.0139\n",
      "Epoch [3/5], Step [13740/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [13750/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13760/30930], Loss: 0.0302\n",
      "Epoch [3/5], Step [13770/30930], Loss: 0.0180\n",
      "Epoch [3/5], Step [13780/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13790/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [13800/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [13810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [13820/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13830/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [13840/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [13850/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [13860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [13870/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [13880/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [13890/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [13900/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [13910/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [13920/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [13930/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [13940/30930], Loss: 0.0109\n",
      "Epoch [3/5], Step [13950/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [13960/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [13970/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [13980/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [13990/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [14000/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [14010/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [14020/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [14030/30930], Loss: 0.0524\n",
      "Epoch [3/5], Step [14040/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [14050/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [14060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14080/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [14090/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [14100/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14110/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [14120/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [14130/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [14140/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [14150/30930], Loss: 0.0146\n",
      "Epoch [3/5], Step [14160/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [14170/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [14180/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [14190/30930], Loss: 0.0218\n",
      "Epoch [3/5], Step [14200/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [14210/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [14220/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [14230/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [14240/30930], Loss: 0.0412\n",
      "Epoch [3/5], Step [14250/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [14260/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14270/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [14280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [14290/30930], Loss: 0.0164\n",
      "Epoch [3/5], Step [14300/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [14310/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [14320/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [14330/30930], Loss: 0.1166\n",
      "Epoch [3/5], Step [14340/30930], Loss: 0.0088\n",
      "Epoch [3/5], Step [14350/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [14360/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [14370/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [14380/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14390/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [14400/30930], Loss: 0.0315\n",
      "Epoch [3/5], Step [14410/30930], Loss: 0.0105\n",
      "Epoch [3/5], Step [14420/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [14430/30930], Loss: 0.0283\n",
      "Epoch [3/5], Step [14440/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [14450/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [14460/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [14470/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [14480/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [14490/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [14500/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [14510/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [14520/30930], Loss: 0.0383\n",
      "Epoch [3/5], Step [14530/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14540/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [14550/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [14560/30930], Loss: 0.0174\n",
      "Epoch [3/5], Step [14570/30930], Loss: 0.0187\n",
      "Epoch [3/5], Step [14580/30930], Loss: 0.0149\n",
      "Epoch [3/5], Step [14590/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [14600/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [14610/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [14620/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [14630/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [14640/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14650/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [14660/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [14670/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [14680/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [14690/30930], Loss: 0.0141\n",
      "Epoch [3/5], Step [14700/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [14710/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14720/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [14730/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14740/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [14750/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [14760/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [14770/30930], Loss: 0.0123\n",
      "Epoch [3/5], Step [14780/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [14790/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14800/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [14810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14820/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [14830/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [14840/30930], Loss: 0.0365\n",
      "Epoch [3/5], Step [14850/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [14860/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14870/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [14880/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [14890/30930], Loss: 0.0315\n",
      "Epoch [3/5], Step [14900/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [14910/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [14920/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [14930/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [14940/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [14950/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [14960/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [14970/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [14980/30930], Loss: 0.0413\n",
      "Epoch [3/5], Step [14990/30930], Loss: 0.0294\n",
      "Epoch [3/5], Step [15000/30930], Loss: 0.0141\n",
      "Epoch [3/5], Step [15010/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [15020/30930], Loss: 0.0101\n",
      "Epoch [3/5], Step [15030/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [15040/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [15050/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [15060/30930], Loss: 0.0365\n",
      "Epoch [3/5], Step [15070/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [15080/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [15090/30930], Loss: 0.0713\n",
      "Epoch [3/5], Step [15100/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [15110/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [15120/30930], Loss: 0.0599\n",
      "Epoch [3/5], Step [15130/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [15140/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [15150/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [15160/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15170/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [15180/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15190/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [15200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15210/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15220/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [15230/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [15240/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15250/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [15260/30930], Loss: 0.0719\n",
      "Epoch [3/5], Step [15270/30930], Loss: 0.0399\n",
      "Epoch [3/5], Step [15280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15290/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15300/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [15310/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [15320/30930], Loss: 0.0336\n",
      "Epoch [3/5], Step [15330/30930], Loss: 0.0483\n",
      "Epoch [3/5], Step [15340/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [15350/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [15360/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15370/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [15380/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [15390/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15400/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [15410/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [15420/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [15430/30930], Loss: 0.0205\n",
      "Epoch [3/5], Step [15440/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15450/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [15460/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [15470/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [15480/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [15490/30930], Loss: 0.0193\n",
      "Epoch [3/5], Step [15500/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [15510/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15520/30930], Loss: 0.0151\n",
      "Epoch [3/5], Step [15530/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [15540/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [15550/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [15560/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [15570/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [15580/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [15590/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15600/30930], Loss: 0.0247\n",
      "Epoch [3/5], Step [15610/30930], Loss: 0.0255\n",
      "Epoch [3/5], Step [15620/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15630/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [15640/30930], Loss: 0.0269\n",
      "Epoch [3/5], Step [15650/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [15660/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [15670/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [15680/30930], Loss: 0.0080\n",
      "Epoch [3/5], Step [15690/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [15700/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [15710/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15720/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15730/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [15740/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [15750/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [15760/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15770/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [15780/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [15790/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [15800/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [15810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [15820/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [15830/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [15840/30930], Loss: 0.0261\n",
      "Epoch [3/5], Step [15850/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [15860/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [15870/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [15880/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [15890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15900/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [15910/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [15920/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [15930/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [15940/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [15950/30930], Loss: 0.0346\n",
      "Epoch [3/5], Step [15960/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [15970/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [15980/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [15990/30930], Loss: 0.0233\n",
      "Epoch [3/5], Step [16000/30930], Loss: 0.0445\n",
      "Epoch [3/5], Step [16010/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [16020/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [16030/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16040/30930], Loss: 0.0961\n",
      "Epoch [3/5], Step [16050/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [16060/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [16070/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [16080/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [16090/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [16100/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [16110/30930], Loss: 0.0281\n",
      "Epoch [3/5], Step [16120/30930], Loss: 0.0209\n",
      "Epoch [3/5], Step [16130/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [16140/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16150/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [16160/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [16170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16180/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [16190/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [16200/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [16210/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16220/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [16230/30930], Loss: 0.0240\n",
      "Epoch [3/5], Step [16240/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [16250/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [16260/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [16270/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [16280/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [16290/30930], Loss: 0.0400\n",
      "Epoch [3/5], Step [16300/30930], Loss: 0.0082\n",
      "Epoch [3/5], Step [16310/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [16320/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [16330/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16340/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [16350/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16360/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [16370/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16380/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16400/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [16410/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16420/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [16430/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16440/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16450/30930], Loss: 0.0139\n",
      "Epoch [3/5], Step [16460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16470/30930], Loss: 0.0233\n",
      "Epoch [3/5], Step [16480/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [16490/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [16500/30930], Loss: 0.0153\n",
      "Epoch [3/5], Step [16510/30930], Loss: 0.0171\n",
      "Epoch [3/5], Step [16520/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [16530/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16540/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [16550/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16560/30930], Loss: 0.0167\n",
      "Epoch [3/5], Step [16570/30930], Loss: 0.0129\n",
      "Epoch [3/5], Step [16580/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [16590/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [16600/30930], Loss: 0.0250\n",
      "Epoch [3/5], Step [16610/30930], Loss: 0.0085\n",
      "Epoch [3/5], Step [16620/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [16630/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [16640/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [16650/30930], Loss: 0.0282\n",
      "Epoch [3/5], Step [16660/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [16670/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [16680/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16690/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16700/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16710/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [16720/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16730/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16740/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [16750/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16760/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [16770/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [16780/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [16790/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [16800/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [16810/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [16820/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [16830/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [16840/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [16850/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16870/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [16880/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16890/30930], Loss: 0.0154\n",
      "Epoch [3/5], Step [16900/30930], Loss: 0.0137\n",
      "Epoch [3/5], Step [16910/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [16920/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [16930/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [16940/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [16950/30930], Loss: 0.0066\n",
      "Epoch [3/5], Step [16960/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16970/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [16980/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [16990/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [17000/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [17010/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17020/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [17030/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17040/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [17050/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [17060/30930], Loss: 0.0275\n",
      "Epoch [3/5], Step [17070/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [17080/30930], Loss: 0.0259\n",
      "Epoch [3/5], Step [17090/30930], Loss: 0.0321\n",
      "Epoch [3/5], Step [17100/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [17110/30930], Loss: 0.0086\n",
      "Epoch [3/5], Step [17120/30930], Loss: 0.0119\n",
      "Epoch [3/5], Step [17130/30930], Loss: 0.0150\n",
      "Epoch [3/5], Step [17140/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [17150/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [17160/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [17170/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [17180/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17190/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17200/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17210/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17230/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [17240/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17250/30930], Loss: 0.0486\n",
      "Epoch [3/5], Step [17260/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [17270/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [17280/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17290/30930], Loss: 0.0299\n",
      "Epoch [3/5], Step [17300/30930], Loss: 0.0426\n",
      "Epoch [3/5], Step [17310/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [17320/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [17330/30930], Loss: 0.0131\n",
      "Epoch [3/5], Step [17340/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [17350/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [17360/30930], Loss: 0.0131\n",
      "Epoch [3/5], Step [17370/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [17380/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [17390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17400/30930], Loss: 0.1114\n",
      "Epoch [3/5], Step [17410/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [17420/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [17430/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [17440/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [17450/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [17460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [17470/30930], Loss: 0.0298\n",
      "Epoch [3/5], Step [17480/30930], Loss: 0.0126\n",
      "Epoch [3/5], Step [17490/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [17500/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [17510/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [17520/30930], Loss: 0.0302\n",
      "Epoch [3/5], Step [17530/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [17540/30930], Loss: 0.0253\n",
      "Epoch [3/5], Step [17550/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17560/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [17570/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [17580/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [17590/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17600/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [17610/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [17620/30930], Loss: 0.0567\n",
      "Epoch [3/5], Step [17630/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [17640/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [17650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17660/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [17670/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [17680/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [17690/30930], Loss: 0.0357\n",
      "Epoch [3/5], Step [17700/30930], Loss: 0.0250\n",
      "Epoch [3/5], Step [17710/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17720/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [17730/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [17740/30930], Loss: 0.0243\n",
      "Epoch [3/5], Step [17750/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [17760/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [17770/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [17780/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17790/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [17800/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [17810/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [17820/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [17830/30930], Loss: 0.0090\n",
      "Epoch [3/5], Step [17840/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [17850/30930], Loss: 0.0160\n",
      "Epoch [3/5], Step [17860/30930], Loss: 0.0140\n",
      "Epoch [3/5], Step [17870/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [17880/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [17890/30930], Loss: 0.0159\n",
      "Epoch [3/5], Step [17900/30930], Loss: 0.1176\n",
      "Epoch [3/5], Step [17910/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [17920/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [17930/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [17940/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [17950/30930], Loss: 0.0168\n",
      "Epoch [3/5], Step [17960/30930], Loss: 0.0212\n",
      "Epoch [3/5], Step [17970/30930], Loss: 0.0855\n",
      "Epoch [3/5], Step [17980/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [17990/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18000/30930], Loss: 0.0417\n",
      "Epoch [3/5], Step [18010/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [18020/30930], Loss: 0.0281\n",
      "Epoch [3/5], Step [18030/30930], Loss: 0.0152\n",
      "Epoch [3/5], Step [18040/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [18050/30930], Loss: 0.0323\n",
      "Epoch [3/5], Step [18060/30930], Loss: 0.0093\n",
      "Epoch [3/5], Step [18070/30930], Loss: 0.0076\n",
      "Epoch [3/5], Step [18080/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [18090/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18100/30930], Loss: 0.0116\n",
      "Epoch [3/5], Step [18110/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [18120/30930], Loss: 0.0166\n",
      "Epoch [3/5], Step [18130/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [18140/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [18150/30930], Loss: 0.0328\n",
      "Epoch [3/5], Step [18160/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [18170/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18180/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [18190/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [18200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18210/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [18220/30930], Loss: 0.0337\n",
      "Epoch [3/5], Step [18230/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18240/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [18250/30930], Loss: 0.1707\n",
      "Epoch [3/5], Step [18260/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [18270/30930], Loss: 0.0118\n",
      "Epoch [3/5], Step [18280/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [18290/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [18300/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [18310/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [18320/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [18330/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [18340/30930], Loss: 0.0210\n",
      "Epoch [3/5], Step [18350/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [18360/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18370/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [18380/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18390/30930], Loss: 0.1367\n",
      "Epoch [3/5], Step [18400/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18410/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [18420/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [18430/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [18440/30930], Loss: 0.0096\n",
      "Epoch [3/5], Step [18450/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18470/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [18480/30930], Loss: 0.0304\n",
      "Epoch [3/5], Step [18490/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18500/30930], Loss: 0.0305\n",
      "Epoch [3/5], Step [18510/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [18520/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [18530/30930], Loss: 0.0190\n",
      "Epoch [3/5], Step [18540/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [18550/30930], Loss: 0.0124\n",
      "Epoch [3/5], Step [18560/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [18570/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [18580/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [18590/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18600/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [18610/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [18620/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [18630/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18640/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [18650/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [18660/30930], Loss: 0.0129\n",
      "Epoch [3/5], Step [18670/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [18680/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [18690/30930], Loss: 0.0115\n",
      "Epoch [3/5], Step [18700/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [18710/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [18720/30930], Loss: 0.1210\n",
      "Epoch [3/5], Step [18730/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [18740/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18750/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [18760/30930], Loss: 0.0198\n",
      "Epoch [3/5], Step [18770/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18780/30930], Loss: 0.0103\n",
      "Epoch [3/5], Step [18790/30930], Loss: 0.0788\n",
      "Epoch [3/5], Step [18800/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [18810/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [18820/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18830/30930], Loss: 0.0100\n",
      "Epoch [3/5], Step [18840/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [18850/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [18860/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [18870/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [18880/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [18890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18900/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [18910/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [18920/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [18930/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [18940/30930], Loss: 0.0507\n",
      "Epoch [3/5], Step [18950/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [18960/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [18970/30930], Loss: 0.0336\n",
      "Epoch [3/5], Step [18980/30930], Loss: 0.0325\n",
      "Epoch [3/5], Step [18990/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19000/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [19010/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19020/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19030/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19040/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19050/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [19060/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19080/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19090/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [19100/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19110/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [19120/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19130/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19140/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [19150/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19160/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [19170/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [19180/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [19190/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [19200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19210/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19220/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [19230/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [19240/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [19250/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [19260/30930], Loss: 0.0069\n",
      "Epoch [3/5], Step [19270/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [19280/30930], Loss: 0.1047\n",
      "Epoch [3/5], Step [19290/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [19300/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19310/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19320/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [19330/30930], Loss: 0.0069\n",
      "Epoch [3/5], Step [19340/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [19350/30930], Loss: 0.0202\n",
      "Epoch [3/5], Step [19360/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19370/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [19380/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [19390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19400/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [19410/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19420/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19430/30930], Loss: 0.0129\n",
      "Epoch [3/5], Step [19440/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19450/30930], Loss: 0.0470\n",
      "Epoch [3/5], Step [19460/30930], Loss: 0.0269\n",
      "Epoch [3/5], Step [19470/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [19480/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [19490/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [19500/30930], Loss: 0.0273\n",
      "Epoch [3/5], Step [19510/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19520/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [19530/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19540/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19550/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [19560/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [19570/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [19580/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [19590/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19600/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [19610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19620/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19630/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [19640/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [19650/30930], Loss: 0.1726\n",
      "Epoch [3/5], Step [19660/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [19670/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [19680/30930], Loss: 0.0166\n",
      "Epoch [3/5], Step [19690/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [19700/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [19710/30930], Loss: 0.0130\n",
      "Epoch [3/5], Step [19720/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [19730/30930], Loss: 0.0347\n",
      "Epoch [3/5], Step [19740/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [19750/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19760/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [19770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19780/30930], Loss: 0.0101\n",
      "Epoch [3/5], Step [19790/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [19800/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [19810/30930], Loss: 0.0310\n",
      "Epoch [3/5], Step [19820/30930], Loss: 0.0496\n",
      "Epoch [3/5], Step [19830/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [19840/30930], Loss: 0.0221\n",
      "Epoch [3/5], Step [19850/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [19860/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [19870/30930], Loss: 0.0061\n",
      "Epoch [3/5], Step [19880/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [19890/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19900/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [19910/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [19920/30930], Loss: 0.0091\n",
      "Epoch [3/5], Step [19930/30930], Loss: 0.0704\n",
      "Epoch [3/5], Step [19940/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [19950/30930], Loss: 0.0099\n",
      "Epoch [3/5], Step [19960/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [19970/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [19980/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [19990/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [20000/30930], Loss: 0.0109\n",
      "Epoch [3/5], Step [20010/30930], Loss: 0.0271\n",
      "Epoch [3/5], Step [20020/30930], Loss: 0.0313\n",
      "Epoch [3/5], Step [20030/30930], Loss: 0.0209\n",
      "Epoch [3/5], Step [20040/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [20050/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [20060/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [20070/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [20080/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20090/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [20100/30930], Loss: 0.0484\n",
      "Epoch [3/5], Step [20110/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [20120/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20130/30930], Loss: 0.0192\n",
      "Epoch [3/5], Step [20140/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [20150/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [20160/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [20170/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [20180/30930], Loss: 0.0239\n",
      "Epoch [3/5], Step [20190/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [20200/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [20210/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20220/30930], Loss: 0.0920\n",
      "Epoch [3/5], Step [20230/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [20240/30930], Loss: 0.0110\n",
      "Epoch [3/5], Step [20250/30930], Loss: 0.0230\n",
      "Epoch [3/5], Step [20260/30930], Loss: 0.0109\n",
      "Epoch [3/5], Step [20270/30930], Loss: 0.0179\n",
      "Epoch [3/5], Step [20280/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [20290/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [20300/30930], Loss: 0.0140\n",
      "Epoch [3/5], Step [20310/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20320/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [20330/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20340/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [20350/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [20360/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [20370/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20380/30930], Loss: 0.0134\n",
      "Epoch [3/5], Step [20390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20400/30930], Loss: 0.1448\n",
      "Epoch [3/5], Step [20410/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [20420/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [20430/30930], Loss: 0.0142\n",
      "Epoch [3/5], Step [20440/30930], Loss: 0.0433\n",
      "Epoch [3/5], Step [20450/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [20460/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [20470/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [20480/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [20490/30930], Loss: 0.0194\n",
      "Epoch [3/5], Step [20500/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [20510/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [20520/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [20530/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [20540/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [20550/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [20560/30930], Loss: 0.0295\n",
      "Epoch [3/5], Step [20570/30930], Loss: 0.0111\n",
      "Epoch [3/5], Step [20580/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [20590/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [20600/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [20620/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [20630/30930], Loss: 0.0176\n",
      "Epoch [3/5], Step [20640/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [20650/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [20660/30930], Loss: 0.0810\n",
      "Epoch [3/5], Step [20670/30930], Loss: 0.0084\n",
      "Epoch [3/5], Step [20680/30930], Loss: 0.0211\n",
      "Epoch [3/5], Step [20690/30930], Loss: 0.0501\n",
      "Epoch [3/5], Step [20700/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [20710/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [20720/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [20730/30930], Loss: 0.0308\n",
      "Epoch [3/5], Step [20740/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [20750/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [20760/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [20770/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [20780/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [20790/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [20800/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [20810/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [20820/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [20830/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [20840/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [20850/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [20860/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [20870/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [20880/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [20890/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [20900/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [20910/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [20920/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [20930/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [20940/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [20950/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [20960/30930], Loss: 0.0368\n",
      "Epoch [3/5], Step [20970/30930], Loss: 0.0103\n",
      "Epoch [3/5], Step [20980/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [20990/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [21000/30930], Loss: 0.0242\n",
      "Epoch [3/5], Step [21010/30930], Loss: 0.0358\n",
      "Epoch [3/5], Step [21020/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [21030/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [21040/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21050/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [21060/30930], Loss: 0.0161\n",
      "Epoch [3/5], Step [21070/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21080/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [21090/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21100/30930], Loss: 0.0646\n",
      "Epoch [3/5], Step [21110/30930], Loss: 0.0195\n",
      "Epoch [3/5], Step [21120/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [21130/30930], Loss: 0.1068\n",
      "Epoch [3/5], Step [21140/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [21150/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [21160/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [21170/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [21180/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [21190/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [21200/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21210/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [21220/30930], Loss: 0.0526\n",
      "Epoch [3/5], Step [21230/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [21240/30930], Loss: 0.0113\n",
      "Epoch [3/5], Step [21250/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [21260/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21270/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [21280/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [21290/30930], Loss: 0.0087\n",
      "Epoch [3/5], Step [21300/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [21310/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [21320/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [21330/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [21340/30930], Loss: 0.0207\n",
      "Epoch [3/5], Step [21350/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21360/30930], Loss: 0.0342\n",
      "Epoch [3/5], Step [21370/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [21380/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [21390/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21400/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [21410/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [21420/30930], Loss: 0.0108\n",
      "Epoch [3/5], Step [21430/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [21440/30930], Loss: 0.0143\n",
      "Epoch [3/5], Step [21450/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21460/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [21470/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [21480/30930], Loss: 0.0146\n",
      "Epoch [3/5], Step [21490/30930], Loss: 0.0544\n",
      "Epoch [3/5], Step [21500/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [21510/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [21520/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21530/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [21540/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [21550/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [21560/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [21570/30930], Loss: 0.0644\n",
      "Epoch [3/5], Step [21580/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21590/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [21600/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21610/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [21620/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [21630/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [21640/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [21650/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [21660/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [21670/30930], Loss: 0.0232\n",
      "Epoch [3/5], Step [21680/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [21690/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21700/30930], Loss: 0.0481\n",
      "Epoch [3/5], Step [21710/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21720/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [21730/30930], Loss: 0.0093\n",
      "Epoch [3/5], Step [21740/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [21750/30930], Loss: 0.0233\n",
      "Epoch [3/5], Step [21760/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [21770/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [21780/30930], Loss: 0.0431\n",
      "Epoch [3/5], Step [21790/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21800/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [21810/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [21820/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [21830/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21840/30930], Loss: 0.0183\n",
      "Epoch [3/5], Step [21850/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [21860/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [21870/30930], Loss: 0.0164\n",
      "Epoch [3/5], Step [21880/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [21890/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [21900/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21910/30930], Loss: 0.0230\n",
      "Epoch [3/5], Step [21920/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [21930/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [21940/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [21950/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [21960/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [21970/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [21980/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [21990/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [22000/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [22010/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [22020/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22030/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [22040/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [22050/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [22060/30930], Loss: 0.0101\n",
      "Epoch [3/5], Step [22070/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [22080/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22090/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [22100/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [22110/30930], Loss: 0.1031\n",
      "Epoch [3/5], Step [22120/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [22130/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22140/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [22150/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [22160/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [22170/30930], Loss: 0.0804\n",
      "Epoch [3/5], Step [22180/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [22190/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22210/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [22220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22230/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22240/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [22250/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [22260/30930], Loss: 0.0249\n",
      "Epoch [3/5], Step [22270/30930], Loss: 0.0146\n",
      "Epoch [3/5], Step [22280/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [22290/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [22300/30930], Loss: 0.0212\n",
      "Epoch [3/5], Step [22310/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22320/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [22330/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [22340/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22350/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [22360/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22370/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22380/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [22390/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22400/30930], Loss: 0.0377\n",
      "Epoch [3/5], Step [22410/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [22420/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [22430/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22440/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22450/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [22460/30930], Loss: 0.0086\n",
      "Epoch [3/5], Step [22470/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22480/30930], Loss: 0.0117\n",
      "Epoch [3/5], Step [22490/30930], Loss: 0.0118\n",
      "Epoch [3/5], Step [22500/30930], Loss: 0.0164\n",
      "Epoch [3/5], Step [22510/30930], Loss: 0.0114\n",
      "Epoch [3/5], Step [22520/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [22530/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [22540/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [22550/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22560/30930], Loss: 0.0244\n",
      "Epoch [3/5], Step [22570/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [22580/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22590/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [22600/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [22610/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [22620/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [22630/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [22640/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22660/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22670/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22680/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22690/30930], Loss: 0.1763\n",
      "Epoch [3/5], Step [22700/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22710/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [22720/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [22730/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22740/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [22750/30930], Loss: 0.0756\n",
      "Epoch [3/5], Step [22760/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [22770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22780/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [22790/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22800/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [22810/30930], Loss: 0.0207\n",
      "Epoch [3/5], Step [22820/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [22830/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [22840/30930], Loss: 0.0099\n",
      "Epoch [3/5], Step [22850/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [22860/30930], Loss: 0.0521\n",
      "Epoch [3/5], Step [22870/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [22880/30930], Loss: 0.0277\n",
      "Epoch [3/5], Step [22890/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [22900/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [22910/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [22920/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [22930/30930], Loss: 0.0294\n",
      "Epoch [3/5], Step [22940/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [22950/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [22960/30930], Loss: 0.0090\n",
      "Epoch [3/5], Step [22970/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [22980/30930], Loss: 0.0140\n",
      "Epoch [3/5], Step [22990/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [23000/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23010/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [23020/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [23030/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [23040/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [23050/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23060/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [23070/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [23080/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23090/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [23100/30930], Loss: 0.0196\n",
      "Epoch [3/5], Step [23110/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23120/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [23130/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [23140/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [23150/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [23160/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [23170/30930], Loss: 0.0243\n",
      "Epoch [3/5], Step [23180/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [23190/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23200/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [23210/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23220/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23230/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [23240/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [23250/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [23260/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [23270/30930], Loss: 0.0161\n",
      "Epoch [3/5], Step [23280/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [23290/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [23300/30930], Loss: 0.0237\n",
      "Epoch [3/5], Step [23310/30930], Loss: 0.0288\n",
      "Epoch [3/5], Step [23320/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [23330/30930], Loss: 0.0301\n",
      "Epoch [3/5], Step [23340/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [23350/30930], Loss: 0.0105\n",
      "Epoch [3/5], Step [23360/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [23370/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [23380/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [23390/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [23400/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [23410/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23420/30930], Loss: 0.0488\n",
      "Epoch [3/5], Step [23430/30930], Loss: 0.0847\n",
      "Epoch [3/5], Step [23440/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23450/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [23460/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [23470/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [23480/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [23490/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [23500/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [23510/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [23520/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23530/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [23540/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23550/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23560/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [23570/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [23580/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23590/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [23600/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [23610/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [23620/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23630/30930], Loss: 0.0335\n",
      "Epoch [3/5], Step [23640/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [23650/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [23660/30930], Loss: 0.0794\n",
      "Epoch [3/5], Step [23670/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [23680/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [23690/30930], Loss: 0.0105\n",
      "Epoch [3/5], Step [23700/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [23710/30930], Loss: 0.0143\n",
      "Epoch [3/5], Step [23720/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [23730/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [23740/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [23750/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [23760/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [23770/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [23780/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [23790/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [23800/30930], Loss: 0.0509\n",
      "Epoch [3/5], Step [23810/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [23820/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [23830/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [23840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23850/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23860/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [23870/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [23880/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [23890/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [23900/30930], Loss: 0.0491\n",
      "Epoch [3/5], Step [23910/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [23920/30930], Loss: 0.0180\n",
      "Epoch [3/5], Step [23930/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [23940/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [23950/30930], Loss: 0.0770\n",
      "Epoch [3/5], Step [23960/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [23970/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [23980/30930], Loss: 0.0224\n",
      "Epoch [3/5], Step [23990/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [24000/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [24010/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24020/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24030/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24040/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [24050/30930], Loss: 0.0052\n",
      "Epoch [3/5], Step [24060/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [24070/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [24080/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [24090/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [24100/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [24110/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [24120/30930], Loss: 0.0207\n",
      "Epoch [3/5], Step [24130/30930], Loss: 0.0137\n",
      "Epoch [3/5], Step [24140/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24150/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [24160/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [24170/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [24180/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24190/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [24200/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [24210/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [24220/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [24230/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [24240/30930], Loss: 0.0104\n",
      "Epoch [3/5], Step [24250/30930], Loss: 0.0178\n",
      "Epoch [3/5], Step [24260/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24270/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [24280/30930], Loss: 0.0059\n",
      "Epoch [3/5], Step [24290/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [24300/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24310/30930], Loss: 0.0149\n",
      "Epoch [3/5], Step [24320/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [24330/30930], Loss: 0.0728\n",
      "Epoch [3/5], Step [24340/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24350/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24360/30930], Loss: 0.0276\n",
      "Epoch [3/5], Step [24370/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [24380/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [24390/30930], Loss: 0.0115\n",
      "Epoch [3/5], Step [24400/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24410/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [24420/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24430/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [24440/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [24450/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [24460/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [24470/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [24480/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [24490/30930], Loss: 0.0374\n",
      "Epoch [3/5], Step [24500/30930], Loss: 0.0106\n",
      "Epoch [3/5], Step [24510/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24520/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [24530/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24540/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [24550/30930], Loss: 0.0516\n",
      "Epoch [3/5], Step [24560/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [24570/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24580/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [24590/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24600/30930], Loss: 0.0453\n",
      "Epoch [3/5], Step [24610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24620/30930], Loss: 0.0489\n",
      "Epoch [3/5], Step [24630/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [24640/30930], Loss: 0.1794\n",
      "Epoch [3/5], Step [24650/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [24660/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [24670/30930], Loss: 0.0167\n",
      "Epoch [3/5], Step [24680/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24690/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [24700/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [24710/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [24720/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [24730/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [24740/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [24750/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [24760/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [24770/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [24780/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [24790/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [24800/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [24810/30930], Loss: 0.0123\n",
      "Epoch [3/5], Step [24820/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [24830/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [24840/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [24850/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [24860/30930], Loss: 0.0093\n",
      "Epoch [3/5], Step [24870/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [24880/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [24890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24900/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24910/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24920/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [24930/30930], Loss: 0.0265\n",
      "Epoch [3/5], Step [24940/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [24950/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [24960/30930], Loss: 0.0313\n",
      "Epoch [3/5], Step [24970/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [24980/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [24990/30930], Loss: 0.0047\n",
      "Epoch [3/5], Step [25000/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [25010/30930], Loss: 0.0830\n",
      "Epoch [3/5], Step [25020/30930], Loss: 0.0072\n",
      "Epoch [3/5], Step [25030/30930], Loss: 0.0101\n",
      "Epoch [3/5], Step [25040/30930], Loss: 0.0131\n",
      "Epoch [3/5], Step [25050/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25060/30930], Loss: 0.0564\n",
      "Epoch [3/5], Step [25070/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [25080/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25090/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [25100/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [25110/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [25120/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [25130/30930], Loss: 0.0223\n",
      "Epoch [3/5], Step [25140/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [25150/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [25160/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25170/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [25180/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [25190/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25200/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [25210/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25220/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [25230/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [25240/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [25250/30930], Loss: 0.0233\n",
      "Epoch [3/5], Step [25260/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [25270/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [25280/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25290/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [25300/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [25310/30930], Loss: 0.0318\n",
      "Epoch [3/5], Step [25320/30930], Loss: 0.0259\n",
      "Epoch [3/5], Step [25330/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25340/30930], Loss: 0.0240\n",
      "Epoch [3/5], Step [25350/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25360/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [25370/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [25380/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25390/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [25400/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [25410/30930], Loss: 0.0419\n",
      "Epoch [3/5], Step [25420/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [25430/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25440/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25450/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [25460/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [25470/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [25480/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [25490/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25500/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [25510/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25520/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25530/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [25540/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [25550/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [25560/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [25570/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25580/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [25590/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [25600/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [25610/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [25620/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25630/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [25640/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [25650/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25660/30930], Loss: 0.0244\n",
      "Epoch [3/5], Step [25670/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [25680/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [25690/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25700/30930], Loss: 0.0196\n",
      "Epoch [3/5], Step [25710/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25720/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25730/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25740/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [25750/30930], Loss: 0.0413\n",
      "Epoch [3/5], Step [25760/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [25770/30930], Loss: 0.0240\n",
      "Epoch [3/5], Step [25780/30930], Loss: 0.0544\n",
      "Epoch [3/5], Step [25790/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [25800/30930], Loss: 0.2281\n",
      "Epoch [3/5], Step [25810/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [25820/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [25830/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [25840/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [25850/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [25860/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [25870/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [25880/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [25890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25900/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25910/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [25920/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [25930/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [25940/30930], Loss: 0.0015\n",
      "Epoch [3/5], Step [25950/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [25960/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [25970/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [25980/30930], Loss: 0.0386\n",
      "Epoch [3/5], Step [25990/30930], Loss: 0.0125\n",
      "Epoch [3/5], Step [26000/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [26010/30930], Loss: 0.0255\n",
      "Epoch [3/5], Step [26020/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26030/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26040/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [26050/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [26060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26070/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [26080/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26090/30930], Loss: 0.0277\n",
      "Epoch [3/5], Step [26100/30930], Loss: 0.0139\n",
      "Epoch [3/5], Step [26110/30930], Loss: 0.0136\n",
      "Epoch [3/5], Step [26120/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26130/30930], Loss: 0.0473\n",
      "Epoch [3/5], Step [26140/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [26150/30930], Loss: 0.0365\n",
      "Epoch [3/5], Step [26160/30930], Loss: 0.0230\n",
      "Epoch [3/5], Step [26170/30930], Loss: 0.0159\n",
      "Epoch [3/5], Step [26180/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [26190/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26210/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26220/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [26230/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [26240/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [26250/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [26260/30930], Loss: 0.0141\n",
      "Epoch [3/5], Step [26270/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [26280/30930], Loss: 0.0207\n",
      "Epoch [3/5], Step [26290/30930], Loss: 0.0564\n",
      "Epoch [3/5], Step [26300/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [26310/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [26320/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26330/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26340/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26350/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26360/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26370/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [26380/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26390/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26400/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [26410/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [26420/30930], Loss: 0.0051\n",
      "Epoch [3/5], Step [26430/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [26440/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [26450/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26460/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [26470/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [26480/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [26490/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26500/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26510/30930], Loss: 0.0382\n",
      "Epoch [3/5], Step [26520/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26530/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [26540/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [26550/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [26560/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26570/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26580/30930], Loss: 0.0030\n",
      "Epoch [3/5], Step [26590/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [26600/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26610/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26620/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [26630/30930], Loss: 0.0045\n",
      "Epoch [3/5], Step [26640/30930], Loss: 0.0156\n",
      "Epoch [3/5], Step [26650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26660/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [26670/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [26680/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26690/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [26700/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [26710/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [26720/30930], Loss: 0.0312\n",
      "Epoch [3/5], Step [26730/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [26740/30930], Loss: 0.0181\n",
      "Epoch [3/5], Step [26750/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [26760/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26770/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [26780/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26790/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [26800/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26810/30930], Loss: 0.0910\n",
      "Epoch [3/5], Step [26820/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26830/30930], Loss: 0.0368\n",
      "Epoch [3/5], Step [26840/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [26850/30930], Loss: 0.0046\n",
      "Epoch [3/5], Step [26860/30930], Loss: 0.0522\n",
      "Epoch [3/5], Step [26870/30930], Loss: 0.0049\n",
      "Epoch [3/5], Step [26880/30930], Loss: 0.0166\n",
      "Epoch [3/5], Step [26890/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [26900/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [26910/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [26920/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [26930/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [26940/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [26950/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [26960/30930], Loss: 0.0074\n",
      "Epoch [3/5], Step [26970/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [26980/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [26990/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [27000/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [27010/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [27020/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [27030/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [27040/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [27050/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [27060/30930], Loss: 0.0591\n",
      "Epoch [3/5], Step [27070/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [27080/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [27090/30930], Loss: 0.0211\n",
      "Epoch [3/5], Step [27100/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [27110/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [27120/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [27130/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27140/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [27150/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [27160/30930], Loss: 0.0304\n",
      "Epoch [3/5], Step [27170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27180/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [27190/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [27200/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27210/30930], Loss: 0.0434\n",
      "Epoch [3/5], Step [27220/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [27230/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27240/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27250/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27260/30930], Loss: 0.0094\n",
      "Epoch [3/5], Step [27270/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27280/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27290/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [27300/30930], Loss: 0.0058\n",
      "Epoch [3/5], Step [27310/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [27320/30930], Loss: 0.0270\n",
      "Epoch [3/5], Step [27330/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [27340/30930], Loss: 0.0542\n",
      "Epoch [3/5], Step [27350/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [27360/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [27370/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [27380/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [27390/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27400/30930], Loss: 0.1102\n",
      "Epoch [3/5], Step [27410/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [27420/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27430/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27440/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [27450/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27460/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27470/30930], Loss: 0.0087\n",
      "Epoch [3/5], Step [27480/30930], Loss: 0.0296\n",
      "Epoch [3/5], Step [27490/30930], Loss: 0.0129\n",
      "Epoch [3/5], Step [27500/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [27510/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [27520/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [27530/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [27540/30930], Loss: 0.0027\n",
      "Epoch [3/5], Step [27550/30930], Loss: 0.0115\n",
      "Epoch [3/5], Step [27560/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27570/30930], Loss: 0.0446\n",
      "Epoch [3/5], Step [27580/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [27590/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [27600/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [27610/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27620/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [27630/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [27640/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27650/30930], Loss: 0.2670\n",
      "Epoch [3/5], Step [27660/30930], Loss: 0.0176\n",
      "Epoch [3/5], Step [27670/30930], Loss: 0.0202\n",
      "Epoch [3/5], Step [27680/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [27690/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [27700/30930], Loss: 0.0229\n",
      "Epoch [3/5], Step [27710/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [27720/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [27730/30930], Loss: 0.0296\n",
      "Epoch [3/5], Step [27740/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [27750/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [27760/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [27770/30930], Loss: 0.0227\n",
      "Epoch [3/5], Step [27780/30930], Loss: 0.0759\n",
      "Epoch [3/5], Step [27790/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [27800/30930], Loss: 0.0173\n",
      "Epoch [3/5], Step [27810/30930], Loss: 0.0397\n",
      "Epoch [3/5], Step [27820/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [27830/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [27840/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [27850/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [27860/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [27870/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27880/30930], Loss: 0.0431\n",
      "Epoch [3/5], Step [27890/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [27900/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [27910/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [27920/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [27930/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [27940/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [27950/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27960/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [27970/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [27980/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [27990/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28000/30930], Loss: 0.0083\n",
      "Epoch [3/5], Step [28010/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28020/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28030/30930], Loss: 0.0195\n",
      "Epoch [3/5], Step [28040/30930], Loss: 0.0098\n",
      "Epoch [3/5], Step [28050/30930], Loss: 0.0239\n",
      "Epoch [3/5], Step [28060/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28070/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [28080/30930], Loss: 0.0081\n",
      "Epoch [3/5], Step [28090/30930], Loss: 0.0436\n",
      "Epoch [3/5], Step [28100/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [28110/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [28120/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [28130/30930], Loss: 0.0169\n",
      "Epoch [3/5], Step [28140/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [28150/30930], Loss: 0.0110\n",
      "Epoch [3/5], Step [28160/30930], Loss: 0.0050\n",
      "Epoch [3/5], Step [28170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28180/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28190/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28200/30930], Loss: 0.0090\n",
      "Epoch [3/5], Step [28210/30930], Loss: 0.0261\n",
      "Epoch [3/5], Step [28220/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [28230/30930], Loss: 0.0176\n",
      "Epoch [3/5], Step [28240/30930], Loss: 0.0035\n",
      "Epoch [3/5], Step [28250/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [28260/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [28270/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [28280/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [28290/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [28300/30930], Loss: 0.0172\n",
      "Epoch [3/5], Step [28310/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [28320/30930], Loss: 0.0164\n",
      "Epoch [3/5], Step [28330/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [28340/30930], Loss: 0.0373\n",
      "Epoch [3/5], Step [28350/30930], Loss: 0.0036\n",
      "Epoch [3/5], Step [28360/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [28370/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [28380/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28390/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [28400/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [28410/30930], Loss: 0.0669\n",
      "Epoch [3/5], Step [28420/30930], Loss: 0.0194\n",
      "Epoch [3/5], Step [28430/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [28440/30930], Loss: 0.0132\n",
      "Epoch [3/5], Step [28450/30930], Loss: 0.0083\n",
      "Epoch [3/5], Step [28460/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [28470/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [28480/30930], Loss: 0.0559\n",
      "Epoch [3/5], Step [28490/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [28500/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [28510/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28520/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [28530/30930], Loss: 0.0063\n",
      "Epoch [3/5], Step [28540/30930], Loss: 0.0067\n",
      "Epoch [3/5], Step [28550/30930], Loss: 0.0636\n",
      "Epoch [3/5], Step [28560/30930], Loss: 0.0220\n",
      "Epoch [3/5], Step [28570/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [28580/30930], Loss: 0.0073\n",
      "Epoch [3/5], Step [28590/30930], Loss: 0.0034\n",
      "Epoch [3/5], Step [28600/30930], Loss: 0.0088\n",
      "Epoch [3/5], Step [28610/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [28620/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28630/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [28640/30930], Loss: 0.0121\n",
      "Epoch [3/5], Step [28650/30930], Loss: 0.0193\n",
      "Epoch [3/5], Step [28660/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28670/30930], Loss: 0.0579\n",
      "Epoch [3/5], Step [28680/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28690/30930], Loss: 0.0075\n",
      "Epoch [3/5], Step [28700/30930], Loss: 0.0369\n",
      "Epoch [3/5], Step [28710/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [28720/30930], Loss: 0.0529\n",
      "Epoch [3/5], Step [28730/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [28740/30930], Loss: 0.0022\n",
      "Epoch [3/5], Step [28750/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [28760/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [28770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28780/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [28790/30930], Loss: 0.0153\n",
      "Epoch [3/5], Step [28800/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [28810/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [28820/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [28830/30930], Loss: 0.0221\n",
      "Epoch [3/5], Step [28840/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [28850/30930], Loss: 0.0202\n",
      "Epoch [3/5], Step [28860/30930], Loss: 0.1446\n",
      "Epoch [3/5], Step [28870/30930], Loss: 0.0190\n",
      "Epoch [3/5], Step [28880/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [28890/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28900/30930], Loss: 0.0038\n",
      "Epoch [3/5], Step [28910/30930], Loss: 0.0206\n",
      "Epoch [3/5], Step [28920/30930], Loss: 0.0053\n",
      "Epoch [3/5], Step [28930/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [28940/30930], Loss: 0.0095\n",
      "Epoch [3/5], Step [28950/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28960/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [28970/30930], Loss: 0.0455\n",
      "Epoch [3/5], Step [28980/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [28990/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [29000/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [29010/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29020/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [29030/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29040/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29050/30930], Loss: 0.0312\n",
      "Epoch [3/5], Step [29060/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [29070/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [29080/30930], Loss: 0.0056\n",
      "Epoch [3/5], Step [29090/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [29100/30930], Loss: 0.0122\n",
      "Epoch [3/5], Step [29110/30930], Loss: 0.0185\n",
      "Epoch [3/5], Step [29120/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29130/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [29140/30930], Loss: 0.0012\n",
      "Epoch [3/5], Step [29150/30930], Loss: 0.0065\n",
      "Epoch [3/5], Step [29160/30930], Loss: 0.0112\n",
      "Epoch [3/5], Step [29170/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29180/30930], Loss: 0.0330\n",
      "Epoch [3/5], Step [29190/30930], Loss: 0.0057\n",
      "Epoch [3/5], Step [29200/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [29210/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [29220/30930], Loss: 0.0209\n",
      "Epoch [3/5], Step [29230/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [29240/30930], Loss: 0.0048\n",
      "Epoch [3/5], Step [29250/30930], Loss: 0.0204\n",
      "Epoch [3/5], Step [29260/30930], Loss: 0.0384\n",
      "Epoch [3/5], Step [29270/30930], Loss: 0.0440\n",
      "Epoch [3/5], Step [29280/30930], Loss: 0.0039\n",
      "Epoch [3/5], Step [29290/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29300/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [29310/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [29320/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [29330/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [29340/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [29350/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [29360/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [29370/30930], Loss: 0.1980\n",
      "Epoch [3/5], Step [29380/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29400/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [29410/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [29420/30930], Loss: 0.0235\n",
      "Epoch [3/5], Step [29430/30930], Loss: 0.0161\n",
      "Epoch [3/5], Step [29440/30930], Loss: 0.0042\n",
      "Epoch [3/5], Step [29450/30930], Loss: 0.0025\n",
      "Epoch [3/5], Step [29460/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [29470/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [29480/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29490/30930], Loss: 0.0521\n",
      "Epoch [3/5], Step [29500/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29510/30930], Loss: 0.0120\n",
      "Epoch [3/5], Step [29520/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [29530/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [29540/30930], Loss: 0.0062\n",
      "Epoch [3/5], Step [29550/30930], Loss: 0.0008\n",
      "Epoch [3/5], Step [29560/30930], Loss: 0.0324\n",
      "Epoch [3/5], Step [29570/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29580/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [29590/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [29600/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29610/30930], Loss: 0.0365\n",
      "Epoch [3/5], Step [29620/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [29630/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [29640/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29660/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29670/30930], Loss: 0.0140\n",
      "Epoch [3/5], Step [29680/30930], Loss: 0.0028\n",
      "Epoch [3/5], Step [29690/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29700/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29710/30930], Loss: 0.0285\n",
      "Epoch [3/5], Step [29720/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [29730/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29740/30930], Loss: 0.0210\n",
      "Epoch [3/5], Step [29750/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [29760/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [29770/30930], Loss: 0.0041\n",
      "Epoch [3/5], Step [29780/30930], Loss: 0.0064\n",
      "Epoch [3/5], Step [29790/30930], Loss: 0.0127\n",
      "Epoch [3/5], Step [29800/30930], Loss: 0.0017\n",
      "Epoch [3/5], Step [29810/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29820/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [29830/30930], Loss: 0.0078\n",
      "Epoch [3/5], Step [29840/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29850/30930], Loss: 0.0099\n",
      "Epoch [3/5], Step [29860/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29870/30930], Loss: 0.0018\n",
      "Epoch [3/5], Step [29880/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29890/30930], Loss: 0.0032\n",
      "Epoch [3/5], Step [29900/30930], Loss: 0.0009\n",
      "Epoch [3/5], Step [29910/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [29920/30930], Loss: 0.0158\n",
      "Epoch [3/5], Step [29930/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [29940/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [29950/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [29960/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [29970/30930], Loss: 0.0054\n",
      "Epoch [3/5], Step [29980/30930], Loss: 0.0159\n",
      "Epoch [3/5], Step [29990/30930], Loss: 0.0013\n",
      "Epoch [3/5], Step [30000/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [30010/30930], Loss: 0.0040\n",
      "Epoch [3/5], Step [30020/30930], Loss: 0.0092\n",
      "Epoch [3/5], Step [30030/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [30040/30930], Loss: 0.0060\n",
      "Epoch [3/5], Step [30050/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [30060/30930], Loss: 0.0356\n",
      "Epoch [3/5], Step [30070/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [30080/30930], Loss: 0.0087\n",
      "Epoch [3/5], Step [30090/30930], Loss: 0.0247\n",
      "Epoch [3/5], Step [30100/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30110/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [30120/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [30130/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30140/30930], Loss: 0.0011\n",
      "Epoch [3/5], Step [30150/30930], Loss: 0.0021\n",
      "Epoch [3/5], Step [30160/30930], Loss: 0.0026\n",
      "Epoch [3/5], Step [30170/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [30180/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [30190/30930], Loss: 0.0165\n",
      "Epoch [3/5], Step [30200/30930], Loss: 0.0068\n",
      "Epoch [3/5], Step [30210/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [30220/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30230/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [30240/30930], Loss: 0.0107\n",
      "Epoch [3/5], Step [30250/30930], Loss: 0.0076\n",
      "Epoch [3/5], Step [30260/30930], Loss: 0.0330\n",
      "Epoch [3/5], Step [30270/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [30280/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [30290/30930], Loss: 0.0029\n",
      "Epoch [3/5], Step [30300/30930], Loss: 0.0241\n",
      "Epoch [3/5], Step [30310/30930], Loss: 0.0275\n",
      "Epoch [3/5], Step [30320/30930], Loss: 0.0014\n",
      "Epoch [3/5], Step [30330/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [30340/30930], Loss: 0.0016\n",
      "Epoch [3/5], Step [30350/30930], Loss: 0.0090\n",
      "Epoch [3/5], Step [30360/30930], Loss: 0.0020\n",
      "Epoch [3/5], Step [30370/30930], Loss: 0.0044\n",
      "Epoch [3/5], Step [30380/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [30390/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30400/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30410/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [30420/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [30430/30930], Loss: 0.0376\n",
      "Epoch [3/5], Step [30440/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [30450/30930], Loss: 0.0148\n",
      "Epoch [3/5], Step [30460/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [30470/30930], Loss: 0.0007\n",
      "Epoch [3/5], Step [30480/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30490/30930], Loss: 0.0077\n",
      "Epoch [3/5], Step [30500/30930], Loss: 0.0298\n",
      "Epoch [3/5], Step [30510/30930], Loss: 0.0202\n",
      "Epoch [3/5], Step [30520/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [30530/30930], Loss: 0.0089\n",
      "Epoch [3/5], Step [30540/30930], Loss: 0.0037\n",
      "Epoch [3/5], Step [30550/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [30560/30930], Loss: 0.0584\n",
      "Epoch [3/5], Step [30570/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [30580/30930], Loss: 0.0010\n",
      "Epoch [3/5], Step [30590/30930], Loss: 0.0043\n",
      "Epoch [3/5], Step [30600/30930], Loss: 0.0019\n",
      "Epoch [3/5], Step [30610/30930], Loss: 0.0135\n",
      "Epoch [3/5], Step [30620/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30630/30930], Loss: 0.0184\n",
      "Epoch [3/5], Step [30640/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [30650/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30660/30930], Loss: 0.0079\n",
      "Epoch [3/5], Step [30670/30930], Loss: 0.0185\n",
      "Epoch [3/5], Step [30680/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [30690/30930], Loss: 0.0182\n",
      "Epoch [3/5], Step [30700/30930], Loss: 0.0071\n",
      "Epoch [3/5], Step [30710/30930], Loss: 0.0055\n",
      "Epoch [3/5], Step [30720/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [30730/30930], Loss: 0.0006\n",
      "Epoch [3/5], Step [30740/30930], Loss: 0.0023\n",
      "Epoch [3/5], Step [30750/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30760/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [30770/30930], Loss: 0.0000\n",
      "Epoch [3/5], Step [30780/30930], Loss: 0.0098\n",
      "Epoch [3/5], Step [30790/30930], Loss: 0.0004\n",
      "Epoch [3/5], Step [30800/30930], Loss: 0.0629\n",
      "Epoch [3/5], Step [30810/30930], Loss: 0.0139\n",
      "Epoch [3/5], Step [30820/30930], Loss: 0.0128\n",
      "Epoch [3/5], Step [30830/30930], Loss: 0.0024\n",
      "Epoch [3/5], Step [30840/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [30850/30930], Loss: 0.0033\n",
      "Epoch [3/5], Step [30860/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [30870/30930], Loss: 0.0003\n",
      "Epoch [3/5], Step [30880/30930], Loss: 0.0031\n",
      "Epoch [3/5], Step [30890/30930], Loss: 0.0005\n",
      "Epoch [3/5], Step [30900/30930], Loss: 0.0001\n",
      "Epoch [3/5], Step [30910/30930], Loss: 0.0002\n",
      "Epoch [3/5], Step [30920/30930], Loss: 0.0093\n",
      "Epoch [3/5], Step [30930/30930], Loss: 0.0295\n",
      "Epoch [3/5], Average Train Loss: 0.0096\n",
      "Epoch [3/5], Validation Loss: 0.0105\n",
      "Epoch [4/5], Step [10/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [30/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [40/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [50/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [60/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [70/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [80/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [90/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [100/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [110/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [120/30930], Loss: 0.0133\n",
      "Epoch [4/5], Step [130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [140/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [150/30930], Loss: 0.0219\n",
      "Epoch [4/5], Step [160/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [170/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [180/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [190/30930], Loss: 0.0160\n",
      "Epoch [4/5], Step [200/30930], Loss: 0.0066\n",
      "Epoch [4/5], Step [210/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [220/30930], Loss: 0.0129\n",
      "Epoch [4/5], Step [230/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [240/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [250/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [260/30930], Loss: 0.0108\n",
      "Epoch [4/5], Step [270/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [280/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [290/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [300/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [310/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [320/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [330/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [340/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [350/30930], Loss: 0.0348\n",
      "Epoch [4/5], Step [360/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [370/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [380/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [390/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [400/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [410/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [420/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [430/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [440/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [450/30930], Loss: 0.0222\n",
      "Epoch [4/5], Step [460/30930], Loss: 0.0106\n",
      "Epoch [4/5], Step [470/30930], Loss: 0.0545\n",
      "Epoch [4/5], Step [480/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [490/30930], Loss: 0.0122\n",
      "Epoch [4/5], Step [500/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [510/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [520/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [530/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [540/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [550/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [560/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [570/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [580/30930], Loss: 0.0334\n",
      "Epoch [4/5], Step [590/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [600/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [610/30930], Loss: 0.0159\n",
      "Epoch [4/5], Step [620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [630/30930], Loss: 0.0041\n",
      "Epoch [4/5], Step [640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [650/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [660/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [670/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [680/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [690/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [700/30930], Loss: 0.0208\n",
      "Epoch [4/5], Step [710/30930], Loss: 0.0066\n",
      "Epoch [4/5], Step [720/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [730/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [740/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [750/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [760/30930], Loss: 0.0209\n",
      "Epoch [4/5], Step [770/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [780/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [790/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [800/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [820/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [830/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [840/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [850/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [860/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [870/30930], Loss: 0.0524\n",
      "Epoch [4/5], Step [880/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [890/30930], Loss: 0.0264\n",
      "Epoch [4/5], Step [900/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [910/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [920/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [930/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [940/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [960/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [970/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [980/30930], Loss: 0.0150\n",
      "Epoch [4/5], Step [990/30930], Loss: 0.0190\n",
      "Epoch [4/5], Step [1000/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [1010/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [1020/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [1030/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1040/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1050/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [1060/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [1070/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [1080/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [1090/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1100/30930], Loss: 0.0255\n",
      "Epoch [4/5], Step [1110/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [1120/30930], Loss: 0.0293\n",
      "Epoch [4/5], Step [1130/30930], Loss: 0.0355\n",
      "Epoch [4/5], Step [1140/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1150/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [1160/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [1170/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [1180/30930], Loss: 0.0187\n",
      "Epoch [4/5], Step [1190/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [1200/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [1210/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [1220/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [1230/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [1240/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [1250/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [1260/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [1270/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1280/30930], Loss: 0.0121\n",
      "Epoch [4/5], Step [1290/30930], Loss: 0.0148\n",
      "Epoch [4/5], Step [1300/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [1310/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1320/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [1330/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [1340/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [1350/30930], Loss: 0.0316\n",
      "Epoch [4/5], Step [1360/30930], Loss: 0.0490\n",
      "Epoch [4/5], Step [1370/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [1380/30930], Loss: 0.0295\n",
      "Epoch [4/5], Step [1390/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [1400/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [1410/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [1420/30930], Loss: 0.0207\n",
      "Epoch [4/5], Step [1430/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [1440/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1450/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [1460/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1470/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [1480/30930], Loss: 0.0259\n",
      "Epoch [4/5], Step [1490/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [1500/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1510/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [1520/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [1530/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1540/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [1550/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [1560/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [1570/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [1580/30930], Loss: 0.0365\n",
      "Epoch [4/5], Step [1590/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [1600/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [1610/30930], Loss: 0.0118\n",
      "Epoch [4/5], Step [1620/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [1630/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [1640/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [1650/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [1660/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [1670/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [1680/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [1690/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [1700/30930], Loss: 0.0632\n",
      "Epoch [4/5], Step [1710/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1720/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1730/30930], Loss: 0.0302\n",
      "Epoch [4/5], Step [1740/30930], Loss: 0.0260\n",
      "Epoch [4/5], Step [1750/30930], Loss: 0.0155\n",
      "Epoch [4/5], Step [1760/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1770/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1780/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [1790/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [1800/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [1810/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [1820/30930], Loss: 0.0247\n",
      "Epoch [4/5], Step [1830/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [1840/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [1850/30930], Loss: 0.0143\n",
      "Epoch [4/5], Step [1860/30930], Loss: 0.0460\n",
      "Epoch [4/5], Step [1870/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [1880/30930], Loss: 0.0224\n",
      "Epoch [4/5], Step [1890/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [1900/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [1910/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [1920/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [1930/30930], Loss: 0.0179\n",
      "Epoch [4/5], Step [1940/30930], Loss: 0.0173\n",
      "Epoch [4/5], Step [1950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [1960/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [1970/30930], Loss: 0.0169\n",
      "Epoch [4/5], Step [1980/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [1990/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2000/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2010/30930], Loss: 0.0172\n",
      "Epoch [4/5], Step [2020/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2030/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2040/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [2050/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [2060/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2070/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2080/30930], Loss: 0.0670\n",
      "Epoch [4/5], Step [2090/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [2100/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [2110/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [2120/30930], Loss: 0.0391\n",
      "Epoch [4/5], Step [2130/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [2140/30930], Loss: 0.0175\n",
      "Epoch [4/5], Step [2150/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [2160/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [2170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2180/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [2190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [2200/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2210/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [2220/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [2230/30930], Loss: 0.0379\n",
      "Epoch [4/5], Step [2240/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2250/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [2260/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2270/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2280/30930], Loss: 0.0183\n",
      "Epoch [4/5], Step [2290/30930], Loss: 0.0245\n",
      "Epoch [4/5], Step [2300/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [2310/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [2320/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [2330/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [2340/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2350/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [2360/30930], Loss: 0.0125\n",
      "Epoch [4/5], Step [2370/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2380/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [2390/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [2400/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2410/30930], Loss: 0.0312\n",
      "Epoch [4/5], Step [2420/30930], Loss: 0.0140\n",
      "Epoch [4/5], Step [2430/30930], Loss: 0.0124\n",
      "Epoch [4/5], Step [2440/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [2450/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [2460/30930], Loss: 0.0466\n",
      "Epoch [4/5], Step [2470/30930], Loss: 0.0173\n",
      "Epoch [4/5], Step [2480/30930], Loss: 0.0397\n",
      "Epoch [4/5], Step [2490/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [2500/30930], Loss: 0.0271\n",
      "Epoch [4/5], Step [2510/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [2520/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [2530/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [2540/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [2550/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [2560/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [2570/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [2580/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [2590/30930], Loss: 0.0106\n",
      "Epoch [4/5], Step [2600/30930], Loss: 0.0097\n",
      "Epoch [4/5], Step [2610/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [2620/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [2630/30930], Loss: 0.0242\n",
      "Epoch [4/5], Step [2640/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [2650/30930], Loss: 0.0106\n",
      "Epoch [4/5], Step [2660/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [2670/30930], Loss: 0.0138\n",
      "Epoch [4/5], Step [2680/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [2690/30930], Loss: 0.0072\n",
      "Epoch [4/5], Step [2700/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [2710/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [2720/30930], Loss: 0.0112\n",
      "Epoch [4/5], Step [2730/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [2740/30930], Loss: 0.0303\n",
      "Epoch [4/5], Step [2750/30930], Loss: 0.0094\n",
      "Epoch [4/5], Step [2760/30930], Loss: 0.0126\n",
      "Epoch [4/5], Step [2770/30930], Loss: 0.0254\n",
      "Epoch [4/5], Step [2780/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [2790/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [2800/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [2810/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [2820/30930], Loss: 0.0642\n",
      "Epoch [4/5], Step [2830/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [2840/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [2850/30930], Loss: 0.0205\n",
      "Epoch [4/5], Step [2860/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2870/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2880/30930], Loss: 0.0280\n",
      "Epoch [4/5], Step [2890/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [2900/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [2910/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [2920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [2930/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [2940/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [2950/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [2960/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [2970/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [2980/30930], Loss: 0.0228\n",
      "Epoch [4/5], Step [2990/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [3000/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3010/30930], Loss: 0.0185\n",
      "Epoch [4/5], Step [3020/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [3030/30930], Loss: 0.0714\n",
      "Epoch [4/5], Step [3040/30930], Loss: 0.0943\n",
      "Epoch [4/5], Step [3050/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3060/30930], Loss: 0.0074\n",
      "Epoch [4/5], Step [3070/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3080/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [3090/30930], Loss: 0.0433\n",
      "Epoch [4/5], Step [3100/30930], Loss: 0.0757\n",
      "Epoch [4/5], Step [3110/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [3120/30930], Loss: 0.0136\n",
      "Epoch [4/5], Step [3130/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [3140/30930], Loss: 0.0214\n",
      "Epoch [4/5], Step [3150/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [3160/30930], Loss: 0.0289\n",
      "Epoch [4/5], Step [3170/30930], Loss: 0.0339\n",
      "Epoch [4/5], Step [3180/30930], Loss: 0.0069\n",
      "Epoch [4/5], Step [3190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3200/30930], Loss: 0.0112\n",
      "Epoch [4/5], Step [3210/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [3220/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [3230/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [3240/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [3250/30930], Loss: 0.0419\n",
      "Epoch [4/5], Step [3260/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3270/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3280/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [3290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3300/30930], Loss: 0.0163\n",
      "Epoch [4/5], Step [3310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3320/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [3330/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [3340/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [3350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3360/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3370/30930], Loss: 0.0190\n",
      "Epoch [4/5], Step [3380/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [3390/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [3400/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [3410/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3420/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [3430/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [3440/30930], Loss: 0.0171\n",
      "Epoch [4/5], Step [3450/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [3460/30930], Loss: 0.0133\n",
      "Epoch [4/5], Step [3470/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [3480/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3490/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [3500/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [3510/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [3520/30930], Loss: 0.0942\n",
      "Epoch [4/5], Step [3530/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3540/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3550/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [3560/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3570/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [3580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3590/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [3600/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3610/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [3620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3630/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [3640/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [3650/30930], Loss: 0.0247\n",
      "Epoch [4/5], Step [3660/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [3670/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [3680/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [3690/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [3700/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [3710/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [3720/30930], Loss: 0.0698\n",
      "Epoch [4/5], Step [3730/30930], Loss: 0.0419\n",
      "Epoch [4/5], Step [3740/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [3750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3760/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [3770/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3780/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [3790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3800/30930], Loss: 0.0427\n",
      "Epoch [4/5], Step [3810/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [3820/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [3830/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [3840/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [3850/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3860/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [3870/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [3880/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [3890/30930], Loss: 0.0148\n",
      "Epoch [4/5], Step [3900/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [3910/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [3920/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3930/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3940/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [3950/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [3960/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [3970/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [3980/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [3990/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [4000/30930], Loss: 0.0116\n",
      "Epoch [4/5], Step [4010/30930], Loss: 0.0139\n",
      "Epoch [4/5], Step [4020/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4030/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [4040/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [4050/30930], Loss: 0.0384\n",
      "Epoch [4/5], Step [4060/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4070/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [4080/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4090/30930], Loss: 0.0146\n",
      "Epoch [4/5], Step [4100/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [4110/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [4120/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [4130/30930], Loss: 0.0116\n",
      "Epoch [4/5], Step [4140/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [4150/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [4160/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [4170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4180/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [4190/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4200/30930], Loss: 0.0111\n",
      "Epoch [4/5], Step [4210/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4220/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4230/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [4240/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4250/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4260/30930], Loss: 0.0278\n",
      "Epoch [4/5], Step [4270/30930], Loss: 0.1014\n",
      "Epoch [4/5], Step [4280/30930], Loss: 0.0119\n",
      "Epoch [4/5], Step [4290/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [4300/30930], Loss: 0.0233\n",
      "Epoch [4/5], Step [4310/30930], Loss: 0.0597\n",
      "Epoch [4/5], Step [4320/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [4330/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [4340/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4350/30930], Loss: 0.0157\n",
      "Epoch [4/5], Step [4360/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4370/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [4380/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [4390/30930], Loss: 0.0313\n",
      "Epoch [4/5], Step [4400/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [4410/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [4420/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [4430/30930], Loss: 0.0141\n",
      "Epoch [4/5], Step [4440/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4450/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4460/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [4470/30930], Loss: 0.0370\n",
      "Epoch [4/5], Step [4480/30930], Loss: 0.0162\n",
      "Epoch [4/5], Step [4490/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [4500/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [4510/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [4520/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4530/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4540/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4550/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [4560/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [4570/30930], Loss: 0.0316\n",
      "Epoch [4/5], Step [4580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4590/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [4600/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [4610/30930], Loss: 0.0081\n",
      "Epoch [4/5], Step [4620/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [4630/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4640/30930], Loss: 0.0191\n",
      "Epoch [4/5], Step [4650/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [4660/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [4670/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [4680/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [4690/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [4700/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [4710/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4720/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [4730/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [4740/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [4750/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [4760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4770/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [4780/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [4790/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [4800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4810/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [4820/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [4830/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [4840/30930], Loss: 0.0494\n",
      "Epoch [4/5], Step [4850/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [4860/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [4870/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [4880/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [4890/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [4900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [4910/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [4920/30930], Loss: 0.0173\n",
      "Epoch [4/5], Step [4930/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [4940/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [4950/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [4960/30930], Loss: 0.0415\n",
      "Epoch [4/5], Step [4970/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [4980/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [4990/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [5000/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [5010/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5020/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [5030/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [5040/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [5050/30930], Loss: 0.0116\n",
      "Epoch [4/5], Step [5060/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5070/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [5080/30930], Loss: 0.0357\n",
      "Epoch [4/5], Step [5090/30930], Loss: 0.0307\n",
      "Epoch [4/5], Step [5100/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [5110/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [5120/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [5130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5140/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [5150/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [5160/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5170/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [5180/30930], Loss: 0.0106\n",
      "Epoch [4/5], Step [5190/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5200/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5210/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [5220/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [5230/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [5240/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [5250/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5260/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [5270/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [5280/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [5290/30930], Loss: 0.0143\n",
      "Epoch [4/5], Step [5300/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5320/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5330/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5340/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [5350/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [5360/30930], Loss: 0.0167\n",
      "Epoch [4/5], Step [5370/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [5380/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5390/30930], Loss: 0.0513\n",
      "Epoch [4/5], Step [5400/30930], Loss: 0.0527\n",
      "Epoch [4/5], Step [5410/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5420/30930], Loss: 0.0121\n",
      "Epoch [4/5], Step [5430/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [5440/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [5450/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [5460/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [5470/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [5480/30930], Loss: 0.0142\n",
      "Epoch [4/5], Step [5490/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [5500/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [5510/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [5520/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [5530/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [5540/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [5550/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5560/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [5570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5590/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [5600/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5610/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [5620/30930], Loss: 0.0242\n",
      "Epoch [4/5], Step [5630/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [5640/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [5650/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [5660/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [5670/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [5680/30930], Loss: 0.0177\n",
      "Epoch [4/5], Step [5690/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5700/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [5710/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [5720/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [5730/30930], Loss: 0.0213\n",
      "Epoch [4/5], Step [5740/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [5750/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [5760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5770/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [5780/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [5790/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [5800/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [5810/30930], Loss: 0.0399\n",
      "Epoch [4/5], Step [5820/30930], Loss: 0.0302\n",
      "Epoch [4/5], Step [5830/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [5840/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [5850/30930], Loss: 0.0243\n",
      "Epoch [4/5], Step [5860/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [5870/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [5880/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [5890/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [5900/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [5910/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [5920/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [5930/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [5940/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [5950/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [5960/30930], Loss: 0.0426\n",
      "Epoch [4/5], Step [5970/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [5980/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [5990/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6000/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [6010/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6020/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6030/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6040/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [6050/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [6060/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [6070/30930], Loss: 0.0187\n",
      "Epoch [4/5], Step [6080/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [6090/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6100/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [6110/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6120/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [6130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6140/30930], Loss: 0.0200\n",
      "Epoch [4/5], Step [6150/30930], Loss: 0.0771\n",
      "Epoch [4/5], Step [6160/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [6170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6180/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [6190/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [6200/30930], Loss: 0.0115\n",
      "Epoch [4/5], Step [6210/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6220/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [6230/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [6240/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6250/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [6260/30930], Loss: 0.0422\n",
      "Epoch [4/5], Step [6270/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6280/30930], Loss: 0.0417\n",
      "Epoch [4/5], Step [6290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6300/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [6310/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [6320/30930], Loss: 0.0131\n",
      "Epoch [4/5], Step [6330/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [6340/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [6350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6360/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [6370/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [6380/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [6390/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [6400/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6410/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [6420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6430/30930], Loss: 0.0112\n",
      "Epoch [4/5], Step [6440/30930], Loss: 0.0400\n",
      "Epoch [4/5], Step [6450/30930], Loss: 0.0254\n",
      "Epoch [4/5], Step [6460/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6470/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [6480/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [6490/30930], Loss: 0.0861\n",
      "Epoch [4/5], Step [6500/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [6510/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6520/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [6530/30930], Loss: 0.0350\n",
      "Epoch [4/5], Step [6540/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6550/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [6560/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6570/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6580/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [6590/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [6600/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [6610/30930], Loss: 0.0127\n",
      "Epoch [4/5], Step [6620/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [6630/30930], Loss: 0.0289\n",
      "Epoch [4/5], Step [6640/30930], Loss: 0.0114\n",
      "Epoch [4/5], Step [6650/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [6660/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [6670/30930], Loss: 0.0225\n",
      "Epoch [4/5], Step [6680/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6690/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6700/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [6710/30930], Loss: 0.0219\n",
      "Epoch [4/5], Step [6720/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [6730/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [6740/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [6750/30930], Loss: 0.0195\n",
      "Epoch [4/5], Step [6760/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [6770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [6780/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [6790/30930], Loss: 0.0325\n",
      "Epoch [4/5], Step [6800/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [6810/30930], Loss: 0.0115\n",
      "Epoch [4/5], Step [6820/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [6830/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [6840/30930], Loss: 0.0880\n",
      "Epoch [4/5], Step [6850/30930], Loss: 0.0224\n",
      "Epoch [4/5], Step [6860/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [6870/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [6880/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [6890/30930], Loss: 0.0210\n",
      "Epoch [4/5], Step [6900/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [6910/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [6920/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [6930/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [6940/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [6950/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [6960/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [6970/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [6980/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [6990/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [7000/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [7010/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [7020/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [7030/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7040/30930], Loss: 0.0203\n",
      "Epoch [4/5], Step [7050/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [7060/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [7070/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7080/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [7090/30930], Loss: 0.0365\n",
      "Epoch [4/5], Step [7100/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [7110/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [7120/30930], Loss: 0.0274\n",
      "Epoch [4/5], Step [7130/30930], Loss: 0.0187\n",
      "Epoch [4/5], Step [7140/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [7150/30930], Loss: 0.0645\n",
      "Epoch [4/5], Step [7160/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [7170/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [7180/30930], Loss: 0.0069\n",
      "Epoch [4/5], Step [7190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7200/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7210/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [7220/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [7230/30930], Loss: 0.0105\n",
      "Epoch [4/5], Step [7240/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [7250/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [7260/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [7270/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [7280/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [7290/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [7300/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [7310/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [7320/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [7330/30930], Loss: 0.0243\n",
      "Epoch [4/5], Step [7340/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7350/30930], Loss: 0.0229\n",
      "Epoch [4/5], Step [7360/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7370/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [7380/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [7390/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [7400/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [7410/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7420/30930], Loss: 0.0091\n",
      "Epoch [4/5], Step [7430/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [7440/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [7450/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7460/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7470/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [7480/30930], Loss: 0.0072\n",
      "Epoch [4/5], Step [7490/30930], Loss: 0.0377\n",
      "Epoch [4/5], Step [7500/30930], Loss: 0.0073\n",
      "Epoch [4/5], Step [7510/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7520/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [7530/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [7540/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7550/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7560/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [7570/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [7580/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7590/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [7600/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [7610/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7620/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [7630/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [7640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7650/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [7660/30930], Loss: 0.0484\n",
      "Epoch [4/5], Step [7670/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [7680/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [7690/30930], Loss: 0.0099\n",
      "Epoch [4/5], Step [7700/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [7710/30930], Loss: 0.0669\n",
      "Epoch [4/5], Step [7720/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [7730/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [7740/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [7750/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [7760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7770/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7780/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [7790/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [7800/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [7810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [7820/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [7830/30930], Loss: 0.0350\n",
      "Epoch [4/5], Step [7840/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [7850/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [7860/30930], Loss: 0.0088\n",
      "Epoch [4/5], Step [7870/30930], Loss: 0.0088\n",
      "Epoch [4/5], Step [7880/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [7890/30930], Loss: 0.0182\n",
      "Epoch [4/5], Step [7900/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7910/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [7920/30930], Loss: 0.1169\n",
      "Epoch [4/5], Step [7930/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [7940/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [7950/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [7960/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [7970/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [7980/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [7990/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [8000/30930], Loss: 0.0056\n",
      "Epoch [4/5], Step [8010/30930], Loss: 0.0179\n",
      "Epoch [4/5], Step [8020/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [8030/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [8040/30930], Loss: 0.0117\n",
      "Epoch [4/5], Step [8050/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [8060/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8070/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8080/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [8090/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [8100/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8110/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [8120/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [8130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8140/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [8150/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [8160/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [8170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8180/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [8190/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [8200/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [8210/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8220/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [8230/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [8240/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [8250/30930], Loss: 0.0197\n",
      "Epoch [4/5], Step [8260/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [8270/30930], Loss: 0.0377\n",
      "Epoch [4/5], Step [8280/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8290/30930], Loss: 0.0159\n",
      "Epoch [4/5], Step [8300/30930], Loss: 0.0162\n",
      "Epoch [4/5], Step [8310/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [8320/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [8330/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [8340/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [8350/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8360/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [8370/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [8380/30930], Loss: 0.0174\n",
      "Epoch [4/5], Step [8390/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [8400/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [8410/30930], Loss: 0.0391\n",
      "Epoch [4/5], Step [8420/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [8430/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [8440/30930], Loss: 0.0816\n",
      "Epoch [4/5], Step [8450/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8460/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8470/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8480/30930], Loss: 0.0158\n",
      "Epoch [4/5], Step [8490/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8500/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [8510/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [8520/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [8530/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [8540/30930], Loss: 0.0389\n",
      "Epoch [4/5], Step [8550/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [8560/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8570/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [8580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8590/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8600/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8610/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [8620/30930], Loss: 0.0198\n",
      "Epoch [4/5], Step [8630/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [8640/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [8650/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [8660/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [8670/30930], Loss: 0.0110\n",
      "Epoch [4/5], Step [8680/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [8690/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [8700/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8710/30930], Loss: 0.0067\n",
      "Epoch [4/5], Step [8720/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [8730/30930], Loss: 0.0146\n",
      "Epoch [4/5], Step [8740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8750/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [8760/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [8770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8780/30930], Loss: 0.0143\n",
      "Epoch [4/5], Step [8790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8800/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8810/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [8820/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [8830/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8850/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [8860/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8870/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [8880/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [8890/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [8910/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [8920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8930/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [8940/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [8950/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [8960/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [8970/30930], Loss: 0.0136\n",
      "Epoch [4/5], Step [8980/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [8990/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [9000/30930], Loss: 0.0132\n",
      "Epoch [4/5], Step [9010/30930], Loss: 0.0392\n",
      "Epoch [4/5], Step [9020/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [9030/30930], Loss: 0.0204\n",
      "Epoch [4/5], Step [9040/30930], Loss: 0.0201\n",
      "Epoch [4/5], Step [9050/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9060/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [9070/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [9080/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9090/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [9100/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9110/30930], Loss: 0.0179\n",
      "Epoch [4/5], Step [9120/30930], Loss: 0.0183\n",
      "Epoch [4/5], Step [9130/30930], Loss: 0.0197\n",
      "Epoch [4/5], Step [9140/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [9150/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [9160/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [9170/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9180/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9190/30930], Loss: 0.0077\n",
      "Epoch [4/5], Step [9200/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9210/30930], Loss: 0.0319\n",
      "Epoch [4/5], Step [9220/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [9230/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9240/30930], Loss: 0.0658\n",
      "Epoch [4/5], Step [9250/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [9260/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [9270/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [9280/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [9290/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [9300/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9310/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9320/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [9330/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9340/30930], Loss: 0.0125\n",
      "Epoch [4/5], Step [9350/30930], Loss: 0.0247\n",
      "Epoch [4/5], Step [9360/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [9370/30930], Loss: 0.0849\n",
      "Epoch [4/5], Step [9380/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [9390/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [9400/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9410/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [9420/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [9430/30930], Loss: 0.0730\n",
      "Epoch [4/5], Step [9440/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [9450/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [9460/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [9470/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [9480/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [9490/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [9500/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [9510/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [9520/30930], Loss: 0.0448\n",
      "Epoch [4/5], Step [9530/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9540/30930], Loss: 0.0619\n",
      "Epoch [4/5], Step [9550/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [9560/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9570/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [9580/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [9590/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [9600/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [9610/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9630/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [9640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9650/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [9660/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [9670/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [9680/30930], Loss: 0.0148\n",
      "Epoch [4/5], Step [9690/30930], Loss: 0.0281\n",
      "Epoch [4/5], Step [9700/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [9710/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9720/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [9730/30930], Loss: 0.0806\n",
      "Epoch [4/5], Step [9740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9750/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9760/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [9770/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [9780/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9790/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [9800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [9810/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [9820/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9830/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9840/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [9850/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [9860/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [9870/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [9880/30930], Loss: 0.0041\n",
      "Epoch [4/5], Step [9890/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [9900/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [9910/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [9920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9930/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [9940/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9950/30930], Loss: 0.0514\n",
      "Epoch [4/5], Step [9960/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [9970/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [9980/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [9990/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [10000/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10010/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10020/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [10030/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10040/30930], Loss: 0.0151\n",
      "Epoch [4/5], Step [10050/30930], Loss: 0.0162\n",
      "Epoch [4/5], Step [10060/30930], Loss: 0.0294\n",
      "Epoch [4/5], Step [10070/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10080/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [10090/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [10100/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [10110/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [10120/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [10130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10140/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [10150/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [10160/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [10170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10180/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [10190/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [10200/30930], Loss: 0.0102\n",
      "Epoch [4/5], Step [10210/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [10220/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [10230/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [10240/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10250/30930], Loss: 0.0450\n",
      "Epoch [4/5], Step [10260/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10270/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [10280/30930], Loss: 0.0067\n",
      "Epoch [4/5], Step [10290/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [10300/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [10310/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [10320/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [10330/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [10340/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [10350/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [10360/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [10370/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [10380/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [10390/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10400/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [10410/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [10420/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [10430/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [10440/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [10450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10460/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10470/30930], Loss: 0.0302\n",
      "Epoch [4/5], Step [10480/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [10490/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [10500/30930], Loss: 0.0094\n",
      "Epoch [4/5], Step [10510/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10520/30930], Loss: 0.0565\n",
      "Epoch [4/5], Step [10530/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [10540/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [10550/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10560/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [10570/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [10580/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [10590/30930], Loss: 0.0444\n",
      "Epoch [4/5], Step [10600/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [10610/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10630/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [10640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10650/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10660/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [10670/30930], Loss: 0.0436\n",
      "Epoch [4/5], Step [10680/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [10690/30930], Loss: 0.0937\n",
      "Epoch [4/5], Step [10700/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [10710/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [10720/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [10730/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [10740/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [10750/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [10760/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [10770/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [10780/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [10790/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [10800/30930], Loss: 0.0088\n",
      "Epoch [4/5], Step [10810/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [10820/30930], Loss: 0.0429\n",
      "Epoch [4/5], Step [10830/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [10840/30930], Loss: 0.0281\n",
      "Epoch [4/5], Step [10850/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [10860/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [10870/30930], Loss: 0.0264\n",
      "Epoch [4/5], Step [10880/30930], Loss: 0.0133\n",
      "Epoch [4/5], Step [10890/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [10900/30930], Loss: 0.0201\n",
      "Epoch [4/5], Step [10910/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10920/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [10930/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [10940/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [10950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [10960/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [10970/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [10980/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [10990/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [11000/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [11010/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [11020/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [11030/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [11040/30930], Loss: 0.0056\n",
      "Epoch [4/5], Step [11050/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [11060/30930], Loss: 0.0216\n",
      "Epoch [4/5], Step [11070/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [11080/30930], Loss: 0.0286\n",
      "Epoch [4/5], Step [11090/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [11100/30930], Loss: 0.0066\n",
      "Epoch [4/5], Step [11110/30930], Loss: 0.0084\n",
      "Epoch [4/5], Step [11120/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11130/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [11140/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [11150/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [11160/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11170/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11180/30930], Loss: 0.0190\n",
      "Epoch [4/5], Step [11190/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11200/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [11210/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [11220/30930], Loss: 0.0084\n",
      "Epoch [4/5], Step [11230/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11240/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [11250/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [11260/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [11270/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11280/30930], Loss: 0.0268\n",
      "Epoch [4/5], Step [11290/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [11300/30930], Loss: 0.0146\n",
      "Epoch [4/5], Step [11310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11320/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [11330/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [11340/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [11350/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11360/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11370/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [11380/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [11390/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [11400/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [11410/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [11420/30930], Loss: 0.1397\n",
      "Epoch [4/5], Step [11430/30930], Loss: 0.0041\n",
      "Epoch [4/5], Step [11440/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11450/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [11460/30930], Loss: 0.0184\n",
      "Epoch [4/5], Step [11470/30930], Loss: 0.0629\n",
      "Epoch [4/5], Step [11480/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11490/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [11500/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [11510/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [11520/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [11530/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [11540/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [11550/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11560/30930], Loss: 0.0369\n",
      "Epoch [4/5], Step [11570/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [11580/30930], Loss: 0.0407\n",
      "Epoch [4/5], Step [11590/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [11600/30930], Loss: 0.0147\n",
      "Epoch [4/5], Step [11610/30930], Loss: 0.0138\n",
      "Epoch [4/5], Step [11620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11630/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11640/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [11650/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11660/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11670/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [11680/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11690/30930], Loss: 0.0212\n",
      "Epoch [4/5], Step [11700/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [11710/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [11720/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [11730/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [11740/30930], Loss: 0.0081\n",
      "Epoch [4/5], Step [11750/30930], Loss: 0.0970\n",
      "Epoch [4/5], Step [11760/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [11770/30930], Loss: 0.0208\n",
      "Epoch [4/5], Step [11780/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [11790/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [11800/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [11810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11820/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [11830/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [11840/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [11850/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [11860/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [11870/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [11880/30930], Loss: 0.0217\n",
      "Epoch [4/5], Step [11890/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [11910/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [11920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11930/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [11940/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [11950/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [11960/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [11970/30930], Loss: 0.0146\n",
      "Epoch [4/5], Step [11980/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [11990/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12000/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [12010/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [12020/30930], Loss: 0.0111\n",
      "Epoch [4/5], Step [12030/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12040/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [12050/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [12060/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [12070/30930], Loss: 0.0337\n",
      "Epoch [4/5], Step [12080/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [12090/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [12100/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [12110/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [12120/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12130/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [12140/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12150/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12160/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [12170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12180/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [12190/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [12200/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [12210/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [12220/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [12230/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [12240/30930], Loss: 0.0234\n",
      "Epoch [4/5], Step [12250/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [12260/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [12270/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [12280/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [12290/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [12300/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [12310/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [12320/30930], Loss: 0.0079\n",
      "Epoch [4/5], Step [12330/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12340/30930], Loss: 0.0358\n",
      "Epoch [4/5], Step [12350/30930], Loss: 0.0159\n",
      "Epoch [4/5], Step [12360/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [12370/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [12380/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12390/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [12400/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [12410/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12420/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [12430/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12440/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12450/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12460/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12470/30930], Loss: 0.0412\n",
      "Epoch [4/5], Step [12480/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12490/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [12500/30930], Loss: 0.0066\n",
      "Epoch [4/5], Step [12510/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12520/30930], Loss: 0.0339\n",
      "Epoch [4/5], Step [12530/30930], Loss: 0.0074\n",
      "Epoch [4/5], Step [12540/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [12550/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [12560/30930], Loss: 0.0150\n",
      "Epoch [4/5], Step [12570/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [12580/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [12590/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12600/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [12610/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [12620/30930], Loss: 0.0393\n",
      "Epoch [4/5], Step [12630/30930], Loss: 0.0203\n",
      "Epoch [4/5], Step [12640/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [12650/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12660/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [12670/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [12680/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12690/30930], Loss: 0.1048\n",
      "Epoch [4/5], Step [12700/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [12710/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [12720/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [12730/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [12740/30930], Loss: 0.0535\n",
      "Epoch [4/5], Step [12750/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [12760/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [12770/30930], Loss: 0.0321\n",
      "Epoch [4/5], Step [12780/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [12790/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [12800/30930], Loss: 0.1618\n",
      "Epoch [4/5], Step [12810/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [12820/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [12830/30930], Loss: 0.0158\n",
      "Epoch [4/5], Step [12840/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [12850/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [12860/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12870/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [12880/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [12890/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [12900/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [12910/30930], Loss: 0.0530\n",
      "Epoch [4/5], Step [12920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12930/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12940/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [12950/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [12960/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [12970/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [12980/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [12990/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [13000/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [13010/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [13020/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [13030/30930], Loss: 0.0400\n",
      "Epoch [4/5], Step [13040/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [13050/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [13060/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [13070/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [13080/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [13090/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [13100/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [13110/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [13120/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [13130/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [13140/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [13150/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [13160/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [13170/30930], Loss: 0.0702\n",
      "Epoch [4/5], Step [13180/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13190/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13200/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [13210/30930], Loss: 0.0186\n",
      "Epoch [4/5], Step [13220/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [13230/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [13240/30930], Loss: 0.0066\n",
      "Epoch [4/5], Step [13250/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [13260/30930], Loss: 0.0198\n",
      "Epoch [4/5], Step [13270/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [13280/30930], Loss: 0.0240\n",
      "Epoch [4/5], Step [13290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13300/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13310/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [13320/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13330/30930], Loss: 0.0201\n",
      "Epoch [4/5], Step [13340/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [13350/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [13360/30930], Loss: 0.0259\n",
      "Epoch [4/5], Step [13370/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [13380/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13390/30930], Loss: 0.0153\n",
      "Epoch [4/5], Step [13400/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13410/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [13420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13430/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13440/30930], Loss: 0.0102\n",
      "Epoch [4/5], Step [13450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13460/30930], Loss: 0.0425\n",
      "Epoch [4/5], Step [13470/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [13480/30930], Loss: 0.0300\n",
      "Epoch [4/5], Step [13490/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13500/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13510/30930], Loss: 0.0072\n",
      "Epoch [4/5], Step [13520/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [13530/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13540/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13550/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [13560/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [13570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13580/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [13590/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [13600/30930], Loss: 0.0157\n",
      "Epoch [4/5], Step [13610/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [13620/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [13630/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13640/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [13650/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13660/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [13670/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [13680/30930], Loss: 0.0344\n",
      "Epoch [4/5], Step [13690/30930], Loss: 0.0142\n",
      "Epoch [4/5], Step [13700/30930], Loss: 0.0203\n",
      "Epoch [4/5], Step [13710/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [13720/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13730/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [13740/30930], Loss: 0.0152\n",
      "Epoch [4/5], Step [13750/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [13760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13770/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [13780/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13790/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [13800/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [13810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13820/30930], Loss: 0.0142\n",
      "Epoch [4/5], Step [13830/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [13840/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [13850/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [13860/30930], Loss: 0.0943\n",
      "Epoch [4/5], Step [13870/30930], Loss: 0.0091\n",
      "Epoch [4/5], Step [13880/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [13890/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [13900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13910/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [13920/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [13930/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [13940/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [13950/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [13960/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [13970/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [13980/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [13990/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14000/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [14010/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [14020/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [14030/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [14040/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14050/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14060/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14070/30930], Loss: 0.0569\n",
      "Epoch [4/5], Step [14080/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [14090/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [14100/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [14110/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [14120/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [14130/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [14140/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [14150/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [14160/30930], Loss: 0.0202\n",
      "Epoch [4/5], Step [14170/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [14180/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [14190/30930], Loss: 0.0146\n",
      "Epoch [4/5], Step [14200/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [14210/30930], Loss: 0.0285\n",
      "Epoch [4/5], Step [14220/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [14230/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [14240/30930], Loss: 0.0203\n",
      "Epoch [4/5], Step [14250/30930], Loss: 0.0124\n",
      "Epoch [4/5], Step [14260/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [14270/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [14280/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [14290/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [14300/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [14310/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14320/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [14330/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14340/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [14350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14360/30930], Loss: 0.0253\n",
      "Epoch [4/5], Step [14370/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [14380/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [14390/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [14400/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [14410/30930], Loss: 0.0280\n",
      "Epoch [4/5], Step [14420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14430/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [14440/30930], Loss: 0.0191\n",
      "Epoch [4/5], Step [14450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14460/30930], Loss: 0.0113\n",
      "Epoch [4/5], Step [14470/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [14480/30930], Loss: 0.0351\n",
      "Epoch [4/5], Step [14490/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [14500/30930], Loss: 0.0416\n",
      "Epoch [4/5], Step [14510/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [14520/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [14530/30930], Loss: 0.0277\n",
      "Epoch [4/5], Step [14540/30930], Loss: 0.0115\n",
      "Epoch [4/5], Step [14550/30930], Loss: 0.0137\n",
      "Epoch [4/5], Step [14560/30930], Loss: 0.0087\n",
      "Epoch [4/5], Step [14570/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [14580/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [14590/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14600/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [14610/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [14620/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14630/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14640/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [14650/30930], Loss: 0.0173\n",
      "Epoch [4/5], Step [14660/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [14670/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14680/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14690/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [14700/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [14710/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14720/30930], Loss: 0.0114\n",
      "Epoch [4/5], Step [14730/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [14740/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [14750/30930], Loss: 0.0276\n",
      "Epoch [4/5], Step [14760/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [14770/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [14780/30930], Loss: 0.0212\n",
      "Epoch [4/5], Step [14790/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [14800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14810/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14820/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [14830/30930], Loss: 0.0685\n",
      "Epoch [4/5], Step [14840/30930], Loss: 0.0210\n",
      "Epoch [4/5], Step [14850/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14860/30930], Loss: 0.0444\n",
      "Epoch [4/5], Step [14870/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14880/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [14890/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14910/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14920/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [14930/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [14940/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [14950/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14960/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [14970/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [14980/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [14990/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [15000/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [15010/30930], Loss: 0.0521\n",
      "Epoch [4/5], Step [15020/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15030/30930], Loss: 0.0305\n",
      "Epoch [4/5], Step [15040/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15050/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [15060/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [15070/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [15080/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [15090/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [15100/30930], Loss: 0.0081\n",
      "Epoch [4/5], Step [15110/30930], Loss: 0.0377\n",
      "Epoch [4/5], Step [15120/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [15130/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [15140/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [15150/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [15160/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [15170/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [15180/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [15190/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15200/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [15210/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [15220/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [15230/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [15240/30930], Loss: 0.0369\n",
      "Epoch [4/5], Step [15250/30930], Loss: 0.0679\n",
      "Epoch [4/5], Step [15260/30930], Loss: 0.0288\n",
      "Epoch [4/5], Step [15270/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15280/30930], Loss: 0.0299\n",
      "Epoch [4/5], Step [15290/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [15300/30930], Loss: 0.0089\n",
      "Epoch [4/5], Step [15310/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [15320/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [15330/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15340/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15350/30930], Loss: 0.0124\n",
      "Epoch [4/5], Step [15360/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [15370/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [15380/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [15390/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [15400/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15410/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [15420/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [15430/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [15440/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [15450/30930], Loss: 0.0069\n",
      "Epoch [4/5], Step [15460/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15470/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [15480/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [15490/30930], Loss: 0.0116\n",
      "Epoch [4/5], Step [15500/30930], Loss: 0.0092\n",
      "Epoch [4/5], Step [15510/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [15520/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [15530/30930], Loss: 0.1475\n",
      "Epoch [4/5], Step [15540/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [15550/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [15560/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [15570/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [15580/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [15590/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15600/30930], Loss: 0.0191\n",
      "Epoch [4/5], Step [15610/30930], Loss: 0.0503\n",
      "Epoch [4/5], Step [15620/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [15630/30930], Loss: 0.0087\n",
      "Epoch [4/5], Step [15640/30930], Loss: 0.0212\n",
      "Epoch [4/5], Step [15650/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [15660/30930], Loss: 0.0237\n",
      "Epoch [4/5], Step [15670/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15680/30930], Loss: 0.0120\n",
      "Epoch [4/5], Step [15690/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15700/30930], Loss: 0.0056\n",
      "Epoch [4/5], Step [15710/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [15720/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [15730/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [15740/30930], Loss: 0.0148\n",
      "Epoch [4/5], Step [15750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15770/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [15780/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [15790/30930], Loss: 0.0520\n",
      "Epoch [4/5], Step [15800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [15820/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [15830/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [15840/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [15850/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [15860/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [15870/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [15880/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [15890/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [15900/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [15910/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [15920/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [15930/30930], Loss: 0.0248\n",
      "Epoch [4/5], Step [15940/30930], Loss: 0.0139\n",
      "Epoch [4/5], Step [15950/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [15960/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [15970/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [15980/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [15990/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [16000/30930], Loss: 0.0127\n",
      "Epoch [4/5], Step [16010/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [16020/30930], Loss: 0.0271\n",
      "Epoch [4/5], Step [16030/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [16040/30930], Loss: 0.0477\n",
      "Epoch [4/5], Step [16050/30930], Loss: 0.0334\n",
      "Epoch [4/5], Step [16060/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [16070/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [16080/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [16090/30930], Loss: 0.0210\n",
      "Epoch [4/5], Step [16100/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [16110/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16120/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [16130/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [16140/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16150/30930], Loss: 0.0596\n",
      "Epoch [4/5], Step [16160/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [16170/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [16180/30930], Loss: 0.0101\n",
      "Epoch [4/5], Step [16190/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [16200/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [16210/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [16220/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [16230/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [16240/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [16250/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [16260/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [16270/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [16280/30930], Loss: 0.0593\n",
      "Epoch [4/5], Step [16290/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [16300/30930], Loss: 0.0139\n",
      "Epoch [4/5], Step [16310/30930], Loss: 0.0122\n",
      "Epoch [4/5], Step [16320/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [16330/30930], Loss: 0.0411\n",
      "Epoch [4/5], Step [16340/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [16350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16360/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [16370/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [16380/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [16390/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [16400/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [16410/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16420/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [16430/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16440/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [16450/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [16460/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [16470/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [16480/30930], Loss: 0.0798\n",
      "Epoch [4/5], Step [16490/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [16500/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [16510/30930], Loss: 0.0092\n",
      "Epoch [4/5], Step [16520/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16530/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [16540/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [16550/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [16560/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [16570/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [16580/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [16590/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [16600/30930], Loss: 0.0041\n",
      "Epoch [4/5], Step [16610/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [16620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16630/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [16640/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16650/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16660/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [16670/30930], Loss: 0.0361\n",
      "Epoch [4/5], Step [16680/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [16690/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16700/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [16710/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [16720/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [16730/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [16740/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [16750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16780/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16790/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [16800/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [16810/30930], Loss: 0.0171\n",
      "Epoch [4/5], Step [16820/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16830/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [16840/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16850/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [16860/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [16870/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [16880/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [16890/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [16900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [16910/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [16920/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [16930/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [16940/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [16950/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [16960/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [16970/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [16980/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [16990/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [17000/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17010/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [17020/30930], Loss: 0.0568\n",
      "Epoch [4/5], Step [17030/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17040/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [17050/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17060/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17070/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [17080/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [17090/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17100/30930], Loss: 0.0041\n",
      "Epoch [4/5], Step [17110/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17120/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17130/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [17140/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [17150/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [17160/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17170/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17180/30930], Loss: 0.0102\n",
      "Epoch [4/5], Step [17190/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17200/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17210/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17220/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [17230/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [17240/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [17250/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17260/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [17270/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [17280/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [17290/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17300/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [17310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17320/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [17330/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17340/30930], Loss: 0.0233\n",
      "Epoch [4/5], Step [17350/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [17360/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17370/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [17380/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17390/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17400/30930], Loss: 0.0069\n",
      "Epoch [4/5], Step [17410/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17420/30930], Loss: 0.0683\n",
      "Epoch [4/5], Step [17430/30930], Loss: 0.0777\n",
      "Epoch [4/5], Step [17440/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17450/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [17460/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [17470/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17480/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17490/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17500/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [17510/30930], Loss: 0.0337\n",
      "Epoch [4/5], Step [17520/30930], Loss: 0.0078\n",
      "Epoch [4/5], Step [17530/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [17540/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [17550/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [17560/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [17570/30930], Loss: 0.0159\n",
      "Epoch [4/5], Step [17580/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17590/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17600/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [17610/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17620/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17630/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17640/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [17650/30930], Loss: 0.0089\n",
      "Epoch [4/5], Step [17660/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17670/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [17680/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [17690/30930], Loss: 0.0216\n",
      "Epoch [4/5], Step [17700/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [17710/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [17720/30930], Loss: 0.0288\n",
      "Epoch [4/5], Step [17730/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [17740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17760/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [17770/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17780/30930], Loss: 0.0117\n",
      "Epoch [4/5], Step [17790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17810/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [17820/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17830/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [17840/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17850/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [17860/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [17870/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [17880/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [17890/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [17900/30930], Loss: 0.0811\n",
      "Epoch [4/5], Step [17910/30930], Loss: 0.0259\n",
      "Epoch [4/5], Step [17920/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [17930/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [17940/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [17950/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [17960/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [17970/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [17980/30930], Loss: 0.0079\n",
      "Epoch [4/5], Step [17990/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [18000/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [18010/30930], Loss: 0.0523\n",
      "Epoch [4/5], Step [18020/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18030/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [18040/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18050/30930], Loss: 0.0356\n",
      "Epoch [4/5], Step [18060/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [18070/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18080/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [18090/30930], Loss: 0.0121\n",
      "Epoch [4/5], Step [18100/30930], Loss: 0.0391\n",
      "Epoch [4/5], Step [18110/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18120/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [18130/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [18140/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18150/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [18160/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [18170/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [18180/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [18190/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [18200/30930], Loss: 0.1245\n",
      "Epoch [4/5], Step [18210/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [18220/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18230/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [18240/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [18250/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18260/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [18270/30930], Loss: 0.0098\n",
      "Epoch [4/5], Step [18280/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18290/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [18300/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [18310/30930], Loss: 0.0666\n",
      "Epoch [4/5], Step [18320/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [18330/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [18340/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [18350/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [18360/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [18370/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [18380/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [18390/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18400/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [18410/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [18420/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18430/30930], Loss: 0.0154\n",
      "Epoch [4/5], Step [18440/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [18450/30930], Loss: 0.0185\n",
      "Epoch [4/5], Step [18460/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [18470/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [18480/30930], Loss: 0.0165\n",
      "Epoch [4/5], Step [18490/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18500/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [18510/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18520/30930], Loss: 0.0073\n",
      "Epoch [4/5], Step [18530/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [18540/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [18550/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18560/30930], Loss: 0.0207\n",
      "Epoch [4/5], Step [18570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18580/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [18590/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [18600/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18610/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [18620/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [18630/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [18640/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [18650/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [18660/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [18670/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18680/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [18690/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [18700/30930], Loss: 0.0067\n",
      "Epoch [4/5], Step [18710/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [18720/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [18730/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [18740/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [18750/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [18760/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [18770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18780/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [18790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18800/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [18810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18820/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [18830/30930], Loss: 0.0407\n",
      "Epoch [4/5], Step [18840/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [18850/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [18860/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [18870/30930], Loss: 0.0091\n",
      "Epoch [4/5], Step [18880/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [18890/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [18900/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [18910/30930], Loss: 0.0265\n",
      "Epoch [4/5], Step [18920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [18930/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [18940/30930], Loss: 0.0775\n",
      "Epoch [4/5], Step [18950/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [18960/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [18970/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [18980/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [18990/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [19000/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19010/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19020/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19030/30930], Loss: 0.0370\n",
      "Epoch [4/5], Step [19040/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19050/30930], Loss: 0.0092\n",
      "Epoch [4/5], Step [19060/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [19070/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19080/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [19090/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19100/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [19110/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [19120/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [19130/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [19140/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [19150/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [19160/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [19170/30930], Loss: 0.0257\n",
      "Epoch [4/5], Step [19180/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19190/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [19200/30930], Loss: 0.0084\n",
      "Epoch [4/5], Step [19210/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [19220/30930], Loss: 0.0157\n",
      "Epoch [4/5], Step [19230/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [19240/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [19250/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [19260/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [19270/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [19280/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19290/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [19300/30930], Loss: 0.0190\n",
      "Epoch [4/5], Step [19310/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [19320/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [19330/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [19340/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [19350/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19360/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19370/30930], Loss: 0.0123\n",
      "Epoch [4/5], Step [19380/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [19390/30930], Loss: 0.0140\n",
      "Epoch [4/5], Step [19400/30930], Loss: 0.0508\n",
      "Epoch [4/5], Step [19410/30930], Loss: 0.0084\n",
      "Epoch [4/5], Step [19420/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [19430/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19440/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [19450/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [19460/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [19470/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19480/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19490/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [19500/30930], Loss: 0.0309\n",
      "Epoch [4/5], Step [19510/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [19520/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [19530/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [19540/30930], Loss: 0.0228\n",
      "Epoch [4/5], Step [19550/30930], Loss: 0.0129\n",
      "Epoch [4/5], Step [19560/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19570/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19590/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [19600/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [19610/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19620/30930], Loss: 0.0525\n",
      "Epoch [4/5], Step [19630/30930], Loss: 0.0348\n",
      "Epoch [4/5], Step [19640/30930], Loss: 0.0125\n",
      "Epoch [4/5], Step [19650/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [19660/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [19670/30930], Loss: 0.0363\n",
      "Epoch [4/5], Step [19680/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19690/30930], Loss: 0.0225\n",
      "Epoch [4/5], Step [19700/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [19710/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [19720/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [19730/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [19740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19750/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [19760/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [19770/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [19780/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [19790/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [19800/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [19810/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [19820/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [19830/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19840/30930], Loss: 0.0144\n",
      "Epoch [4/5], Step [19850/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [19860/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [19870/30930], Loss: 0.0344\n",
      "Epoch [4/5], Step [19880/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [19890/30930], Loss: 0.0328\n",
      "Epoch [4/5], Step [19900/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [19910/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [19920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19930/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19940/30930], Loss: 0.0136\n",
      "Epoch [4/5], Step [19950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19960/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [19970/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [19980/30930], Loss: 0.0365\n",
      "Epoch [4/5], Step [19990/30930], Loss: 0.0119\n",
      "Epoch [4/5], Step [20000/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20010/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [20020/30930], Loss: 0.0267\n",
      "Epoch [4/5], Step [20030/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [20040/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [20050/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [20060/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [20070/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [20080/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [20090/30930], Loss: 0.0093\n",
      "Epoch [4/5], Step [20100/30930], Loss: 0.0327\n",
      "Epoch [4/5], Step [20110/30930], Loss: 0.0311\n",
      "Epoch [4/5], Step [20120/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [20130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20140/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [20150/30930], Loss: 0.0227\n",
      "Epoch [4/5], Step [20160/30930], Loss: 0.0255\n",
      "Epoch [4/5], Step [20170/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [20180/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [20190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [20200/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20210/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20220/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20230/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [20240/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [20250/30930], Loss: 0.0098\n",
      "Epoch [4/5], Step [20260/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [20270/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20280/30930], Loss: 0.0522\n",
      "Epoch [4/5], Step [20290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20300/30930], Loss: 0.0097\n",
      "Epoch [4/5], Step [20310/30930], Loss: 0.0127\n",
      "Epoch [4/5], Step [20320/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [20330/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [20340/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [20350/30930], Loss: 0.0094\n",
      "Epoch [4/5], Step [20360/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [20370/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [20380/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [20390/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [20400/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [20410/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [20420/30930], Loss: 0.0349\n",
      "Epoch [4/5], Step [20430/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20440/30930], Loss: 0.0094\n",
      "Epoch [4/5], Step [20450/30930], Loss: 0.0093\n",
      "Epoch [4/5], Step [20460/30930], Loss: 0.0207\n",
      "Epoch [4/5], Step [20470/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [20480/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20490/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20500/30930], Loss: 0.0438\n",
      "Epoch [4/5], Step [20510/30930], Loss: 0.0629\n",
      "Epoch [4/5], Step [20520/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20530/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [20540/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20550/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [20560/30930], Loss: 0.0231\n",
      "Epoch [4/5], Step [20570/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20590/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [20600/30930], Loss: 0.0117\n",
      "Epoch [4/5], Step [20610/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20620/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [20630/30930], Loss: 0.0288\n",
      "Epoch [4/5], Step [20640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20650/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [20660/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20670/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [20680/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [20690/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [20700/30930], Loss: 0.0264\n",
      "Epoch [4/5], Step [20710/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [20720/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20730/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [20740/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [20750/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [20760/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [20770/30930], Loss: 0.1681\n",
      "Epoch [4/5], Step [20780/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [20790/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [20800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20810/30930], Loss: 0.0098\n",
      "Epoch [4/5], Step [20820/30930], Loss: 0.0130\n",
      "Epoch [4/5], Step [20830/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [20840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20850/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [20860/30930], Loss: 0.0543\n",
      "Epoch [4/5], Step [20870/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [20880/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [20890/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [20900/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [20910/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [20920/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [20930/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20940/30930], Loss: 0.0450\n",
      "Epoch [4/5], Step [20950/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [20960/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [20970/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [20980/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [20990/30930], Loss: 0.0233\n",
      "Epoch [4/5], Step [21000/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21010/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [21020/30930], Loss: 0.0072\n",
      "Epoch [4/5], Step [21030/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [21040/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [21050/30930], Loss: 0.0571\n",
      "Epoch [4/5], Step [21060/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21070/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [21080/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21090/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [21100/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21110/30930], Loss: 0.0112\n",
      "Epoch [4/5], Step [21120/30930], Loss: 0.0512\n",
      "Epoch [4/5], Step [21130/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [21140/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [21150/30930], Loss: 0.1585\n",
      "Epoch [4/5], Step [21160/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [21170/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [21180/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [21190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [21200/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [21210/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [21220/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [21230/30930], Loss: 0.0352\n",
      "Epoch [4/5], Step [21240/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [21250/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [21260/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [21270/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [21280/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [21290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21300/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [21310/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [21320/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21330/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [21340/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [21350/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [21360/30930], Loss: 0.0117\n",
      "Epoch [4/5], Step [21370/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [21380/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [21390/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [21400/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [21410/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21430/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [21440/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [21450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21460/30930], Loss: 0.0113\n",
      "Epoch [4/5], Step [21470/30930], Loss: 0.0458\n",
      "Epoch [4/5], Step [21480/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21490/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21500/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [21510/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [21520/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21530/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21540/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [21550/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [21560/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [21570/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [21580/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [21590/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21600/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [21610/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [21620/30930], Loss: 0.0277\n",
      "Epoch [4/5], Step [21630/30930], Loss: 0.1080\n",
      "Epoch [4/5], Step [21640/30930], Loss: 0.0125\n",
      "Epoch [4/5], Step [21650/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21660/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [21670/30930], Loss: 0.0306\n",
      "Epoch [4/5], Step [21680/30930], Loss: 0.0634\n",
      "Epoch [4/5], Step [21690/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [21700/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [21710/30930], Loss: 0.0110\n",
      "Epoch [4/5], Step [21720/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21730/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [21740/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [21750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21760/30930], Loss: 0.0253\n",
      "Epoch [4/5], Step [21770/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21780/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [21790/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21800/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [21810/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21820/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21830/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [21840/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [21850/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21860/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [21870/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [21880/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21890/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [21900/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [21910/30930], Loss: 0.0124\n",
      "Epoch [4/5], Step [21920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [21930/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [21940/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [21950/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [21960/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [21970/30930], Loss: 0.0370\n",
      "Epoch [4/5], Step [21980/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [21990/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22000/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22010/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [22020/30930], Loss: 0.0392\n",
      "Epoch [4/5], Step [22030/30930], Loss: 0.0201\n",
      "Epoch [4/5], Step [22040/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22050/30930], Loss: 0.0898\n",
      "Epoch [4/5], Step [22060/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22070/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22080/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22090/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22100/30930], Loss: 0.0446\n",
      "Epoch [4/5], Step [22110/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22120/30930], Loss: 0.0984\n",
      "Epoch [4/5], Step [22130/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22140/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22150/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [22160/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22170/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [22180/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22190/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22200/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22210/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22220/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [22230/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22240/30930], Loss: 0.0768\n",
      "Epoch [4/5], Step [22250/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [22260/30930], Loss: 0.0436\n",
      "Epoch [4/5], Step [22270/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [22280/30930], Loss: 0.0404\n",
      "Epoch [4/5], Step [22290/30930], Loss: 0.0236\n",
      "Epoch [4/5], Step [22300/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [22310/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [22320/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22330/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22340/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [22350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22360/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22370/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [22380/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [22390/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22400/30930], Loss: 0.0297\n",
      "Epoch [4/5], Step [22410/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22420/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22430/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [22440/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [22450/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22460/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [22470/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22480/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [22490/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22500/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22510/30930], Loss: 0.0143\n",
      "Epoch [4/5], Step [22520/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22530/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [22540/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [22550/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [22560/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [22570/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22580/30930], Loss: 0.0637\n",
      "Epoch [4/5], Step [22590/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [22600/30930], Loss: 0.0193\n",
      "Epoch [4/5], Step [22610/30930], Loss: 0.0232\n",
      "Epoch [4/5], Step [22620/30930], Loss: 0.1327\n",
      "Epoch [4/5], Step [22630/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [22640/30930], Loss: 0.0200\n",
      "Epoch [4/5], Step [22650/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [22660/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22670/30930], Loss: 0.0525\n",
      "Epoch [4/5], Step [22680/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [22690/30930], Loss: 0.0350\n",
      "Epoch [4/5], Step [22700/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22710/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [22720/30930], Loss: 0.0216\n",
      "Epoch [4/5], Step [22730/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22750/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [22760/30930], Loss: 0.0396\n",
      "Epoch [4/5], Step [22770/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22780/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [22790/30930], Loss: 0.0440\n",
      "Epoch [4/5], Step [22800/30930], Loss: 0.0060\n",
      "Epoch [4/5], Step [22810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22820/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [22830/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [22840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [22850/30930], Loss: 0.0406\n",
      "Epoch [4/5], Step [22860/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [22870/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [22880/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [22890/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22900/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [22910/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [22920/30930], Loss: 0.0160\n",
      "Epoch [4/5], Step [22930/30930], Loss: 0.0611\n",
      "Epoch [4/5], Step [22940/30930], Loss: 0.0180\n",
      "Epoch [4/5], Step [22950/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [22960/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [22970/30930], Loss: 0.0316\n",
      "Epoch [4/5], Step [22980/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [22990/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [23000/30930], Loss: 0.0201\n",
      "Epoch [4/5], Step [23010/30930], Loss: 0.1261\n",
      "Epoch [4/5], Step [23020/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [23030/30930], Loss: 0.0179\n",
      "Epoch [4/5], Step [23040/30930], Loss: 0.0174\n",
      "Epoch [4/5], Step [23050/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [23060/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [23070/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [23080/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [23090/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [23100/30930], Loss: 0.0594\n",
      "Epoch [4/5], Step [23110/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [23120/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [23130/30930], Loss: 0.0223\n",
      "Epoch [4/5], Step [23140/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [23150/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [23160/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23170/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23180/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [23190/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23200/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [23210/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23220/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [23230/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23240/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23250/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [23260/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [23270/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [23280/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [23290/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [23300/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [23310/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [23320/30930], Loss: 0.0238\n",
      "Epoch [4/5], Step [23330/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [23340/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [23350/30930], Loss: 0.0077\n",
      "Epoch [4/5], Step [23360/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [23370/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23380/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [23390/30930], Loss: 0.0210\n",
      "Epoch [4/5], Step [23400/30930], Loss: 0.0278\n",
      "Epoch [4/5], Step [23410/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23420/30930], Loss: 0.0238\n",
      "Epoch [4/5], Step [23430/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [23440/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [23450/30930], Loss: 0.0286\n",
      "Epoch [4/5], Step [23460/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [23470/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [23480/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [23490/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [23500/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [23510/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23520/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [23530/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [23540/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [23550/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [23560/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [23570/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [23580/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [23590/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [23600/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [23610/30930], Loss: 0.0535\n",
      "Epoch [4/5], Step [23620/30930], Loss: 0.0074\n",
      "Epoch [4/5], Step [23630/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [23640/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [23650/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [23660/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [23670/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [23680/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [23690/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [23700/30930], Loss: 0.0420\n",
      "Epoch [4/5], Step [23710/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [23720/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [23730/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [23740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23750/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [23760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23770/30930], Loss: 0.0166\n",
      "Epoch [4/5], Step [23780/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [23790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23800/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [23810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23820/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23830/30930], Loss: 0.0052\n",
      "Epoch [4/5], Step [23840/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [23850/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [23860/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [23870/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [23880/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23890/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23900/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23910/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [23920/30930], Loss: 0.0414\n",
      "Epoch [4/5], Step [23930/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [23940/30930], Loss: 0.0214\n",
      "Epoch [4/5], Step [23950/30930], Loss: 0.0073\n",
      "Epoch [4/5], Step [23960/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [23970/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [23980/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [23990/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [24000/30930], Loss: 0.0372\n",
      "Epoch [4/5], Step [24010/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [24020/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [24030/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [24040/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24050/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [24060/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [24070/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [24080/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24090/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24100/30930], Loss: 0.0047\n",
      "Epoch [4/5], Step [24110/30930], Loss: 0.0043\n",
      "Epoch [4/5], Step [24120/30930], Loss: 0.0454\n",
      "Epoch [4/5], Step [24130/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [24140/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [24150/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [24160/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [24170/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [24180/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [24190/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24200/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [24210/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [24220/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [24230/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24240/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [24250/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [24260/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24270/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [24280/30930], Loss: 0.0111\n",
      "Epoch [4/5], Step [24290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24300/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [24310/30930], Loss: 0.0338\n",
      "Epoch [4/5], Step [24320/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24330/30930], Loss: 0.0419\n",
      "Epoch [4/5], Step [24340/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24350/30930], Loss: 0.0094\n",
      "Epoch [4/5], Step [24360/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [24370/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [24380/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [24390/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [24400/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [24410/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [24420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24430/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [24440/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24450/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [24460/30930], Loss: 0.0365\n",
      "Epoch [4/5], Step [24470/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24480/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [24490/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [24500/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [24510/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [24520/30930], Loss: 0.0142\n",
      "Epoch [4/5], Step [24530/30930], Loss: 0.0190\n",
      "Epoch [4/5], Step [24540/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [24550/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [24560/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [24580/30930], Loss: 0.0188\n",
      "Epoch [4/5], Step [24590/30930], Loss: 0.0996\n",
      "Epoch [4/5], Step [24600/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [24610/30930], Loss: 0.0113\n",
      "Epoch [4/5], Step [24620/30930], Loss: 0.0158\n",
      "Epoch [4/5], Step [24630/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24640/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [24650/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24660/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [24670/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [24680/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [24690/30930], Loss: 0.0292\n",
      "Epoch [4/5], Step [24700/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24710/30930], Loss: 0.0406\n",
      "Epoch [4/5], Step [24720/30930], Loss: 0.0731\n",
      "Epoch [4/5], Step [24730/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [24740/30930], Loss: 0.0064\n",
      "Epoch [4/5], Step [24750/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24760/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [24770/30930], Loss: 0.0348\n",
      "Epoch [4/5], Step [24780/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [24790/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [24800/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [24810/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [24820/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [24830/30930], Loss: 0.0347\n",
      "Epoch [4/5], Step [24840/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [24850/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [24860/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [24870/30930], Loss: 0.0054\n",
      "Epoch [4/5], Step [24880/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [24890/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [24900/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [24910/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [24920/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [24930/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [24940/30930], Loss: 0.0398\n",
      "Epoch [4/5], Step [24950/30930], Loss: 0.0238\n",
      "Epoch [4/5], Step [24960/30930], Loss: 0.0092\n",
      "Epoch [4/5], Step [24970/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [24980/30930], Loss: 0.0182\n",
      "Epoch [4/5], Step [24990/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [25000/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [25010/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [25020/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25030/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [25040/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [25050/30930], Loss: 0.0056\n",
      "Epoch [4/5], Step [25060/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [25070/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [25080/30930], Loss: 0.0589\n",
      "Epoch [4/5], Step [25090/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [25100/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25110/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [25120/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25130/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [25140/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25150/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [25160/30930], Loss: 0.0381\n",
      "Epoch [4/5], Step [25170/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25180/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25190/30930], Loss: 0.0276\n",
      "Epoch [4/5], Step [25200/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25210/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [25220/30930], Loss: 0.0174\n",
      "Epoch [4/5], Step [25230/30930], Loss: 0.0072\n",
      "Epoch [4/5], Step [25240/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [25250/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [25260/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25270/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [25280/30930], Loss: 0.0686\n",
      "Epoch [4/5], Step [25290/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25300/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25310/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25320/30930], Loss: 0.0076\n",
      "Epoch [4/5], Step [25330/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25340/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25350/30930], Loss: 0.0056\n",
      "Epoch [4/5], Step [25360/30930], Loss: 0.0101\n",
      "Epoch [4/5], Step [25370/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [25380/30930], Loss: 0.0174\n",
      "Epoch [4/5], Step [25390/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25400/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [25410/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [25420/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [25430/30930], Loss: 0.0180\n",
      "Epoch [4/5], Step [25440/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25450/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [25460/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [25470/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25480/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [25490/30930], Loss: 0.0120\n",
      "Epoch [4/5], Step [25500/30930], Loss: 0.0453\n",
      "Epoch [4/5], Step [25510/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [25520/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25530/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [25540/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [25550/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [25560/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [25570/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [25580/30930], Loss: 0.0206\n",
      "Epoch [4/5], Step [25590/30930], Loss: 0.0111\n",
      "Epoch [4/5], Step [25600/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [25610/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [25620/30930], Loss: 0.0465\n",
      "Epoch [4/5], Step [25630/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [25640/30930], Loss: 0.0077\n",
      "Epoch [4/5], Step [25650/30930], Loss: 0.0087\n",
      "Epoch [4/5], Step [25660/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25670/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [25680/30930], Loss: 0.0079\n",
      "Epoch [4/5], Step [25690/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [25700/30930], Loss: 0.0301\n",
      "Epoch [4/5], Step [25710/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25720/30930], Loss: 0.0045\n",
      "Epoch [4/5], Step [25730/30930], Loss: 0.0552\n",
      "Epoch [4/5], Step [25740/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [25750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25760/30930], Loss: 0.0261\n",
      "Epoch [4/5], Step [25770/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [25780/30930], Loss: 0.0213\n",
      "Epoch [4/5], Step [25790/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [25800/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25810/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [25820/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [25830/30930], Loss: 0.0057\n",
      "Epoch [4/5], Step [25840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25850/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [25860/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25870/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25880/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [25890/30930], Loss: 0.0609\n",
      "Epoch [4/5], Step [25900/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [25910/30930], Loss: 0.0051\n",
      "Epoch [4/5], Step [25920/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [25930/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [25940/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [25950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25960/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [25970/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [25980/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [25990/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [26000/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [26010/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [26020/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26030/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26040/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [26050/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [26060/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26070/30930], Loss: 0.0067\n",
      "Epoch [4/5], Step [26080/30930], Loss: 0.0158\n",
      "Epoch [4/5], Step [26090/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26100/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [26110/30930], Loss: 0.0079\n",
      "Epoch [4/5], Step [26120/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26130/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [26140/30930], Loss: 0.0161\n",
      "Epoch [4/5], Step [26150/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [26160/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26170/30930], Loss: 0.0071\n",
      "Epoch [4/5], Step [26180/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [26190/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [26200/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [26210/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26220/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [26230/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [26240/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [26250/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [26260/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [26270/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [26280/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [26290/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [26300/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [26310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26320/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [26330/30930], Loss: 0.0284\n",
      "Epoch [4/5], Step [26340/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [26350/30930], Loss: 0.0300\n",
      "Epoch [4/5], Step [26360/30930], Loss: 0.0097\n",
      "Epoch [4/5], Step [26370/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26380/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [26390/30930], Loss: 0.0155\n",
      "Epoch [4/5], Step [26400/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26410/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [26420/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26430/30930], Loss: 0.0148\n",
      "Epoch [4/5], Step [26440/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [26450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26460/30930], Loss: 0.0138\n",
      "Epoch [4/5], Step [26470/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26480/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [26490/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [26500/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [26510/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [26520/30930], Loss: 0.0075\n",
      "Epoch [4/5], Step [26530/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [26540/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26550/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [26560/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26580/30930], Loss: 0.0135\n",
      "Epoch [4/5], Step [26590/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [26600/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26610/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [26620/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [26630/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26640/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [26650/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [26660/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [26670/30930], Loss: 0.0570\n",
      "Epoch [4/5], Step [26680/30930], Loss: 0.0301\n",
      "Epoch [4/5], Step [26690/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [26700/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [26710/30930], Loss: 0.0111\n",
      "Epoch [4/5], Step [26720/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [26730/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [26740/30930], Loss: 0.0374\n",
      "Epoch [4/5], Step [26750/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [26760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26780/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [26790/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [26800/30930], Loss: 0.0392\n",
      "Epoch [4/5], Step [26810/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [26820/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26830/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26850/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [26860/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [26870/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [26880/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [26890/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [26900/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [26910/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [26920/30930], Loss: 0.0124\n",
      "Epoch [4/5], Step [26930/30930], Loss: 0.0455\n",
      "Epoch [4/5], Step [26940/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [26950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [26960/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [26970/30930], Loss: 0.0141\n",
      "Epoch [4/5], Step [26980/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [26990/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27000/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27010/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27020/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [27030/30930], Loss: 0.0030\n",
      "Epoch [4/5], Step [27040/30930], Loss: 0.0077\n",
      "Epoch [4/5], Step [27050/30930], Loss: 0.0418\n",
      "Epoch [4/5], Step [27060/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [27070/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [27080/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [27090/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27100/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27110/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27120/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27130/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [27140/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [27150/30930], Loss: 0.0092\n",
      "Epoch [4/5], Step [27160/30930], Loss: 0.2535\n",
      "Epoch [4/5], Step [27170/30930], Loss: 0.0108\n",
      "Epoch [4/5], Step [27180/30930], Loss: 0.0082\n",
      "Epoch [4/5], Step [27190/30930], Loss: 0.0025\n",
      "Epoch [4/5], Step [27200/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [27210/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [27220/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [27230/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [27240/30930], Loss: 0.0870\n",
      "Epoch [4/5], Step [27250/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [27260/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [27270/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [27280/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [27290/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [27300/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [27310/30930], Loss: 0.0009\n",
      "Epoch [4/5], Step [27320/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [27330/30930], Loss: 0.0379\n",
      "Epoch [4/5], Step [27340/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [27350/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [27360/30930], Loss: 0.0398\n",
      "Epoch [4/5], Step [27370/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27380/30930], Loss: 0.0097\n",
      "Epoch [4/5], Step [27390/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [27400/30930], Loss: 0.0200\n",
      "Epoch [4/5], Step [27410/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [27420/30930], Loss: 0.0333\n",
      "Epoch [4/5], Step [27430/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [27440/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27450/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27460/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [27470/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27480/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27490/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [27500/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27510/30930], Loss: 0.0335\n",
      "Epoch [4/5], Step [27520/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [27530/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27540/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [27550/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [27560/30930], Loss: 0.0107\n",
      "Epoch [4/5], Step [27570/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [27580/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [27590/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [27600/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [27610/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [27620/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27630/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [27640/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27650/30930], Loss: 0.0496\n",
      "Epoch [4/5], Step [27660/30930], Loss: 0.0096\n",
      "Epoch [4/5], Step [27670/30930], Loss: 0.0097\n",
      "Epoch [4/5], Step [27680/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [27690/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [27700/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27710/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [27720/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27730/30930], Loss: 0.0077\n",
      "Epoch [4/5], Step [27740/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [27750/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27760/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27770/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [27780/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [27790/30930], Loss: 0.0192\n",
      "Epoch [4/5], Step [27800/30930], Loss: 0.0070\n",
      "Epoch [4/5], Step [27810/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27820/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [27830/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27850/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27860/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [27870/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [27880/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [27890/30930], Loss: 0.0062\n",
      "Epoch [4/5], Step [27900/30930], Loss: 0.0137\n",
      "Epoch [4/5], Step [27910/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [27920/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [27930/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [27940/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [27950/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27960/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [27970/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [27980/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [27990/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28000/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [28010/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28020/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [28030/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [28040/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [28050/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28060/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28070/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28080/30930], Loss: 0.0716\n",
      "Epoch [4/5], Step [28090/30930], Loss: 0.0109\n",
      "Epoch [4/5], Step [28100/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [28110/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28120/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28130/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [28140/30930], Loss: 0.1191\n",
      "Epoch [4/5], Step [28150/30930], Loss: 0.0319\n",
      "Epoch [4/5], Step [28160/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28170/30930], Loss: 0.0386\n",
      "Epoch [4/5], Step [28180/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [28190/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [28200/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28210/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [28220/30930], Loss: 0.0308\n",
      "Epoch [4/5], Step [28230/30930], Loss: 0.0316\n",
      "Epoch [4/5], Step [28240/30930], Loss: 0.0063\n",
      "Epoch [4/5], Step [28250/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [28260/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [28270/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [28280/30930], Loss: 0.0307\n",
      "Epoch [4/5], Step [28290/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [28300/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28320/30930], Loss: 0.0314\n",
      "Epoch [4/5], Step [28330/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28340/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [28350/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28360/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28370/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [28380/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28390/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [28400/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28410/30930], Loss: 0.0042\n",
      "Epoch [4/5], Step [28420/30930], Loss: 0.0413\n",
      "Epoch [4/5], Step [28430/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [28440/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28450/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [28460/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [28470/30930], Loss: 0.0032\n",
      "Epoch [4/5], Step [28480/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [28490/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28500/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [28510/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28520/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28530/30930], Loss: 0.0119\n",
      "Epoch [4/5], Step [28540/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28550/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [28560/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [28570/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [28580/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28590/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [28600/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [28610/30930], Loss: 0.0102\n",
      "Epoch [4/5], Step [28620/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28630/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28640/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [28650/30930], Loss: 0.0450\n",
      "Epoch [4/5], Step [28660/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28670/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28680/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [28690/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [28700/30930], Loss: 0.0031\n",
      "Epoch [4/5], Step [28710/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28720/30930], Loss: 0.0483\n",
      "Epoch [4/5], Step [28730/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [28740/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28750/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28760/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [28770/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [28780/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [28790/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [28800/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [28810/30930], Loss: 0.0192\n",
      "Epoch [4/5], Step [28820/30930], Loss: 0.0198\n",
      "Epoch [4/5], Step [28830/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28840/30930], Loss: 0.0211\n",
      "Epoch [4/5], Step [28850/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28860/30930], Loss: 0.0058\n",
      "Epoch [4/5], Step [28870/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28880/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [28890/30930], Loss: 0.0322\n",
      "Epoch [4/5], Step [28900/30930], Loss: 0.0049\n",
      "Epoch [4/5], Step [28910/30930], Loss: 0.0279\n",
      "Epoch [4/5], Step [28920/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [28930/30930], Loss: 0.0463\n",
      "Epoch [4/5], Step [28940/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [28950/30930], Loss: 0.0101\n",
      "Epoch [4/5], Step [28960/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28970/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [28980/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [28990/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [29000/30930], Loss: 0.0186\n",
      "Epoch [4/5], Step [29010/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [29020/30930], Loss: 0.0115\n",
      "Epoch [4/5], Step [29030/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [29040/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [29050/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29060/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [29070/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [29080/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29090/30930], Loss: 0.0693\n",
      "Epoch [4/5], Step [29100/30930], Loss: 0.0324\n",
      "Epoch [4/5], Step [29110/30930], Loss: 0.0091\n",
      "Epoch [4/5], Step [29120/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [29130/30930], Loss: 0.0212\n",
      "Epoch [4/5], Step [29140/30930], Loss: 0.0176\n",
      "Epoch [4/5], Step [29150/30930], Loss: 0.0033\n",
      "Epoch [4/5], Step [29160/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [29170/30930], Loss: 0.0065\n",
      "Epoch [4/5], Step [29180/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [29190/30930], Loss: 0.0129\n",
      "Epoch [4/5], Step [29200/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29210/30930], Loss: 0.0398\n",
      "Epoch [4/5], Step [29220/30930], Loss: 0.0162\n",
      "Epoch [4/5], Step [29230/30930], Loss: 0.0206\n",
      "Epoch [4/5], Step [29240/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29250/30930], Loss: 0.0069\n",
      "Epoch [4/5], Step [29260/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [29270/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [29280/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [29290/30930], Loss: 0.0017\n",
      "Epoch [4/5], Step [29300/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [29310/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [29320/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29330/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [29340/30930], Loss: 0.0005\n",
      "Epoch [4/5], Step [29350/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29360/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [29370/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [29380/30930], Loss: 0.0080\n",
      "Epoch [4/5], Step [29390/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [29400/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29410/30930], Loss: 0.0008\n",
      "Epoch [4/5], Step [29420/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [29430/30930], Loss: 0.0103\n",
      "Epoch [4/5], Step [29440/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [29450/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29460/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [29470/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [29480/30930], Loss: 0.0023\n",
      "Epoch [4/5], Step [29490/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [29500/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29510/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29520/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [29530/30930], Loss: 0.1361\n",
      "Epoch [4/5], Step [29540/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [29550/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [29560/30930], Loss: 0.0611\n",
      "Epoch [4/5], Step [29570/30930], Loss: 0.0061\n",
      "Epoch [4/5], Step [29580/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [29590/30930], Loss: 0.0122\n",
      "Epoch [4/5], Step [29600/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [29610/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29620/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29630/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [29640/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29650/30930], Loss: 0.0138\n",
      "Epoch [4/5], Step [29660/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [29670/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29680/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [29690/30930], Loss: 0.0059\n",
      "Epoch [4/5], Step [29700/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [29710/30930], Loss: 0.0026\n",
      "Epoch [4/5], Step [29720/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29730/30930], Loss: 0.0053\n",
      "Epoch [4/5], Step [29740/30930], Loss: 0.0039\n",
      "Epoch [4/5], Step [29750/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29760/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [29770/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29780/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [29790/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29800/30930], Loss: 0.0021\n",
      "Epoch [4/5], Step [29810/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [29820/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29830/30930], Loss: 0.0147\n",
      "Epoch [4/5], Step [29840/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29850/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [29860/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29870/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29880/30930], Loss: 0.0038\n",
      "Epoch [4/5], Step [29890/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29900/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [29910/30930], Loss: 0.0085\n",
      "Epoch [4/5], Step [29920/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [29930/30930], Loss: 0.0087\n",
      "Epoch [4/5], Step [29940/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [29950/30930], Loss: 0.0019\n",
      "Epoch [4/5], Step [29960/30930], Loss: 0.0028\n",
      "Epoch [4/5], Step [29970/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [29980/30930], Loss: 0.0425\n",
      "Epoch [4/5], Step [29990/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [30000/30930], Loss: 0.0024\n",
      "Epoch [4/5], Step [30010/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [30020/30930], Loss: 0.0147\n",
      "Epoch [4/5], Step [30030/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30040/30930], Loss: 0.0010\n",
      "Epoch [4/5], Step [30050/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [30060/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [30070/30930], Loss: 0.0007\n",
      "Epoch [4/5], Step [30080/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30090/30930], Loss: 0.0418\n",
      "Epoch [4/5], Step [30100/30930], Loss: 0.0011\n",
      "Epoch [4/5], Step [30110/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30120/30930], Loss: 0.0584\n",
      "Epoch [4/5], Step [30130/30930], Loss: 0.0119\n",
      "Epoch [4/5], Step [30140/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30150/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30160/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [30170/30930], Loss: 0.0406\n",
      "Epoch [4/5], Step [30180/30930], Loss: 0.0068\n",
      "Epoch [4/5], Step [30190/30930], Loss: 0.0055\n",
      "Epoch [4/5], Step [30200/30930], Loss: 0.0264\n",
      "Epoch [4/5], Step [30210/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30220/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [30230/30930], Loss: 0.0014\n",
      "Epoch [4/5], Step [30240/30930], Loss: 0.0211\n",
      "Epoch [4/5], Step [30250/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30260/30930], Loss: 0.0268\n",
      "Epoch [4/5], Step [30270/30930], Loss: 0.0678\n",
      "Epoch [4/5], Step [30280/30930], Loss: 0.0189\n",
      "Epoch [4/5], Step [30290/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30300/30930], Loss: 0.0104\n",
      "Epoch [4/5], Step [30310/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30320/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30330/30930], Loss: 0.0342\n",
      "Epoch [4/5], Step [30340/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [30350/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [30360/30930], Loss: 0.0090\n",
      "Epoch [4/5], Step [30370/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30380/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30390/30930], Loss: 0.0145\n",
      "Epoch [4/5], Step [30400/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [30410/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30420/30930], Loss: 0.0086\n",
      "Epoch [4/5], Step [30430/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30440/30930], Loss: 0.0100\n",
      "Epoch [4/5], Step [30450/30930], Loss: 0.0004\n",
      "Epoch [4/5], Step [30460/30930], Loss: 0.0018\n",
      "Epoch [4/5], Step [30470/30930], Loss: 0.0006\n",
      "Epoch [4/5], Step [30480/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [30490/30930], Loss: 0.0048\n",
      "Epoch [4/5], Step [30500/30930], Loss: 0.0050\n",
      "Epoch [4/5], Step [30510/30930], Loss: 0.0029\n",
      "Epoch [4/5], Step [30520/30930], Loss: 0.0044\n",
      "Epoch [4/5], Step [30530/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30540/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30550/30930], Loss: 0.0241\n",
      "Epoch [4/5], Step [30560/30930], Loss: 0.0035\n",
      "Epoch [4/5], Step [30570/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30580/30930], Loss: 0.0003\n",
      "Epoch [4/5], Step [30590/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30600/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30610/30930], Loss: 0.0577\n",
      "Epoch [4/5], Step [30620/30930], Loss: 0.0095\n",
      "Epoch [4/5], Step [30630/30930], Loss: 0.0002\n",
      "Epoch [4/5], Step [30640/30930], Loss: 0.0037\n",
      "Epoch [4/5], Step [30650/30930], Loss: 0.0022\n",
      "Epoch [4/5], Step [30660/30930], Loss: 0.0001\n",
      "Epoch [4/5], Step [30670/30930], Loss: 0.0275\n",
      "Epoch [4/5], Step [30680/30930], Loss: 0.0040\n",
      "Epoch [4/5], Step [30690/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30700/30930], Loss: 0.0083\n",
      "Epoch [4/5], Step [30710/30930], Loss: 0.0093\n",
      "Epoch [4/5], Step [30720/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [30730/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30740/30930], Loss: 0.0020\n",
      "Epoch [4/5], Step [30750/30930], Loss: 0.0027\n",
      "Epoch [4/5], Step [30760/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [30770/30930], Loss: 0.0013\n",
      "Epoch [4/5], Step [30780/30930], Loss: 0.0015\n",
      "Epoch [4/5], Step [30790/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30800/30930], Loss: 0.0012\n",
      "Epoch [4/5], Step [30810/30930], Loss: 0.0034\n",
      "Epoch [4/5], Step [30820/30930], Loss: 0.0036\n",
      "Epoch [4/5], Step [30830/30930], Loss: 0.0180\n",
      "Epoch [4/5], Step [30840/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30850/30930], Loss: 0.0016\n",
      "Epoch [4/5], Step [30860/30930], Loss: 0.0346\n",
      "Epoch [4/5], Step [30870/30930], Loss: 0.0280\n",
      "Epoch [4/5], Step [30880/30930], Loss: 0.0046\n",
      "Epoch [4/5], Step [30890/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30900/30930], Loss: 0.1023\n",
      "Epoch [4/5], Step [30910/30930], Loss: 0.0000\n",
      "Epoch [4/5], Step [30920/30930], Loss: 0.0084\n",
      "Epoch [4/5], Step [30930/30930], Loss: 0.0000\n",
      "Epoch [4/5], Average Train Loss: 0.0087\n",
      "Epoch [4/5], Validation Loss: 0.0068\n",
      "Epoch [5/5], Step [10/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20/30930], Loss: 0.0652\n",
      "Epoch [5/5], Step [30/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [40/30930], Loss: 0.0504\n",
      "Epoch [5/5], Step [50/30930], Loss: 0.0381\n",
      "Epoch [5/5], Step [60/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [70/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [80/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [90/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [100/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [110/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [120/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [130/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [140/30930], Loss: 0.0100\n",
      "Epoch [5/5], Step [150/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [160/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [170/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [180/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [190/30930], Loss: 0.0117\n",
      "Epoch [5/5], Step [200/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [210/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [220/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [230/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [240/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [250/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [260/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [270/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [280/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [290/30930], Loss: 0.0690\n",
      "Epoch [5/5], Step [300/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [320/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [330/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [340/30930], Loss: 0.0408\n",
      "Epoch [5/5], Step [350/30930], Loss: 0.0228\n",
      "Epoch [5/5], Step [360/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [370/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [380/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [390/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [400/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [410/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [420/30930], Loss: 0.0124\n",
      "Epoch [5/5], Step [430/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [440/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [460/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [470/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [480/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [490/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [500/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [520/30930], Loss: 0.0529\n",
      "Epoch [5/5], Step [530/30930], Loss: 0.0285\n",
      "Epoch [5/5], Step [540/30930], Loss: 0.0100\n",
      "Epoch [5/5], Step [550/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [560/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [570/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [580/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [590/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [600/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [610/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [620/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [630/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [640/30930], Loss: 0.0186\n",
      "Epoch [5/5], Step [650/30930], Loss: 0.0488\n",
      "Epoch [5/5], Step [660/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [670/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [680/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [690/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [700/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [710/30930], Loss: 0.0093\n",
      "Epoch [5/5], Step [720/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [730/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [740/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [750/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [760/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [780/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [790/30930], Loss: 0.0245\n",
      "Epoch [5/5], Step [800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [820/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [830/30930], Loss: 0.0402\n",
      "Epoch [5/5], Step [840/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [850/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [860/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [870/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [880/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [890/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [900/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [910/30930], Loss: 0.0171\n",
      "Epoch [5/5], Step [920/30930], Loss: 0.0107\n",
      "Epoch [5/5], Step [930/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [940/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [950/30930], Loss: 0.1150\n",
      "Epoch [5/5], Step [960/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [970/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [980/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [990/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [1000/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [1010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1020/30930], Loss: 0.0180\n",
      "Epoch [5/5], Step [1030/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [1040/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [1050/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1060/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [1070/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [1080/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1090/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [1100/30930], Loss: 0.0148\n",
      "Epoch [5/5], Step [1110/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [1120/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [1130/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1140/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [1150/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1160/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1170/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [1180/30930], Loss: 0.2125\n",
      "Epoch [5/5], Step [1190/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [1200/30930], Loss: 0.0219\n",
      "Epoch [5/5], Step [1210/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [1220/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [1230/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [1240/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1250/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [1260/30930], Loss: 0.0148\n",
      "Epoch [5/5], Step [1270/30930], Loss: 0.0097\n",
      "Epoch [5/5], Step [1280/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [1290/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [1300/30930], Loss: 0.0070\n",
      "Epoch [5/5], Step [1310/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [1320/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1330/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [1340/30930], Loss: 0.0127\n",
      "Epoch [5/5], Step [1350/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [1360/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [1370/30930], Loss: 0.0436\n",
      "Epoch [5/5], Step [1380/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [1390/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [1400/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1410/30930], Loss: 0.1796\n",
      "Epoch [5/5], Step [1420/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1430/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [1440/30930], Loss: 0.0269\n",
      "Epoch [5/5], Step [1450/30930], Loss: 0.0579\n",
      "Epoch [5/5], Step [1460/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [1470/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [1480/30930], Loss: 0.1454\n",
      "Epoch [5/5], Step [1490/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [1500/30930], Loss: 0.0223\n",
      "Epoch [5/5], Step [1510/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [1520/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [1530/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [1540/30930], Loss: 0.0078\n",
      "Epoch [5/5], Step [1550/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [1560/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [1570/30930], Loss: 0.0293\n",
      "Epoch [5/5], Step [1580/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [1590/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [1600/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [1610/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [1620/30930], Loss: 0.1179\n",
      "Epoch [5/5], Step [1630/30930], Loss: 0.0133\n",
      "Epoch [5/5], Step [1640/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [1650/30930], Loss: 0.0518\n",
      "Epoch [5/5], Step [1660/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [1670/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [1680/30930], Loss: 0.0190\n",
      "Epoch [5/5], Step [1690/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [1700/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [1710/30930], Loss: 0.0091\n",
      "Epoch [5/5], Step [1720/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1730/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1740/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [1750/30930], Loss: 0.0111\n",
      "Epoch [5/5], Step [1760/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [1770/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [1780/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [1790/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [1800/30930], Loss: 0.0100\n",
      "Epoch [5/5], Step [1810/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [1820/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [1830/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [1840/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [1850/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [1860/30930], Loss: 0.0078\n",
      "Epoch [5/5], Step [1870/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [1880/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [1890/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [1900/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [1910/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [1920/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [1930/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [1940/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [1950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [1960/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [1970/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [1980/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [1990/30930], Loss: 0.0746\n",
      "Epoch [5/5], Step [2000/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [2010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2020/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [2030/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [2040/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [2050/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [2060/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [2070/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [2080/30930], Loss: 0.0116\n",
      "Epoch [5/5], Step [2090/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2100/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2110/30930], Loss: 0.0708\n",
      "Epoch [5/5], Step [2120/30930], Loss: 0.0106\n",
      "Epoch [5/5], Step [2130/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [2140/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [2150/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [2160/30930], Loss: 0.0170\n",
      "Epoch [5/5], Step [2170/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [2180/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [2190/30930], Loss: 0.0307\n",
      "Epoch [5/5], Step [2200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2210/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [2220/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [2230/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [2240/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [2250/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [2260/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [2270/30930], Loss: 0.0479\n",
      "Epoch [5/5], Step [2280/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [2290/30930], Loss: 0.0128\n",
      "Epoch [5/5], Step [2300/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [2310/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [2320/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [2330/30930], Loss: 0.0360\n",
      "Epoch [5/5], Step [2340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2350/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [2360/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [2370/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [2380/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2400/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [2410/30930], Loss: 0.0102\n",
      "Epoch [5/5], Step [2420/30930], Loss: 0.0842\n",
      "Epoch [5/5], Step [2430/30930], Loss: 0.0277\n",
      "Epoch [5/5], Step [2440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2450/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [2460/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [2470/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [2480/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2490/30930], Loss: 0.0397\n",
      "Epoch [5/5], Step [2500/30930], Loss: 0.0593\n",
      "Epoch [5/5], Step [2510/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [2520/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [2530/30930], Loss: 0.0069\n",
      "Epoch [5/5], Step [2540/30930], Loss: 0.0308\n",
      "Epoch [5/5], Step [2550/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [2560/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [2570/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [2580/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [2590/30930], Loss: 0.0568\n",
      "Epoch [5/5], Step [2600/30930], Loss: 0.0173\n",
      "Epoch [5/5], Step [2610/30930], Loss: 0.0222\n",
      "Epoch [5/5], Step [2620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2630/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [2640/30930], Loss: 0.0089\n",
      "Epoch [5/5], Step [2650/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [2660/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [2670/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2680/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2690/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [2700/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [2710/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [2720/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [2730/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [2740/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [2750/30930], Loss: 0.0070\n",
      "Epoch [5/5], Step [2760/30930], Loss: 0.0317\n",
      "Epoch [5/5], Step [2770/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [2780/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [2790/30930], Loss: 0.0362\n",
      "Epoch [5/5], Step [2800/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [2810/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [2820/30930], Loss: 0.0147\n",
      "Epoch [5/5], Step [2830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2840/30930], Loss: 0.0581\n",
      "Epoch [5/5], Step [2850/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [2860/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [2870/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [2880/30930], Loss: 0.0343\n",
      "Epoch [5/5], Step [2890/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [2900/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [2910/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [2920/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [2930/30930], Loss: 0.0138\n",
      "Epoch [5/5], Step [2940/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [2950/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [2960/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2970/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [2980/30930], Loss: 0.0084\n",
      "Epoch [5/5], Step [2990/30930], Loss: 0.0163\n",
      "Epoch [5/5], Step [3000/30930], Loss: 0.0114\n",
      "Epoch [5/5], Step [3010/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [3020/30930], Loss: 0.0363\n",
      "Epoch [5/5], Step [3030/30930], Loss: 0.0070\n",
      "Epoch [5/5], Step [3040/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [3050/30930], Loss: 0.0091\n",
      "Epoch [5/5], Step [3060/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3070/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3080/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [3090/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3100/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [3110/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [3120/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [3130/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [3140/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [3150/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3160/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [3170/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [3180/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [3190/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [3200/30930], Loss: 0.0202\n",
      "Epoch [5/5], Step [3210/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [3220/30930], Loss: 0.0220\n",
      "Epoch [5/5], Step [3230/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [3240/30930], Loss: 0.0068\n",
      "Epoch [5/5], Step [3250/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3260/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [3270/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [3280/30930], Loss: 0.0879\n",
      "Epoch [5/5], Step [3290/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3300/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [3310/30930], Loss: 0.0134\n",
      "Epoch [5/5], Step [3320/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [3330/30930], Loss: 0.0061\n",
      "Epoch [5/5], Step [3340/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [3350/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3360/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [3370/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [3380/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [3390/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3400/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [3410/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3420/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [3430/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [3440/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [3450/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [3460/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3470/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [3480/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [3490/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [3500/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [3510/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [3520/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [3530/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [3540/30930], Loss: 0.0108\n",
      "Epoch [5/5], Step [3550/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [3560/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3570/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [3580/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3590/30930], Loss: 0.0216\n",
      "Epoch [5/5], Step [3600/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3610/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [3620/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3630/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3640/30930], Loss: 0.0438\n",
      "Epoch [5/5], Step [3650/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3670/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [3680/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [3690/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3700/30930], Loss: 0.0363\n",
      "Epoch [5/5], Step [3710/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [3720/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [3730/30930], Loss: 0.0280\n",
      "Epoch [5/5], Step [3740/30930], Loss: 0.0200\n",
      "Epoch [5/5], Step [3750/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [3760/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [3770/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [3780/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3790/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [3800/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3810/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [3820/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [3830/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [3840/30930], Loss: 0.0332\n",
      "Epoch [5/5], Step [3850/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3860/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [3870/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3880/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [3890/30930], Loss: 0.0498\n",
      "Epoch [5/5], Step [3900/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [3910/30930], Loss: 0.0184\n",
      "Epoch [5/5], Step [3920/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [3930/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [3940/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [3950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [3960/30930], Loss: 0.0320\n",
      "Epoch [5/5], Step [3970/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [3980/30930], Loss: 0.0356\n",
      "Epoch [5/5], Step [3990/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4000/30930], Loss: 0.0493\n",
      "Epoch [5/5], Step [4010/30930], Loss: 0.0241\n",
      "Epoch [5/5], Step [4020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4030/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [4040/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4050/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [4060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4070/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4080/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4090/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [4100/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [4110/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [4120/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [4130/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [4140/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4150/30930], Loss: 0.0284\n",
      "Epoch [5/5], Step [4160/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4170/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4180/30930], Loss: 0.0565\n",
      "Epoch [5/5], Step [4190/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [4200/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4210/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [4220/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [4230/30930], Loss: 0.0060\n",
      "Epoch [5/5], Step [4240/30930], Loss: 0.0111\n",
      "Epoch [5/5], Step [4250/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [4260/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [4270/30930], Loss: 0.0260\n",
      "Epoch [5/5], Step [4280/30930], Loss: 0.0513\n",
      "Epoch [5/5], Step [4290/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [4300/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [4310/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [4320/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [4330/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4340/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4350/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [4360/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4370/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4380/30930], Loss: 0.0484\n",
      "Epoch [5/5], Step [4390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4400/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [4410/30930], Loss: 0.0336\n",
      "Epoch [5/5], Step [4420/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [4430/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [4440/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [4450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4460/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [4470/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [4480/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [4490/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4500/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [4510/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [4520/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [4530/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [4540/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [4550/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [4560/30930], Loss: 0.0333\n",
      "Epoch [5/5], Step [4570/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [4580/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [4590/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [4600/30930], Loss: 0.0481\n",
      "Epoch [5/5], Step [4610/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4620/30930], Loss: 0.0436\n",
      "Epoch [5/5], Step [4630/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [4640/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [4650/30930], Loss: 0.0115\n",
      "Epoch [5/5], Step [4660/30930], Loss: 0.0130\n",
      "Epoch [5/5], Step [4670/30930], Loss: 0.0103\n",
      "Epoch [5/5], Step [4680/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4690/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4700/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4720/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [4730/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [4740/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [4750/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [4760/30930], Loss: 0.0373\n",
      "Epoch [5/5], Step [4770/30930], Loss: 0.0236\n",
      "Epoch [5/5], Step [4780/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [4790/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4800/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [4810/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [4820/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [4830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4840/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [4850/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4860/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [4870/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [4880/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [4890/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [4900/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [4910/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [4920/30930], Loss: 0.0222\n",
      "Epoch [5/5], Step [4930/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [4940/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [4950/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [4960/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [4970/30930], Loss: 0.0060\n",
      "Epoch [5/5], Step [4980/30930], Loss: 0.0151\n",
      "Epoch [5/5], Step [4990/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5000/30930], Loss: 0.0098\n",
      "Epoch [5/5], Step [5010/30930], Loss: 0.0252\n",
      "Epoch [5/5], Step [5020/30930], Loss: 0.0173\n",
      "Epoch [5/5], Step [5030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5040/30930], Loss: 0.0583\n",
      "Epoch [5/5], Step [5050/30930], Loss: 0.0535\n",
      "Epoch [5/5], Step [5060/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5070/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [5080/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [5090/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [5100/30930], Loss: 0.0084\n",
      "Epoch [5/5], Step [5110/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [5120/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [5130/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [5140/30930], Loss: 0.0362\n",
      "Epoch [5/5], Step [5150/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5160/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [5170/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5180/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5190/30930], Loss: 0.0182\n",
      "Epoch [5/5], Step [5200/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5210/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [5220/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [5230/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [5240/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [5250/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5260/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5270/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5280/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [5290/30930], Loss: 0.0110\n",
      "Epoch [5/5], Step [5300/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [5310/30930], Loss: 0.0309\n",
      "Epoch [5/5], Step [5320/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [5330/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5340/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [5350/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [5360/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [5370/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [5380/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [5390/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [5400/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5410/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [5420/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5430/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [5440/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [5450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5460/30930], Loss: 0.0787\n",
      "Epoch [5/5], Step [5470/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5480/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [5490/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [5500/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [5510/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [5520/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5530/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5540/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5550/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [5560/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5570/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [5580/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [5590/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [5600/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5610/30930], Loss: 0.0726\n",
      "Epoch [5/5], Step [5620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5630/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [5640/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5650/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [5660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5670/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5680/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5690/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [5700/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5710/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [5720/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [5730/30930], Loss: 0.0184\n",
      "Epoch [5/5], Step [5740/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [5750/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5760/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [5770/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [5780/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [5790/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5800/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [5810/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [5820/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [5830/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [5840/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [5850/30930], Loss: 0.0314\n",
      "Epoch [5/5], Step [5860/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [5870/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [5880/30930], Loss: 0.0090\n",
      "Epoch [5/5], Step [5890/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5900/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [5910/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [5920/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [5930/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [5940/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [5950/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [5960/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [5970/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [5980/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [5990/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6000/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6010/30930], Loss: 0.0414\n",
      "Epoch [5/5], Step [6020/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [6030/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [6040/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [6050/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6060/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6070/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [6080/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [6090/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6100/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [6110/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [6120/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6130/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [6140/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [6150/30930], Loss: 0.0368\n",
      "Epoch [5/5], Step [6160/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [6170/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [6180/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [6190/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [6200/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [6210/30930], Loss: 0.0634\n",
      "Epoch [5/5], Step [6220/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6230/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6240/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [6250/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [6260/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6270/30930], Loss: 0.0108\n",
      "Epoch [5/5], Step [6280/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [6290/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6300/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6310/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [6320/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [6330/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [6340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6350/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6360/30930], Loss: 0.0188\n",
      "Epoch [5/5], Step [6370/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [6380/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6390/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6400/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6410/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [6420/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [6430/30930], Loss: 0.0252\n",
      "Epoch [5/5], Step [6440/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [6450/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [6460/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6470/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6480/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [6490/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [6500/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [6510/30930], Loss: 0.0148\n",
      "Epoch [5/5], Step [6520/30930], Loss: 0.0233\n",
      "Epoch [5/5], Step [6530/30930], Loss: 0.0084\n",
      "Epoch [5/5], Step [6540/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6550/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [6560/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [6570/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [6580/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [6590/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6600/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6610/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [6620/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [6630/30930], Loss: 0.0365\n",
      "Epoch [5/5], Step [6640/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [6650/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6660/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [6670/30930], Loss: 0.0081\n",
      "Epoch [5/5], Step [6680/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6690/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [6700/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [6710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6720/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [6730/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [6740/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [6750/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6760/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [6770/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [6780/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [6790/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [6800/30930], Loss: 0.0282\n",
      "Epoch [5/5], Step [6810/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [6820/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6840/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [6850/30930], Loss: 0.0402\n",
      "Epoch [5/5], Step [6860/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [6870/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [6880/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [6890/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [6900/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [6910/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [6920/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [6930/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [6940/30930], Loss: 0.0100\n",
      "Epoch [5/5], Step [6950/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [6960/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [6970/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [6980/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [6990/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7020/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [7030/30930], Loss: 0.0155\n",
      "Epoch [5/5], Step [7040/30930], Loss: 0.0109\n",
      "Epoch [5/5], Step [7050/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [7060/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [7070/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [7080/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [7090/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [7100/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7110/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7120/30930], Loss: 0.0402\n",
      "Epoch [5/5], Step [7130/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7140/30930], Loss: 0.0567\n",
      "Epoch [5/5], Step [7150/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7160/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7170/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [7180/30930], Loss: 0.0146\n",
      "Epoch [5/5], Step [7190/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7210/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [7220/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [7230/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [7240/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [7250/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7260/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [7270/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7280/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7290/30930], Loss: 0.0284\n",
      "Epoch [5/5], Step [7300/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [7310/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [7320/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [7330/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [7340/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [7350/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [7360/30930], Loss: 0.0098\n",
      "Epoch [5/5], Step [7370/30930], Loss: 0.0128\n",
      "Epoch [5/5], Step [7380/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7390/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [7400/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [7410/30930], Loss: 0.0153\n",
      "Epoch [5/5], Step [7420/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7430/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7440/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [7450/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [7460/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [7470/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7480/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [7490/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [7500/30930], Loss: 0.0210\n",
      "Epoch [5/5], Step [7510/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [7520/30930], Loss: 0.0255\n",
      "Epoch [5/5], Step [7530/30930], Loss: 0.0396\n",
      "Epoch [5/5], Step [7540/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [7550/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7560/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [7570/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7580/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7590/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [7600/30930], Loss: 0.0583\n",
      "Epoch [5/5], Step [7610/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7620/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [7630/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [7640/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [7650/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [7660/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7670/30930], Loss: 0.0290\n",
      "Epoch [5/5], Step [7680/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [7690/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [7700/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7710/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [7720/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [7730/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [7740/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [7750/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [7760/30930], Loss: 0.0070\n",
      "Epoch [5/5], Step [7770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7780/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7790/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [7800/30930], Loss: 0.0078\n",
      "Epoch [5/5], Step [7810/30930], Loss: 0.0275\n",
      "Epoch [5/5], Step [7820/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [7830/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [7840/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [7850/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [7860/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [7870/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [7880/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [7890/30930], Loss: 0.0185\n",
      "Epoch [5/5], Step [7900/30930], Loss: 0.0093\n",
      "Epoch [5/5], Step [7910/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [7920/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [7930/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [7940/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [7950/30930], Loss: 0.0278\n",
      "Epoch [5/5], Step [7960/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [7970/30930], Loss: 0.0227\n",
      "Epoch [5/5], Step [7980/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [7990/30930], Loss: 0.0351\n",
      "Epoch [5/5], Step [8000/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8010/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [8020/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [8030/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [8040/30930], Loss: 0.0362\n",
      "Epoch [5/5], Step [8050/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [8060/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [8070/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [8080/30930], Loss: 0.0259\n",
      "Epoch [5/5], Step [8090/30930], Loss: 0.0099\n",
      "Epoch [5/5], Step [8100/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [8110/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [8120/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [8130/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [8140/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [8150/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [8160/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [8170/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [8180/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [8190/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8210/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [8220/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [8230/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8240/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [8250/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [8260/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [8270/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [8280/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8290/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8300/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [8310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8320/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [8330/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8340/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [8350/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [8360/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [8370/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [8380/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8390/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [8400/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8410/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8420/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [8430/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [8440/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [8450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8460/30930], Loss: 0.0226\n",
      "Epoch [5/5], Step [8470/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [8480/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [8490/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [8500/30930], Loss: 0.1195\n",
      "Epoch [5/5], Step [8510/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [8520/30930], Loss: 0.0332\n",
      "Epoch [5/5], Step [8530/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [8540/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [8550/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [8560/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [8570/30930], Loss: 0.0122\n",
      "Epoch [5/5], Step [8580/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [8590/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8600/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [8610/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [8620/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [8630/30930], Loss: 0.0289\n",
      "Epoch [5/5], Step [8640/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [8650/30930], Loss: 0.0239\n",
      "Epoch [5/5], Step [8660/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [8670/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [8680/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [8690/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [8700/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [8710/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [8720/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [8730/30930], Loss: 0.2506\n",
      "Epoch [5/5], Step [8740/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [8750/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [8760/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [8770/30930], Loss: 0.0722\n",
      "Epoch [5/5], Step [8780/30930], Loss: 0.0444\n",
      "Epoch [5/5], Step [8790/30930], Loss: 0.0254\n",
      "Epoch [5/5], Step [8800/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [8810/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [8820/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [8830/30930], Loss: 0.0147\n",
      "Epoch [5/5], Step [8840/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [8850/30930], Loss: 0.0098\n",
      "Epoch [5/5], Step [8860/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [8870/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [8880/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [8890/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [8900/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [8910/30930], Loss: 0.0302\n",
      "Epoch [5/5], Step [8920/30930], Loss: 0.0218\n",
      "Epoch [5/5], Step [8930/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [8940/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [8950/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [8960/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [8970/30930], Loss: 0.0428\n",
      "Epoch [5/5], Step [8980/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [8990/30930], Loss: 0.0211\n",
      "Epoch [5/5], Step [9000/30930], Loss: 0.0364\n",
      "Epoch [5/5], Step [9010/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9020/30930], Loss: 0.0417\n",
      "Epoch [5/5], Step [9030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9040/30930], Loss: 0.0152\n",
      "Epoch [5/5], Step [9050/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [9060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9070/30930], Loss: 0.0102\n",
      "Epoch [5/5], Step [9080/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [9090/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [9100/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [9110/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [9120/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [9130/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [9140/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [9150/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9160/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [9170/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [9180/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [9190/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9200/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [9210/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [9220/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [9230/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [9240/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [9250/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [9260/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [9270/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [9280/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [9290/30930], Loss: 0.0093\n",
      "Epoch [5/5], Step [9300/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [9310/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [9320/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [9330/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9340/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9350/30930], Loss: 0.0111\n",
      "Epoch [5/5], Step [9360/30930], Loss: 0.0273\n",
      "Epoch [5/5], Step [9370/30930], Loss: 0.0061\n",
      "Epoch [5/5], Step [9380/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [9390/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [9400/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9410/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9420/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [9430/30930], Loss: 0.0142\n",
      "Epoch [5/5], Step [9440/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [9450/30930], Loss: 0.0292\n",
      "Epoch [5/5], Step [9460/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [9470/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [9480/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [9490/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [9500/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [9510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9530/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9540/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [9550/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [9560/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [9570/30930], Loss: 0.0335\n",
      "Epoch [5/5], Step [9580/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9590/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [9600/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [9610/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [9620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9630/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9640/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [9650/30930], Loss: 0.0091\n",
      "Epoch [5/5], Step [9660/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [9670/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [9680/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [9690/30930], Loss: 0.0106\n",
      "Epoch [5/5], Step [9700/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [9710/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [9720/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [9730/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [9740/30930], Loss: 0.0110\n",
      "Epoch [5/5], Step [9750/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9760/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [9770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9780/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [9790/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [9800/30930], Loss: 0.0431\n",
      "Epoch [5/5], Step [9810/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [9820/30930], Loss: 0.0182\n",
      "Epoch [5/5], Step [9830/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [9840/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [9850/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [9860/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [9870/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [9880/30930], Loss: 0.1031\n",
      "Epoch [5/5], Step [9890/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [9900/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [9910/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [9920/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [9930/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [9940/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [9950/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [9960/30930], Loss: 0.0251\n",
      "Epoch [5/5], Step [9970/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [9980/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [9990/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [10000/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [10010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10020/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [10030/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [10040/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [10050/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10070/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10080/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [10090/30930], Loss: 0.0751\n",
      "Epoch [5/5], Step [10100/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [10110/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [10120/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [10130/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [10140/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [10150/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [10160/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [10170/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [10180/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [10190/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [10200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10210/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [10220/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [10230/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [10240/30930], Loss: 0.0319\n",
      "Epoch [5/5], Step [10250/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [10260/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [10270/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10280/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [10290/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [10300/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10310/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [10320/30930], Loss: 0.0105\n",
      "Epoch [5/5], Step [10330/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10340/30930], Loss: 0.0105\n",
      "Epoch [5/5], Step [10350/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10360/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [10370/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [10380/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [10390/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [10400/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [10410/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [10420/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [10430/30930], Loss: 0.0058\n",
      "Epoch [5/5], Step [10440/30930], Loss: 0.0117\n",
      "Epoch [5/5], Step [10450/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [10460/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [10470/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [10480/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [10490/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [10500/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [10510/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [10520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10530/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [10540/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [10550/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [10560/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [10570/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [10580/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [10590/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [10600/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [10610/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [10620/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [10630/30930], Loss: 0.0520\n",
      "Epoch [5/5], Step [10640/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [10650/30930], Loss: 0.0126\n",
      "Epoch [5/5], Step [10660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10670/30930], Loss: 0.0175\n",
      "Epoch [5/5], Step [10680/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [10690/30930], Loss: 0.0436\n",
      "Epoch [5/5], Step [10700/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10720/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [10730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [10740/30930], Loss: 0.0291\n",
      "Epoch [5/5], Step [10750/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [10760/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [10770/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [10780/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [10790/30930], Loss: 0.0322\n",
      "Epoch [5/5], Step [10800/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10810/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [10820/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [10830/30930], Loss: 0.0626\n",
      "Epoch [5/5], Step [10840/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [10850/30930], Loss: 0.0303\n",
      "Epoch [5/5], Step [10860/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [10870/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [10880/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [10890/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [10900/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [10910/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [10920/30930], Loss: 0.0127\n",
      "Epoch [5/5], Step [10930/30930], Loss: 0.0068\n",
      "Epoch [5/5], Step [10940/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [10950/30930], Loss: 0.0326\n",
      "Epoch [5/5], Step [10960/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [10970/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [10980/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [10990/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [11000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11020/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [11030/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [11040/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11050/30930], Loss: 0.0118\n",
      "Epoch [5/5], Step [11060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11070/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [11080/30930], Loss: 0.0581\n",
      "Epoch [5/5], Step [11090/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11100/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11110/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [11120/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [11130/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [11140/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [11150/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [11160/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [11170/30930], Loss: 0.0440\n",
      "Epoch [5/5], Step [11180/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [11190/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [11200/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [11210/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [11220/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [11230/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [11240/30930], Loss: 0.1110\n",
      "Epoch [5/5], Step [11250/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [11260/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [11270/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [11280/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [11290/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [11300/30930], Loss: 0.0212\n",
      "Epoch [5/5], Step [11310/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11320/30930], Loss: 0.0230\n",
      "Epoch [5/5], Step [11330/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [11340/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11350/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [11360/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11370/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [11380/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [11390/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [11400/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [11410/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [11420/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11430/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11440/30930], Loss: 0.0119\n",
      "Epoch [5/5], Step [11450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11460/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [11470/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [11480/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [11490/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [11500/30930], Loss: 0.0095\n",
      "Epoch [5/5], Step [11510/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11520/30930], Loss: 0.0179\n",
      "Epoch [5/5], Step [11530/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [11540/30930], Loss: 0.0112\n",
      "Epoch [5/5], Step [11550/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [11560/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11570/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [11580/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [11590/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11600/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [11610/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [11620/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [11630/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [11640/30930], Loss: 0.0246\n",
      "Epoch [5/5], Step [11650/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [11660/30930], Loss: 0.0540\n",
      "Epoch [5/5], Step [11670/30930], Loss: 0.0816\n",
      "Epoch [5/5], Step [11680/30930], Loss: 0.0431\n",
      "Epoch [5/5], Step [11690/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [11700/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [11710/30930], Loss: 0.0135\n",
      "Epoch [5/5], Step [11720/30930], Loss: 0.0070\n",
      "Epoch [5/5], Step [11730/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [11740/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11750/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [11760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11780/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [11790/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [11800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11810/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11820/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [11830/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [11840/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11850/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [11860/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [11870/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11880/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [11890/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11900/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11910/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [11920/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [11930/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11940/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11950/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [11960/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11970/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [11980/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [11990/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [12000/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [12010/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [12020/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [12030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12040/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [12050/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [12060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12070/30930], Loss: 0.0097\n",
      "Epoch [5/5], Step [12080/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [12090/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [12100/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [12110/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [12120/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [12130/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [12140/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12150/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12160/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [12170/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [12180/30930], Loss: 0.0096\n",
      "Epoch [5/5], Step [12190/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12200/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [12210/30930], Loss: 0.0433\n",
      "Epoch [5/5], Step [12220/30930], Loss: 0.0319\n",
      "Epoch [5/5], Step [12230/30930], Loss: 0.0603\n",
      "Epoch [5/5], Step [12240/30930], Loss: 0.0220\n",
      "Epoch [5/5], Step [12250/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [12260/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [12270/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [12280/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [12290/30930], Loss: 0.0473\n",
      "Epoch [5/5], Step [12300/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [12310/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [12320/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [12330/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [12340/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [12350/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [12360/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [12370/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [12380/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [12390/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [12400/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12410/30930], Loss: 0.0397\n",
      "Epoch [5/5], Step [12420/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [12430/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [12440/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [12450/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [12460/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [12470/30930], Loss: 0.0742\n",
      "Epoch [5/5], Step [12480/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [12490/30930], Loss: 0.0172\n",
      "Epoch [5/5], Step [12500/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [12510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12520/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [12530/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [12540/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [12550/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [12560/30930], Loss: 0.0127\n",
      "Epoch [5/5], Step [12570/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12580/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [12590/30930], Loss: 0.0833\n",
      "Epoch [5/5], Step [12600/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12610/30930], Loss: 0.0246\n",
      "Epoch [5/5], Step [12620/30930], Loss: 0.0444\n",
      "Epoch [5/5], Step [12630/30930], Loss: 0.0056\n",
      "Epoch [5/5], Step [12640/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [12650/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [12660/30930], Loss: 0.2250\n",
      "Epoch [5/5], Step [12670/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [12680/30930], Loss: 0.0257\n",
      "Epoch [5/5], Step [12690/30930], Loss: 0.0087\n",
      "Epoch [5/5], Step [12700/30930], Loss: 0.0348\n",
      "Epoch [5/5], Step [12710/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [12720/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [12730/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [12740/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [12750/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [12760/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [12770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12780/30930], Loss: 0.0222\n",
      "Epoch [5/5], Step [12790/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [12810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12820/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [12830/30930], Loss: 0.1284\n",
      "Epoch [5/5], Step [12840/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12850/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [12860/30930], Loss: 0.0283\n",
      "Epoch [5/5], Step [12870/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [12880/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [12890/30930], Loss: 0.0056\n",
      "Epoch [5/5], Step [12900/30930], Loss: 0.0213\n",
      "Epoch [5/5], Step [12910/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [12920/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [12930/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [12940/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [12950/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [12960/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [12970/30930], Loss: 0.0143\n",
      "Epoch [5/5], Step [12980/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [12990/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [13000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13010/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [13020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13030/30930], Loss: 0.0301\n",
      "Epoch [5/5], Step [13040/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [13050/30930], Loss: 0.0418\n",
      "Epoch [5/5], Step [13060/30930], Loss: 0.0170\n",
      "Epoch [5/5], Step [13070/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [13080/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13090/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [13100/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [13110/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [13120/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [13130/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [13140/30930], Loss: 0.0095\n",
      "Epoch [5/5], Step [13150/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [13160/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [13170/30930], Loss: 0.0188\n",
      "Epoch [5/5], Step [13180/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13190/30930], Loss: 0.0711\n",
      "Epoch [5/5], Step [13200/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [13210/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [13220/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [13230/30930], Loss: 0.0475\n",
      "Epoch [5/5], Step [13240/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [13250/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [13260/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [13270/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [13280/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [13290/30930], Loss: 0.0575\n",
      "Epoch [5/5], Step [13300/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [13310/30930], Loss: 0.0060\n",
      "Epoch [5/5], Step [13320/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13330/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [13340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13350/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [13360/30930], Loss: 0.0194\n",
      "Epoch [5/5], Step [13370/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [13380/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [13390/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [13400/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [13410/30930], Loss: 0.0123\n",
      "Epoch [5/5], Step [13420/30930], Loss: 0.0266\n",
      "Epoch [5/5], Step [13430/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [13440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13450/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [13460/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [13470/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [13480/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [13490/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [13500/30930], Loss: 0.0105\n",
      "Epoch [5/5], Step [13510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13520/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [13530/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13540/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [13550/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [13560/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13570/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [13580/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13590/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [13600/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [13610/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [13620/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [13630/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [13640/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [13650/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [13660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13670/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [13680/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [13690/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13700/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [13710/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [13720/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [13730/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [13740/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [13750/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [13760/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [13770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13780/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13790/30930], Loss: 0.0219\n",
      "Epoch [5/5], Step [13800/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [13810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13820/30930], Loss: 0.0687\n",
      "Epoch [5/5], Step [13830/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [13840/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [13850/30930], Loss: 0.0174\n",
      "Epoch [5/5], Step [13860/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [13870/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [13880/30930], Loss: 0.0762\n",
      "Epoch [5/5], Step [13890/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [13900/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [13910/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [13920/30930], Loss: 0.0192\n",
      "Epoch [5/5], Step [13930/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13940/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [13950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13960/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [13970/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13980/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [13990/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14000/30930], Loss: 0.0822\n",
      "Epoch [5/5], Step [14010/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [14020/30930], Loss: 0.0505\n",
      "Epoch [5/5], Step [14030/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [14040/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [14050/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [14060/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [14070/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14080/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [14090/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [14100/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14110/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [14120/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [14130/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [14140/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [14150/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [14160/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14170/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14180/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14190/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [14200/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14210/30930], Loss: 0.0205\n",
      "Epoch [5/5], Step [14220/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14230/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [14240/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14250/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [14260/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14270/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [14280/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [14290/30930], Loss: 0.0547\n",
      "Epoch [5/5], Step [14300/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14310/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [14320/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14330/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [14340/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [14350/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14360/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14370/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14380/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14390/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [14400/30930], Loss: 0.0617\n",
      "Epoch [5/5], Step [14410/30930], Loss: 0.0122\n",
      "Epoch [5/5], Step [14420/30930], Loss: 0.0068\n",
      "Epoch [5/5], Step [14430/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [14440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14460/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [14470/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [14480/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [14490/30930], Loss: 0.0273\n",
      "Epoch [5/5], Step [14500/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [14510/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14520/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14530/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14540/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [14550/30930], Loss: 0.0260\n",
      "Epoch [5/5], Step [14560/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [14570/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [14580/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [14590/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [14600/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [14610/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14620/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14630/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14640/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14650/30930], Loss: 0.0354\n",
      "Epoch [5/5], Step [14660/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [14670/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14680/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [14690/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14700/30930], Loss: 0.0347\n",
      "Epoch [5/5], Step [14710/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14720/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [14730/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [14740/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14750/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [14760/30930], Loss: 0.0114\n",
      "Epoch [5/5], Step [14770/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [14780/30930], Loss: 0.1183\n",
      "Epoch [5/5], Step [14790/30930], Loss: 0.0483\n",
      "Epoch [5/5], Step [14800/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14810/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [14820/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [14830/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [14840/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [14850/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14860/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [14870/30930], Loss: 0.0191\n",
      "Epoch [5/5], Step [14880/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [14890/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [14900/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [14910/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [14920/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [14930/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [14940/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [14950/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [14960/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [14970/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [14980/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [14990/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [15000/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15010/30930], Loss: 0.0297\n",
      "Epoch [5/5], Step [15020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15030/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [15040/30930], Loss: 0.0737\n",
      "Epoch [5/5], Step [15050/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [15060/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [15070/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15080/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15090/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [15100/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [15110/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [15120/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15130/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15140/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [15150/30930], Loss: 0.0184\n",
      "Epoch [5/5], Step [15160/30930], Loss: 0.0331\n",
      "Epoch [5/5], Step [15170/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15180/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [15190/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [15200/30930], Loss: 0.0428\n",
      "Epoch [5/5], Step [15210/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15220/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15230/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15240/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15250/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15260/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15270/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [15280/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [15290/30930], Loss: 0.0425\n",
      "Epoch [5/5], Step [15300/30930], Loss: 0.0056\n",
      "Epoch [5/5], Step [15310/30930], Loss: 0.0217\n",
      "Epoch [5/5], Step [15320/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15330/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15340/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [15350/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [15360/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15370/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [15380/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [15390/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [15400/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15410/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [15420/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [15430/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [15440/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15450/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15460/30930], Loss: 0.0118\n",
      "Epoch [5/5], Step [15470/30930], Loss: 0.0221\n",
      "Epoch [5/5], Step [15480/30930], Loss: 0.0476\n",
      "Epoch [5/5], Step [15490/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [15500/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [15510/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15520/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15530/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [15540/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [15550/30930], Loss: 0.0345\n",
      "Epoch [5/5], Step [15560/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15570/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [15580/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15590/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15600/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [15610/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15620/30930], Loss: 0.0069\n",
      "Epoch [5/5], Step [15630/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15640/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [15650/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [15660/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [15670/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15680/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15690/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [15700/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [15710/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15720/30930], Loss: 0.0426\n",
      "Epoch [5/5], Step [15730/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15740/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [15750/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [15760/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [15770/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [15780/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15790/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15800/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15820/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [15830/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [15840/30930], Loss: 0.0076\n",
      "Epoch [5/5], Step [15850/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15860/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15870/30930], Loss: 0.0160\n",
      "Epoch [5/5], Step [15880/30930], Loss: 0.0199\n",
      "Epoch [5/5], Step [15890/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15900/30930], Loss: 0.0841\n",
      "Epoch [5/5], Step [15910/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15920/30930], Loss: 0.0958\n",
      "Epoch [5/5], Step [15930/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [15940/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [15950/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [15960/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [15970/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [15980/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [15990/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16000/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16010/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16040/30930], Loss: 0.0530\n",
      "Epoch [5/5], Step [16050/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [16060/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [16070/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [16080/30930], Loss: 0.0193\n",
      "Epoch [5/5], Step [16090/30930], Loss: 0.0061\n",
      "Epoch [5/5], Step [16100/30930], Loss: 0.0106\n",
      "Epoch [5/5], Step [16110/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [16120/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [16130/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [16140/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16150/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [16160/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [16170/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [16180/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16190/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [16200/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [16210/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [16220/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [16230/30930], Loss: 0.0094\n",
      "Epoch [5/5], Step [16240/30930], Loss: 0.0446\n",
      "Epoch [5/5], Step [16250/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16260/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16270/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [16280/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [16290/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [16300/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16320/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [16330/30930], Loss: 0.0364\n",
      "Epoch [5/5], Step [16340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16350/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [16360/30930], Loss: 0.1082\n",
      "Epoch [5/5], Step [16370/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [16380/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [16390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16400/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [16410/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [16420/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [16430/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16440/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [16450/30930], Loss: 0.0112\n",
      "Epoch [5/5], Step [16460/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [16470/30930], Loss: 0.0169\n",
      "Epoch [5/5], Step [16480/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [16490/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [16500/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [16510/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [16520/30930], Loss: 0.0282\n",
      "Epoch [5/5], Step [16530/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16540/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16550/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [16560/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [16570/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [16580/30930], Loss: 0.0331\n",
      "Epoch [5/5], Step [16590/30930], Loss: 0.0276\n",
      "Epoch [5/5], Step [16600/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16610/30930], Loss: 0.0679\n",
      "Epoch [5/5], Step [16620/30930], Loss: 0.0429\n",
      "Epoch [5/5], Step [16630/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [16640/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16650/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [16660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16670/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [16680/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [16690/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16700/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16710/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16720/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [16730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16740/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16750/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16770/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16780/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [16790/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [16800/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [16810/30930], Loss: 0.0234\n",
      "Epoch [5/5], Step [16820/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16830/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16840/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16850/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [16860/30930], Loss: 0.0321\n",
      "Epoch [5/5], Step [16870/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [16880/30930], Loss: 0.0312\n",
      "Epoch [5/5], Step [16890/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [16900/30930], Loss: 0.0143\n",
      "Epoch [5/5], Step [16910/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [16920/30930], Loss: 0.0182\n",
      "Epoch [5/5], Step [16930/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [16940/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16950/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [16960/30930], Loss: 0.0061\n",
      "Epoch [5/5], Step [16970/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [16980/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [16990/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [17000/30930], Loss: 0.0287\n",
      "Epoch [5/5], Step [17010/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [17020/30930], Loss: 0.0275\n",
      "Epoch [5/5], Step [17030/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [17040/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17050/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [17060/30930], Loss: 0.0209\n",
      "Epoch [5/5], Step [17070/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [17080/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [17090/30930], Loss: 0.0450\n",
      "Epoch [5/5], Step [17100/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [17110/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [17120/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17130/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17140/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [17150/30930], Loss: 0.0081\n",
      "Epoch [5/5], Step [17160/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [17170/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [17180/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [17190/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [17200/30930], Loss: 0.0174\n",
      "Epoch [5/5], Step [17210/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [17220/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [17230/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [17240/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [17250/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17260/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [17270/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [17280/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17290/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17300/30930], Loss: 0.0264\n",
      "Epoch [5/5], Step [17310/30930], Loss: 0.0089\n",
      "Epoch [5/5], Step [17320/30930], Loss: 0.0319\n",
      "Epoch [5/5], Step [17330/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17340/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [17350/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [17360/30930], Loss: 0.0127\n",
      "Epoch [5/5], Step [17370/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [17380/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [17390/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [17400/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [17410/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [17420/30930], Loss: 0.0249\n",
      "Epoch [5/5], Step [17430/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17440/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17450/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [17460/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17470/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [17480/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [17490/30930], Loss: 0.0072\n",
      "Epoch [5/5], Step [17500/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [17510/30930], Loss: 0.0149\n",
      "Epoch [5/5], Step [17520/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [17530/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [17540/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17550/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17560/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17570/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [17580/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [17590/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [17600/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [17610/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [17620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17630/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17640/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17650/30930], Loss: 0.0068\n",
      "Epoch [5/5], Step [17660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17670/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [17680/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [17690/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [17700/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17710/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [17720/30930], Loss: 0.0403\n",
      "Epoch [5/5], Step [17730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17740/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [17750/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [17760/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17770/30930], Loss: 0.0165\n",
      "Epoch [5/5], Step [17780/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [17790/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [17800/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [17810/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17820/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17830/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [17840/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [17850/30930], Loss: 0.0593\n",
      "Epoch [5/5], Step [17860/30930], Loss: 0.0063\n",
      "Epoch [5/5], Step [17870/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [17880/30930], Loss: 0.0625\n",
      "Epoch [5/5], Step [17890/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [17900/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17910/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17920/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [17930/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [17940/30930], Loss: 0.0285\n",
      "Epoch [5/5], Step [17950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [17960/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [17970/30930], Loss: 0.0512\n",
      "Epoch [5/5], Step [17980/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [17990/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [18000/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [18010/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [18020/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [18030/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [18040/30930], Loss: 0.0111\n",
      "Epoch [5/5], Step [18050/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [18060/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [18070/30930], Loss: 0.0280\n",
      "Epoch [5/5], Step [18080/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [18090/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [18100/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [18110/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18120/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [18130/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [18140/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [18150/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [18160/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18170/30930], Loss: 0.0434\n",
      "Epoch [5/5], Step [18180/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18190/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [18200/30930], Loss: 0.0128\n",
      "Epoch [5/5], Step [18210/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [18220/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18230/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [18240/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [18250/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [18260/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [18270/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18280/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [18290/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [18300/30930], Loss: 0.0218\n",
      "Epoch [5/5], Step [18310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18320/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18330/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18340/30930], Loss: 0.2212\n",
      "Epoch [5/5], Step [18350/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [18360/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [18370/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [18380/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [18390/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [18400/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [18410/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [18420/30930], Loss: 0.0074\n",
      "Epoch [5/5], Step [18430/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18440/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [18450/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [18460/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18470/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18480/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [18490/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [18500/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [18510/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [18520/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [18530/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [18540/30930], Loss: 0.0457\n",
      "Epoch [5/5], Step [18550/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18560/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [18570/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [18580/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [18590/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [18600/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [18610/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [18620/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [18630/30930], Loss: 0.0095\n",
      "Epoch [5/5], Step [18640/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [18650/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18660/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [18670/30930], Loss: 0.0432\n",
      "Epoch [5/5], Step [18680/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [18690/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [18700/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [18710/30930], Loss: 0.0219\n",
      "Epoch [5/5], Step [18720/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [18730/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18740/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [18750/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [18760/30930], Loss: 0.0317\n",
      "Epoch [5/5], Step [18770/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [18780/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [18790/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [18800/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18810/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [18820/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [18830/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [18840/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [18850/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [18860/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [18870/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [18880/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [18890/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [18900/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [18910/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [18920/30930], Loss: 0.0338\n",
      "Epoch [5/5], Step [18930/30930], Loss: 0.0437\n",
      "Epoch [5/5], Step [18940/30930], Loss: 0.0251\n",
      "Epoch [5/5], Step [18950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18960/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [18970/30930], Loss: 0.0142\n",
      "Epoch [5/5], Step [18980/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [18990/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [19000/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [19010/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [19020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19030/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [19040/30930], Loss: 0.0433\n",
      "Epoch [5/5], Step [19050/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [19060/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [19070/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [19080/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [19090/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [19100/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19110/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19120/30930], Loss: 0.0101\n",
      "Epoch [5/5], Step [19130/30930], Loss: 0.0622\n",
      "Epoch [5/5], Step [19140/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [19150/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [19160/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19170/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [19180/30930], Loss: 0.0429\n",
      "Epoch [5/5], Step [19190/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19200/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [19210/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [19220/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [19230/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [19240/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [19250/30930], Loss: 0.0125\n",
      "Epoch [5/5], Step [19260/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [19270/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [19280/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [19290/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19300/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [19310/30930], Loss: 0.0147\n",
      "Epoch [5/5], Step [19320/30930], Loss: 0.0145\n",
      "Epoch [5/5], Step [19330/30930], Loss: 0.0200\n",
      "Epoch [5/5], Step [19340/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [19350/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [19360/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [19370/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [19380/30930], Loss: 0.0460\n",
      "Epoch [5/5], Step [19390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19400/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [19410/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [19420/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [19430/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19440/30930], Loss: 0.1254\n",
      "Epoch [5/5], Step [19450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19460/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [19470/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [19480/30930], Loss: 0.0216\n",
      "Epoch [5/5], Step [19490/30930], Loss: 0.0433\n",
      "Epoch [5/5], Step [19500/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19510/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [19520/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [19530/30930], Loss: 0.0126\n",
      "Epoch [5/5], Step [19540/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19550/30930], Loss: 0.0145\n",
      "Epoch [5/5], Step [19560/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [19570/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [19580/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [19590/30930], Loss: 0.0109\n",
      "Epoch [5/5], Step [19600/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [19610/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [19620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19630/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [19640/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [19650/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19670/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19680/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [19690/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [19700/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [19710/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [19720/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [19730/30930], Loss: 0.0060\n",
      "Epoch [5/5], Step [19740/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [19750/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [19760/30930], Loss: 0.0102\n",
      "Epoch [5/5], Step [19770/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [19780/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [19790/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19800/30930], Loss: 0.0406\n",
      "Epoch [5/5], Step [19810/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [19820/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [19830/30930], Loss: 0.0081\n",
      "Epoch [5/5], Step [19840/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [19850/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [19860/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [19870/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [19880/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [19890/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [19900/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [19910/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [19920/30930], Loss: 0.0085\n",
      "Epoch [5/5], Step [19930/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [19940/30930], Loss: 0.0157\n",
      "Epoch [5/5], Step [19950/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [19960/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [19970/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [19980/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [19990/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20010/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [20020/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [20030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20040/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [20050/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20060/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [20070/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20080/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20090/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [20100/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20110/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [20120/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [20130/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [20140/30930], Loss: 0.0219\n",
      "Epoch [5/5], Step [20150/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [20160/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20170/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [20180/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20190/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [20200/30930], Loss: 0.0166\n",
      "Epoch [5/5], Step [20210/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [20220/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [20230/30930], Loss: 0.0370\n",
      "Epoch [5/5], Step [20240/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [20250/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [20260/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20270/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [20280/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [20290/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20300/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [20310/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [20320/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [20330/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [20340/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20350/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [20360/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [20370/30930], Loss: 0.0139\n",
      "Epoch [5/5], Step [20380/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [20390/30930], Loss: 0.0097\n",
      "Epoch [5/5], Step [20400/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20410/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [20420/30930], Loss: 0.0563\n",
      "Epoch [5/5], Step [20430/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [20440/30930], Loss: 0.0089\n",
      "Epoch [5/5], Step [20450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20460/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [20470/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [20480/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [20490/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [20500/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20510/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [20520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20530/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20540/30930], Loss: 0.0087\n",
      "Epoch [5/5], Step [20550/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [20560/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [20570/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [20580/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [20590/30930], Loss: 0.0231\n",
      "Epoch [5/5], Step [20600/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20610/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20620/30930], Loss: 0.0084\n",
      "Epoch [5/5], Step [20630/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20640/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20650/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [20660/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [20670/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20680/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [20690/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [20700/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [20710/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [20720/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [20730/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [20740/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [20750/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20770/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20780/30930], Loss: 0.0612\n",
      "Epoch [5/5], Step [20790/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [20800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20810/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20820/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [20830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20840/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [20850/30930], Loss: 0.0231\n",
      "Epoch [5/5], Step [20860/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20870/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [20880/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [20890/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [20900/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [20910/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [20920/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20930/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [20940/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [20960/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [20970/30930], Loss: 0.0500\n",
      "Epoch [5/5], Step [20980/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [20990/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [21000/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [21010/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21020/30930], Loss: 0.0096\n",
      "Epoch [5/5], Step [21030/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [21040/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [21050/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21060/30930], Loss: 0.0208\n",
      "Epoch [5/5], Step [21070/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [21080/30930], Loss: 0.0355\n",
      "Epoch [5/5], Step [21090/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [21100/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [21110/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21120/30930], Loss: 0.0627\n",
      "Epoch [5/5], Step [21130/30930], Loss: 0.0060\n",
      "Epoch [5/5], Step [21140/30930], Loss: 0.0399\n",
      "Epoch [5/5], Step [21150/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [21160/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [21170/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [21180/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21190/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21210/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [21220/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21230/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21240/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21250/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21260/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [21270/30930], Loss: 0.0204\n",
      "Epoch [5/5], Step [21280/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21290/30930], Loss: 0.0216\n",
      "Epoch [5/5], Step [21300/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21320/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21330/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [21340/30930], Loss: 0.0327\n",
      "Epoch [5/5], Step [21350/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [21360/30930], Loss: 0.0419\n",
      "Epoch [5/5], Step [21370/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [21380/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [21390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21400/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [21410/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [21420/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [21430/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21460/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21470/30930], Loss: 0.0888\n",
      "Epoch [5/5], Step [21480/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [21490/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21500/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [21510/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [21520/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21530/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [21540/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21550/30930], Loss: 0.0170\n",
      "Epoch [5/5], Step [21560/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21570/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [21580/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [21590/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [21600/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [21610/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [21620/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [21630/30930], Loss: 0.0369\n",
      "Epoch [5/5], Step [21640/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21650/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [21660/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [21670/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [21680/30930], Loss: 0.0247\n",
      "Epoch [5/5], Step [21690/30930], Loss: 0.0300\n",
      "Epoch [5/5], Step [21700/30930], Loss: 0.0549\n",
      "Epoch [5/5], Step [21710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21720/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [21730/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [21740/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [21750/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [21760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21770/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [21780/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [21790/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [21800/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [21810/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [21820/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [21830/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [21840/30930], Loss: 0.0087\n",
      "Epoch [5/5], Step [21850/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [21860/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [21870/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [21880/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [21890/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [21900/30930], Loss: 0.0056\n",
      "Epoch [5/5], Step [21910/30930], Loss: 0.0210\n",
      "Epoch [5/5], Step [21920/30930], Loss: 0.0075\n",
      "Epoch [5/5], Step [21930/30930], Loss: 0.1676\n",
      "Epoch [5/5], Step [21940/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [21950/30930], Loss: 0.0069\n",
      "Epoch [5/5], Step [21960/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [21970/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [21980/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [21990/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [22000/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [22010/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22020/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [22030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22040/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22050/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22060/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [22070/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [22080/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [22090/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22100/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22110/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22120/30930], Loss: 0.0149\n",
      "Epoch [5/5], Step [22130/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [22140/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [22150/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [22160/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [22170/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [22180/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22190/30930], Loss: 0.1093\n",
      "Epoch [5/5], Step [22200/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [22210/30930], Loss: 0.0236\n",
      "Epoch [5/5], Step [22220/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22230/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22240/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22250/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [22260/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [22270/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [22280/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22290/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22300/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [22310/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22320/30930], Loss: 0.0197\n",
      "Epoch [5/5], Step [22330/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [22340/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [22350/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [22360/30930], Loss: 0.0295\n",
      "Epoch [5/5], Step [22370/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22380/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [22390/30930], Loss: 0.0114\n",
      "Epoch [5/5], Step [22400/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [22410/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [22420/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22430/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22440/30930], Loss: 0.0058\n",
      "Epoch [5/5], Step [22450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22460/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22470/30930], Loss: 0.0458\n",
      "Epoch [5/5], Step [22480/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22490/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22500/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [22510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22530/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [22540/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [22550/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22560/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [22570/30930], Loss: 0.0227\n",
      "Epoch [5/5], Step [22580/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22590/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22600/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [22610/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22620/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [22630/30930], Loss: 0.0098\n",
      "Epoch [5/5], Step [22640/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22650/30930], Loss: 0.0278\n",
      "Epoch [5/5], Step [22660/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22670/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [22680/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22690/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [22700/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22710/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [22720/30930], Loss: 0.0080\n",
      "Epoch [5/5], Step [22730/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [22740/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [22750/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [22760/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [22770/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [22780/30930], Loss: 0.0161\n",
      "Epoch [5/5], Step [22790/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22800/30930], Loss: 0.0276\n",
      "Epoch [5/5], Step [22810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22820/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [22830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22840/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22850/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22860/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [22870/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [22880/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [22890/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [22900/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [22910/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [22920/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [22930/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [22940/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [22950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [22960/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [22970/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [22980/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [22990/30930], Loss: 0.0077\n",
      "Epoch [5/5], Step [23000/30930], Loss: 0.0713\n",
      "Epoch [5/5], Step [23010/30930], Loss: 0.0918\n",
      "Epoch [5/5], Step [23020/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [23030/30930], Loss: 0.0561\n",
      "Epoch [5/5], Step [23040/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23050/30930], Loss: 0.0633\n",
      "Epoch [5/5], Step [23060/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [23070/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [23080/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [23090/30930], Loss: 0.0078\n",
      "Epoch [5/5], Step [23100/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23110/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [23120/30930], Loss: 0.0368\n",
      "Epoch [5/5], Step [23130/30930], Loss: 0.0526\n",
      "Epoch [5/5], Step [23140/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23150/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [23160/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23170/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23180/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23190/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23200/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23210/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [23220/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [23230/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23240/30930], Loss: 0.0580\n",
      "Epoch [5/5], Step [23250/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [23260/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23270/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [23280/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [23290/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [23300/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [23310/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [23320/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [23330/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23340/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23350/30930], Loss: 0.0088\n",
      "Epoch [5/5], Step [23360/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [23370/30930], Loss: 0.0058\n",
      "Epoch [5/5], Step [23380/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [23390/30930], Loss: 0.0210\n",
      "Epoch [5/5], Step [23400/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [23410/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [23420/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [23430/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [23440/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [23450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23460/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [23470/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [23480/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [23490/30930], Loss: 0.0068\n",
      "Epoch [5/5], Step [23500/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [23510/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [23520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23530/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [23540/30930], Loss: 0.0125\n",
      "Epoch [5/5], Step [23550/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23560/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [23570/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23580/30930], Loss: 0.0414\n",
      "Epoch [5/5], Step [23590/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23600/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23610/30930], Loss: 0.0427\n",
      "Epoch [5/5], Step [23620/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23630/30930], Loss: 0.0276\n",
      "Epoch [5/5], Step [23640/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [23650/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [23660/30930], Loss: 0.0097\n",
      "Epoch [5/5], Step [23670/30930], Loss: 0.0095\n",
      "Epoch [5/5], Step [23680/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [23690/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [23700/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [23710/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [23720/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [23730/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [23740/30930], Loss: 0.0194\n",
      "Epoch [5/5], Step [23750/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23760/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [23770/30930], Loss: 0.0232\n",
      "Epoch [5/5], Step [23780/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [23790/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23800/30930], Loss: 0.0089\n",
      "Epoch [5/5], Step [23810/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23820/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [23830/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [23840/30930], Loss: 0.1506\n",
      "Epoch [5/5], Step [23850/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23860/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [23870/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [23880/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [23890/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [23900/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [23910/30930], Loss: 0.0073\n",
      "Epoch [5/5], Step [23920/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [23930/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [23940/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [23950/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [23960/30930], Loss: 0.0104\n",
      "Epoch [5/5], Step [23970/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [23980/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [23990/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24010/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [24020/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24030/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [24040/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [24050/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24060/30930], Loss: 0.0478\n",
      "Epoch [5/5], Step [24070/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [24080/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24090/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [24100/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [24110/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [24120/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24130/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [24140/30930], Loss: 0.0297\n",
      "Epoch [5/5], Step [24150/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24160/30930], Loss: 0.0154\n",
      "Epoch [5/5], Step [24170/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [24180/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [24190/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [24200/30930], Loss: 0.1044\n",
      "Epoch [5/5], Step [24210/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [24220/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [24230/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [24240/30930], Loss: 0.0107\n",
      "Epoch [5/5], Step [24250/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [24260/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [24270/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [24280/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [24290/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [24300/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [24310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24320/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [24330/30930], Loss: 0.2007\n",
      "Epoch [5/5], Step [24340/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [24350/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [24360/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [24370/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [24380/30930], Loss: 0.0064\n",
      "Epoch [5/5], Step [24390/30930], Loss: 0.0108\n",
      "Epoch [5/5], Step [24400/30930], Loss: 0.0236\n",
      "Epoch [5/5], Step [24410/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [24420/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [24430/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [24440/30930], Loss: 0.0383\n",
      "Epoch [5/5], Step [24450/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [24460/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [24470/30930], Loss: 0.0568\n",
      "Epoch [5/5], Step [24480/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [24490/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [24500/30930], Loss: 0.0469\n",
      "Epoch [5/5], Step [24510/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24520/30930], Loss: 0.0757\n",
      "Epoch [5/5], Step [24530/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [24540/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24550/30930], Loss: 0.0340\n",
      "Epoch [5/5], Step [24560/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24570/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [24580/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [24590/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [24600/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [24610/30930], Loss: 0.0336\n",
      "Epoch [5/5], Step [24620/30930], Loss: 0.0391\n",
      "Epoch [5/5], Step [24630/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [24640/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [24650/30930], Loss: 0.0142\n",
      "Epoch [5/5], Step [24660/30930], Loss: 0.0208\n",
      "Epoch [5/5], Step [24670/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [24680/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [24690/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [24700/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [24710/30930], Loss: 0.0867\n",
      "Epoch [5/5], Step [24720/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24730/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [24740/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [24750/30930], Loss: 0.0090\n",
      "Epoch [5/5], Step [24760/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [24770/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [24780/30930], Loss: 0.0138\n",
      "Epoch [5/5], Step [24790/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [24800/30930], Loss: 0.0030\n",
      "Epoch [5/5], Step [24810/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [24820/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24830/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24840/30930], Loss: 0.0069\n",
      "Epoch [5/5], Step [24850/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [24860/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [24870/30930], Loss: 0.0415\n",
      "Epoch [5/5], Step [24880/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24890/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [24900/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [24910/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [24920/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [24930/30930], Loss: 0.0154\n",
      "Epoch [5/5], Step [24940/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [24950/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [24960/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [24970/30930], Loss: 0.0413\n",
      "Epoch [5/5], Step [24980/30930], Loss: 0.0137\n",
      "Epoch [5/5], Step [24990/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [25000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25010/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [25020/30930], Loss: 0.0607\n",
      "Epoch [5/5], Step [25030/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [25040/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [25050/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [25060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25070/30930], Loss: 0.0138\n",
      "Epoch [5/5], Step [25080/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [25090/30930], Loss: 0.0079\n",
      "Epoch [5/5], Step [25100/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [25110/30930], Loss: 0.4261\n",
      "Epoch [5/5], Step [25120/30930], Loss: 0.0122\n",
      "Epoch [5/5], Step [25130/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [25140/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [25150/30930], Loss: 0.0122\n",
      "Epoch [5/5], Step [25160/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [25170/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [25180/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [25190/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [25200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25210/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [25220/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [25230/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [25240/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [25250/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25260/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25270/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25280/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [25290/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [25300/30930], Loss: 0.0036\n",
      "Epoch [5/5], Step [25310/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25320/30930], Loss: 0.0308\n",
      "Epoch [5/5], Step [25330/30930], Loss: 0.2568\n",
      "Epoch [5/5], Step [25340/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [25350/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [25360/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [25370/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [25380/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [25390/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [25400/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [25410/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [25420/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [25430/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [25440/30930], Loss: 0.0079\n",
      "Epoch [5/5], Step [25450/30930], Loss: 0.0275\n",
      "Epoch [5/5], Step [25460/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25470/30930], Loss: 0.0332\n",
      "Epoch [5/5], Step [25480/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25490/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25500/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25510/30930], Loss: 0.0710\n",
      "Epoch [5/5], Step [25520/30930], Loss: 0.0378\n",
      "Epoch [5/5], Step [25530/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25540/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25550/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [25560/30930], Loss: 0.0484\n",
      "Epoch [5/5], Step [25570/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [25580/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [25590/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25600/30930], Loss: 0.0207\n",
      "Epoch [5/5], Step [25610/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [25620/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [25630/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [25640/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25650/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [25660/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [25670/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25680/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [25690/30930], Loss: 0.0162\n",
      "Epoch [5/5], Step [25700/30930], Loss: 0.0132\n",
      "Epoch [5/5], Step [25710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25720/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [25730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25740/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25750/30930], Loss: 0.0167\n",
      "Epoch [5/5], Step [25760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25770/30930], Loss: 0.0151\n",
      "Epoch [5/5], Step [25780/30930], Loss: 0.0116\n",
      "Epoch [5/5], Step [25790/30930], Loss: 0.0226\n",
      "Epoch [5/5], Step [25800/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [25810/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [25820/30930], Loss: 0.0139\n",
      "Epoch [5/5], Step [25830/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [25840/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [25850/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [25860/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [25870/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [25880/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [25890/30930], Loss: 0.0088\n",
      "Epoch [5/5], Step [25900/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [25910/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25920/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [25930/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [25940/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [25950/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [25960/30930], Loss: 0.0506\n",
      "Epoch [5/5], Step [25970/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [25980/30930], Loss: 0.0124\n",
      "Epoch [5/5], Step [25990/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26000/30930], Loss: 0.0249\n",
      "Epoch [5/5], Step [26010/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [26020/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [26030/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26040/30930], Loss: 0.0057\n",
      "Epoch [5/5], Step [26050/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [26060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26070/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [26080/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [26090/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [26100/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26110/30930], Loss: 0.0260\n",
      "Epoch [5/5], Step [26120/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [26130/30930], Loss: 0.0110\n",
      "Epoch [5/5], Step [26140/30930], Loss: 0.0094\n",
      "Epoch [5/5], Step [26150/30930], Loss: 0.0130\n",
      "Epoch [5/5], Step [26160/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [26170/30930], Loss: 0.0269\n",
      "Epoch [5/5], Step [26180/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [26190/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [26200/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [26210/30930], Loss: 0.0441\n",
      "Epoch [5/5], Step [26220/30930], Loss: 0.0360\n",
      "Epoch [5/5], Step [26230/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26240/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [26250/30930], Loss: 0.0144\n",
      "Epoch [5/5], Step [26260/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [26270/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [26280/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [26290/30930], Loss: 0.0469\n",
      "Epoch [5/5], Step [26300/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [26310/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [26320/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [26330/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [26340/30930], Loss: 0.0365\n",
      "Epoch [5/5], Step [26350/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [26360/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [26370/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26380/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26390/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [26400/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [26410/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [26420/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [26430/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [26440/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [26450/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26460/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [26470/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [26480/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [26490/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [26500/30930], Loss: 0.0097\n",
      "Epoch [5/5], Step [26510/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [26520/30930], Loss: 0.0398\n",
      "Epoch [5/5], Step [26530/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26540/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26550/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26560/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [26570/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [26580/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [26590/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [26600/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [26610/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26620/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [26630/30930], Loss: 0.1208\n",
      "Epoch [5/5], Step [26640/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [26650/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [26660/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26670/30930], Loss: 0.0032\n",
      "Epoch [5/5], Step [26680/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [26690/30930], Loss: 0.0037\n",
      "Epoch [5/5], Step [26700/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [26710/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [26720/30930], Loss: 0.0409\n",
      "Epoch [5/5], Step [26730/30930], Loss: 0.0096\n",
      "Epoch [5/5], Step [26740/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [26750/30930], Loss: 0.0140\n",
      "Epoch [5/5], Step [26760/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [26770/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26780/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [26790/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [26800/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [26810/30930], Loss: 0.0427\n",
      "Epoch [5/5], Step [26820/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26830/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [26840/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [26850/30930], Loss: 0.0078\n",
      "Epoch [5/5], Step [26860/30930], Loss: 0.0461\n",
      "Epoch [5/5], Step [26870/30930], Loss: 0.0043\n",
      "Epoch [5/5], Step [26880/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [26890/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [26900/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [26910/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [26920/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [26930/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [26940/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [26950/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [26960/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [26970/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [26980/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [26990/30930], Loss: 0.0215\n",
      "Epoch [5/5], Step [27000/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [27010/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27020/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [27030/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [27040/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27050/30930], Loss: 0.1933\n",
      "Epoch [5/5], Step [27060/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [27070/30930], Loss: 0.0310\n",
      "Epoch [5/5], Step [27080/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [27090/30930], Loss: 0.0047\n",
      "Epoch [5/5], Step [27100/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [27110/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [27120/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27130/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27140/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [27150/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [27160/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [27170/30930], Loss: 0.0092\n",
      "Epoch [5/5], Step [27180/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [27190/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27210/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [27220/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27230/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27240/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27250/30930], Loss: 0.0403\n",
      "Epoch [5/5], Step [27260/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [27270/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [27280/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [27290/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27300/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [27310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27320/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [27330/30930], Loss: 0.0263\n",
      "Epoch [5/5], Step [27340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27350/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27360/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [27370/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [27380/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [27390/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27400/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [27410/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27420/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [27430/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [27440/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27450/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [27460/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [27470/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27480/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27490/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [27500/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27510/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [27520/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [27530/30930], Loss: 0.0326\n",
      "Epoch [5/5], Step [27540/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27550/30930], Loss: 0.0054\n",
      "Epoch [5/5], Step [27560/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [27570/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [27580/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27590/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [27600/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27610/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [27620/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [27630/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27640/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [27650/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [27660/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [27670/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [27680/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [27690/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [27700/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [27710/30930], Loss: 0.0182\n",
      "Epoch [5/5], Step [27720/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [27730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27740/30930], Loss: 0.0273\n",
      "Epoch [5/5], Step [27750/30930], Loss: 0.0066\n",
      "Epoch [5/5], Step [27760/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27770/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [27780/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [27790/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [27800/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [27810/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27820/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [27830/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [27840/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27850/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [27860/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [27870/30930], Loss: 0.0189\n",
      "Epoch [5/5], Step [27880/30930], Loss: 0.0051\n",
      "Epoch [5/5], Step [27890/30930], Loss: 0.0108\n",
      "Epoch [5/5], Step [27900/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27910/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [27920/30930], Loss: 0.0469\n",
      "Epoch [5/5], Step [27930/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27940/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [27950/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [27960/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [27970/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [27980/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [27990/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28000/30930], Loss: 0.0488\n",
      "Epoch [5/5], Step [28010/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28020/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [28030/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [28040/30930], Loss: 0.0345\n",
      "Epoch [5/5], Step [28050/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28060/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [28070/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28080/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [28090/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [28100/30930], Loss: 0.0018\n",
      "Epoch [5/5], Step [28110/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28120/30930], Loss: 0.0900\n",
      "Epoch [5/5], Step [28130/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28140/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [28150/30930], Loss: 0.0046\n",
      "Epoch [5/5], Step [28160/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28170/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28180/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [28190/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [28200/30930], Loss: 0.0102\n",
      "Epoch [5/5], Step [28210/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [28220/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28230/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [28240/30930], Loss: 0.0088\n",
      "Epoch [5/5], Step [28250/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [28260/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [28270/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [28280/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28290/30930], Loss: 0.0185\n",
      "Epoch [5/5], Step [28300/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [28310/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [28320/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [28330/30930], Loss: 0.0443\n",
      "Epoch [5/5], Step [28340/30930], Loss: 0.0091\n",
      "Epoch [5/5], Step [28350/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [28360/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [28370/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28380/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [28390/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [28400/30930], Loss: 0.0086\n",
      "Epoch [5/5], Step [28410/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [28420/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28430/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28440/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28450/30930], Loss: 0.0035\n",
      "Epoch [5/5], Step [28460/30930], Loss: 0.0015\n",
      "Epoch [5/5], Step [28470/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [28480/30930], Loss: 0.0045\n",
      "Epoch [5/5], Step [28490/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [28500/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [28510/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28520/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28530/30930], Loss: 0.0253\n",
      "Epoch [5/5], Step [28540/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28550/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28560/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28570/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28580/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28590/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [28600/30930], Loss: 0.0024\n",
      "Epoch [5/5], Step [28610/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28620/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [28630/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28640/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [28650/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28660/30930], Loss: 0.0438\n",
      "Epoch [5/5], Step [28670/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [28680/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28690/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28700/30930], Loss: 0.0052\n",
      "Epoch [5/5], Step [28710/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28720/30930], Loss: 0.0053\n",
      "Epoch [5/5], Step [28730/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28740/30930], Loss: 0.0156\n",
      "Epoch [5/5], Step [28750/30930], Loss: 0.0091\n",
      "Epoch [5/5], Step [28760/30930], Loss: 0.0021\n",
      "Epoch [5/5], Step [28770/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [28780/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [28790/30930], Loss: 0.0017\n",
      "Epoch [5/5], Step [28800/30930], Loss: 0.0212\n",
      "Epoch [5/5], Step [28810/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [28820/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [28830/30930], Loss: 0.0434\n",
      "Epoch [5/5], Step [28840/30930], Loss: 0.0056\n",
      "Epoch [5/5], Step [28850/30930], Loss: 0.0082\n",
      "Epoch [5/5], Step [28860/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [28870/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28880/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [28890/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [28900/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [28910/30930], Loss: 0.0071\n",
      "Epoch [5/5], Step [28920/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28930/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [28940/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [28950/30930], Loss: 0.0352\n",
      "Epoch [5/5], Step [28960/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [28970/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [28980/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [28990/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [29000/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [29010/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [29020/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [29030/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [29040/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [29050/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29070/30930], Loss: 0.1151\n",
      "Epoch [5/5], Step [29080/30930], Loss: 0.0281\n",
      "Epoch [5/5], Step [29090/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [29100/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29110/30930], Loss: 0.0254\n",
      "Epoch [5/5], Step [29120/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29130/30930], Loss: 0.0238\n",
      "Epoch [5/5], Step [29140/30930], Loss: 0.0355\n",
      "Epoch [5/5], Step [29150/30930], Loss: 0.0011\n",
      "Epoch [5/5], Step [29160/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29170/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29180/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [29190/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [29200/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29210/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [29220/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [29230/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [29240/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [29250/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [29260/30930], Loss: 0.0259\n",
      "Epoch [5/5], Step [29270/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [29280/30930], Loss: 0.0009\n",
      "Epoch [5/5], Step [29290/30930], Loss: 0.0065\n",
      "Epoch [5/5], Step [29300/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29310/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [29320/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [29330/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29340/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [29350/30930], Loss: 0.0306\n",
      "Epoch [5/5], Step [29360/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29370/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29380/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29390/30930], Loss: 0.0485\n",
      "Epoch [5/5], Step [29400/30930], Loss: 0.0012\n",
      "Epoch [5/5], Step [29410/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29420/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [29430/30930], Loss: 0.0055\n",
      "Epoch [5/5], Step [29440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29450/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29460/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [29470/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29480/30930], Loss: 0.0477\n",
      "Epoch [5/5], Step [29490/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [29500/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29510/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29520/30930], Loss: 0.0292\n",
      "Epoch [5/5], Step [29530/30930], Loss: 0.0026\n",
      "Epoch [5/5], Step [29540/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [29550/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29560/30930], Loss: 0.0025\n",
      "Epoch [5/5], Step [29570/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29580/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29590/30930], Loss: 0.0311\n",
      "Epoch [5/5], Step [29600/30930], Loss: 0.0100\n",
      "Epoch [5/5], Step [29610/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29620/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29630/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [29640/30930], Loss: 0.0265\n",
      "Epoch [5/5], Step [29650/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29660/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29670/30930], Loss: 0.0579\n",
      "Epoch [5/5], Step [29680/30930], Loss: 0.0815\n",
      "Epoch [5/5], Step [29690/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [29700/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [29710/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [29720/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29730/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29740/30930], Loss: 0.1643\n",
      "Epoch [5/5], Step [29750/30930], Loss: 0.0114\n",
      "Epoch [5/5], Step [29760/30930], Loss: 0.0118\n",
      "Epoch [5/5], Step [29770/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [29780/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [29790/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [29800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29810/30930], Loss: 0.0250\n",
      "Epoch [5/5], Step [29820/30930], Loss: 0.0141\n",
      "Epoch [5/5], Step [29830/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29840/30930], Loss: 0.0013\n",
      "Epoch [5/5], Step [29850/30930], Loss: 0.0039\n",
      "Epoch [5/5], Step [29860/30930], Loss: 0.0048\n",
      "Epoch [5/5], Step [29870/30930], Loss: 0.0131\n",
      "Epoch [5/5], Step [29880/30930], Loss: 0.0191\n",
      "Epoch [5/5], Step [29890/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [29900/30930], Loss: 0.0042\n",
      "Epoch [5/5], Step [29910/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [29920/30930], Loss: 0.0483\n",
      "Epoch [5/5], Step [29930/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [29940/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [29950/30930], Loss: 0.0204\n",
      "Epoch [5/5], Step [29960/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29970/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [29980/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [29990/30930], Loss: 0.0008\n",
      "Epoch [5/5], Step [30000/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30010/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [30020/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30030/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30040/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [30050/30930], Loss: 0.0061\n",
      "Epoch [5/5], Step [30060/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30070/30930], Loss: 0.0007\n",
      "Epoch [5/5], Step [30080/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30090/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30100/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [30110/30930], Loss: 0.0059\n",
      "Epoch [5/5], Step [30120/30930], Loss: 0.0223\n",
      "Epoch [5/5], Step [30130/30930], Loss: 0.0476\n",
      "Epoch [5/5], Step [30140/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30150/30930], Loss: 0.0093\n",
      "Epoch [5/5], Step [30160/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30170/30930], Loss: 0.0122\n",
      "Epoch [5/5], Step [30180/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30190/30930], Loss: 0.0023\n",
      "Epoch [5/5], Step [30200/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30210/30930], Loss: 0.0062\n",
      "Epoch [5/5], Step [30220/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [30230/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30240/30930], Loss: 0.0399\n",
      "Epoch [5/5], Step [30250/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30260/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30270/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30280/30930], Loss: 0.0019\n",
      "Epoch [5/5], Step [30290/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [30300/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30310/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30320/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30330/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [30340/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30350/30930], Loss: 0.0050\n",
      "Epoch [5/5], Step [30360/30930], Loss: 0.0587\n",
      "Epoch [5/5], Step [30370/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30380/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30390/30930], Loss: 0.0067\n",
      "Epoch [5/5], Step [30400/30930], Loss: 0.0041\n",
      "Epoch [5/5], Step [30410/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30420/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30430/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [30440/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30450/30930], Loss: 0.0798\n",
      "Epoch [5/5], Step [30460/30930], Loss: 0.0016\n",
      "Epoch [5/5], Step [30470/30930], Loss: 0.0020\n",
      "Epoch [5/5], Step [30480/30930], Loss: 0.0033\n",
      "Epoch [5/5], Step [30490/30930], Loss: 0.0096\n",
      "Epoch [5/5], Step [30500/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30510/30930], Loss: 0.0014\n",
      "Epoch [5/5], Step [30520/30930], Loss: 0.0022\n",
      "Epoch [5/5], Step [30530/30930], Loss: 0.0083\n",
      "Epoch [5/5], Step [30540/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30550/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [30560/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30570/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30580/30930], Loss: 0.0076\n",
      "Epoch [5/5], Step [30590/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30600/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30610/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30620/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30630/30930], Loss: 0.0002\n",
      "Epoch [5/5], Step [30640/30930], Loss: 0.0034\n",
      "Epoch [5/5], Step [30650/30930], Loss: 0.0044\n",
      "Epoch [5/5], Step [30660/30930], Loss: 0.0049\n",
      "Epoch [5/5], Step [30670/30930], Loss: 0.0089\n",
      "Epoch [5/5], Step [30680/30930], Loss: 0.0031\n",
      "Epoch [5/5], Step [30690/30930], Loss: 0.0005\n",
      "Epoch [5/5], Step [30700/30930], Loss: 0.0460\n",
      "Epoch [5/5], Step [30710/30930], Loss: 0.0058\n",
      "Epoch [5/5], Step [30720/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [30730/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30740/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30750/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30760/30930], Loss: 0.0010\n",
      "Epoch [5/5], Step [30770/30930], Loss: 0.0166\n",
      "Epoch [5/5], Step [30780/30930], Loss: 0.0029\n",
      "Epoch [5/5], Step [30790/30930], Loss: 0.0088\n",
      "Epoch [5/5], Step [30800/30930], Loss: 0.0001\n",
      "Epoch [5/5], Step [30810/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30820/30930], Loss: 0.0027\n",
      "Epoch [5/5], Step [30830/30930], Loss: 0.0003\n",
      "Epoch [5/5], Step [30840/30930], Loss: 0.0028\n",
      "Epoch [5/5], Step [30850/30930], Loss: 0.0038\n",
      "Epoch [5/5], Step [30860/30930], Loss: 0.0040\n",
      "Epoch [5/5], Step [30870/30930], Loss: 0.0072\n",
      "Epoch [5/5], Step [30880/30930], Loss: 0.0004\n",
      "Epoch [5/5], Step [30890/30930], Loss: 0.0303\n",
      "Epoch [5/5], Step [30900/30930], Loss: 0.0095\n",
      "Epoch [5/5], Step [30910/30930], Loss: 0.0006\n",
      "Epoch [5/5], Step [30920/30930], Loss: 0.0000\n",
      "Epoch [5/5], Step [30930/30930], Loss: 0.0004\n",
      "Epoch [5/5], Average Train Loss: 0.0078\n",
      "Epoch [5/5], Validation Loss: 0.0083\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Possible overfitting detected (validation loss > training loss).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleCNN(num_classes=9).to(device)\n",
    "train_model_verbose(model, train_dataloader, val_dataloader, num_epochs=5,  learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d3ee1f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test dataset: 99.75%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model on test dataset and calculate accuracy and plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "def test_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test dataset: {accuracy:.2f}%')\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_to_idx.keys(), yticklabels=label_to_idx.keys())\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, all_labels, all_predictions\n",
    "\n",
    "accuracy, all_labels, all_predictions = test_model(model, test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f1960b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   WebAttack       0.89      0.42      0.57       327\n",
      "    PortScan       1.00      1.00      1.00     23821\n",
      "  Heartbleed       1.00      1.00      1.00         1\n",
      "  BruteForce       0.98      0.98      0.98      2075\n",
      "         DoS       0.99      1.00      0.99     37757\n",
      "        DDoS       1.00      1.00      1.00     19204\n",
      "         Bot       0.99      0.64      0.78       294\n",
      "      BENIGN       1.00      1.00      1.00    340698\n",
      "Infiltration       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           1.00    424182\n",
      "   macro avg       0.98      0.80      0.85    424182\n",
      "weighted avg       1.00      1.00      1.00    424182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the f1-score, precision, recall and accuracy\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(all_labels, all_predictions, target_names=label_to_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f4627188",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_idx = []\n",
    "malicious_idx = []\n",
    "for idx, data in enumerate(train_dataset):\n",
    "    if data[1] == 'BENIGN':\n",
    "        benign_idx.append(idx)\n",
    "    else:\n",
    "        malicious_idx.append(idx)\n",
    "\n",
    "import random\n",
    "sample_size = 250_000  # Or similar to DoS/DDoS/PortScan counts\n",
    "benign_sampled = random.sample(benign_idx, sample_size)\n",
    "final_indices = benign_sampled + malicious_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ef1d3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled_train_dataset = torch.utils.data.Subset(\n",
    "    train_dataset,\n",
    "    final_indices\n",
    ")\n",
    "transformed_undersampled_train_dataset = TransformDataset(undersampled_train_dataset, transform)\n",
    "undersampled_train_dataloader = torch.utils.data.DataLoader(\n",
    "    transformed_undersampled_train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "95fbfe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [10/9994], Loss: 1.3676\n",
      "Epoch [1/5], Step [20/9994], Loss: 1.3485\n",
      "Epoch [1/5], Step [30/9994], Loss: 1.3960\n",
      "Epoch [1/5], Step [40/9994], Loss: 1.1284\n",
      "Epoch [1/5], Step [50/9994], Loss: 1.1058\n",
      "Epoch [1/5], Step [60/9994], Loss: 0.9490\n",
      "Epoch [1/5], Step [70/9994], Loss: 0.9576\n",
      "Epoch [1/5], Step [80/9994], Loss: 0.6311\n",
      "Epoch [1/5], Step [90/9994], Loss: 0.5267\n",
      "Epoch [1/5], Step [100/9994], Loss: 0.6267\n",
      "Epoch [1/5], Step [110/9994], Loss: 0.7312\n",
      "Epoch [1/5], Step [120/9994], Loss: 0.5257\n",
      "Epoch [1/5], Step [130/9994], Loss: 0.4755\n",
      "Epoch [1/5], Step [140/9994], Loss: 0.3970\n",
      "Epoch [1/5], Step [150/9994], Loss: 0.5088\n",
      "Epoch [1/5], Step [160/9994], Loss: 0.5992\n",
      "Epoch [1/5], Step [170/9994], Loss: 0.3815\n",
      "Epoch [1/5], Step [180/9994], Loss: 0.5435\n",
      "Epoch [1/5], Step [190/9994], Loss: 0.2951\n",
      "Epoch [1/5], Step [200/9994], Loss: 0.4314\n",
      "Epoch [1/5], Step [210/9994], Loss: 0.2068\n",
      "Epoch [1/5], Step [220/9994], Loss: 0.2317\n",
      "Epoch [1/5], Step [230/9994], Loss: 0.1992\n",
      "Epoch [1/5], Step [240/9994], Loss: 0.3891\n",
      "Epoch [1/5], Step [250/9994], Loss: 0.1715\n",
      "Epoch [1/5], Step [260/9994], Loss: 0.1932\n",
      "Epoch [1/5], Step [270/9994], Loss: 0.2854\n",
      "Epoch [1/5], Step [280/9994], Loss: 0.2797\n",
      "Epoch [1/5], Step [290/9994], Loss: 0.1326\n",
      "Epoch [1/5], Step [300/9994], Loss: 0.2262\n",
      "Epoch [1/5], Step [310/9994], Loss: 0.1488\n",
      "Epoch [1/5], Step [320/9994], Loss: 0.1614\n",
      "Epoch [1/5], Step [330/9994], Loss: 0.3322\n",
      "Epoch [1/5], Step [340/9994], Loss: 0.1491\n",
      "Epoch [1/5], Step [350/9994], Loss: 0.3528\n",
      "Epoch [1/5], Step [360/9994], Loss: 0.2548\n",
      "Epoch [1/5], Step [370/9994], Loss: 0.0963\n",
      "Epoch [1/5], Step [380/9994], Loss: 0.2097\n",
      "Epoch [1/5], Step [390/9994], Loss: 0.2190\n",
      "Epoch [1/5], Step [400/9994], Loss: 0.3218\n",
      "Epoch [1/5], Step [410/9994], Loss: 0.1776\n",
      "Epoch [1/5], Step [420/9994], Loss: 0.1427\n",
      "Epoch [1/5], Step [430/9994], Loss: 0.3753\n",
      "Epoch [1/5], Step [440/9994], Loss: 0.1999\n",
      "Epoch [1/5], Step [450/9994], Loss: 0.2053\n",
      "Epoch [1/5], Step [460/9994], Loss: 0.1874\n",
      "Epoch [1/5], Step [470/9994], Loss: 0.3179\n",
      "Epoch [1/5], Step [480/9994], Loss: 0.1554\n",
      "Epoch [1/5], Step [490/9994], Loss: 0.4044\n",
      "Epoch [1/5], Step [500/9994], Loss: 0.2302\n",
      "Epoch [1/5], Step [510/9994], Loss: 0.1369\n",
      "Epoch [1/5], Step [520/9994], Loss: 0.0876\n",
      "Epoch [1/5], Step [530/9994], Loss: 0.1459\n",
      "Epoch [1/5], Step [540/9994], Loss: 0.3598\n",
      "Epoch [1/5], Step [550/9994], Loss: 0.1836\n",
      "Epoch [1/5], Step [560/9994], Loss: 0.1530\n",
      "Epoch [1/5], Step [570/9994], Loss: 0.2355\n",
      "Epoch [1/5], Step [580/9994], Loss: 0.1442\n",
      "Epoch [1/5], Step [590/9994], Loss: 0.2317\n",
      "Epoch [1/5], Step [600/9994], Loss: 0.0625\n",
      "Epoch [1/5], Step [610/9994], Loss: 0.0920\n",
      "Epoch [1/5], Step [620/9994], Loss: 0.1442\n",
      "Epoch [1/5], Step [630/9994], Loss: 0.1855\n",
      "Epoch [1/5], Step [640/9994], Loss: 0.2064\n",
      "Epoch [1/5], Step [650/9994], Loss: 0.0414\n",
      "Epoch [1/5], Step [660/9994], Loss: 0.1136\n",
      "Epoch [1/5], Step [670/9994], Loss: 0.0331\n",
      "Epoch [1/5], Step [680/9994], Loss: 0.1374\n",
      "Epoch [1/5], Step [690/9994], Loss: 0.1033\n",
      "Epoch [1/5], Step [700/9994], Loss: 0.0898\n",
      "Epoch [1/5], Step [710/9994], Loss: 0.2376\n",
      "Epoch [1/5], Step [720/9994], Loss: 0.0763\n",
      "Epoch [1/5], Step [730/9994], Loss: 0.1737\n",
      "Epoch [1/5], Step [740/9994], Loss: 0.1794\n",
      "Epoch [1/5], Step [750/9994], Loss: 0.0850\n",
      "Epoch [1/5], Step [760/9994], Loss: 0.1297\n",
      "Epoch [1/5], Step [770/9994], Loss: 0.1889\n",
      "Epoch [1/5], Step [780/9994], Loss: 0.0628\n",
      "Epoch [1/5], Step [790/9994], Loss: 0.1921\n",
      "Epoch [1/5], Step [800/9994], Loss: 0.1180\n",
      "Epoch [1/5], Step [810/9994], Loss: 0.1084\n",
      "Epoch [1/5], Step [820/9994], Loss: 0.1066\n",
      "Epoch [1/5], Step [830/9994], Loss: 0.1412\n",
      "Epoch [1/5], Step [840/9994], Loss: 0.1188\n",
      "Epoch [1/5], Step [850/9994], Loss: 0.0759\n",
      "Epoch [1/5], Step [860/9994], Loss: 0.1625\n",
      "Epoch [1/5], Step [870/9994], Loss: 0.0751\n",
      "Epoch [1/5], Step [880/9994], Loss: 0.0818\n",
      "Epoch [1/5], Step [890/9994], Loss: 0.1480\n",
      "Epoch [1/5], Step [900/9994], Loss: 0.0999\n",
      "Epoch [1/5], Step [910/9994], Loss: 0.1465\n",
      "Epoch [1/5], Step [920/9994], Loss: 0.0904\n",
      "Epoch [1/5], Step [930/9994], Loss: 0.0918\n",
      "Epoch [1/5], Step [940/9994], Loss: 0.1423\n",
      "Epoch [1/5], Step [950/9994], Loss: 0.1356\n",
      "Epoch [1/5], Step [960/9994], Loss: 0.1181\n",
      "Epoch [1/5], Step [970/9994], Loss: 0.1365\n",
      "Epoch [1/5], Step [980/9994], Loss: 0.1752\n",
      "Epoch [1/5], Step [990/9994], Loss: 0.1743\n",
      "Epoch [1/5], Step [1000/9994], Loss: 0.0400\n",
      "Epoch [1/5], Step [1010/9994], Loss: 0.2076\n",
      "Epoch [1/5], Step [1020/9994], Loss: 0.1450\n",
      "Epoch [1/5], Step [1030/9994], Loss: 0.0750\n",
      "Epoch [1/5], Step [1040/9994], Loss: 0.0311\n",
      "Epoch [1/5], Step [1050/9994], Loss: 0.2269\n",
      "Epoch [1/5], Step [1060/9994], Loss: 0.0896\n",
      "Epoch [1/5], Step [1070/9994], Loss: 0.0890\n",
      "Epoch [1/5], Step [1080/9994], Loss: 0.0144\n",
      "Epoch [1/5], Step [1090/9994], Loss: 0.1437\n",
      "Epoch [1/5], Step [1100/9994], Loss: 0.0637\n",
      "Epoch [1/5], Step [1110/9994], Loss: 0.0289\n",
      "Epoch [1/5], Step [1120/9994], Loss: 0.1227\n",
      "Epoch [1/5], Step [1130/9994], Loss: 0.0262\n",
      "Epoch [1/5], Step [1140/9994], Loss: 0.1232\n",
      "Epoch [1/5], Step [1150/9994], Loss: 0.2469\n",
      "Epoch [1/5], Step [1160/9994], Loss: 0.0371\n",
      "Epoch [1/5], Step [1170/9994], Loss: 0.0494\n",
      "Epoch [1/5], Step [1180/9994], Loss: 0.0308\n",
      "Epoch [1/5], Step [1190/9994], Loss: 0.0418\n",
      "Epoch [1/5], Step [1200/9994], Loss: 0.2182\n",
      "Epoch [1/5], Step [1210/9994], Loss: 0.1432\n",
      "Epoch [1/5], Step [1220/9994], Loss: 0.1897\n",
      "Epoch [1/5], Step [1230/9994], Loss: 0.0727\n",
      "Epoch [1/5], Step [1240/9994], Loss: 0.0631\n",
      "Epoch [1/5], Step [1250/9994], Loss: 0.0521\n",
      "Epoch [1/5], Step [1260/9994], Loss: 0.0555\n",
      "Epoch [1/5], Step [1270/9994], Loss: 0.2815\n",
      "Epoch [1/5], Step [1280/9994], Loss: 0.0258\n",
      "Epoch [1/5], Step [1290/9994], Loss: 0.0333\n",
      "Epoch [1/5], Step [1300/9994], Loss: 0.0114\n",
      "Epoch [1/5], Step [1310/9994], Loss: 0.0387\n",
      "Epoch [1/5], Step [1320/9994], Loss: 0.0556\n",
      "Epoch [1/5], Step [1330/9994], Loss: 0.1036\n",
      "Epoch [1/5], Step [1340/9994], Loss: 0.0225\n",
      "Epoch [1/5], Step [1350/9994], Loss: 0.0467\n",
      "Epoch [1/5], Step [1360/9994], Loss: 0.0478\n",
      "Epoch [1/5], Step [1370/9994], Loss: 0.0344\n",
      "Epoch [1/5], Step [1380/9994], Loss: 0.0495\n",
      "Epoch [1/5], Step [1390/9994], Loss: 0.0919\n",
      "Epoch [1/5], Step [1400/9994], Loss: 0.1261\n",
      "Epoch [1/5], Step [1410/9994], Loss: 0.0306\n",
      "Epoch [1/5], Step [1420/9994], Loss: 0.1264\n",
      "Epoch [1/5], Step [1430/9994], Loss: 0.0395\n",
      "Epoch [1/5], Step [1440/9994], Loss: 0.1985\n",
      "Epoch [1/5], Step [1450/9994], Loss: 0.0167\n",
      "Epoch [1/5], Step [1460/9994], Loss: 0.1001\n",
      "Epoch [1/5], Step [1470/9994], Loss: 0.1088\n",
      "Epoch [1/5], Step [1480/9994], Loss: 0.0308\n",
      "Epoch [1/5], Step [1490/9994], Loss: 0.1281\n",
      "Epoch [1/5], Step [1500/9994], Loss: 0.0259\n",
      "Epoch [1/5], Step [1510/9994], Loss: 0.1581\n",
      "Epoch [1/5], Step [1520/9994], Loss: 0.0215\n",
      "Epoch [1/5], Step [1530/9994], Loss: 0.1190\n",
      "Epoch [1/5], Step [1540/9994], Loss: 0.0370\n",
      "Epoch [1/5], Step [1550/9994], Loss: 0.0314\n",
      "Epoch [1/5], Step [1560/9994], Loss: 0.0804\n",
      "Epoch [1/5], Step [1570/9994], Loss: 0.0230\n",
      "Epoch [1/5], Step [1580/9994], Loss: 0.0503\n",
      "Epoch [1/5], Step [1590/9994], Loss: 0.0566\n",
      "Epoch [1/5], Step [1600/9994], Loss: 0.0120\n",
      "Epoch [1/5], Step [1610/9994], Loss: 0.0242\n",
      "Epoch [1/5], Step [1620/9994], Loss: 0.0155\n",
      "Epoch [1/5], Step [1630/9994], Loss: 0.0355\n",
      "Epoch [1/5], Step [1640/9994], Loss: 0.0272\n",
      "Epoch [1/5], Step [1650/9994], Loss: 0.0100\n",
      "Epoch [1/5], Step [1660/9994], Loss: 0.0076\n",
      "Epoch [1/5], Step [1670/9994], Loss: 0.1901\n",
      "Epoch [1/5], Step [1680/9994], Loss: 0.1850\n",
      "Epoch [1/5], Step [1690/9994], Loss: 0.0456\n",
      "Epoch [1/5], Step [1700/9994], Loss: 0.0328\n",
      "Epoch [1/5], Step [1710/9994], Loss: 0.0215\n",
      "Epoch [1/5], Step [1720/9994], Loss: 0.0482\n",
      "Epoch [1/5], Step [1730/9994], Loss: 0.0150\n",
      "Epoch [1/5], Step [1740/9994], Loss: 0.0430\n",
      "Epoch [1/5], Step [1750/9994], Loss: 0.0270\n",
      "Epoch [1/5], Step [1760/9994], Loss: 0.0148\n",
      "Epoch [1/5], Step [1770/9994], Loss: 0.0475\n",
      "Epoch [1/5], Step [1780/9994], Loss: 0.0181\n",
      "Epoch [1/5], Step [1790/9994], Loss: 0.0332\n",
      "Epoch [1/5], Step [1800/9994], Loss: 0.0781\n",
      "Epoch [1/5], Step [1810/9994], Loss: 0.0684\n",
      "Epoch [1/5], Step [1820/9994], Loss: 0.0126\n",
      "Epoch [1/5], Step [1830/9994], Loss: 0.0690\n",
      "Epoch [1/5], Step [1840/9994], Loss: 0.0204\n",
      "Epoch [1/5], Step [1850/9994], Loss: 0.0641\n",
      "Epoch [1/5], Step [1860/9994], Loss: 0.0683\n",
      "Epoch [1/5], Step [1870/9994], Loss: 0.0587\n",
      "Epoch [1/5], Step [1880/9994], Loss: 0.0878\n",
      "Epoch [1/5], Step [1890/9994], Loss: 0.0463\n",
      "Epoch [1/5], Step [1900/9994], Loss: 0.0516\n",
      "Epoch [1/5], Step [1910/9994], Loss: 0.1623\n",
      "Epoch [1/5], Step [1920/9994], Loss: 0.0602\n",
      "Epoch [1/5], Step [1930/9994], Loss: 0.1958\n",
      "Epoch [1/5], Step [1940/9994], Loss: 0.0448\n",
      "Epoch [1/5], Step [1950/9994], Loss: 0.0213\n",
      "Epoch [1/5], Step [1960/9994], Loss: 0.0044\n",
      "Epoch [1/5], Step [1970/9994], Loss: 0.0880\n",
      "Epoch [1/5], Step [1980/9994], Loss: 0.0408\n",
      "Epoch [1/5], Step [1990/9994], Loss: 0.0505\n",
      "Epoch [1/5], Step [2000/9994], Loss: 0.1294\n",
      "Epoch [1/5], Step [2010/9994], Loss: 0.0354\n",
      "Epoch [1/5], Step [2020/9994], Loss: 0.0501\n",
      "Epoch [1/5], Step [2030/9994], Loss: 0.0505\n",
      "Epoch [1/5], Step [2040/9994], Loss: 0.0934\n",
      "Epoch [1/5], Step [2050/9994], Loss: 0.0621\n",
      "Epoch [1/5], Step [2060/9994], Loss: 0.0560\n",
      "Epoch [1/5], Step [2070/9994], Loss: 0.0245\n",
      "Epoch [1/5], Step [2080/9994], Loss: 0.0417\n",
      "Epoch [1/5], Step [2090/9994], Loss: 0.0477\n",
      "Epoch [1/5], Step [2100/9994], Loss: 0.0108\n",
      "Epoch [1/5], Step [2110/9994], Loss: 0.0385\n",
      "Epoch [1/5], Step [2120/9994], Loss: 0.0843\n",
      "Epoch [1/5], Step [2130/9994], Loss: 0.0692\n",
      "Epoch [1/5], Step [2140/9994], Loss: 0.0275\n",
      "Epoch [1/5], Step [2150/9994], Loss: 0.0063\n",
      "Epoch [1/5], Step [2160/9994], Loss: 0.0241\n",
      "Epoch [1/5], Step [2170/9994], Loss: 0.1606\n",
      "Epoch [1/5], Step [2180/9994], Loss: 0.0201\n",
      "Epoch [1/5], Step [2190/9994], Loss: 0.0238\n",
      "Epoch [1/5], Step [2200/9994], Loss: 0.1140\n",
      "Epoch [1/5], Step [2210/9994], Loss: 0.0459\n",
      "Epoch [1/5], Step [2220/9994], Loss: 0.0169\n",
      "Epoch [1/5], Step [2230/9994], Loss: 0.1006\n",
      "Epoch [1/5], Step [2240/9994], Loss: 0.0247\n",
      "Epoch [1/5], Step [2250/9994], Loss: 0.0112\n",
      "Epoch [1/5], Step [2260/9994], Loss: 0.0943\n",
      "Epoch [1/5], Step [2270/9994], Loss: 0.0214\n",
      "Epoch [1/5], Step [2280/9994], Loss: 0.0962\n",
      "Epoch [1/5], Step [2290/9994], Loss: 0.0332\n",
      "Epoch [1/5], Step [2300/9994], Loss: 0.0480\n",
      "Epoch [1/5], Step [2310/9994], Loss: 0.0241\n",
      "Epoch [1/5], Step [2320/9994], Loss: 0.1080\n",
      "Epoch [1/5], Step [2330/9994], Loss: 0.0240\n",
      "Epoch [1/5], Step [2340/9994], Loss: 0.0207\n",
      "Epoch [1/5], Step [2350/9994], Loss: 0.1979\n",
      "Epoch [1/5], Step [2360/9994], Loss: 0.0601\n",
      "Epoch [1/5], Step [2370/9994], Loss: 0.0232\n",
      "Epoch [1/5], Step [2380/9994], Loss: 0.0614\n",
      "Epoch [1/5], Step [2390/9994], Loss: 0.0061\n",
      "Epoch [1/5], Step [2400/9994], Loss: 0.0257\n",
      "Epoch [1/5], Step [2410/9994], Loss: 0.0224\n",
      "Epoch [1/5], Step [2420/9994], Loss: 0.0321\n",
      "Epoch [1/5], Step [2430/9994], Loss: 0.1100\n",
      "Epoch [1/5], Step [2440/9994], Loss: 0.0321\n",
      "Epoch [1/5], Step [2450/9994], Loss: 0.0112\n",
      "Epoch [1/5], Step [2460/9994], Loss: 0.0124\n",
      "Epoch [1/5], Step [2470/9994], Loss: 0.0562\n",
      "Epoch [1/5], Step [2480/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [2490/9994], Loss: 0.0709\n",
      "Epoch [1/5], Step [2500/9994], Loss: 0.0442\n",
      "Epoch [1/5], Step [2510/9994], Loss: 0.0633\n",
      "Epoch [1/5], Step [2520/9994], Loss: 0.0469\n",
      "Epoch [1/5], Step [2530/9994], Loss: 0.0188\n",
      "Epoch [1/5], Step [2540/9994], Loss: 0.0568\n",
      "Epoch [1/5], Step [2550/9994], Loss: 0.0783\n",
      "Epoch [1/5], Step [2560/9994], Loss: 0.0348\n",
      "Epoch [1/5], Step [2570/9994], Loss: 0.0243\n",
      "Epoch [1/5], Step [2580/9994], Loss: 0.0084\n",
      "Epoch [1/5], Step [2590/9994], Loss: 0.0033\n",
      "Epoch [1/5], Step [2600/9994], Loss: 0.0060\n",
      "Epoch [1/5], Step [2610/9994], Loss: 0.0366\n",
      "Epoch [1/5], Step [2620/9994], Loss: 0.0158\n",
      "Epoch [1/5], Step [2630/9994], Loss: 0.0585\n",
      "Epoch [1/5], Step [2640/9994], Loss: 0.0105\n",
      "Epoch [1/5], Step [2650/9994], Loss: 0.0150\n",
      "Epoch [1/5], Step [2660/9994], Loss: 0.0095\n",
      "Epoch [1/5], Step [2670/9994], Loss: 0.0872\n",
      "Epoch [1/5], Step [2680/9994], Loss: 0.1240\n",
      "Epoch [1/5], Step [2690/9994], Loss: 0.0343\n",
      "Epoch [1/5], Step [2700/9994], Loss: 0.0160\n",
      "Epoch [1/5], Step [2710/9994], Loss: 0.0077\n",
      "Epoch [1/5], Step [2720/9994], Loss: 0.0259\n",
      "Epoch [1/5], Step [2730/9994], Loss: 0.0106\n",
      "Epoch [1/5], Step [2740/9994], Loss: 0.0130\n",
      "Epoch [1/5], Step [2750/9994], Loss: 0.0224\n",
      "Epoch [1/5], Step [2760/9994], Loss: 0.0911\n",
      "Epoch [1/5], Step [2770/9994], Loss: 0.0726\n",
      "Epoch [1/5], Step [2780/9994], Loss: 0.1268\n",
      "Epoch [1/5], Step [2790/9994], Loss: 0.0094\n",
      "Epoch [1/5], Step [2800/9994], Loss: 0.0123\n",
      "Epoch [1/5], Step [2810/9994], Loss: 0.0859\n",
      "Epoch [1/5], Step [2820/9994], Loss: 0.0076\n",
      "Epoch [1/5], Step [2830/9994], Loss: 0.0106\n",
      "Epoch [1/5], Step [2840/9994], Loss: 0.0562\n",
      "Epoch [1/5], Step [2850/9994], Loss: 0.0984\n",
      "Epoch [1/5], Step [2860/9994], Loss: 0.2035\n",
      "Epoch [1/5], Step [2870/9994], Loss: 0.0070\n",
      "Epoch [1/5], Step [2880/9994], Loss: 0.0113\n",
      "Epoch [1/5], Step [2890/9994], Loss: 0.0165\n",
      "Epoch [1/5], Step [2900/9994], Loss: 0.0901\n",
      "Epoch [1/5], Step [2910/9994], Loss: 0.2105\n",
      "Epoch [1/5], Step [2920/9994], Loss: 0.0183\n",
      "Epoch [1/5], Step [2930/9994], Loss: 0.0165\n",
      "Epoch [1/5], Step [2940/9994], Loss: 0.0535\n",
      "Epoch [1/5], Step [2950/9994], Loss: 0.0190\n",
      "Epoch [1/5], Step [2960/9994], Loss: 0.0185\n",
      "Epoch [1/5], Step [2970/9994], Loss: 0.1992\n",
      "Epoch [1/5], Step [2980/9994], Loss: 0.0239\n",
      "Epoch [1/5], Step [2990/9994], Loss: 0.0237\n",
      "Epoch [1/5], Step [3000/9994], Loss: 0.0078\n",
      "Epoch [1/5], Step [3010/9994], Loss: 0.0228\n",
      "Epoch [1/5], Step [3020/9994], Loss: 0.0706\n",
      "Epoch [1/5], Step [3030/9994], Loss: 0.0332\n",
      "Epoch [1/5], Step [3040/9994], Loss: 0.0471\n",
      "Epoch [1/5], Step [3050/9994], Loss: 0.0792\n",
      "Epoch [1/5], Step [3060/9994], Loss: 0.0131\n",
      "Epoch [1/5], Step [3070/9994], Loss: 0.0128\n",
      "Epoch [1/5], Step [3080/9994], Loss: 0.0491\n",
      "Epoch [1/5], Step [3090/9994], Loss: 0.1903\n",
      "Epoch [1/5], Step [3100/9994], Loss: 0.0452\n",
      "Epoch [1/5], Step [3110/9994], Loss: 0.1589\n",
      "Epoch [1/5], Step [3120/9994], Loss: 0.0556\n",
      "Epoch [1/5], Step [3130/9994], Loss: 0.0123\n",
      "Epoch [1/5], Step [3140/9994], Loss: 0.0125\n",
      "Epoch [1/5], Step [3150/9994], Loss: 0.0245\n",
      "Epoch [1/5], Step [3160/9994], Loss: 0.0403\n",
      "Epoch [1/5], Step [3170/9994], Loss: 0.0149\n",
      "Epoch [1/5], Step [3180/9994], Loss: 0.0146\n",
      "Epoch [1/5], Step [3190/9994], Loss: 0.1277\n",
      "Epoch [1/5], Step [3200/9994], Loss: 0.0159\n",
      "Epoch [1/5], Step [3210/9994], Loss: 0.0051\n",
      "Epoch [1/5], Step [3220/9994], Loss: 0.0162\n",
      "Epoch [1/5], Step [3230/9994], Loss: 0.2317\n",
      "Epoch [1/5], Step [3240/9994], Loss: 0.0224\n",
      "Epoch [1/5], Step [3250/9994], Loss: 0.0310\n",
      "Epoch [1/5], Step [3260/9994], Loss: 0.0574\n",
      "Epoch [1/5], Step [3270/9994], Loss: 0.0188\n",
      "Epoch [1/5], Step [3280/9994], Loss: 0.0227\n",
      "Epoch [1/5], Step [3290/9994], Loss: 0.1124\n",
      "Epoch [1/5], Step [3300/9994], Loss: 0.0351\n",
      "Epoch [1/5], Step [3310/9994], Loss: 0.0078\n",
      "Epoch [1/5], Step [3320/9994], Loss: 0.0244\n",
      "Epoch [1/5], Step [3330/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [3340/9994], Loss: 0.0218\n",
      "Epoch [1/5], Step [3350/9994], Loss: 0.0320\n",
      "Epoch [1/5], Step [3360/9994], Loss: 0.0313\n",
      "Epoch [1/5], Step [3370/9994], Loss: 0.0260\n",
      "Epoch [1/5], Step [3380/9994], Loss: 0.0131\n",
      "Epoch [1/5], Step [3390/9994], Loss: 0.0654\n",
      "Epoch [1/5], Step [3400/9994], Loss: 0.0267\n",
      "Epoch [1/5], Step [3410/9994], Loss: 0.0142\n",
      "Epoch [1/5], Step [3420/9994], Loss: 0.0024\n",
      "Epoch [1/5], Step [3430/9994], Loss: 0.0170\n",
      "Epoch [1/5], Step [3440/9994], Loss: 0.0635\n",
      "Epoch [1/5], Step [3450/9994], Loss: 0.0189\n",
      "Epoch [1/5], Step [3460/9994], Loss: 0.0288\n",
      "Epoch [1/5], Step [3470/9994], Loss: 0.0482\n",
      "Epoch [1/5], Step [3480/9994], Loss: 0.0357\n",
      "Epoch [1/5], Step [3490/9994], Loss: 0.0234\n",
      "Epoch [1/5], Step [3500/9994], Loss: 0.0128\n",
      "Epoch [1/5], Step [3510/9994], Loss: 0.0234\n",
      "Epoch [1/5], Step [3520/9994], Loss: 0.0167\n",
      "Epoch [1/5], Step [3530/9994], Loss: 0.0105\n",
      "Epoch [1/5], Step [3540/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [3550/9994], Loss: 0.0178\n",
      "Epoch [1/5], Step [3560/9994], Loss: 0.0136\n",
      "Epoch [1/5], Step [3570/9994], Loss: 0.0047\n",
      "Epoch [1/5], Step [3580/9994], Loss: 0.1489\n",
      "Epoch [1/5], Step [3590/9994], Loss: 0.0087\n",
      "Epoch [1/5], Step [3600/9994], Loss: 0.0027\n",
      "Epoch [1/5], Step [3610/9994], Loss: 0.0102\n",
      "Epoch [1/5], Step [3620/9994], Loss: 0.0403\n",
      "Epoch [1/5], Step [3630/9994], Loss: 0.0189\n",
      "Epoch [1/5], Step [3640/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [3650/9994], Loss: 0.0035\n",
      "Epoch [1/5], Step [3660/9994], Loss: 0.0144\n",
      "Epoch [1/5], Step [3670/9994], Loss: 0.0197\n",
      "Epoch [1/5], Step [3680/9994], Loss: 0.0107\n",
      "Epoch [1/5], Step [3690/9994], Loss: 0.0390\n",
      "Epoch [1/5], Step [3700/9994], Loss: 0.0079\n",
      "Epoch [1/5], Step [3710/9994], Loss: 0.0354\n",
      "Epoch [1/5], Step [3720/9994], Loss: 0.2248\n",
      "Epoch [1/5], Step [3730/9994], Loss: 0.0272\n",
      "Epoch [1/5], Step [3740/9994], Loss: 0.0139\n",
      "Epoch [1/5], Step [3750/9994], Loss: 0.0129\n",
      "Epoch [1/5], Step [3760/9994], Loss: 0.0203\n",
      "Epoch [1/5], Step [3770/9994], Loss: 0.0344\n",
      "Epoch [1/5], Step [3780/9994], Loss: 0.0093\n",
      "Epoch [1/5], Step [3790/9994], Loss: 0.0166\n",
      "Epoch [1/5], Step [3800/9994], Loss: 0.0476\n",
      "Epoch [1/5], Step [3810/9994], Loss: 0.0549\n",
      "Epoch [1/5], Step [3820/9994], Loss: 0.0551\n",
      "Epoch [1/5], Step [3830/9994], Loss: 0.0622\n",
      "Epoch [1/5], Step [3840/9994], Loss: 0.0132\n",
      "Epoch [1/5], Step [3850/9994], Loss: 0.0359\n",
      "Epoch [1/5], Step [3860/9994], Loss: 0.0153\n",
      "Epoch [1/5], Step [3870/9994], Loss: 0.0119\n",
      "Epoch [1/5], Step [3880/9994], Loss: 0.0180\n",
      "Epoch [1/5], Step [3890/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [3900/9994], Loss: 0.0102\n",
      "Epoch [1/5], Step [3910/9994], Loss: 0.0484\n",
      "Epoch [1/5], Step [3920/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [3930/9994], Loss: 0.0181\n",
      "Epoch [1/5], Step [3940/9994], Loss: 0.0200\n",
      "Epoch [1/5], Step [3950/9994], Loss: 0.0165\n",
      "Epoch [1/5], Step [3960/9994], Loss: 0.1769\n",
      "Epoch [1/5], Step [3970/9994], Loss: 0.0230\n",
      "Epoch [1/5], Step [3980/9994], Loss: 0.0060\n",
      "Epoch [1/5], Step [3990/9994], Loss: 0.0019\n",
      "Epoch [1/5], Step [4000/9994], Loss: 0.0407\n",
      "Epoch [1/5], Step [4010/9994], Loss: 0.0060\n",
      "Epoch [1/5], Step [4020/9994], Loss: 0.0282\n",
      "Epoch [1/5], Step [4030/9994], Loss: 0.1605\n",
      "Epoch [1/5], Step [4040/9994], Loss: 0.1177\n",
      "Epoch [1/5], Step [4050/9994], Loss: 0.0376\n",
      "Epoch [1/5], Step [4060/9994], Loss: 0.0509\n",
      "Epoch [1/5], Step [4070/9994], Loss: 0.0126\n",
      "Epoch [1/5], Step [4080/9994], Loss: 0.0208\n",
      "Epoch [1/5], Step [4090/9994], Loss: 0.0102\n",
      "Epoch [1/5], Step [4100/9994], Loss: 0.0219\n",
      "Epoch [1/5], Step [4110/9994], Loss: 0.0035\n",
      "Epoch [1/5], Step [4120/9994], Loss: 0.0201\n",
      "Epoch [1/5], Step [4130/9994], Loss: 0.0047\n",
      "Epoch [1/5], Step [4140/9994], Loss: 0.0333\n",
      "Epoch [1/5], Step [4150/9994], Loss: 0.0543\n",
      "Epoch [1/5], Step [4160/9994], Loss: 0.0140\n",
      "Epoch [1/5], Step [4170/9994], Loss: 0.0718\n",
      "Epoch [1/5], Step [4180/9994], Loss: 0.0087\n",
      "Epoch [1/5], Step [4190/9994], Loss: 0.0131\n",
      "Epoch [1/5], Step [4200/9994], Loss: 0.0127\n",
      "Epoch [1/5], Step [4210/9994], Loss: 0.0266\n",
      "Epoch [1/5], Step [4220/9994], Loss: 0.0220\n",
      "Epoch [1/5], Step [4230/9994], Loss: 0.0485\n",
      "Epoch [1/5], Step [4240/9994], Loss: 0.0162\n",
      "Epoch [1/5], Step [4250/9994], Loss: 0.3244\n",
      "Epoch [1/5], Step [4260/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [4270/9994], Loss: 0.0150\n",
      "Epoch [1/5], Step [4280/9994], Loss: 0.0237\n",
      "Epoch [1/5], Step [4290/9994], Loss: 0.0042\n",
      "Epoch [1/5], Step [4300/9994], Loss: 0.0091\n",
      "Epoch [1/5], Step [4310/9994], Loss: 0.0330\n",
      "Epoch [1/5], Step [4320/9994], Loss: 0.0048\n",
      "Epoch [1/5], Step [4330/9994], Loss: 0.0268\n",
      "Epoch [1/5], Step [4340/9994], Loss: 0.0113\n",
      "Epoch [1/5], Step [4350/9994], Loss: 0.0790\n",
      "Epoch [1/5], Step [4360/9994], Loss: 0.0041\n",
      "Epoch [1/5], Step [4370/9994], Loss: 0.0433\n",
      "Epoch [1/5], Step [4380/9994], Loss: 0.0193\n",
      "Epoch [1/5], Step [4390/9994], Loss: 0.0082\n",
      "Epoch [1/5], Step [4400/9994], Loss: 0.0269\n",
      "Epoch [1/5], Step [4410/9994], Loss: 0.0228\n",
      "Epoch [1/5], Step [4420/9994], Loss: 0.0348\n",
      "Epoch [1/5], Step [4430/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [4440/9994], Loss: 0.0073\n",
      "Epoch [1/5], Step [4450/9994], Loss: 0.0406\n",
      "Epoch [1/5], Step [4460/9994], Loss: 0.0926\n",
      "Epoch [1/5], Step [4470/9994], Loss: 0.0126\n",
      "Epoch [1/5], Step [4480/9994], Loss: 0.0387\n",
      "Epoch [1/5], Step [4490/9994], Loss: 0.1854\n",
      "Epoch [1/5], Step [4500/9994], Loss: 0.0632\n",
      "Epoch [1/5], Step [4510/9994], Loss: 0.0113\n",
      "Epoch [1/5], Step [4520/9994], Loss: 0.0343\n",
      "Epoch [1/5], Step [4530/9994], Loss: 0.0409\n",
      "Epoch [1/5], Step [4540/9994], Loss: 0.0626\n",
      "Epoch [1/5], Step [4550/9994], Loss: 0.0276\n",
      "Epoch [1/5], Step [4560/9994], Loss: 0.0317\n",
      "Epoch [1/5], Step [4570/9994], Loss: 0.0874\n",
      "Epoch [1/5], Step [4580/9994], Loss: 0.0129\n",
      "Epoch [1/5], Step [4590/9994], Loss: 0.0148\n",
      "Epoch [1/5], Step [4600/9994], Loss: 0.0237\n",
      "Epoch [1/5], Step [4610/9994], Loss: 0.0384\n",
      "Epoch [1/5], Step [4620/9994], Loss: 0.0523\n",
      "Epoch [1/5], Step [4630/9994], Loss: 0.0578\n",
      "Epoch [1/5], Step [4640/9994], Loss: 0.0129\n",
      "Epoch [1/5], Step [4650/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [4660/9994], Loss: 0.0646\n",
      "Epoch [1/5], Step [4670/9994], Loss: 0.0384\n",
      "Epoch [1/5], Step [4680/9994], Loss: 0.0247\n",
      "Epoch [1/5], Step [4690/9994], Loss: 0.0966\n",
      "Epoch [1/5], Step [4700/9994], Loss: 0.0473\n",
      "Epoch [1/5], Step [4710/9994], Loss: 0.0969\n",
      "Epoch [1/5], Step [4720/9994], Loss: 0.0224\n",
      "Epoch [1/5], Step [4730/9994], Loss: 0.0144\n",
      "Epoch [1/5], Step [4740/9994], Loss: 0.0011\n",
      "Epoch [1/5], Step [4750/9994], Loss: 0.2500\n",
      "Epoch [1/5], Step [4760/9994], Loss: 0.1091\n",
      "Epoch [1/5], Step [4770/9994], Loss: 0.0544\n",
      "Epoch [1/5], Step [4780/9994], Loss: 0.0388\n",
      "Epoch [1/5], Step [4790/9994], Loss: 0.0044\n",
      "Epoch [1/5], Step [4800/9994], Loss: 0.1084\n",
      "Epoch [1/5], Step [4810/9994], Loss: 0.0093\n",
      "Epoch [1/5], Step [4820/9994], Loss: 0.0463\n",
      "Epoch [1/5], Step [4830/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [4840/9994], Loss: 0.0112\n",
      "Epoch [1/5], Step [4850/9994], Loss: 0.0341\n",
      "Epoch [1/5], Step [4860/9994], Loss: 0.0544\n",
      "Epoch [1/5], Step [4870/9994], Loss: 0.0053\n",
      "Epoch [1/5], Step [4880/9994], Loss: 0.0073\n",
      "Epoch [1/5], Step [4890/9994], Loss: 0.0072\n",
      "Epoch [1/5], Step [4900/9994], Loss: 0.0389\n",
      "Epoch [1/5], Step [4910/9994], Loss: 0.0008\n",
      "Epoch [1/5], Step [4920/9994], Loss: 0.0011\n",
      "Epoch [1/5], Step [4930/9994], Loss: 0.0387\n",
      "Epoch [1/5], Step [4940/9994], Loss: 0.1614\n",
      "Epoch [1/5], Step [4950/9994], Loss: 0.0154\n",
      "Epoch [1/5], Step [4960/9994], Loss: 0.0313\n",
      "Epoch [1/5], Step [4970/9994], Loss: 0.0571\n",
      "Epoch [1/5], Step [4980/9994], Loss: 0.0056\n",
      "Epoch [1/5], Step [4990/9994], Loss: 0.1007\n",
      "Epoch [1/5], Step [5000/9994], Loss: 0.2007\n",
      "Epoch [1/5], Step [5010/9994], Loss: 0.0206\n",
      "Epoch [1/5], Step [5020/9994], Loss: 0.0279\n",
      "Epoch [1/5], Step [5030/9994], Loss: 0.0566\n",
      "Epoch [1/5], Step [5040/9994], Loss: 0.0073\n",
      "Epoch [1/5], Step [5050/9994], Loss: 0.0435\n",
      "Epoch [1/5], Step [5060/9994], Loss: 0.0103\n",
      "Epoch [1/5], Step [5070/9994], Loss: 0.0229\n",
      "Epoch [1/5], Step [5080/9994], Loss: 0.0070\n",
      "Epoch [1/5], Step [5090/9994], Loss: 0.0232\n",
      "Epoch [1/5], Step [5100/9994], Loss: 0.1038\n",
      "Epoch [1/5], Step [5110/9994], Loss: 0.0157\n",
      "Epoch [1/5], Step [5120/9994], Loss: 0.0226\n",
      "Epoch [1/5], Step [5130/9994], Loss: 0.0126\n",
      "Epoch [1/5], Step [5140/9994], Loss: 0.0047\n",
      "Epoch [1/5], Step [5150/9994], Loss: 0.0245\n",
      "Epoch [1/5], Step [5160/9994], Loss: 0.0156\n",
      "Epoch [1/5], Step [5170/9994], Loss: 0.0383\n",
      "Epoch [1/5], Step [5180/9994], Loss: 0.0549\n",
      "Epoch [1/5], Step [5190/9994], Loss: 0.0083\n",
      "Epoch [1/5], Step [5200/9994], Loss: 0.0296\n",
      "Epoch [1/5], Step [5210/9994], Loss: 0.0123\n",
      "Epoch [1/5], Step [5220/9994], Loss: 0.0681\n",
      "Epoch [1/5], Step [5230/9994], Loss: 0.0201\n",
      "Epoch [1/5], Step [5240/9994], Loss: 0.0054\n",
      "Epoch [1/5], Step [5250/9994], Loss: 0.0081\n",
      "Epoch [1/5], Step [5260/9994], Loss: 0.0116\n",
      "Epoch [1/5], Step [5270/9994], Loss: 0.0031\n",
      "Epoch [1/5], Step [5280/9994], Loss: 0.0596\n",
      "Epoch [1/5], Step [5290/9994], Loss: 0.0327\n",
      "Epoch [1/5], Step [5300/9994], Loss: 0.0066\n",
      "Epoch [1/5], Step [5310/9994], Loss: 0.0042\n",
      "Epoch [1/5], Step [5320/9994], Loss: 0.0060\n",
      "Epoch [1/5], Step [5330/9994], Loss: 0.0028\n",
      "Epoch [1/5], Step [5340/9994], Loss: 0.0184\n",
      "Epoch [1/5], Step [5350/9994], Loss: 0.0156\n",
      "Epoch [1/5], Step [5360/9994], Loss: 0.0058\n",
      "Epoch [1/5], Step [5370/9994], Loss: 0.0139\n",
      "Epoch [1/5], Step [5380/9994], Loss: 0.0114\n",
      "Epoch [1/5], Step [5390/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [5400/9994], Loss: 0.0580\n",
      "Epoch [1/5], Step [5410/9994], Loss: 0.0133\n",
      "Epoch [1/5], Step [5420/9994], Loss: 0.0418\n",
      "Epoch [1/5], Step [5430/9994], Loss: 0.0006\n",
      "Epoch [1/5], Step [5440/9994], Loss: 0.0185\n",
      "Epoch [1/5], Step [5450/9994], Loss: 0.0858\n",
      "Epoch [1/5], Step [5460/9994], Loss: 0.0096\n",
      "Epoch [1/5], Step [5470/9994], Loss: 0.0303\n",
      "Epoch [1/5], Step [5480/9994], Loss: 0.0208\n",
      "Epoch [1/5], Step [5490/9994], Loss: 0.0815\n",
      "Epoch [1/5], Step [5500/9994], Loss: 0.0052\n",
      "Epoch [1/5], Step [5510/9994], Loss: 0.0121\n",
      "Epoch [1/5], Step [5520/9994], Loss: 0.0044\n",
      "Epoch [1/5], Step [5530/9994], Loss: 0.0120\n",
      "Epoch [1/5], Step [5540/9994], Loss: 0.0845\n",
      "Epoch [1/5], Step [5550/9994], Loss: 0.0211\n",
      "Epoch [1/5], Step [5560/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [5570/9994], Loss: 0.0241\n",
      "Epoch [1/5], Step [5580/9994], Loss: 0.0061\n",
      "Epoch [1/5], Step [5590/9994], Loss: 0.0054\n",
      "Epoch [1/5], Step [5600/9994], Loss: 0.0207\n",
      "Epoch [1/5], Step [5610/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [5620/9994], Loss: 0.0024\n",
      "Epoch [1/5], Step [5630/9994], Loss: 0.0262\n",
      "Epoch [1/5], Step [5640/9994], Loss: 0.0391\n",
      "Epoch [1/5], Step [5650/9994], Loss: 0.0059\n",
      "Epoch [1/5], Step [5660/9994], Loss: 0.0163\n",
      "Epoch [1/5], Step [5670/9994], Loss: 0.0320\n",
      "Epoch [1/5], Step [5680/9994], Loss: 0.0046\n",
      "Epoch [1/5], Step [5690/9994], Loss: 0.0540\n",
      "Epoch [1/5], Step [5700/9994], Loss: 0.0082\n",
      "Epoch [1/5], Step [5710/9994], Loss: 0.1011\n",
      "Epoch [1/5], Step [5720/9994], Loss: 0.0119\n",
      "Epoch [1/5], Step [5730/9994], Loss: 0.0072\n",
      "Epoch [1/5], Step [5740/9994], Loss: 0.1247\n",
      "Epoch [1/5], Step [5750/9994], Loss: 0.0338\n",
      "Epoch [1/5], Step [5760/9994], Loss: 0.0201\n",
      "Epoch [1/5], Step [5770/9994], Loss: 0.1086\n",
      "Epoch [1/5], Step [5780/9994], Loss: 0.0559\n",
      "Epoch [1/5], Step [5790/9994], Loss: 0.0056\n",
      "Epoch [1/5], Step [5800/9994], Loss: 0.0952\n",
      "Epoch [1/5], Step [5810/9994], Loss: 0.0294\n",
      "Epoch [1/5], Step [5820/9994], Loss: 0.0225\n",
      "Epoch [1/5], Step [5830/9994], Loss: 0.0449\n",
      "Epoch [1/5], Step [5840/9994], Loss: 0.0042\n",
      "Epoch [1/5], Step [5850/9994], Loss: 0.0046\n",
      "Epoch [1/5], Step [5860/9994], Loss: 0.0032\n",
      "Epoch [1/5], Step [5870/9994], Loss: 0.0012\n",
      "Epoch [1/5], Step [5880/9994], Loss: 0.0129\n",
      "Epoch [1/5], Step [5890/9994], Loss: 0.0328\n",
      "Epoch [1/5], Step [5900/9994], Loss: 0.0398\n",
      "Epoch [1/5], Step [5910/9994], Loss: 0.0130\n",
      "Epoch [1/5], Step [5920/9994], Loss: 0.1541\n",
      "Epoch [1/5], Step [5930/9994], Loss: 0.0084\n",
      "Epoch [1/5], Step [5940/9994], Loss: 0.0168\n",
      "Epoch [1/5], Step [5950/9994], Loss: 0.0085\n",
      "Epoch [1/5], Step [5960/9994], Loss: 0.0659\n",
      "Epoch [1/5], Step [5970/9994], Loss: 0.0072\n",
      "Epoch [1/5], Step [5980/9994], Loss: 0.0008\n",
      "Epoch [1/5], Step [5990/9994], Loss: 0.0016\n",
      "Epoch [1/5], Step [6000/9994], Loss: 0.0128\n",
      "Epoch [1/5], Step [6010/9994], Loss: 0.0234\n",
      "Epoch [1/5], Step [6020/9994], Loss: 0.0200\n",
      "Epoch [1/5], Step [6030/9994], Loss: 0.0014\n",
      "Epoch [1/5], Step [6040/9994], Loss: 0.0095\n",
      "Epoch [1/5], Step [6050/9994], Loss: 0.0262\n",
      "Epoch [1/5], Step [6060/9994], Loss: 0.0320\n",
      "Epoch [1/5], Step [6070/9994], Loss: 0.0523\n",
      "Epoch [1/5], Step [6080/9994], Loss: 0.0097\n",
      "Epoch [1/5], Step [6090/9994], Loss: 0.0013\n",
      "Epoch [1/5], Step [6100/9994], Loss: 0.0176\n",
      "Epoch [1/5], Step [6110/9994], Loss: 0.0131\n",
      "Epoch [1/5], Step [6120/9994], Loss: 0.0253\n",
      "Epoch [1/5], Step [6130/9994], Loss: 0.0101\n",
      "Epoch [1/5], Step [6140/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [6150/9994], Loss: 0.0037\n",
      "Epoch [1/5], Step [6160/9994], Loss: 0.0174\n",
      "Epoch [1/5], Step [6170/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [6180/9994], Loss: 0.0591\n",
      "Epoch [1/5], Step [6190/9994], Loss: 0.0076\n",
      "Epoch [1/5], Step [6200/9994], Loss: 0.0071\n",
      "Epoch [1/5], Step [6210/9994], Loss: 0.0110\n",
      "Epoch [1/5], Step [6220/9994], Loss: 0.0481\n",
      "Epoch [1/5], Step [6230/9994], Loss: 0.1032\n",
      "Epoch [1/5], Step [6240/9994], Loss: 0.0354\n",
      "Epoch [1/5], Step [6250/9994], Loss: 0.0096\n",
      "Epoch [1/5], Step [6260/9994], Loss: 0.1209\n",
      "Epoch [1/5], Step [6270/9994], Loss: 0.0477\n",
      "Epoch [1/5], Step [6280/9994], Loss: 0.0106\n",
      "Epoch [1/5], Step [6290/9994], Loss: 0.0076\n",
      "Epoch [1/5], Step [6300/9994], Loss: 0.0088\n",
      "Epoch [1/5], Step [6310/9994], Loss: 0.0045\n",
      "Epoch [1/5], Step [6320/9994], Loss: 0.0632\n",
      "Epoch [1/5], Step [6330/9994], Loss: 0.0023\n",
      "Epoch [1/5], Step [6340/9994], Loss: 0.0016\n",
      "Epoch [1/5], Step [6350/9994], Loss: 0.0020\n",
      "Epoch [1/5], Step [6360/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [6370/9994], Loss: 0.0601\n",
      "Epoch [1/5], Step [6380/9994], Loss: 0.0658\n",
      "Epoch [1/5], Step [6390/9994], Loss: 0.0087\n",
      "Epoch [1/5], Step [6400/9994], Loss: 0.0057\n",
      "Epoch [1/5], Step [6410/9994], Loss: 0.0171\n",
      "Epoch [1/5], Step [6420/9994], Loss: 0.0292\n",
      "Epoch [1/5], Step [6430/9994], Loss: 0.0149\n",
      "Epoch [1/5], Step [6440/9994], Loss: 0.0633\n",
      "Epoch [1/5], Step [6450/9994], Loss: 0.0104\n",
      "Epoch [1/5], Step [6460/9994], Loss: 0.0009\n",
      "Epoch [1/5], Step [6470/9994], Loss: 0.0093\n",
      "Epoch [1/5], Step [6480/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [6490/9994], Loss: 0.0023\n",
      "Epoch [1/5], Step [6500/9994], Loss: 0.0016\n",
      "Epoch [1/5], Step [6510/9994], Loss: 0.0190\n",
      "Epoch [1/5], Step [6520/9994], Loss: 0.0533\n",
      "Epoch [1/5], Step [6530/9994], Loss: 0.0088\n",
      "Epoch [1/5], Step [6540/9994], Loss: 0.0058\n",
      "Epoch [1/5], Step [6550/9994], Loss: 0.0120\n",
      "Epoch [1/5], Step [6560/9994], Loss: 0.1334\n",
      "Epoch [1/5], Step [6570/9994], Loss: 0.0213\n",
      "Epoch [1/5], Step [6580/9994], Loss: 0.0125\n",
      "Epoch [1/5], Step [6590/9994], Loss: 0.0024\n",
      "Epoch [1/5], Step [6600/9994], Loss: 0.0036\n",
      "Epoch [1/5], Step [6610/9994], Loss: 0.0169\n",
      "Epoch [1/5], Step [6620/9994], Loss: 0.0183\n",
      "Epoch [1/5], Step [6630/9994], Loss: 0.0031\n",
      "Epoch [1/5], Step [6640/9994], Loss: 0.0031\n",
      "Epoch [1/5], Step [6650/9994], Loss: 0.0091\n",
      "Epoch [1/5], Step [6660/9994], Loss: 0.0143\n",
      "Epoch [1/5], Step [6670/9994], Loss: 0.0022\n",
      "Epoch [1/5], Step [6680/9994], Loss: 0.0518\n",
      "Epoch [1/5], Step [6690/9994], Loss: 0.0708\n",
      "Epoch [1/5], Step [6700/9994], Loss: 0.0027\n",
      "Epoch [1/5], Step [6710/9994], Loss: 0.0132\n",
      "Epoch [1/5], Step [6720/9994], Loss: 0.0111\n",
      "Epoch [1/5], Step [6730/9994], Loss: 0.0143\n",
      "Epoch [1/5], Step [6740/9994], Loss: 0.0091\n",
      "Epoch [1/5], Step [6750/9994], Loss: 0.0489\n",
      "Epoch [1/5], Step [6760/9994], Loss: 0.0117\n",
      "Epoch [1/5], Step [6770/9994], Loss: 0.0098\n",
      "Epoch [1/5], Step [6780/9994], Loss: 0.0234\n",
      "Epoch [1/5], Step [6790/9994], Loss: 0.0662\n",
      "Epoch [1/5], Step [6800/9994], Loss: 0.0043\n",
      "Epoch [1/5], Step [6810/9994], Loss: 0.0133\n",
      "Epoch [1/5], Step [6820/9994], Loss: 0.0069\n",
      "Epoch [1/5], Step [6830/9994], Loss: 0.0101\n",
      "Epoch [1/5], Step [6840/9994], Loss: 0.0077\n",
      "Epoch [1/5], Step [6850/9994], Loss: 0.0237\n",
      "Epoch [1/5], Step [6860/9994], Loss: 0.0131\n",
      "Epoch [1/5], Step [6870/9994], Loss: 0.0056\n",
      "Epoch [1/5], Step [6880/9994], Loss: 0.0055\n",
      "Epoch [1/5], Step [6890/9994], Loss: 0.0021\n",
      "Epoch [1/5], Step [6900/9994], Loss: 0.0058\n",
      "Epoch [1/5], Step [6910/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [6920/9994], Loss: 0.0230\n",
      "Epoch [1/5], Step [6930/9994], Loss: 0.0017\n",
      "Epoch [1/5], Step [6940/9994], Loss: 0.0100\n",
      "Epoch [1/5], Step [6950/9994], Loss: 0.0062\n",
      "Epoch [1/5], Step [6960/9994], Loss: 0.0069\n",
      "Epoch [1/5], Step [6970/9994], Loss: 0.0105\n",
      "Epoch [1/5], Step [6980/9994], Loss: 0.0075\n",
      "Epoch [1/5], Step [6990/9994], Loss: 0.0038\n",
      "Epoch [1/5], Step [7000/9994], Loss: 0.0089\n",
      "Epoch [1/5], Step [7010/9994], Loss: 0.0043\n",
      "Epoch [1/5], Step [7020/9994], Loss: 0.0041\n",
      "Epoch [1/5], Step [7030/9994], Loss: 0.0015\n",
      "Epoch [1/5], Step [7040/9994], Loss: 0.0013\n",
      "Epoch [1/5], Step [7050/9994], Loss: 0.2045\n",
      "Epoch [1/5], Step [7060/9994], Loss: 0.0202\n",
      "Epoch [1/5], Step [7070/9994], Loss: 0.0461\n",
      "Epoch [1/5], Step [7080/9994], Loss: 0.0167\n",
      "Epoch [1/5], Step [7090/9994], Loss: 0.0020\n",
      "Epoch [1/5], Step [7100/9994], Loss: 0.0087\n",
      "Epoch [1/5], Step [7110/9994], Loss: 0.0064\n",
      "Epoch [1/5], Step [7120/9994], Loss: 0.0099\n",
      "Epoch [1/5], Step [7130/9994], Loss: 0.0054\n",
      "Epoch [1/5], Step [7140/9994], Loss: 0.0117\n",
      "Epoch [1/5], Step [7150/9994], Loss: 0.0039\n",
      "Epoch [1/5], Step [7160/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [7170/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [7180/9994], Loss: 0.0025\n",
      "Epoch [1/5], Step [7190/9994], Loss: 0.0511\n",
      "Epoch [1/5], Step [7200/9994], Loss: 0.0041\n",
      "Epoch [1/5], Step [7210/9994], Loss: 0.0063\n",
      "Epoch [1/5], Step [7220/9994], Loss: 0.0481\n",
      "Epoch [1/5], Step [7230/9994], Loss: 0.0277\n",
      "Epoch [1/5], Step [7240/9994], Loss: 0.0157\n",
      "Epoch [1/5], Step [7250/9994], Loss: 0.0080\n",
      "Epoch [1/5], Step [7260/9994], Loss: 0.0061\n",
      "Epoch [1/5], Step [7270/9994], Loss: 0.0127\n",
      "Epoch [1/5], Step [7280/9994], Loss: 0.0555\n",
      "Epoch [1/5], Step [7290/9994], Loss: 0.0158\n",
      "Epoch [1/5], Step [7300/9994], Loss: 0.0051\n",
      "Epoch [1/5], Step [7310/9994], Loss: 0.0032\n",
      "Epoch [1/5], Step [7320/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [7330/9994], Loss: 0.0884\n",
      "Epoch [1/5], Step [7340/9994], Loss: 0.0095\n",
      "Epoch [1/5], Step [7350/9994], Loss: 0.0314\n",
      "Epoch [1/5], Step [7360/9994], Loss: 0.0305\n",
      "Epoch [1/5], Step [7370/9994], Loss: 0.0021\n",
      "Epoch [1/5], Step [7380/9994], Loss: 0.0280\n",
      "Epoch [1/5], Step [7390/9994], Loss: 0.0083\n",
      "Epoch [1/5], Step [7400/9994], Loss: 0.0653\n",
      "Epoch [1/5], Step [7410/9994], Loss: 0.0066\n",
      "Epoch [1/5], Step [7420/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [7430/9994], Loss: 0.0447\n",
      "Epoch [1/5], Step [7440/9994], Loss: 0.0333\n",
      "Epoch [1/5], Step [7450/9994], Loss: 0.0842\n",
      "Epoch [1/5], Step [7460/9994], Loss: 0.0057\n",
      "Epoch [1/5], Step [7470/9994], Loss: 0.0041\n",
      "Epoch [1/5], Step [7480/9994], Loss: 0.0576\n",
      "Epoch [1/5], Step [7490/9994], Loss: 0.0033\n",
      "Epoch [1/5], Step [7500/9994], Loss: 0.0212\n",
      "Epoch [1/5], Step [7510/9994], Loss: 0.0137\n",
      "Epoch [1/5], Step [7520/9994], Loss: 0.0165\n",
      "Epoch [1/5], Step [7530/9994], Loss: 0.0059\n",
      "Epoch [1/5], Step [7540/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [7550/9994], Loss: 0.0068\n",
      "Epoch [1/5], Step [7560/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [7570/9994], Loss: 0.0140\n",
      "Epoch [1/5], Step [7580/9994], Loss: 0.0693\n",
      "Epoch [1/5], Step [7590/9994], Loss: 0.0165\n",
      "Epoch [1/5], Step [7600/9994], Loss: 0.0209\n",
      "Epoch [1/5], Step [7610/9994], Loss: 0.0098\n",
      "Epoch [1/5], Step [7620/9994], Loss: 0.1046\n",
      "Epoch [1/5], Step [7630/9994], Loss: 0.0802\n",
      "Epoch [1/5], Step [7640/9994], Loss: 0.0127\n",
      "Epoch [1/5], Step [7650/9994], Loss: 0.0071\n",
      "Epoch [1/5], Step [7660/9994], Loss: 0.0710\n",
      "Epoch [1/5], Step [7670/9994], Loss: 0.0124\n",
      "Epoch [1/5], Step [7680/9994], Loss: 0.2063\n",
      "Epoch [1/5], Step [7690/9994], Loss: 0.0601\n",
      "Epoch [1/5], Step [7700/9994], Loss: 0.0017\n",
      "Epoch [1/5], Step [7710/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [7720/9994], Loss: 0.0043\n",
      "Epoch [1/5], Step [7730/9994], Loss: 0.0539\n",
      "Epoch [1/5], Step [7740/9994], Loss: 0.0168\n",
      "Epoch [1/5], Step [7750/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [7760/9994], Loss: 0.0186\n",
      "Epoch [1/5], Step [7770/9994], Loss: 0.0020\n",
      "Epoch [1/5], Step [7780/9994], Loss: 0.0010\n",
      "Epoch [1/5], Step [7790/9994], Loss: 0.0032\n",
      "Epoch [1/5], Step [7800/9994], Loss: 0.0019\n",
      "Epoch [1/5], Step [7810/9994], Loss: 0.0179\n",
      "Epoch [1/5], Step [7820/9994], Loss: 0.0120\n",
      "Epoch [1/5], Step [7830/9994], Loss: 0.0020\n",
      "Epoch [1/5], Step [7840/9994], Loss: 0.0117\n",
      "Epoch [1/5], Step [7850/9994], Loss: 0.0047\n",
      "Epoch [1/5], Step [7860/9994], Loss: 0.0071\n",
      "Epoch [1/5], Step [7870/9994], Loss: 0.0093\n",
      "Epoch [1/5], Step [7880/9994], Loss: 0.0547\n",
      "Epoch [1/5], Step [7890/9994], Loss: 0.0009\n",
      "Epoch [1/5], Step [7900/9994], Loss: 0.0157\n",
      "Epoch [1/5], Step [7910/9994], Loss: 0.0039\n",
      "Epoch [1/5], Step [7920/9994], Loss: 0.0173\n",
      "Epoch [1/5], Step [7930/9994], Loss: 0.0050\n",
      "Epoch [1/5], Step [7940/9994], Loss: 0.0635\n",
      "Epoch [1/5], Step [7950/9994], Loss: 0.0054\n",
      "Epoch [1/5], Step [7960/9994], Loss: 0.1037\n",
      "Epoch [1/5], Step [7970/9994], Loss: 0.0039\n",
      "Epoch [1/5], Step [7980/9994], Loss: 0.0074\n",
      "Epoch [1/5], Step [7990/9994], Loss: 0.0421\n",
      "Epoch [1/5], Step [8000/9994], Loss: 0.0298\n",
      "Epoch [1/5], Step [8010/9994], Loss: 0.0481\n",
      "Epoch [1/5], Step [8020/9994], Loss: 0.0769\n",
      "Epoch [1/5], Step [8030/9994], Loss: 0.0479\n",
      "Epoch [1/5], Step [8040/9994], Loss: 0.0133\n",
      "Epoch [1/5], Step [8050/9994], Loss: 0.0084\n",
      "Epoch [1/5], Step [8060/9994], Loss: 0.0818\n",
      "Epoch [1/5], Step [8070/9994], Loss: 0.0069\n",
      "Epoch [1/5], Step [8080/9994], Loss: 0.0144\n",
      "Epoch [1/5], Step [8090/9994], Loss: 0.0017\n",
      "Epoch [1/5], Step [8100/9994], Loss: 0.0119\n",
      "Epoch [1/5], Step [8110/9994], Loss: 0.0118\n",
      "Epoch [1/5], Step [8120/9994], Loss: 0.0037\n",
      "Epoch [1/5], Step [8130/9994], Loss: 0.0419\n",
      "Epoch [1/5], Step [8140/9994], Loss: 0.0694\n",
      "Epoch [1/5], Step [8150/9994], Loss: 0.0481\n",
      "Epoch [1/5], Step [8160/9994], Loss: 0.0007\n",
      "Epoch [1/5], Step [8170/9994], Loss: 0.0302\n",
      "Epoch [1/5], Step [8180/9994], Loss: 0.0053\n",
      "Epoch [1/5], Step [8190/9994], Loss: 0.0264\n",
      "Epoch [1/5], Step [8200/9994], Loss: 0.0638\n",
      "Epoch [1/5], Step [8210/9994], Loss: 0.0010\n",
      "Epoch [1/5], Step [8220/9994], Loss: 0.0842\n",
      "Epoch [1/5], Step [8230/9994], Loss: 0.0108\n",
      "Epoch [1/5], Step [8240/9994], Loss: 0.0148\n",
      "Epoch [1/5], Step [8250/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8260/9994], Loss: 0.0138\n",
      "Epoch [1/5], Step [8270/9994], Loss: 0.0097\n",
      "Epoch [1/5], Step [8280/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [8290/9994], Loss: 0.0500\n",
      "Epoch [1/5], Step [8300/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [8310/9994], Loss: 0.0087\n",
      "Epoch [1/5], Step [8320/9994], Loss: 0.0050\n",
      "Epoch [1/5], Step [8330/9994], Loss: 0.0072\n",
      "Epoch [1/5], Step [8340/9994], Loss: 0.0060\n",
      "Epoch [1/5], Step [8350/9994], Loss: 0.0128\n",
      "Epoch [1/5], Step [8360/9994], Loss: 0.0068\n",
      "Epoch [1/5], Step [8370/9994], Loss: 0.0020\n",
      "Epoch [1/5], Step [8380/9994], Loss: 0.1333\n",
      "Epoch [1/5], Step [8390/9994], Loss: 0.0058\n",
      "Epoch [1/5], Step [8400/9994], Loss: 0.0528\n",
      "Epoch [1/5], Step [8410/9994], Loss: 0.0677\n",
      "Epoch [1/5], Step [8420/9994], Loss: 0.0044\n",
      "Epoch [1/5], Step [8430/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [8440/9994], Loss: 0.0206\n",
      "Epoch [1/5], Step [8450/9994], Loss: 0.0726\n",
      "Epoch [1/5], Step [8460/9994], Loss: 0.0927\n",
      "Epoch [1/5], Step [8470/9994], Loss: 0.0034\n",
      "Epoch [1/5], Step [8480/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8490/9994], Loss: 0.0050\n",
      "Epoch [1/5], Step [8500/9994], Loss: 0.0104\n",
      "Epoch [1/5], Step [8510/9994], Loss: 0.0726\n",
      "Epoch [1/5], Step [8520/9994], Loss: 0.0227\n",
      "Epoch [1/5], Step [8530/9994], Loss: 0.0323\n",
      "Epoch [1/5], Step [8540/9994], Loss: 0.0088\n",
      "Epoch [1/5], Step [8550/9994], Loss: 0.0299\n",
      "Epoch [1/5], Step [8560/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8570/9994], Loss: 0.0499\n",
      "Epoch [1/5], Step [8580/9994], Loss: 0.0021\n",
      "Epoch [1/5], Step [8590/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [8600/9994], Loss: 0.1070\n",
      "Epoch [1/5], Step [8610/9994], Loss: 0.1092\n",
      "Epoch [1/5], Step [8620/9994], Loss: 0.0478\n",
      "Epoch [1/5], Step [8630/9994], Loss: 0.0151\n",
      "Epoch [1/5], Step [8640/9994], Loss: 0.0978\n",
      "Epoch [1/5], Step [8650/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8660/9994], Loss: 0.0848\n",
      "Epoch [1/5], Step [8670/9994], Loss: 0.0098\n",
      "Epoch [1/5], Step [8680/9994], Loss: 0.0081\n",
      "Epoch [1/5], Step [8690/9994], Loss: 0.0196\n",
      "Epoch [1/5], Step [8700/9994], Loss: 0.0013\n",
      "Epoch [1/5], Step [8710/9994], Loss: 0.0009\n",
      "Epoch [1/5], Step [8720/9994], Loss: 0.0315\n",
      "Epoch [1/5], Step [8730/9994], Loss: 0.0019\n",
      "Epoch [1/5], Step [8740/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8750/9994], Loss: 0.0011\n",
      "Epoch [1/5], Step [8760/9994], Loss: 0.0021\n",
      "Epoch [1/5], Step [8770/9994], Loss: 0.0037\n",
      "Epoch [1/5], Step [8780/9994], Loss: 0.0108\n",
      "Epoch [1/5], Step [8790/9994], Loss: 0.0078\n",
      "Epoch [1/5], Step [8800/9994], Loss: 0.0100\n",
      "Epoch [1/5], Step [8810/9994], Loss: 0.0187\n",
      "Epoch [1/5], Step [8820/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [8830/9994], Loss: 0.0574\n",
      "Epoch [1/5], Step [8840/9994], Loss: 0.0119\n",
      "Epoch [1/5], Step [8850/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [8860/9994], Loss: 0.0035\n",
      "Epoch [1/5], Step [8870/9994], Loss: 0.1499\n",
      "Epoch [1/5], Step [8880/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [8890/9994], Loss: 0.0048\n",
      "Epoch [1/5], Step [8900/9994], Loss: 0.0074\n",
      "Epoch [1/5], Step [8910/9994], Loss: 0.0017\n",
      "Epoch [1/5], Step [8920/9994], Loss: 0.0533\n",
      "Epoch [1/5], Step [8930/9994], Loss: 0.0399\n",
      "Epoch [1/5], Step [8940/9994], Loss: 0.0025\n",
      "Epoch [1/5], Step [8950/9994], Loss: 0.0040\n",
      "Epoch [1/5], Step [8960/9994], Loss: 0.0066\n",
      "Epoch [1/5], Step [8970/9994], Loss: 0.0092\n",
      "Epoch [1/5], Step [8980/9994], Loss: 0.0204\n",
      "Epoch [1/5], Step [8990/9994], Loss: 0.0003\n",
      "Epoch [1/5], Step [9000/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [9010/9994], Loss: 0.0111\n",
      "Epoch [1/5], Step [9020/9994], Loss: 0.0183\n",
      "Epoch [1/5], Step [9030/9994], Loss: 0.0014\n",
      "Epoch [1/5], Step [9040/9994], Loss: 0.0137\n",
      "Epoch [1/5], Step [9050/9994], Loss: 0.0263\n",
      "Epoch [1/5], Step [9060/9994], Loss: 0.0026\n",
      "Epoch [1/5], Step [9070/9994], Loss: 0.0134\n",
      "Epoch [1/5], Step [9080/9994], Loss: 0.0110\n",
      "Epoch [1/5], Step [9090/9994], Loss: 0.0052\n",
      "Epoch [1/5], Step [9100/9994], Loss: 0.0012\n",
      "Epoch [1/5], Step [9110/9994], Loss: 0.0074\n",
      "Epoch [1/5], Step [9120/9994], Loss: 0.0498\n",
      "Epoch [1/5], Step [9130/9994], Loss: 0.0075\n",
      "Epoch [1/5], Step [9140/9994], Loss: 0.0613\n",
      "Epoch [1/5], Step [9150/9994], Loss: 0.0023\n",
      "Epoch [1/5], Step [9160/9994], Loss: 0.0392\n",
      "Epoch [1/5], Step [9170/9994], Loss: 0.0487\n",
      "Epoch [1/5], Step [9180/9994], Loss: 0.0010\n",
      "Epoch [1/5], Step [9190/9994], Loss: 0.0083\n",
      "Epoch [1/5], Step [9200/9994], Loss: 0.0003\n",
      "Epoch [1/5], Step [9210/9994], Loss: 0.0012\n",
      "Epoch [1/5], Step [9220/9994], Loss: 0.0404\n",
      "Epoch [1/5], Step [9230/9994], Loss: 0.0103\n",
      "Epoch [1/5], Step [9240/9994], Loss: 0.0063\n",
      "Epoch [1/5], Step [9250/9994], Loss: 0.0961\n",
      "Epoch [1/5], Step [9260/9994], Loss: 0.0178\n",
      "Epoch [1/5], Step [9270/9994], Loss: 0.0080\n",
      "Epoch [1/5], Step [9280/9994], Loss: 0.0080\n",
      "Epoch [1/5], Step [9290/9994], Loss: 0.0023\n",
      "Epoch [1/5], Step [9300/9994], Loss: 0.0010\n",
      "Epoch [1/5], Step [9310/9994], Loss: 0.0011\n",
      "Epoch [1/5], Step [9320/9994], Loss: 0.0037\n",
      "Epoch [1/5], Step [9330/9994], Loss: 0.0030\n",
      "Epoch [1/5], Step [9340/9994], Loss: 0.0082\n",
      "Epoch [1/5], Step [9350/9994], Loss: 0.0427\n",
      "Epoch [1/5], Step [9360/9994], Loss: 0.0027\n",
      "Epoch [1/5], Step [9370/9994], Loss: 0.0017\n",
      "Epoch [1/5], Step [9380/9994], Loss: 0.0152\n",
      "Epoch [1/5], Step [9390/9994], Loss: 0.0022\n",
      "Epoch [1/5], Step [9400/9994], Loss: 0.0564\n",
      "Epoch [1/5], Step [9410/9994], Loss: 0.0018\n",
      "Epoch [1/5], Step [9420/9994], Loss: 0.0002\n",
      "Epoch [1/5], Step [9430/9994], Loss: 0.0362\n",
      "Epoch [1/5], Step [9440/9994], Loss: 0.0046\n",
      "Epoch [1/5], Step [9450/9994], Loss: 0.0023\n",
      "Epoch [1/5], Step [9460/9994], Loss: 0.0917\n",
      "Epoch [1/5], Step [9470/9994], Loss: 0.0412\n",
      "Epoch [1/5], Step [9480/9994], Loss: 0.0084\n",
      "Epoch [1/5], Step [9490/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [9500/9994], Loss: 0.0103\n",
      "Epoch [1/5], Step [9510/9994], Loss: 0.0013\n",
      "Epoch [1/5], Step [9520/9994], Loss: 0.0049\n",
      "Epoch [1/5], Step [9530/9994], Loss: 0.0718\n",
      "Epoch [1/5], Step [9540/9994], Loss: 0.0031\n",
      "Epoch [1/5], Step [9550/9994], Loss: 0.0041\n",
      "Epoch [1/5], Step [9560/9994], Loss: 0.3391\n",
      "Epoch [1/5], Step [9570/9994], Loss: 0.0057\n",
      "Epoch [1/5], Step [9580/9994], Loss: 0.0111\n",
      "Epoch [1/5], Step [9590/9994], Loss: 0.0048\n",
      "Epoch [1/5], Step [9600/9994], Loss: 0.0012\n",
      "Epoch [1/5], Step [9610/9994], Loss: 0.0013\n",
      "Epoch [1/5], Step [9620/9994], Loss: 0.0225\n",
      "Epoch [1/5], Step [9630/9994], Loss: 0.0825\n",
      "Epoch [1/5], Step [9640/9994], Loss: 0.0028\n",
      "Epoch [1/5], Step [9650/9994], Loss: 0.2488\n",
      "Epoch [1/5], Step [9660/9994], Loss: 0.0387\n",
      "Epoch [1/5], Step [9670/9994], Loss: 0.0035\n",
      "Epoch [1/5], Step [9680/9994], Loss: 0.0061\n",
      "Epoch [1/5], Step [9690/9994], Loss: 0.0057\n",
      "Epoch [1/5], Step [9700/9994], Loss: 0.0891\n",
      "Epoch [1/5], Step [9710/9994], Loss: 0.0071\n",
      "Epoch [1/5], Step [9720/9994], Loss: 0.0039\n",
      "Epoch [1/5], Step [9730/9994], Loss: 0.0064\n",
      "Epoch [1/5], Step [9740/9994], Loss: 0.0027\n",
      "Epoch [1/5], Step [9750/9994], Loss: 0.0078\n",
      "Epoch [1/5], Step [9760/9994], Loss: 0.0037\n",
      "Epoch [1/5], Step [9770/9994], Loss: 0.0059\n",
      "Epoch [1/5], Step [9780/9994], Loss: 0.0624\n",
      "Epoch [1/5], Step [9790/9994], Loss: 0.0029\n",
      "Epoch [1/5], Step [9800/9994], Loss: 0.0342\n",
      "Epoch [1/5], Step [9810/9994], Loss: 0.0149\n",
      "Epoch [1/5], Step [9820/9994], Loss: 0.0097\n",
      "Epoch [1/5], Step [9830/9994], Loss: 0.0014\n",
      "Epoch [1/5], Step [9840/9994], Loss: 0.0031\n",
      "Epoch [1/5], Step [9850/9994], Loss: 0.0011\n",
      "Epoch [1/5], Step [9860/9994], Loss: 0.0091\n",
      "Epoch [1/5], Step [9870/9994], Loss: 0.0068\n",
      "Epoch [1/5], Step [9880/9994], Loss: 0.0079\n",
      "Epoch [1/5], Step [9890/9994], Loss: 0.0173\n",
      "Epoch [1/5], Step [9900/9994], Loss: 0.0547\n",
      "Epoch [1/5], Step [9910/9994], Loss: 0.0038\n",
      "Epoch [1/5], Step [9920/9994], Loss: 0.0025\n",
      "Epoch [1/5], Step [9930/9994], Loss: 0.0010\n",
      "Epoch [1/5], Step [9940/9994], Loss: 0.0264\n",
      "Epoch [1/5], Step [9950/9994], Loss: 0.0093\n",
      "Epoch [1/5], Step [9960/9994], Loss: 0.0123\n",
      "Epoch [1/5], Step [9970/9994], Loss: 0.0039\n",
      "Epoch [1/5], Step [9980/9994], Loss: 0.0061\n",
      "Epoch [1/5], Step [9990/9994], Loss: 0.0038\n",
      "Epoch [1/5], Average Train Loss: 0.0596\n",
      "Epoch [1/5], Validation Loss: 0.0173\n",
      "Epoch [2/5], Step [10/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [20/9994], Loss: 0.0151\n",
      "Epoch [2/5], Step [30/9994], Loss: 0.0481\n",
      "Epoch [2/5], Step [40/9994], Loss: 0.0186\n",
      "Epoch [2/5], Step [50/9994], Loss: 0.0521\n",
      "Epoch [2/5], Step [60/9994], Loss: 0.0545\n",
      "Epoch [2/5], Step [70/9994], Loss: 0.0196\n",
      "Epoch [2/5], Step [80/9994], Loss: 0.0719\n",
      "Epoch [2/5], Step [90/9994], Loss: 0.0189\n",
      "Epoch [2/5], Step [100/9994], Loss: 0.0079\n",
      "Epoch [2/5], Step [110/9994], Loss: 0.0268\n",
      "Epoch [2/5], Step [120/9994], Loss: 0.0083\n",
      "Epoch [2/5], Step [130/9994], Loss: 0.0068\n",
      "Epoch [2/5], Step [140/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [150/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [160/9994], Loss: 0.0333\n",
      "Epoch [2/5], Step [170/9994], Loss: 0.0043\n",
      "Epoch [2/5], Step [180/9994], Loss: 0.0430\n",
      "Epoch [2/5], Step [190/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [200/9994], Loss: 0.1509\n",
      "Epoch [2/5], Step [210/9994], Loss: 0.1289\n",
      "Epoch [2/5], Step [220/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [230/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [240/9994], Loss: 0.0055\n",
      "Epoch [2/5], Step [250/9994], Loss: 0.0187\n",
      "Epoch [2/5], Step [260/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [270/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [280/9994], Loss: 0.0517\n",
      "Epoch [2/5], Step [290/9994], Loss: 0.0102\n",
      "Epoch [2/5], Step [300/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [310/9994], Loss: 0.0181\n",
      "Epoch [2/5], Step [320/9994], Loss: 0.0141\n",
      "Epoch [2/5], Step [330/9994], Loss: 0.0058\n",
      "Epoch [2/5], Step [340/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [350/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [360/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [370/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [380/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [390/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [400/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [410/9994], Loss: 0.0355\n",
      "Epoch [2/5], Step [420/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [430/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [440/9994], Loss: 0.0042\n",
      "Epoch [2/5], Step [450/9994], Loss: 0.0313\n",
      "Epoch [2/5], Step [460/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [470/9994], Loss: 0.0098\n",
      "Epoch [2/5], Step [480/9994], Loss: 0.0317\n",
      "Epoch [2/5], Step [490/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [500/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [510/9994], Loss: 0.0452\n",
      "Epoch [2/5], Step [520/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [530/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [540/9994], Loss: 0.0085\n",
      "Epoch [2/5], Step [550/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [560/9994], Loss: 0.0720\n",
      "Epoch [2/5], Step [570/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [580/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [590/9994], Loss: 0.0355\n",
      "Epoch [2/5], Step [600/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [610/9994], Loss: 0.0110\n",
      "Epoch [2/5], Step [620/9994], Loss: 0.0097\n",
      "Epoch [2/5], Step [630/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [640/9994], Loss: 0.0144\n",
      "Epoch [2/5], Step [650/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [660/9994], Loss: 0.0232\n",
      "Epoch [2/5], Step [670/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [680/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [690/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [700/9994], Loss: 0.0544\n",
      "Epoch [2/5], Step [710/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [720/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [730/9994], Loss: 0.0236\n",
      "Epoch [2/5], Step [740/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [750/9994], Loss: 0.0170\n",
      "Epoch [2/5], Step [760/9994], Loss: 0.0179\n",
      "Epoch [2/5], Step [770/9994], Loss: 0.0496\n",
      "Epoch [2/5], Step [780/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [790/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [800/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [810/9994], Loss: 0.0195\n",
      "Epoch [2/5], Step [820/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [830/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [840/9994], Loss: 0.1498\n",
      "Epoch [2/5], Step [850/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [860/9994], Loss: 0.0063\n",
      "Epoch [2/5], Step [870/9994], Loss: 0.0699\n",
      "Epoch [2/5], Step [880/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [890/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [900/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [910/9994], Loss: 0.0118\n",
      "Epoch [2/5], Step [920/9994], Loss: 0.0320\n",
      "Epoch [2/5], Step [930/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [940/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [950/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [960/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [970/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [980/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [990/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [1000/9994], Loss: 0.0104\n",
      "Epoch [2/5], Step [1010/9994], Loss: 0.0085\n",
      "Epoch [2/5], Step [1020/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [1030/9994], Loss: 0.0381\n",
      "Epoch [2/5], Step [1040/9994], Loss: 0.0211\n",
      "Epoch [2/5], Step [1050/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [1060/9994], Loss: 0.0437\n",
      "Epoch [2/5], Step [1070/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [1080/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [1090/9994], Loss: 0.0653\n",
      "Epoch [2/5], Step [1100/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [1110/9994], Loss: 0.0481\n",
      "Epoch [2/5], Step [1120/9994], Loss: 0.0054\n",
      "Epoch [2/5], Step [1130/9994], Loss: 0.0148\n",
      "Epoch [2/5], Step [1140/9994], Loss: 0.0054\n",
      "Epoch [2/5], Step [1150/9994], Loss: 0.0068\n",
      "Epoch [2/5], Step [1160/9994], Loss: 0.0338\n",
      "Epoch [2/5], Step [1170/9994], Loss: 0.0177\n",
      "Epoch [2/5], Step [1180/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [1190/9994], Loss: 0.0069\n",
      "Epoch [2/5], Step [1200/9994], Loss: 0.0093\n",
      "Epoch [2/5], Step [1210/9994], Loss: 0.0049\n",
      "Epoch [2/5], Step [1220/9994], Loss: 0.0364\n",
      "Epoch [2/5], Step [1230/9994], Loss: 0.0045\n",
      "Epoch [2/5], Step [1240/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [1250/9994], Loss: 0.0059\n",
      "Epoch [2/5], Step [1260/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [1270/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [1280/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [1290/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [1300/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [1310/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [1320/9994], Loss: 0.0200\n",
      "Epoch [2/5], Step [1330/9994], Loss: 0.0088\n",
      "Epoch [2/5], Step [1340/9994], Loss: 0.1064\n",
      "Epoch [2/5], Step [1350/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [1360/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [1370/9994], Loss: 0.0654\n",
      "Epoch [2/5], Step [1380/9994], Loss: 0.0627\n",
      "Epoch [2/5], Step [1390/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [1400/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [1410/9994], Loss: 0.0082\n",
      "Epoch [2/5], Step [1420/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [1430/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [1440/9994], Loss: 0.0321\n",
      "Epoch [2/5], Step [1450/9994], Loss: 0.0148\n",
      "Epoch [2/5], Step [1460/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [1470/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [1480/9994], Loss: 0.0069\n",
      "Epoch [2/5], Step [1490/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [1500/9994], Loss: 0.0062\n",
      "Epoch [2/5], Step [1510/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [1520/9994], Loss: 0.0060\n",
      "Epoch [2/5], Step [1530/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [1540/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [1550/9994], Loss: 0.0045\n",
      "Epoch [2/5], Step [1560/9994], Loss: 0.0834\n",
      "Epoch [2/5], Step [1570/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [1580/9994], Loss: 0.0278\n",
      "Epoch [2/5], Step [1590/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [1600/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [1610/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [1620/9994], Loss: 0.0579\n",
      "Epoch [2/5], Step [1630/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [1640/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [1650/9994], Loss: 0.0033\n",
      "Epoch [2/5], Step [1660/9994], Loss: 0.0044\n",
      "Epoch [2/5], Step [1670/9994], Loss: 0.0075\n",
      "Epoch [2/5], Step [1680/9994], Loss: 0.0495\n",
      "Epoch [2/5], Step [1690/9994], Loss: 0.0113\n",
      "Epoch [2/5], Step [1700/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [1710/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [1720/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [1730/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [1740/9994], Loss: 0.0342\n",
      "Epoch [2/5], Step [1750/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [1760/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [1770/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [1780/9994], Loss: 0.0094\n",
      "Epoch [2/5], Step [1790/9994], Loss: 0.0064\n",
      "Epoch [2/5], Step [1800/9994], Loss: 0.0291\n",
      "Epoch [2/5], Step [1810/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [1820/9994], Loss: 0.0774\n",
      "Epoch [2/5], Step [1830/9994], Loss: 0.0142\n",
      "Epoch [2/5], Step [1840/9994], Loss: 0.0321\n",
      "Epoch [2/5], Step [1850/9994], Loss: 0.0210\n",
      "Epoch [2/5], Step [1860/9994], Loss: 0.0678\n",
      "Epoch [2/5], Step [1870/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [1880/9994], Loss: 0.0356\n",
      "Epoch [2/5], Step [1890/9994], Loss: 0.0334\n",
      "Epoch [2/5], Step [1900/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [1910/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [1920/9994], Loss: 0.0490\n",
      "Epoch [2/5], Step [1930/9994], Loss: 0.0090\n",
      "Epoch [2/5], Step [1940/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [1950/9994], Loss: 0.0331\n",
      "Epoch [2/5], Step [1960/9994], Loss: 0.0080\n",
      "Epoch [2/5], Step [1970/9994], Loss: 0.0467\n",
      "Epoch [2/5], Step [1980/9994], Loss: 0.0063\n",
      "Epoch [2/5], Step [1990/9994], Loss: 0.0334\n",
      "Epoch [2/5], Step [2000/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [2010/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [2020/9994], Loss: 0.0034\n",
      "Epoch [2/5], Step [2030/9994], Loss: 0.0051\n",
      "Epoch [2/5], Step [2040/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [2050/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [2060/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [2070/9994], Loss: 0.0154\n",
      "Epoch [2/5], Step [2080/9994], Loss: 0.0615\n",
      "Epoch [2/5], Step [2090/9994], Loss: 0.0591\n",
      "Epoch [2/5], Step [2100/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [2110/9994], Loss: 0.0034\n",
      "Epoch [2/5], Step [2120/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [2130/9994], Loss: 0.0051\n",
      "Epoch [2/5], Step [2140/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [2150/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [2160/9994], Loss: 0.0570\n",
      "Epoch [2/5], Step [2170/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [2180/9994], Loss: 0.0200\n",
      "Epoch [2/5], Step [2190/9994], Loss: 0.0760\n",
      "Epoch [2/5], Step [2200/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [2210/9994], Loss: 0.0250\n",
      "Epoch [2/5], Step [2220/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [2230/9994], Loss: 0.0106\n",
      "Epoch [2/5], Step [2240/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [2250/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [2260/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [2270/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [2280/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [2290/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [2300/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [2310/9994], Loss: 0.1003\n",
      "Epoch [2/5], Step [2320/9994], Loss: 0.0102\n",
      "Epoch [2/5], Step [2330/9994], Loss: 0.0114\n",
      "Epoch [2/5], Step [2340/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [2350/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [2360/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [2370/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [2380/9994], Loss: 0.0110\n",
      "Epoch [2/5], Step [2390/9994], Loss: 0.0140\n",
      "Epoch [2/5], Step [2400/9994], Loss: 0.0041\n",
      "Epoch [2/5], Step [2410/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [2420/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [2430/9994], Loss: 0.0148\n",
      "Epoch [2/5], Step [2440/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [2450/9994], Loss: 0.0130\n",
      "Epoch [2/5], Step [2460/9994], Loss: 0.0602\n",
      "Epoch [2/5], Step [2470/9994], Loss: 0.0772\n",
      "Epoch [2/5], Step [2480/9994], Loss: 0.0035\n",
      "Epoch [2/5], Step [2490/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [2500/9994], Loss: 0.0035\n",
      "Epoch [2/5], Step [2510/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [2520/9994], Loss: 0.0053\n",
      "Epoch [2/5], Step [2530/9994], Loss: 0.1346\n",
      "Epoch [2/5], Step [2540/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [2550/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [2560/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [2570/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [2580/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [2590/9994], Loss: 0.0637\n",
      "Epoch [2/5], Step [2600/9994], Loss: 0.0090\n",
      "Epoch [2/5], Step [2610/9994], Loss: 0.0073\n",
      "Epoch [2/5], Step [2620/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [2630/9994], Loss: 0.0569\n",
      "Epoch [2/5], Step [2640/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [2650/9994], Loss: 0.0648\n",
      "Epoch [2/5], Step [2660/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [2670/9994], Loss: 0.0162\n",
      "Epoch [2/5], Step [2680/9994], Loss: 0.0055\n",
      "Epoch [2/5], Step [2690/9994], Loss: 0.0509\n",
      "Epoch [2/5], Step [2700/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [2710/9994], Loss: 0.0061\n",
      "Epoch [2/5], Step [2720/9994], Loss: 0.0483\n",
      "Epoch [2/5], Step [2730/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [2740/9994], Loss: 0.0069\n",
      "Epoch [2/5], Step [2750/9994], Loss: 0.0095\n",
      "Epoch [2/5], Step [2760/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [2770/9994], Loss: 0.0154\n",
      "Epoch [2/5], Step [2780/9994], Loss: 0.0436\n",
      "Epoch [2/5], Step [2790/9994], Loss: 0.0247\n",
      "Epoch [2/5], Step [2800/9994], Loss: 0.0049\n",
      "Epoch [2/5], Step [2810/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [2820/9994], Loss: 0.0808\n",
      "Epoch [2/5], Step [2830/9994], Loss: 0.0076\n",
      "Epoch [2/5], Step [2840/9994], Loss: 0.1336\n",
      "Epoch [2/5], Step [2850/9994], Loss: 0.0658\n",
      "Epoch [2/5], Step [2860/9994], Loss: 0.0079\n",
      "Epoch [2/5], Step [2870/9994], Loss: 0.0211\n",
      "Epoch [2/5], Step [2880/9994], Loss: 0.0077\n",
      "Epoch [2/5], Step [2890/9994], Loss: 0.0721\n",
      "Epoch [2/5], Step [2900/9994], Loss: 0.0094\n",
      "Epoch [2/5], Step [2910/9994], Loss: 0.0751\n",
      "Epoch [2/5], Step [2920/9994], Loss: 0.0060\n",
      "Epoch [2/5], Step [2930/9994], Loss: 0.0897\n",
      "Epoch [2/5], Step [2940/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [2950/9994], Loss: 0.0056\n",
      "Epoch [2/5], Step [2960/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [2970/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [2980/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [2990/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [3000/9994], Loss: 0.0196\n",
      "Epoch [2/5], Step [3010/9994], Loss: 0.0236\n",
      "Epoch [2/5], Step [3020/9994], Loss: 0.0072\n",
      "Epoch [2/5], Step [3030/9994], Loss: 0.1665\n",
      "Epoch [2/5], Step [3040/9994], Loss: 0.0042\n",
      "Epoch [2/5], Step [3050/9994], Loss: 0.0099\n",
      "Epoch [2/5], Step [3060/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [3070/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [3080/9994], Loss: 0.0153\n",
      "Epoch [2/5], Step [3090/9994], Loss: 0.1349\n",
      "Epoch [2/5], Step [3100/9994], Loss: 0.0056\n",
      "Epoch [2/5], Step [3110/9994], Loss: 0.0140\n",
      "Epoch [2/5], Step [3120/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [3130/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [3140/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [3150/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [3160/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [3170/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [3180/9994], Loss: 0.0555\n",
      "Epoch [2/5], Step [3190/9994], Loss: 0.0396\n",
      "Epoch [2/5], Step [3200/9994], Loss: 0.1158\n",
      "Epoch [2/5], Step [3210/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [3220/9994], Loss: 0.0119\n",
      "Epoch [2/5], Step [3230/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [3240/9994], Loss: 0.0121\n",
      "Epoch [2/5], Step [3250/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [3260/9994], Loss: 0.0641\n",
      "Epoch [2/5], Step [3270/9994], Loss: 0.1030\n",
      "Epoch [2/5], Step [3280/9994], Loss: 0.0058\n",
      "Epoch [2/5], Step [3290/9994], Loss: 0.0067\n",
      "Epoch [2/5], Step [3300/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [3310/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [3320/9994], Loss: 0.0279\n",
      "Epoch [2/5], Step [3330/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [3340/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [3350/9994], Loss: 0.0131\n",
      "Epoch [2/5], Step [3360/9994], Loss: 0.0055\n",
      "Epoch [2/5], Step [3370/9994], Loss: 0.0115\n",
      "Epoch [2/5], Step [3380/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [3390/9994], Loss: 0.0317\n",
      "Epoch [2/5], Step [3400/9994], Loss: 0.0076\n",
      "Epoch [2/5], Step [3410/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [3420/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [3430/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [3440/9994], Loss: 0.0264\n",
      "Epoch [2/5], Step [3450/9994], Loss: 0.0622\n",
      "Epoch [2/5], Step [3460/9994], Loss: 0.0384\n",
      "Epoch [2/5], Step [3470/9994], Loss: 0.0053\n",
      "Epoch [2/5], Step [3480/9994], Loss: 0.0458\n",
      "Epoch [2/5], Step [3490/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [3500/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [3510/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [3520/9994], Loss: 0.0429\n",
      "Epoch [2/5], Step [3530/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [3540/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [3550/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [3560/9994], Loss: 0.0773\n",
      "Epoch [2/5], Step [3570/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [3580/9994], Loss: 0.0121\n",
      "Epoch [2/5], Step [3590/9994], Loss: 0.0195\n",
      "Epoch [2/5], Step [3600/9994], Loss: 0.0430\n",
      "Epoch [2/5], Step [3610/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [3620/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [3630/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [3640/9994], Loss: 0.0435\n",
      "Epoch [2/5], Step [3650/9994], Loss: 0.0411\n",
      "Epoch [2/5], Step [3660/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [3670/9994], Loss: 0.0094\n",
      "Epoch [2/5], Step [3680/9994], Loss: 0.0437\n",
      "Epoch [2/5], Step [3690/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [3700/9994], Loss: 0.0621\n",
      "Epoch [2/5], Step [3710/9994], Loss: 0.0042\n",
      "Epoch [2/5], Step [3720/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [3730/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [3740/9994], Loss: 0.0570\n",
      "Epoch [2/5], Step [3750/9994], Loss: 0.0049\n",
      "Epoch [2/5], Step [3760/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [3770/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [3780/9994], Loss: 0.0511\n",
      "Epoch [2/5], Step [3790/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [3800/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [3810/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [3820/9994], Loss: 0.0223\n",
      "Epoch [2/5], Step [3830/9994], Loss: 0.0081\n",
      "Epoch [2/5], Step [3840/9994], Loss: 0.0255\n",
      "Epoch [2/5], Step [3850/9994], Loss: 0.0043\n",
      "Epoch [2/5], Step [3860/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [3870/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [3880/9994], Loss: 0.0940\n",
      "Epoch [2/5], Step [3890/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [3900/9994], Loss: 0.0085\n",
      "Epoch [2/5], Step [3910/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [3920/9994], Loss: 0.0232\n",
      "Epoch [2/5], Step [3930/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [3940/9994], Loss: 0.0065\n",
      "Epoch [2/5], Step [3950/9994], Loss: 0.0845\n",
      "Epoch [2/5], Step [3960/9994], Loss: 0.0117\n",
      "Epoch [2/5], Step [3970/9994], Loss: 0.0519\n",
      "Epoch [2/5], Step [3980/9994], Loss: 0.0487\n",
      "Epoch [2/5], Step [3990/9994], Loss: 0.0059\n",
      "Epoch [2/5], Step [4000/9994], Loss: 0.0242\n",
      "Epoch [2/5], Step [4010/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [4020/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [4030/9994], Loss: 0.0034\n",
      "Epoch [2/5], Step [4040/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [4050/9994], Loss: 0.0078\n",
      "Epoch [2/5], Step [4060/9994], Loss: 0.0578\n",
      "Epoch [2/5], Step [4070/9994], Loss: 0.0054\n",
      "Epoch [2/5], Step [4080/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [4090/9994], Loss: 0.0041\n",
      "Epoch [2/5], Step [4100/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [4110/9994], Loss: 0.0043\n",
      "Epoch [2/5], Step [4120/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [4130/9994], Loss: 0.0753\n",
      "Epoch [2/5], Step [4140/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [4150/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [4160/9994], Loss: 0.0411\n",
      "Epoch [2/5], Step [4170/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [4180/9994], Loss: 0.0405\n",
      "Epoch [2/5], Step [4190/9994], Loss: 0.0181\n",
      "Epoch [2/5], Step [4200/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [4210/9994], Loss: 0.0255\n",
      "Epoch [2/5], Step [4220/9994], Loss: 0.0095\n",
      "Epoch [2/5], Step [4230/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [4240/9994], Loss: 0.0964\n",
      "Epoch [2/5], Step [4250/9994], Loss: 0.0065\n",
      "Epoch [2/5], Step [4260/9994], Loss: 0.0044\n",
      "Epoch [2/5], Step [4270/9994], Loss: 0.0637\n",
      "Epoch [2/5], Step [4280/9994], Loss: 0.0664\n",
      "Epoch [2/5], Step [4290/9994], Loss: 0.0413\n",
      "Epoch [2/5], Step [4300/9994], Loss: 0.0075\n",
      "Epoch [2/5], Step [4310/9994], Loss: 0.0051\n",
      "Epoch [2/5], Step [4320/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [4330/9994], Loss: 0.0054\n",
      "Epoch [2/5], Step [4340/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [4350/9994], Loss: 0.0202\n",
      "Epoch [2/5], Step [4360/9994], Loss: 0.0412\n",
      "Epoch [2/5], Step [4370/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [4380/9994], Loss: 0.0597\n",
      "Epoch [2/5], Step [4390/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [4400/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [4410/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [4420/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [4430/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [4440/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [4450/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [4460/9994], Loss: 0.0229\n",
      "Epoch [2/5], Step [4470/9994], Loss: 0.0602\n",
      "Epoch [2/5], Step [4480/9994], Loss: 0.0191\n",
      "Epoch [2/5], Step [4490/9994], Loss: 0.0625\n",
      "Epoch [2/5], Step [4500/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [4510/9994], Loss: 0.0097\n",
      "Epoch [2/5], Step [4520/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [4530/9994], Loss: 0.0474\n",
      "Epoch [2/5], Step [4540/9994], Loss: 0.0108\n",
      "Epoch [2/5], Step [4550/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [4560/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [4570/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [4580/9994], Loss: 0.0147\n",
      "Epoch [2/5], Step [4590/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [4600/9994], Loss: 0.0100\n",
      "Epoch [2/5], Step [4610/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [4620/9994], Loss: 0.0563\n",
      "Epoch [2/5], Step [4630/9994], Loss: 0.0058\n",
      "Epoch [2/5], Step [4640/9994], Loss: 0.0410\n",
      "Epoch [2/5], Step [4650/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [4660/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [4670/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [4680/9994], Loss: 0.0520\n",
      "Epoch [2/5], Step [4690/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [4700/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [4710/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [4720/9994], Loss: 0.0136\n",
      "Epoch [2/5], Step [4730/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [4740/9994], Loss: 0.0059\n",
      "Epoch [2/5], Step [4750/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [4760/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [4770/9994], Loss: 0.0065\n",
      "Epoch [2/5], Step [4780/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [4790/9994], Loss: 0.0452\n",
      "Epoch [2/5], Step [4800/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [4810/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [4820/9994], Loss: 0.0744\n",
      "Epoch [2/5], Step [4830/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [4840/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [4850/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [4860/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [4870/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [4880/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [4890/9994], Loss: 0.0821\n",
      "Epoch [2/5], Step [4900/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [4910/9994], Loss: 0.0082\n",
      "Epoch [2/5], Step [4920/9994], Loss: 0.0124\n",
      "Epoch [2/5], Step [4930/9994], Loss: 0.0053\n",
      "Epoch [2/5], Step [4940/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [4950/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [4960/9994], Loss: 0.0428\n",
      "Epoch [2/5], Step [4970/9994], Loss: 0.0069\n",
      "Epoch [2/5], Step [4980/9994], Loss: 0.0241\n",
      "Epoch [2/5], Step [4990/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [5000/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [5010/9994], Loss: 0.0225\n",
      "Epoch [2/5], Step [5020/9994], Loss: 0.0136\n",
      "Epoch [2/5], Step [5030/9994], Loss: 0.0945\n",
      "Epoch [2/5], Step [5040/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [5050/9994], Loss: 0.0180\n",
      "Epoch [2/5], Step [5060/9994], Loss: 0.1620\n",
      "Epoch [2/5], Step [5070/9994], Loss: 0.0773\n",
      "Epoch [2/5], Step [5080/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [5090/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [5100/9994], Loss: 0.0086\n",
      "Epoch [2/5], Step [5110/9994], Loss: 0.0115\n",
      "Epoch [2/5], Step [5120/9994], Loss: 0.0064\n",
      "Epoch [2/5], Step [5130/9994], Loss: 0.0177\n",
      "Epoch [2/5], Step [5140/9994], Loss: 0.0416\n",
      "Epoch [2/5], Step [5150/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [5160/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [5170/9994], Loss: 0.0041\n",
      "Epoch [2/5], Step [5180/9994], Loss: 0.0746\n",
      "Epoch [2/5], Step [5190/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [5200/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [5210/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [5220/9994], Loss: 0.1003\n",
      "Epoch [2/5], Step [5230/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [5240/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [5250/9994], Loss: 0.0511\n",
      "Epoch [2/5], Step [5260/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [5270/9994], Loss: 0.0535\n",
      "Epoch [2/5], Step [5280/9994], Loss: 0.0133\n",
      "Epoch [2/5], Step [5290/9994], Loss: 0.0068\n",
      "Epoch [2/5], Step [5300/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [5310/9994], Loss: 0.0076\n",
      "Epoch [2/5], Step [5320/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [5330/9994], Loss: 0.0051\n",
      "Epoch [2/5], Step [5340/9994], Loss: 0.0483\n",
      "Epoch [2/5], Step [5350/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [5360/9994], Loss: 0.0064\n",
      "Epoch [2/5], Step [5370/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [5380/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [5390/9994], Loss: 0.0101\n",
      "Epoch [2/5], Step [5400/9994], Loss: 0.0144\n",
      "Epoch [2/5], Step [5410/9994], Loss: 0.0131\n",
      "Epoch [2/5], Step [5420/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [5430/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [5440/9994], Loss: 0.0042\n",
      "Epoch [2/5], Step [5450/9994], Loss: 0.0928\n",
      "Epoch [2/5], Step [5460/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [5470/9994], Loss: 0.0068\n",
      "Epoch [2/5], Step [5480/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [5490/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [5500/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [5510/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [5520/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [5530/9994], Loss: 0.0033\n",
      "Epoch [2/5], Step [5540/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [5550/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [5560/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [5570/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [5580/9994], Loss: 0.0080\n",
      "Epoch [2/5], Step [5590/9994], Loss: 0.0086\n",
      "Epoch [2/5], Step [5600/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [5610/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [5620/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [5630/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [5640/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [5650/9994], Loss: 0.0472\n",
      "Epoch [2/5], Step [5660/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [5670/9994], Loss: 0.0061\n",
      "Epoch [2/5], Step [5680/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [5690/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [5700/9994], Loss: 0.0156\n",
      "Epoch [2/5], Step [5710/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [5720/9994], Loss: 0.0063\n",
      "Epoch [2/5], Step [5730/9994], Loss: 0.0606\n",
      "Epoch [2/5], Step [5740/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [5750/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [5760/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [5770/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [5780/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [5790/9994], Loss: 0.0799\n",
      "Epoch [2/5], Step [5800/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [5810/9994], Loss: 0.0255\n",
      "Epoch [2/5], Step [5820/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [5830/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [5840/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [5850/9994], Loss: 0.0401\n",
      "Epoch [2/5], Step [5860/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [5870/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [5880/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [5890/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [5900/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [5910/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [5920/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [5930/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [5940/9994], Loss: 0.0255\n",
      "Epoch [2/5], Step [5950/9994], Loss: 0.0060\n",
      "Epoch [2/5], Step [5960/9994], Loss: 0.0357\n",
      "Epoch [2/5], Step [5970/9994], Loss: 0.0104\n",
      "Epoch [2/5], Step [5980/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [5990/9994], Loss: 0.0086\n",
      "Epoch [2/5], Step [6000/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [6010/9994], Loss: 0.0844\n",
      "Epoch [2/5], Step [6020/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [6030/9994], Loss: 0.0051\n",
      "Epoch [2/5], Step [6040/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [6050/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [6060/9994], Loss: 0.0530\n",
      "Epoch [2/5], Step [6070/9994], Loss: 0.0069\n",
      "Epoch [2/5], Step [6080/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [6090/9994], Loss: 0.0049\n",
      "Epoch [2/5], Step [6100/9994], Loss: 0.0483\n",
      "Epoch [2/5], Step [6110/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [6120/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [6130/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [6140/9994], Loss: 0.0249\n",
      "Epoch [2/5], Step [6150/9994], Loss: 0.0174\n",
      "Epoch [2/5], Step [6160/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [6170/9994], Loss: 0.0823\n",
      "Epoch [2/5], Step [6180/9994], Loss: 0.0053\n",
      "Epoch [2/5], Step [6190/9994], Loss: 0.0170\n",
      "Epoch [2/5], Step [6200/9994], Loss: 0.0057\n",
      "Epoch [2/5], Step [6210/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [6220/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [6230/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [6240/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [6250/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [6260/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [6270/9994], Loss: 0.0361\n",
      "Epoch [2/5], Step [6280/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [6290/9994], Loss: 0.1312\n",
      "Epoch [2/5], Step [6300/9994], Loss: 0.0388\n",
      "Epoch [2/5], Step [6310/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [6320/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [6330/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [6340/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [6350/9994], Loss: 0.0322\n",
      "Epoch [2/5], Step [6360/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [6370/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [6380/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [6390/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [6400/9994], Loss: 0.0132\n",
      "Epoch [2/5], Step [6410/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [6420/9994], Loss: 0.0120\n",
      "Epoch [2/5], Step [6430/9994], Loss: 0.0087\n",
      "Epoch [2/5], Step [6440/9994], Loss: 0.0059\n",
      "Epoch [2/5], Step [6450/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [6460/9994], Loss: 0.0131\n",
      "Epoch [2/5], Step [6470/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [6480/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [6490/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [6500/9994], Loss: 0.0146\n",
      "Epoch [2/5], Step [6510/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [6520/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [6530/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [6540/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [6550/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [6560/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [6570/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [6580/9994], Loss: 0.0439\n",
      "Epoch [2/5], Step [6590/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [6600/9994], Loss: 0.0798\n",
      "Epoch [2/5], Step [6610/9994], Loss: 0.0317\n",
      "Epoch [2/5], Step [6620/9994], Loss: 0.0067\n",
      "Epoch [2/5], Step [6630/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [6640/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [6650/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [6660/9994], Loss: 0.0000\n",
      "Epoch [2/5], Step [6670/9994], Loss: 0.0139\n",
      "Epoch [2/5], Step [6680/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [6690/9994], Loss: 0.0181\n",
      "Epoch [2/5], Step [6700/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [6710/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [6720/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [6730/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [6740/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [6750/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [6760/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [6770/9994], Loss: 0.0254\n",
      "Epoch [2/5], Step [6780/9994], Loss: 0.0212\n",
      "Epoch [2/5], Step [6790/9994], Loss: 0.0141\n",
      "Epoch [2/5], Step [6800/9994], Loss: 0.0098\n",
      "Epoch [2/5], Step [6810/9994], Loss: 0.0194\n",
      "Epoch [2/5], Step [6820/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [6830/9994], Loss: 0.0364\n",
      "Epoch [2/5], Step [6840/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [6850/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [6860/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [6870/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [6880/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [6890/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [6900/9994], Loss: 0.0002\n",
      "Epoch [2/5], Step [6910/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [6920/9994], Loss: 0.0075\n",
      "Epoch [2/5], Step [6930/9994], Loss: 0.0600\n",
      "Epoch [2/5], Step [6940/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [6950/9994], Loss: 0.0123\n",
      "Epoch [2/5], Step [6960/9994], Loss: 0.0659\n",
      "Epoch [2/5], Step [6970/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [6980/9994], Loss: 0.0083\n",
      "Epoch [2/5], Step [6990/9994], Loss: 0.0733\n",
      "Epoch [2/5], Step [7000/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [7010/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [7020/9994], Loss: 0.0547\n",
      "Epoch [2/5], Step [7030/9994], Loss: 0.0409\n",
      "Epoch [2/5], Step [7040/9994], Loss: 0.0146\n",
      "Epoch [2/5], Step [7050/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [7060/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [7070/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [7080/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [7090/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [7100/9994], Loss: 0.1024\n",
      "Epoch [2/5], Step [7110/9994], Loss: 0.0238\n",
      "Epoch [2/5], Step [7120/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [7130/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [7140/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [7150/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [7160/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [7170/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [7180/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [7190/9994], Loss: 0.0064\n",
      "Epoch [2/5], Step [7200/9994], Loss: 0.0049\n",
      "Epoch [2/5], Step [7210/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [7220/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [7230/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [7240/9994], Loss: 0.0273\n",
      "Epoch [2/5], Step [7250/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [7260/9994], Loss: 0.0297\n",
      "Epoch [2/5], Step [7270/9994], Loss: 0.0082\n",
      "Epoch [2/5], Step [7280/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [7290/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [7300/9994], Loss: 0.0052\n",
      "Epoch [2/5], Step [7310/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [7320/9994], Loss: 0.0398\n",
      "Epoch [2/5], Step [7330/9994], Loss: 0.0088\n",
      "Epoch [2/5], Step [7340/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [7350/9994], Loss: 0.0044\n",
      "Epoch [2/5], Step [7360/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [7370/9994], Loss: 0.0252\n",
      "Epoch [2/5], Step [7380/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [7390/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [7400/9994], Loss: 0.0033\n",
      "Epoch [2/5], Step [7410/9994], Loss: 0.0624\n",
      "Epoch [2/5], Step [7420/9994], Loss: 0.0236\n",
      "Epoch [2/5], Step [7430/9994], Loss: 0.0116\n",
      "Epoch [2/5], Step [7440/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [7450/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [7460/9994], Loss: 0.0063\n",
      "Epoch [2/5], Step [7470/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [7480/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [7490/9994], Loss: 0.0464\n",
      "Epoch [2/5], Step [7500/9994], Loss: 0.0645\n",
      "Epoch [2/5], Step [7510/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [7520/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [7530/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [7540/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [7550/9994], Loss: 0.0061\n",
      "Epoch [2/5], Step [7560/9994], Loss: 0.0615\n",
      "Epoch [2/5], Step [7570/9994], Loss: 0.0347\n",
      "Epoch [2/5], Step [7580/9994], Loss: 0.0641\n",
      "Epoch [2/5], Step [7590/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [7600/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [7610/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [7620/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [7630/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [7640/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [7650/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [7660/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [7670/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [7680/9994], Loss: 0.0141\n",
      "Epoch [2/5], Step [7690/9994], Loss: 0.0436\n",
      "Epoch [2/5], Step [7700/9994], Loss: 0.0086\n",
      "Epoch [2/5], Step [7710/9994], Loss: 0.0035\n",
      "Epoch [2/5], Step [7720/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [7730/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [7740/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [7750/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [7760/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [7770/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [7780/9994], Loss: 0.0654\n",
      "Epoch [2/5], Step [7790/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [7800/9994], Loss: 0.0091\n",
      "Epoch [2/5], Step [7810/9994], Loss: 0.0089\n",
      "Epoch [2/5], Step [7820/9994], Loss: 0.0332\n",
      "Epoch [2/5], Step [7830/9994], Loss: 0.0149\n",
      "Epoch [2/5], Step [7840/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [7850/9994], Loss: 0.0394\n",
      "Epoch [2/5], Step [7860/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [7870/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [7880/9994], Loss: 0.0071\n",
      "Epoch [2/5], Step [7890/9994], Loss: 0.0489\n",
      "Epoch [2/5], Step [7900/9994], Loss: 0.0112\n",
      "Epoch [2/5], Step [7910/9994], Loss: 0.0385\n",
      "Epoch [2/5], Step [7920/9994], Loss: 0.0374\n",
      "Epoch [2/5], Step [7930/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [7940/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [7950/9994], Loss: 0.0104\n",
      "Epoch [2/5], Step [7960/9994], Loss: 0.0541\n",
      "Epoch [2/5], Step [7970/9994], Loss: 0.0725\n",
      "Epoch [2/5], Step [7980/9994], Loss: 0.0033\n",
      "Epoch [2/5], Step [7990/9994], Loss: 0.0068\n",
      "Epoch [2/5], Step [8000/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [8010/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [8020/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [8030/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [8040/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [8050/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [8060/9994], Loss: 0.0443\n",
      "Epoch [2/5], Step [8070/9994], Loss: 0.0042\n",
      "Epoch [2/5], Step [8080/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [8090/9994], Loss: 0.0012\n",
      "Epoch [2/5], Step [8100/9994], Loss: 0.0135\n",
      "Epoch [2/5], Step [8110/9994], Loss: 0.0339\n",
      "Epoch [2/5], Step [8120/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [8130/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [8140/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [8150/9994], Loss: 0.0531\n",
      "Epoch [2/5], Step [8160/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [8170/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [8180/9994], Loss: 0.0053\n",
      "Epoch [2/5], Step [8190/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [8200/9994], Loss: 0.0541\n",
      "Epoch [2/5], Step [8210/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [8220/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [8230/9994], Loss: 0.0170\n",
      "Epoch [2/5], Step [8240/9994], Loss: 0.0066\n",
      "Epoch [2/5], Step [8250/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [8260/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [8270/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [8280/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [8290/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [8300/9994], Loss: 0.0034\n",
      "Epoch [2/5], Step [8310/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [8320/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [8330/9994], Loss: 0.1376\n",
      "Epoch [2/5], Step [8340/9994], Loss: 0.0374\n",
      "Epoch [2/5], Step [8350/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [8360/9994], Loss: 0.0095\n",
      "Epoch [2/5], Step [8370/9994], Loss: 0.0046\n",
      "Epoch [2/5], Step [8380/9994], Loss: 0.0189\n",
      "Epoch [2/5], Step [8390/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [8400/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [8410/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [8420/9994], Loss: 0.0154\n",
      "Epoch [2/5], Step [8430/9994], Loss: 0.0241\n",
      "Epoch [2/5], Step [8440/9994], Loss: 0.0103\n",
      "Epoch [2/5], Step [8450/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [8460/9994], Loss: 0.0660\n",
      "Epoch [2/5], Step [8470/9994], Loss: 0.0500\n",
      "Epoch [2/5], Step [8480/9994], Loss: 0.0548\n",
      "Epoch [2/5], Step [8490/9994], Loss: 0.0061\n",
      "Epoch [2/5], Step [8500/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [8510/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [8520/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [8530/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [8540/9994], Loss: 0.0034\n",
      "Epoch [2/5], Step [8550/9994], Loss: 0.0547\n",
      "Epoch [2/5], Step [8560/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [8570/9994], Loss: 0.0023\n",
      "Epoch [2/5], Step [8580/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [8590/9994], Loss: 0.0056\n",
      "Epoch [2/5], Step [8600/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [8610/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [8620/9994], Loss: 0.0121\n",
      "Epoch [2/5], Step [8630/9994], Loss: 0.1322\n",
      "Epoch [2/5], Step [8640/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [8650/9994], Loss: 0.0588\n",
      "Epoch [2/5], Step [8660/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [8670/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [8680/9994], Loss: 0.0134\n",
      "Epoch [2/5], Step [8690/9994], Loss: 0.0059\n",
      "Epoch [2/5], Step [8700/9994], Loss: 0.0024\n",
      "Epoch [2/5], Step [8710/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [8720/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [8730/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [8740/9994], Loss: 0.0148\n",
      "Epoch [2/5], Step [8750/9994], Loss: 0.0192\n",
      "Epoch [2/5], Step [8760/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [8770/9994], Loss: 0.0333\n",
      "Epoch [2/5], Step [8780/9994], Loss: 0.0312\n",
      "Epoch [2/5], Step [8790/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [8800/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [8810/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [8820/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [8830/9994], Loss: 0.0348\n",
      "Epoch [2/5], Step [8840/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [8850/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [8860/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [8870/9994], Loss: 0.0001\n",
      "Epoch [2/5], Step [8880/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [8890/9994], Loss: 0.0229\n",
      "Epoch [2/5], Step [8900/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [8910/9994], Loss: 0.0568\n",
      "Epoch [2/5], Step [8920/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [8930/9994], Loss: 0.0321\n",
      "Epoch [2/5], Step [8940/9994], Loss: 0.0006\n",
      "Epoch [2/5], Step [8950/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [8960/9994], Loss: 0.0432\n",
      "Epoch [2/5], Step [8970/9994], Loss: 0.0163\n",
      "Epoch [2/5], Step [8980/9994], Loss: 0.0065\n",
      "Epoch [2/5], Step [8990/9994], Loss: 0.0215\n",
      "Epoch [2/5], Step [9000/9994], Loss: 0.0449\n",
      "Epoch [2/5], Step [9010/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [9020/9994], Loss: 0.0043\n",
      "Epoch [2/5], Step [9030/9994], Loss: 0.0897\n",
      "Epoch [2/5], Step [9040/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [9050/9994], Loss: 0.0016\n",
      "Epoch [2/5], Step [9060/9994], Loss: 0.0039\n",
      "Epoch [2/5], Step [9070/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [9080/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [9090/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [9100/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [9110/9994], Loss: 0.0231\n",
      "Epoch [2/5], Step [9120/9994], Loss: 0.0102\n",
      "Epoch [2/5], Step [9130/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [9140/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [9150/9994], Loss: 0.1356\n",
      "Epoch [2/5], Step [9160/9994], Loss: 0.0013\n",
      "Epoch [2/5], Step [9170/9994], Loss: 0.0008\n",
      "Epoch [2/5], Step [9180/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [9190/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [9200/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [9210/9994], Loss: 0.0189\n",
      "Epoch [2/5], Step [9220/9994], Loss: 0.0840\n",
      "Epoch [2/5], Step [9230/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [9240/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [9250/9994], Loss: 0.0139\n",
      "Epoch [2/5], Step [9260/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [9270/9994], Loss: 0.0152\n",
      "Epoch [2/5], Step [9280/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [9290/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [9300/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [9310/9994], Loss: 0.0518\n",
      "Epoch [2/5], Step [9320/9994], Loss: 0.0164\n",
      "Epoch [2/5], Step [9330/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [9340/9994], Loss: 0.0043\n",
      "Epoch [2/5], Step [9350/9994], Loss: 0.0096\n",
      "Epoch [2/5], Step [9360/9994], Loss: 0.0044\n",
      "Epoch [2/5], Step [9370/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [9380/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [9390/9994], Loss: 0.0015\n",
      "Epoch [2/5], Step [9400/9994], Loss: 0.0003\n",
      "Epoch [2/5], Step [9410/9994], Loss: 0.0081\n",
      "Epoch [2/5], Step [9420/9994], Loss: 0.0544\n",
      "Epoch [2/5], Step [9430/9994], Loss: 0.0064\n",
      "Epoch [2/5], Step [9440/9994], Loss: 0.0029\n",
      "Epoch [2/5], Step [9450/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [9460/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [9470/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [9480/9994], Loss: 0.0027\n",
      "Epoch [2/5], Step [9490/9994], Loss: 0.0388\n",
      "Epoch [2/5], Step [9500/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [9510/9994], Loss: 0.0031\n",
      "Epoch [2/5], Step [9520/9994], Loss: 0.0062\n",
      "Epoch [2/5], Step [9530/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [9540/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [9550/9994], Loss: 0.0047\n",
      "Epoch [2/5], Step [9560/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [9570/9994], Loss: 0.0037\n",
      "Epoch [2/5], Step [9580/9994], Loss: 0.0048\n",
      "Epoch [2/5], Step [9590/9994], Loss: 0.0490\n",
      "Epoch [2/5], Step [9600/9994], Loss: 0.0026\n",
      "Epoch [2/5], Step [9610/9994], Loss: 0.0070\n",
      "Epoch [2/5], Step [9620/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [9630/9994], Loss: 0.0032\n",
      "Epoch [2/5], Step [9640/9994], Loss: 0.0226\n",
      "Epoch [2/5], Step [9650/9994], Loss: 0.0022\n",
      "Epoch [2/5], Step [9660/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [9670/9994], Loss: 0.0005\n",
      "Epoch [2/5], Step [9680/9994], Loss: 0.0014\n",
      "Epoch [2/5], Step [9690/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [9700/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [9710/9994], Loss: 0.0018\n",
      "Epoch [2/5], Step [9720/9994], Loss: 0.0036\n",
      "Epoch [2/5], Step [9730/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [9740/9994], Loss: 0.0017\n",
      "Epoch [2/5], Step [9750/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [9760/9994], Loss: 0.0030\n",
      "Epoch [2/5], Step [9770/9994], Loss: 0.0685\n",
      "Epoch [2/5], Step [9780/9994], Loss: 0.0028\n",
      "Epoch [2/5], Step [9790/9994], Loss: 0.0065\n",
      "Epoch [2/5], Step [9800/9994], Loss: 0.0040\n",
      "Epoch [2/5], Step [9810/9994], Loss: 0.0009\n",
      "Epoch [2/5], Step [9820/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [9830/9994], Loss: 0.0007\n",
      "Epoch [2/5], Step [9840/9994], Loss: 0.0010\n",
      "Epoch [2/5], Step [9850/9994], Loss: 0.0004\n",
      "Epoch [2/5], Step [9860/9994], Loss: 0.0021\n",
      "Epoch [2/5], Step [9870/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [9880/9994], Loss: 0.0643\n",
      "Epoch [2/5], Step [9890/9994], Loss: 0.0025\n",
      "Epoch [2/5], Step [9900/9994], Loss: 0.0594\n",
      "Epoch [2/5], Step [9910/9994], Loss: 0.0019\n",
      "Epoch [2/5], Step [9920/9994], Loss: 0.0935\n",
      "Epoch [2/5], Step [9930/9994], Loss: 0.0392\n",
      "Epoch [2/5], Step [9940/9994], Loss: 0.0303\n",
      "Epoch [2/5], Step [9950/9994], Loss: 0.0038\n",
      "Epoch [2/5], Step [9960/9994], Loss: 0.0020\n",
      "Epoch [2/5], Step [9970/9994], Loss: 0.0050\n",
      "Epoch [2/5], Step [9980/9994], Loss: 0.0011\n",
      "Epoch [2/5], Step [9990/9994], Loss: 0.0010\n",
      "Epoch [2/5], Average Train Loss: 0.0161\n",
      "Epoch [2/5], Validation Loss: 0.0166\n",
      "Epoch [3/5], Step [10/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [20/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [30/9994], Loss: 0.0879\n",
      "Epoch [3/5], Step [40/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [50/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [60/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [70/9994], Loss: 0.0395\n",
      "Epoch [3/5], Step [80/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [90/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [100/9994], Loss: 0.0138\n",
      "Epoch [3/5], Step [110/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [120/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [130/9994], Loss: 0.0128\n",
      "Epoch [3/5], Step [140/9994], Loss: 0.0082\n",
      "Epoch [3/5], Step [150/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [160/9994], Loss: 0.0063\n",
      "Epoch [3/5], Step [170/9994], Loss: 0.0057\n",
      "Epoch [3/5], Step [180/9994], Loss: 0.0157\n",
      "Epoch [3/5], Step [190/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [200/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [210/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [220/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [230/9994], Loss: 0.0683\n",
      "Epoch [3/5], Step [240/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [250/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [260/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [270/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [280/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [290/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [300/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [310/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [320/9994], Loss: 0.0135\n",
      "Epoch [3/5], Step [330/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [340/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [350/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [360/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [370/9994], Loss: 0.0501\n",
      "Epoch [3/5], Step [380/9994], Loss: 0.0626\n",
      "Epoch [3/5], Step [390/9994], Loss: 0.0095\n",
      "Epoch [3/5], Step [400/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [410/9994], Loss: 0.0250\n",
      "Epoch [3/5], Step [420/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [430/9994], Loss: 0.0478\n",
      "Epoch [3/5], Step [440/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [450/9994], Loss: 0.0069\n",
      "Epoch [3/5], Step [460/9994], Loss: 0.0132\n",
      "Epoch [3/5], Step [470/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [480/9994], Loss: 0.1964\n",
      "Epoch [3/5], Step [490/9994], Loss: 0.0523\n",
      "Epoch [3/5], Step [500/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [510/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [520/9994], Loss: 0.0327\n",
      "Epoch [3/5], Step [530/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [540/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [550/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [560/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [570/9994], Loss: 0.0083\n",
      "Epoch [3/5], Step [580/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [590/9994], Loss: 0.0331\n",
      "Epoch [3/5], Step [600/9994], Loss: 0.0105\n",
      "Epoch [3/5], Step [610/9994], Loss: 0.0138\n",
      "Epoch [3/5], Step [620/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [630/9994], Loss: 0.0116\n",
      "Epoch [3/5], Step [640/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [650/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [660/9994], Loss: 0.0121\n",
      "Epoch [3/5], Step [670/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [680/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [690/9994], Loss: 0.0067\n",
      "Epoch [3/5], Step [700/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [710/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [720/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [730/9994], Loss: 0.0109\n",
      "Epoch [3/5], Step [740/9994], Loss: 0.0234\n",
      "Epoch [3/5], Step [750/9994], Loss: 0.0950\n",
      "Epoch [3/5], Step [760/9994], Loss: 0.3146\n",
      "Epoch [3/5], Step [770/9994], Loss: 0.0372\n",
      "Epoch [3/5], Step [780/9994], Loss: 0.0550\n",
      "Epoch [3/5], Step [790/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [800/9994], Loss: 0.0058\n",
      "Epoch [3/5], Step [810/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [820/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [830/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [840/9994], Loss: 0.0153\n",
      "Epoch [3/5], Step [850/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [860/9994], Loss: 0.0799\n",
      "Epoch [3/5], Step [870/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [880/9994], Loss: 0.0060\n",
      "Epoch [3/5], Step [890/9994], Loss: 0.1843\n",
      "Epoch [3/5], Step [900/9994], Loss: 0.0036\n",
      "Epoch [3/5], Step [910/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [920/9994], Loss: 0.0072\n",
      "Epoch [3/5], Step [930/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [940/9994], Loss: 0.0433\n",
      "Epoch [3/5], Step [950/9994], Loss: 0.0125\n",
      "Epoch [3/5], Step [960/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [970/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [980/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [990/9994], Loss: 0.0626\n",
      "Epoch [3/5], Step [1000/9994], Loss: 0.0080\n",
      "Epoch [3/5], Step [1010/9994], Loss: 0.0482\n",
      "Epoch [3/5], Step [1020/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [1030/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [1040/9994], Loss: 0.0545\n",
      "Epoch [3/5], Step [1050/9994], Loss: 0.0300\n",
      "Epoch [3/5], Step [1060/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [1070/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [1080/9994], Loss: 0.0447\n",
      "Epoch [3/5], Step [1090/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [1100/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [1110/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [1120/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [1130/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [1140/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [1150/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [1160/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [1170/9994], Loss: 0.0135\n",
      "Epoch [3/5], Step [1180/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [1190/9994], Loss: 0.0072\n",
      "Epoch [3/5], Step [1200/9994], Loss: 0.0089\n",
      "Epoch [3/5], Step [1210/9994], Loss: 0.0179\n",
      "Epoch [3/5], Step [1220/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [1230/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [1240/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [1250/9994], Loss: 0.0054\n",
      "Epoch [3/5], Step [1260/9994], Loss: 0.0208\n",
      "Epoch [3/5], Step [1270/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [1280/9994], Loss: 0.1347\n",
      "Epoch [3/5], Step [1290/9994], Loss: 0.0082\n",
      "Epoch [3/5], Step [1300/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [1310/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [1320/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [1330/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [1340/9994], Loss: 0.0531\n",
      "Epoch [3/5], Step [1350/9994], Loss: 0.0407\n",
      "Epoch [3/5], Step [1360/9994], Loss: 0.0098\n",
      "Epoch [3/5], Step [1370/9994], Loss: 0.0060\n",
      "Epoch [3/5], Step [1380/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [1390/9994], Loss: 0.0159\n",
      "Epoch [3/5], Step [1400/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [1410/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [1420/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [1430/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [1440/9994], Loss: 0.0601\n",
      "Epoch [3/5], Step [1450/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [1460/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [1470/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [1480/9994], Loss: 0.0099\n",
      "Epoch [3/5], Step [1490/9994], Loss: 0.0108\n",
      "Epoch [3/5], Step [1500/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [1510/9994], Loss: 0.0102\n",
      "Epoch [3/5], Step [1520/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [1530/9994], Loss: 0.0432\n",
      "Epoch [3/5], Step [1540/9994], Loss: 0.0158\n",
      "Epoch [3/5], Step [1550/9994], Loss: 0.0871\n",
      "Epoch [3/5], Step [1560/9994], Loss: 0.0476\n",
      "Epoch [3/5], Step [1570/9994], Loss: 0.0200\n",
      "Epoch [3/5], Step [1580/9994], Loss: 0.0181\n",
      "Epoch [3/5], Step [1590/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [1600/9994], Loss: 0.0065\n",
      "Epoch [3/5], Step [1610/9994], Loss: 0.0074\n",
      "Epoch [3/5], Step [1620/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [1630/9994], Loss: 0.0064\n",
      "Epoch [3/5], Step [1640/9994], Loss: 0.0040\n",
      "Epoch [3/5], Step [1650/9994], Loss: 0.1045\n",
      "Epoch [3/5], Step [1660/9994], Loss: 0.0217\n",
      "Epoch [3/5], Step [1670/9994], Loss: 0.0402\n",
      "Epoch [3/5], Step [1680/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [1690/9994], Loss: 0.0065\n",
      "Epoch [3/5], Step [1700/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [1710/9994], Loss: 0.0217\n",
      "Epoch [3/5], Step [1720/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [1730/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [1740/9994], Loss: 0.0458\n",
      "Epoch [3/5], Step [1750/9994], Loss: 0.0057\n",
      "Epoch [3/5], Step [1760/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [1770/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [1780/9994], Loss: 0.0539\n",
      "Epoch [3/5], Step [1790/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [1800/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [1810/9994], Loss: 0.0052\n",
      "Epoch [3/5], Step [1820/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [1830/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [1840/9994], Loss: 0.0384\n",
      "Epoch [3/5], Step [1850/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [1860/9994], Loss: 0.0900\n",
      "Epoch [3/5], Step [1870/9994], Loss: 0.1524\n",
      "Epoch [3/5], Step [1880/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [1890/9994], Loss: 0.0103\n",
      "Epoch [3/5], Step [1900/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [1910/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [1920/9994], Loss: 0.0173\n",
      "Epoch [3/5], Step [1930/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [1940/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [1950/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [1960/9994], Loss: 0.1059\n",
      "Epoch [3/5], Step [1970/9994], Loss: 0.0068\n",
      "Epoch [3/5], Step [1980/9994], Loss: 0.0399\n",
      "Epoch [3/5], Step [1990/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [2000/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [2010/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [2020/9994], Loss: 0.0572\n",
      "Epoch [3/5], Step [2030/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [2040/9994], Loss: 0.0213\n",
      "Epoch [3/5], Step [2050/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [2060/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [2070/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [2080/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [2090/9994], Loss: 0.0214\n",
      "Epoch [3/5], Step [2100/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [2110/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [2120/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [2130/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [2140/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [2150/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [2160/9994], Loss: 0.0073\n",
      "Epoch [3/5], Step [2170/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [2180/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [2190/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [2200/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [2210/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [2220/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [2230/9994], Loss: 0.0329\n",
      "Epoch [3/5], Step [2240/9994], Loss: 0.0095\n",
      "Epoch [3/5], Step [2250/9994], Loss: 0.0076\n",
      "Epoch [3/5], Step [2260/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [2270/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [2280/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [2290/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [2300/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [2310/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [2320/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [2330/9994], Loss: 0.0040\n",
      "Epoch [3/5], Step [2340/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [2350/9994], Loss: 0.0275\n",
      "Epoch [3/5], Step [2360/9994], Loss: 0.0065\n",
      "Epoch [3/5], Step [2370/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [2380/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [2390/9994], Loss: 0.0297\n",
      "Epoch [3/5], Step [2400/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [2410/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [2420/9994], Loss: 0.0086\n",
      "Epoch [3/5], Step [2430/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [2440/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [2450/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [2460/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [2470/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [2480/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [2490/9994], Loss: 0.0276\n",
      "Epoch [3/5], Step [2500/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [2510/9994], Loss: 0.0061\n",
      "Epoch [3/5], Step [2520/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [2530/9994], Loss: 0.0093\n",
      "Epoch [3/5], Step [2540/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [2550/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [2560/9994], Loss: 0.0066\n",
      "Epoch [3/5], Step [2570/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [2580/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [2590/9994], Loss: 0.0974\n",
      "Epoch [3/5], Step [2600/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [2610/9994], Loss: 0.0117\n",
      "Epoch [3/5], Step [2620/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [2630/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [2640/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [2650/9994], Loss: 0.0067\n",
      "Epoch [3/5], Step [2660/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [2670/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [2680/9994], Loss: 0.0423\n",
      "Epoch [3/5], Step [2690/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [2700/9994], Loss: 0.0552\n",
      "Epoch [3/5], Step [2710/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [2720/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [2730/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [2740/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [2750/9994], Loss: 0.0457\n",
      "Epoch [3/5], Step [2760/9994], Loss: 0.0282\n",
      "Epoch [3/5], Step [2770/9994], Loss: 0.0230\n",
      "Epoch [3/5], Step [2780/9994], Loss: 0.0290\n",
      "Epoch [3/5], Step [2790/9994], Loss: 0.0078\n",
      "Epoch [3/5], Step [2800/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [2810/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [2820/9994], Loss: 0.0729\n",
      "Epoch [3/5], Step [2830/9994], Loss: 0.0193\n",
      "Epoch [3/5], Step [2840/9994], Loss: 0.0033\n",
      "Epoch [3/5], Step [2850/9994], Loss: 0.0035\n",
      "Epoch [3/5], Step [2860/9994], Loss: 0.0098\n",
      "Epoch [3/5], Step [2870/9994], Loss: 0.0062\n",
      "Epoch [3/5], Step [2880/9994], Loss: 0.0051\n",
      "Epoch [3/5], Step [2890/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [2900/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [2910/9994], Loss: 0.0067\n",
      "Epoch [3/5], Step [2920/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [2930/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [2940/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [2950/9994], Loss: 0.0057\n",
      "Epoch [3/5], Step [2960/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [2970/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [2980/9994], Loss: 0.0052\n",
      "Epoch [3/5], Step [2990/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [3000/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [3010/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [3020/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [3030/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [3040/9994], Loss: 0.1120\n",
      "Epoch [3/5], Step [3050/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [3060/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [3070/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [3080/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [3090/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [3100/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [3110/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [3120/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [3130/9994], Loss: 0.0289\n",
      "Epoch [3/5], Step [3140/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [3150/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [3160/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [3170/9994], Loss: 0.0766\n",
      "Epoch [3/5], Step [3180/9994], Loss: 0.0340\n",
      "Epoch [3/5], Step [3190/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [3200/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [3210/9994], Loss: 0.0041\n",
      "Epoch [3/5], Step [3220/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [3230/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [3240/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [3250/9994], Loss: 0.0035\n",
      "Epoch [3/5], Step [3260/9994], Loss: 0.0085\n",
      "Epoch [3/5], Step [3270/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [3280/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [3290/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [3300/9994], Loss: 0.0169\n",
      "Epoch [3/5], Step [3310/9994], Loss: 0.0818\n",
      "Epoch [3/5], Step [3320/9994], Loss: 0.0193\n",
      "Epoch [3/5], Step [3330/9994], Loss: 0.0065\n",
      "Epoch [3/5], Step [3340/9994], Loss: 0.0079\n",
      "Epoch [3/5], Step [3350/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [3360/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [3370/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [3380/9994], Loss: 0.1284\n",
      "Epoch [3/5], Step [3390/9994], Loss: 0.0606\n",
      "Epoch [3/5], Step [3400/9994], Loss: 0.0075\n",
      "Epoch [3/5], Step [3410/9994], Loss: 0.0077\n",
      "Epoch [3/5], Step [3420/9994], Loss: 0.0446\n",
      "Epoch [3/5], Step [3430/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [3440/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [3450/9994], Loss: 0.0512\n",
      "Epoch [3/5], Step [3460/9994], Loss: 0.0206\n",
      "Epoch [3/5], Step [3470/9994], Loss: 0.0055\n",
      "Epoch [3/5], Step [3480/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [3490/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [3500/9994], Loss: 0.0574\n",
      "Epoch [3/5], Step [3510/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [3520/9994], Loss: 0.0121\n",
      "Epoch [3/5], Step [3530/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [3540/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [3550/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [3560/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [3570/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [3580/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [3590/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [3600/9994], Loss: 0.1067\n",
      "Epoch [3/5], Step [3610/9994], Loss: 0.0169\n",
      "Epoch [3/5], Step [3620/9994], Loss: 0.0072\n",
      "Epoch [3/5], Step [3630/9994], Loss: 0.0055\n",
      "Epoch [3/5], Step [3640/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [3650/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [3660/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [3670/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [3680/9994], Loss: 0.0064\n",
      "Epoch [3/5], Step [3690/9994], Loss: 0.0783\n",
      "Epoch [3/5], Step [3700/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [3710/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [3720/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [3730/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [3740/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [3750/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [3760/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [3770/9994], Loss: 0.0854\n",
      "Epoch [3/5], Step [3780/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [3790/9994], Loss: 0.0093\n",
      "Epoch [3/5], Step [3800/9994], Loss: 0.1032\n",
      "Epoch [3/5], Step [3810/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [3820/9994], Loss: 0.0823\n",
      "Epoch [3/5], Step [3830/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [3840/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [3850/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [3860/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [3870/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [3880/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [3890/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [3900/9994], Loss: 0.1554\n",
      "Epoch [3/5], Step [3910/9994], Loss: 0.1346\n",
      "Epoch [3/5], Step [3920/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [3930/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [3940/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [3950/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [3960/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [3970/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [3980/9994], Loss: 0.0115\n",
      "Epoch [3/5], Step [3990/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [4000/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [4010/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [4020/9994], Loss: 0.0123\n",
      "Epoch [3/5], Step [4030/9994], Loss: 0.0735\n",
      "Epoch [3/5], Step [4040/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [4050/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [4060/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [4070/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [4080/9994], Loss: 0.0094\n",
      "Epoch [3/5], Step [4090/9994], Loss: 0.0059\n",
      "Epoch [3/5], Step [4100/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [4110/9994], Loss: 0.0151\n",
      "Epoch [3/5], Step [4120/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [4130/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [4140/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [4150/9994], Loss: 0.0000\n",
      "Epoch [3/5], Step [4160/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [4170/9994], Loss: 0.0108\n",
      "Epoch [3/5], Step [4180/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [4190/9994], Loss: 0.0294\n",
      "Epoch [3/5], Step [4200/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [4210/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [4220/9994], Loss: 0.0158\n",
      "Epoch [3/5], Step [4230/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [4240/9994], Loss: 0.0068\n",
      "Epoch [3/5], Step [4250/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [4260/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [4270/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [4280/9994], Loss: 0.0734\n",
      "Epoch [3/5], Step [4290/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [4300/9994], Loss: 0.0033\n",
      "Epoch [3/5], Step [4310/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [4320/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [4330/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [4340/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [4350/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [4360/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [4370/9994], Loss: 0.0035\n",
      "Epoch [3/5], Step [4380/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [4390/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [4400/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [4410/9994], Loss: 0.0036\n",
      "Epoch [3/5], Step [4420/9994], Loss: 0.0218\n",
      "Epoch [3/5], Step [4430/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [4440/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [4450/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [4460/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [4470/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [4480/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [4490/9994], Loss: 0.1846\n",
      "Epoch [3/5], Step [4500/9994], Loss: 0.0086\n",
      "Epoch [3/5], Step [4510/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [4520/9994], Loss: 0.0055\n",
      "Epoch [3/5], Step [4530/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [4540/9994], Loss: 0.0298\n",
      "Epoch [3/5], Step [4550/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [4560/9994], Loss: 0.0054\n",
      "Epoch [3/5], Step [4570/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [4580/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [4590/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [4600/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [4610/9994], Loss: 0.0587\n",
      "Epoch [3/5], Step [4620/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [4630/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [4640/9994], Loss: 0.0463\n",
      "Epoch [3/5], Step [4650/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [4660/9994], Loss: 0.0539\n",
      "Epoch [3/5], Step [4670/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [4680/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [4690/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [4700/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [4710/9994], Loss: 0.0172\n",
      "Epoch [3/5], Step [4720/9994], Loss: 0.0125\n",
      "Epoch [3/5], Step [4730/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [4740/9994], Loss: 0.0660\n",
      "Epoch [3/5], Step [4750/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [4760/9994], Loss: 0.0179\n",
      "Epoch [3/5], Step [4770/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [4780/9994], Loss: 0.0050\n",
      "Epoch [3/5], Step [4790/9994], Loss: 0.0109\n",
      "Epoch [3/5], Step [4800/9994], Loss: 0.0080\n",
      "Epoch [3/5], Step [4810/9994], Loss: 0.0111\n",
      "Epoch [3/5], Step [4820/9994], Loss: 0.0199\n",
      "Epoch [3/5], Step [4830/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [4840/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [4850/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [4860/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [4870/9994], Loss: 0.0515\n",
      "Epoch [3/5], Step [4880/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [4890/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [4900/9994], Loss: 0.0054\n",
      "Epoch [3/5], Step [4910/9994], Loss: 0.0061\n",
      "Epoch [3/5], Step [4920/9994], Loss: 0.0095\n",
      "Epoch [3/5], Step [4930/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [4940/9994], Loss: 0.0072\n",
      "Epoch [3/5], Step [4950/9994], Loss: 0.0510\n",
      "Epoch [3/5], Step [4960/9994], Loss: 0.0505\n",
      "Epoch [3/5], Step [4970/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [4980/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [4990/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [5000/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [5010/9994], Loss: 0.0450\n",
      "Epoch [3/5], Step [5020/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [5030/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [5040/9994], Loss: 0.0115\n",
      "Epoch [3/5], Step [5050/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [5060/9994], Loss: 0.0105\n",
      "Epoch [3/5], Step [5070/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [5080/9994], Loss: 0.0051\n",
      "Epoch [3/5], Step [5090/9994], Loss: 0.0399\n",
      "Epoch [3/5], Step [5100/9994], Loss: 0.0100\n",
      "Epoch [3/5], Step [5110/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [5120/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [5130/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [5140/9994], Loss: 0.0509\n",
      "Epoch [3/5], Step [5150/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [5160/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [5170/9994], Loss: 0.0172\n",
      "Epoch [3/5], Step [5180/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [5190/9994], Loss: 0.0639\n",
      "Epoch [3/5], Step [5200/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [5210/9994], Loss: 0.0337\n",
      "Epoch [3/5], Step [5220/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [5230/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [5240/9994], Loss: 0.0205\n",
      "Epoch [3/5], Step [5250/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [5260/9994], Loss: 0.0055\n",
      "Epoch [3/5], Step [5270/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [5280/9994], Loss: 0.0150\n",
      "Epoch [3/5], Step [5290/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [5300/9994], Loss: 0.0040\n",
      "Epoch [3/5], Step [5310/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [5320/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [5330/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [5340/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [5350/9994], Loss: 0.0040\n",
      "Epoch [3/5], Step [5360/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [5370/9994], Loss: 0.0036\n",
      "Epoch [3/5], Step [5380/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [5390/9994], Loss: 0.0166\n",
      "Epoch [3/5], Step [5400/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [5410/9994], Loss: 0.0041\n",
      "Epoch [3/5], Step [5420/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [5430/9994], Loss: 0.0111\n",
      "Epoch [3/5], Step [5440/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [5450/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [5460/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [5470/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [5480/9994], Loss: 0.0143\n",
      "Epoch [3/5], Step [5490/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [5500/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [5510/9994], Loss: 0.0121\n",
      "Epoch [3/5], Step [5520/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [5530/9994], Loss: 0.0108\n",
      "Epoch [3/5], Step [5540/9994], Loss: 0.0172\n",
      "Epoch [3/5], Step [5550/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [5560/9994], Loss: 0.0938\n",
      "Epoch [3/5], Step [5570/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [5580/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [5590/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [5600/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [5610/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [5620/9994], Loss: 0.1407\n",
      "Epoch [3/5], Step [5630/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [5640/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [5650/9994], Loss: 0.0033\n",
      "Epoch [3/5], Step [5660/9994], Loss: 0.0072\n",
      "Epoch [3/5], Step [5670/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [5680/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [5690/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [5700/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [5710/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [5720/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [5730/9994], Loss: 0.0272\n",
      "Epoch [3/5], Step [5740/9994], Loss: 0.0094\n",
      "Epoch [3/5], Step [5750/9994], Loss: 0.0202\n",
      "Epoch [3/5], Step [5760/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [5770/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [5780/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [5790/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [5800/9994], Loss: 0.0216\n",
      "Epoch [3/5], Step [5810/9994], Loss: 0.0203\n",
      "Epoch [3/5], Step [5820/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [5830/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [5840/9994], Loss: 0.0063\n",
      "Epoch [3/5], Step [5850/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [5860/9994], Loss: 0.0097\n",
      "Epoch [3/5], Step [5870/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [5880/9994], Loss: 0.0035\n",
      "Epoch [3/5], Step [5890/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [5900/9994], Loss: 0.0060\n",
      "Epoch [3/5], Step [5910/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [5920/9994], Loss: 0.0597\n",
      "Epoch [3/5], Step [5930/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [5940/9994], Loss: 0.0670\n",
      "Epoch [3/5], Step [5950/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [5960/9994], Loss: 0.0532\n",
      "Epoch [3/5], Step [5970/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [5980/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [5990/9994], Loss: 0.0002\n",
      "Epoch [3/5], Step [6000/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [6010/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [6020/9994], Loss: 0.0545\n",
      "Epoch [3/5], Step [6030/9994], Loss: 0.0702\n",
      "Epoch [3/5], Step [6040/9994], Loss: 0.0279\n",
      "Epoch [3/5], Step [6050/9994], Loss: 0.0111\n",
      "Epoch [3/5], Step [6060/9994], Loss: 0.0303\n",
      "Epoch [3/5], Step [6070/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [6080/9994], Loss: 0.0402\n",
      "Epoch [3/5], Step [6090/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [6100/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [6110/9994], Loss: 0.0187\n",
      "Epoch [3/5], Step [6120/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [6130/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [6140/9994], Loss: 0.0074\n",
      "Epoch [3/5], Step [6150/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [6160/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [6170/9994], Loss: 0.0187\n",
      "Epoch [3/5], Step [6180/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [6190/9994], Loss: 0.0118\n",
      "Epoch [3/5], Step [6200/9994], Loss: 0.0882\n",
      "Epoch [3/5], Step [6210/9994], Loss: 0.0349\n",
      "Epoch [3/5], Step [6220/9994], Loss: 0.0236\n",
      "Epoch [3/5], Step [6230/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [6240/9994], Loss: 0.0053\n",
      "Epoch [3/5], Step [6250/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [6260/9994], Loss: 0.0093\n",
      "Epoch [3/5], Step [6270/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [6280/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [6290/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [6300/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [6310/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [6320/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [6330/9994], Loss: 0.0634\n",
      "Epoch [3/5], Step [6340/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [6350/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [6360/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [6370/9994], Loss: 0.0173\n",
      "Epoch [3/5], Step [6380/9994], Loss: 0.0974\n",
      "Epoch [3/5], Step [6390/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [6400/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [6410/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [6420/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [6430/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [6440/9994], Loss: 0.0717\n",
      "Epoch [3/5], Step [6450/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [6460/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [6470/9994], Loss: 0.0620\n",
      "Epoch [3/5], Step [6480/9994], Loss: 0.0197\n",
      "Epoch [3/5], Step [6490/9994], Loss: 0.0063\n",
      "Epoch [3/5], Step [6500/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [6510/9994], Loss: 0.0041\n",
      "Epoch [3/5], Step [6520/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [6530/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [6540/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [6550/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [6560/9994], Loss: 0.0694\n",
      "Epoch [3/5], Step [6570/9994], Loss: 0.0473\n",
      "Epoch [3/5], Step [6580/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [6590/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [6600/9994], Loss: 0.0064\n",
      "Epoch [3/5], Step [6610/9994], Loss: 0.0000\n",
      "Epoch [3/5], Step [6620/9994], Loss: 0.0144\n",
      "Epoch [3/5], Step [6630/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [6640/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [6650/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [6660/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [6670/9994], Loss: 0.0248\n",
      "Epoch [3/5], Step [6680/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [6690/9994], Loss: 0.0135\n",
      "Epoch [3/5], Step [6700/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [6710/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [6720/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [6730/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [6740/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [6750/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [6760/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [6770/9994], Loss: 0.0350\n",
      "Epoch [3/5], Step [6780/9994], Loss: 0.0060\n",
      "Epoch [3/5], Step [6790/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [6800/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [6810/9994], Loss: 0.0081\n",
      "Epoch [3/5], Step [6820/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [6830/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [6840/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [6850/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [6860/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [6870/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [6880/9994], Loss: 0.0059\n",
      "Epoch [3/5], Step [6890/9994], Loss: 0.0036\n",
      "Epoch [3/5], Step [6900/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [6910/9994], Loss: 0.0088\n",
      "Epoch [3/5], Step [6920/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [6930/9994], Loss: 0.0372\n",
      "Epoch [3/5], Step [6940/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [6950/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [6960/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [6970/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [6980/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [6990/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [7000/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [7010/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [7020/9994], Loss: 0.0052\n",
      "Epoch [3/5], Step [7030/9994], Loss: 0.0265\n",
      "Epoch [3/5], Step [7040/9994], Loss: 0.0100\n",
      "Epoch [3/5], Step [7050/9994], Loss: 0.0065\n",
      "Epoch [3/5], Step [7060/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [7070/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [7080/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [7090/9994], Loss: 0.0426\n",
      "Epoch [3/5], Step [7100/9994], Loss: 0.0268\n",
      "Epoch [3/5], Step [7110/9994], Loss: 0.1800\n",
      "Epoch [3/5], Step [7120/9994], Loss: 0.0384\n",
      "Epoch [3/5], Step [7130/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [7140/9994], Loss: 0.0596\n",
      "Epoch [3/5], Step [7150/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [7160/9994], Loss: 0.0110\n",
      "Epoch [3/5], Step [7170/9994], Loss: 0.0132\n",
      "Epoch [3/5], Step [7180/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [7190/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [7200/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [7210/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [7220/9994], Loss: 0.0336\n",
      "Epoch [3/5], Step [7230/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [7240/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [7250/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [7260/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [7270/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [7280/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [7290/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [7300/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [7310/9994], Loss: 0.0052\n",
      "Epoch [3/5], Step [7320/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [7330/9994], Loss: 0.0742\n",
      "Epoch [3/5], Step [7340/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [7350/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [7360/9994], Loss: 0.0077\n",
      "Epoch [3/5], Step [7370/9994], Loss: 0.0118\n",
      "Epoch [3/5], Step [7380/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [7390/9994], Loss: 0.0353\n",
      "Epoch [3/5], Step [7400/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [7410/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [7420/9994], Loss: 0.0224\n",
      "Epoch [3/5], Step [7430/9994], Loss: 0.0052\n",
      "Epoch [3/5], Step [7440/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [7450/9994], Loss: 0.0048\n",
      "Epoch [3/5], Step [7460/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [7470/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [7480/9994], Loss: 0.0495\n",
      "Epoch [3/5], Step [7490/9994], Loss: 0.0415\n",
      "Epoch [3/5], Step [7500/9994], Loss: 0.0031\n",
      "Epoch [3/5], Step [7510/9994], Loss: 0.0151\n",
      "Epoch [3/5], Step [7520/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [7530/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [7540/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [7550/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [7560/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [7570/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [7580/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [7590/9994], Loss: 0.0202\n",
      "Epoch [3/5], Step [7600/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [7610/9994], Loss: 0.0336\n",
      "Epoch [3/5], Step [7620/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [7630/9994], Loss: 0.0109\n",
      "Epoch [3/5], Step [7640/9994], Loss: 0.0406\n",
      "Epoch [3/5], Step [7650/9994], Loss: 0.0164\n",
      "Epoch [3/5], Step [7660/9994], Loss: 0.0456\n",
      "Epoch [3/5], Step [7670/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [7680/9994], Loss: 0.0459\n",
      "Epoch [3/5], Step [7690/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [7700/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [7710/9994], Loss: 0.1229\n",
      "Epoch [3/5], Step [7720/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [7730/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [7740/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [7750/9994], Loss: 0.0133\n",
      "Epoch [3/5], Step [7760/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [7770/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [7780/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [7790/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [7800/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [7810/9994], Loss: 0.0002\n",
      "Epoch [3/5], Step [7820/9994], Loss: 0.0003\n",
      "Epoch [3/5], Step [7830/9994], Loss: 0.0006\n",
      "Epoch [3/5], Step [7840/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [7850/9994], Loss: 0.0030\n",
      "Epoch [3/5], Step [7860/9994], Loss: 0.0067\n",
      "Epoch [3/5], Step [7870/9994], Loss: 0.0611\n",
      "Epoch [3/5], Step [7880/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [7890/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [7900/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [7910/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [7920/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [7930/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [7940/9994], Loss: 0.0002\n",
      "Epoch [3/5], Step [7950/9994], Loss: 0.0062\n",
      "Epoch [3/5], Step [7960/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [7970/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [7980/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [7990/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [8000/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [8010/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [8020/9994], Loss: 0.0087\n",
      "Epoch [3/5], Step [8030/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [8040/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [8050/9994], Loss: 0.0273\n",
      "Epoch [3/5], Step [8060/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [8070/9994], Loss: 0.0002\n",
      "Epoch [3/5], Step [8080/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [8090/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [8100/9994], Loss: 0.1070\n",
      "Epoch [3/5], Step [8110/9994], Loss: 0.0596\n",
      "Epoch [3/5], Step [8120/9994], Loss: 0.0074\n",
      "Epoch [3/5], Step [8130/9994], Loss: 0.0095\n",
      "Epoch [3/5], Step [8140/9994], Loss: 0.0195\n",
      "Epoch [3/5], Step [8150/9994], Loss: 0.0789\n",
      "Epoch [3/5], Step [8160/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [8170/9994], Loss: 0.0698\n",
      "Epoch [3/5], Step [8180/9994], Loss: 0.0827\n",
      "Epoch [3/5], Step [8190/9994], Loss: 0.0714\n",
      "Epoch [3/5], Step [8200/9994], Loss: 0.0343\n",
      "Epoch [3/5], Step [8210/9994], Loss: 0.0061\n",
      "Epoch [3/5], Step [8220/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [8230/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [8240/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [8250/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [8260/9994], Loss: 0.0681\n",
      "Epoch [3/5], Step [8270/9994], Loss: 0.0337\n",
      "Epoch [3/5], Step [8280/9994], Loss: 0.0697\n",
      "Epoch [3/5], Step [8290/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [8300/9994], Loss: 0.0305\n",
      "Epoch [3/5], Step [8310/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [8320/9994], Loss: 0.0095\n",
      "Epoch [3/5], Step [8330/9994], Loss: 0.0593\n",
      "Epoch [3/5], Step [8340/9994], Loss: 0.0049\n",
      "Epoch [3/5], Step [8350/9994], Loss: 0.0227\n",
      "Epoch [3/5], Step [8360/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [8370/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [8380/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [8390/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [8400/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [8410/9994], Loss: 0.0554\n",
      "Epoch [3/5], Step [8420/9994], Loss: 0.0751\n",
      "Epoch [3/5], Step [8430/9994], Loss: 0.0407\n",
      "Epoch [3/5], Step [8440/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [8450/9994], Loss: 0.0838\n",
      "Epoch [3/5], Step [8460/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [8470/9994], Loss: 0.0330\n",
      "Epoch [3/5], Step [8480/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [8490/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [8500/9994], Loss: 0.0587\n",
      "Epoch [3/5], Step [8510/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [8520/9994], Loss: 0.0180\n",
      "Epoch [3/5], Step [8530/9994], Loss: 0.0063\n",
      "Epoch [3/5], Step [8540/9994], Loss: 0.0027\n",
      "Epoch [3/5], Step [8550/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [8560/9994], Loss: 0.0062\n",
      "Epoch [3/5], Step [8570/9994], Loss: 0.0411\n",
      "Epoch [3/5], Step [8580/9994], Loss: 0.0621\n",
      "Epoch [3/5], Step [8590/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [8600/9994], Loss: 0.0018\n",
      "Epoch [3/5], Step [8610/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [8620/9994], Loss: 0.0044\n",
      "Epoch [3/5], Step [8630/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [8640/9994], Loss: 0.0087\n",
      "Epoch [3/5], Step [8650/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [8660/9994], Loss: 0.0047\n",
      "Epoch [3/5], Step [8670/9994], Loss: 0.0022\n",
      "Epoch [3/5], Step [8680/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [8690/9994], Loss: 0.0185\n",
      "Epoch [3/5], Step [8700/9994], Loss: 0.0614\n",
      "Epoch [3/5], Step [8710/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [8720/9994], Loss: 0.0609\n",
      "Epoch [3/5], Step [8730/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [8740/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [8750/9994], Loss: 0.0028\n",
      "Epoch [3/5], Step [8760/9994], Loss: 0.0053\n",
      "Epoch [3/5], Step [8770/9994], Loss: 0.0041\n",
      "Epoch [3/5], Step [8780/9994], Loss: 0.0096\n",
      "Epoch [3/5], Step [8790/9994], Loss: 0.0035\n",
      "Epoch [3/5], Step [8800/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [8810/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [8820/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [8830/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [8840/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [8850/9994], Loss: 0.0066\n",
      "Epoch [3/5], Step [8860/9994], Loss: 0.0188\n",
      "Epoch [3/5], Step [8870/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [8880/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [8890/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [8900/9994], Loss: 0.0058\n",
      "Epoch [3/5], Step [8910/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [8920/9994], Loss: 0.0019\n",
      "Epoch [3/5], Step [8930/9994], Loss: 0.0043\n",
      "Epoch [3/5], Step [8940/9994], Loss: 0.0025\n",
      "Epoch [3/5], Step [8950/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [8960/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [8970/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [8980/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [8990/9994], Loss: 0.0064\n",
      "Epoch [3/5], Step [9000/9994], Loss: 0.0045\n",
      "Epoch [3/5], Step [9010/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [9020/9994], Loss: 0.0492\n",
      "Epoch [3/5], Step [9030/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [9040/9994], Loss: 0.0360\n",
      "Epoch [3/5], Step [9050/9994], Loss: 0.0091\n",
      "Epoch [3/5], Step [9060/9994], Loss: 0.0059\n",
      "Epoch [3/5], Step [9070/9994], Loss: 0.0057\n",
      "Epoch [3/5], Step [9080/9994], Loss: 0.0152\n",
      "Epoch [3/5], Step [9090/9994], Loss: 0.0039\n",
      "Epoch [3/5], Step [9100/9994], Loss: 0.0349\n",
      "Epoch [3/5], Step [9110/9994], Loss: 0.0040\n",
      "Epoch [3/5], Step [9120/9994], Loss: 0.0079\n",
      "Epoch [3/5], Step [9130/9994], Loss: 0.0365\n",
      "Epoch [3/5], Step [9140/9994], Loss: 0.0451\n",
      "Epoch [3/5], Step [9150/9994], Loss: 0.0090\n",
      "Epoch [3/5], Step [9160/9994], Loss: 0.0067\n",
      "Epoch [3/5], Step [9170/9994], Loss: 0.0211\n",
      "Epoch [3/5], Step [9180/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [9190/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [9200/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [9210/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [9220/9994], Loss: 0.0502\n",
      "Epoch [3/5], Step [9230/9994], Loss: 0.0041\n",
      "Epoch [3/5], Step [9240/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [9250/9994], Loss: 0.0042\n",
      "Epoch [3/5], Step [9260/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [9270/9994], Loss: 0.0000\n",
      "Epoch [3/5], Step [9280/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [9290/9994], Loss: 0.0061\n",
      "Epoch [3/5], Step [9300/9994], Loss: 0.0111\n",
      "Epoch [3/5], Step [9310/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [9320/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [9330/9994], Loss: 0.0331\n",
      "Epoch [3/5], Step [9340/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [9350/9994], Loss: 0.0226\n",
      "Epoch [3/5], Step [9360/9994], Loss: 0.0348\n",
      "Epoch [3/5], Step [9370/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [9380/9994], Loss: 0.0032\n",
      "Epoch [3/5], Step [9390/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [9400/9994], Loss: 0.0531\n",
      "Epoch [3/5], Step [9410/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [9420/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [9430/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [9440/9994], Loss: 0.0038\n",
      "Epoch [3/5], Step [9450/9994], Loss: 0.0016\n",
      "Epoch [3/5], Step [9460/9994], Loss: 0.0051\n",
      "Epoch [3/5], Step [9470/9994], Loss: 0.0174\n",
      "Epoch [3/5], Step [9480/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [9490/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [9500/9994], Loss: 0.0001\n",
      "Epoch [3/5], Step [9510/9994], Loss: 0.0160\n",
      "Epoch [3/5], Step [9520/9994], Loss: 0.0229\n",
      "Epoch [3/5], Step [9530/9994], Loss: 0.0087\n",
      "Epoch [3/5], Step [9540/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [9550/9994], Loss: 0.0017\n",
      "Epoch [3/5], Step [9560/9994], Loss: 0.0010\n",
      "Epoch [3/5], Step [9570/9994], Loss: 0.0020\n",
      "Epoch [3/5], Step [9580/9994], Loss: 0.0034\n",
      "Epoch [3/5], Step [9590/9994], Loss: 0.0024\n",
      "Epoch [3/5], Step [9600/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [9610/9994], Loss: 0.0525\n",
      "Epoch [3/5], Step [9620/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [9630/9994], Loss: 0.0021\n",
      "Epoch [3/5], Step [9640/9994], Loss: 0.0256\n",
      "Epoch [3/5], Step [9650/9994], Loss: 0.0364\n",
      "Epoch [3/5], Step [9660/9994], Loss: 0.0015\n",
      "Epoch [3/5], Step [9670/9994], Loss: 0.0287\n",
      "Epoch [3/5], Step [9680/9994], Loss: 0.0009\n",
      "Epoch [3/5], Step [9690/9994], Loss: 0.0023\n",
      "Epoch [3/5], Step [9700/9994], Loss: 0.0002\n",
      "Epoch [3/5], Step [9710/9994], Loss: 0.0852\n",
      "Epoch [3/5], Step [9720/9994], Loss: 0.0013\n",
      "Epoch [3/5], Step [9730/9994], Loss: 0.0759\n",
      "Epoch [3/5], Step [9740/9994], Loss: 0.0012\n",
      "Epoch [3/5], Step [9750/9994], Loss: 0.0141\n",
      "Epoch [3/5], Step [9760/9994], Loss: 0.0037\n",
      "Epoch [3/5], Step [9770/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [9780/9994], Loss: 0.0064\n",
      "Epoch [3/5], Step [9790/9994], Loss: 0.0304\n",
      "Epoch [3/5], Step [9800/9994], Loss: 0.0106\n",
      "Epoch [3/5], Step [9810/9994], Loss: 0.0029\n",
      "Epoch [3/5], Step [9820/9994], Loss: 0.0056\n",
      "Epoch [3/5], Step [9830/9994], Loss: 0.0014\n",
      "Epoch [3/5], Step [9840/9994], Loss: 0.0005\n",
      "Epoch [3/5], Step [9850/9994], Loss: 0.1172\n",
      "Epoch [3/5], Step [9860/9994], Loss: 0.0428\n",
      "Epoch [3/5], Step [9870/9994], Loss: 0.0058\n",
      "Epoch [3/5], Step [9880/9994], Loss: 0.0109\n",
      "Epoch [3/5], Step [9890/9994], Loss: 0.0058\n",
      "Epoch [3/5], Step [9900/9994], Loss: 0.0033\n",
      "Epoch [3/5], Step [9910/9994], Loss: 0.0036\n",
      "Epoch [3/5], Step [9920/9994], Loss: 0.0446\n",
      "Epoch [3/5], Step [9930/9994], Loss: 0.0026\n",
      "Epoch [3/5], Step [9940/9994], Loss: 0.0004\n",
      "Epoch [3/5], Step [9950/9994], Loss: 0.0007\n",
      "Epoch [3/5], Step [9960/9994], Loss: 0.0011\n",
      "Epoch [3/5], Step [9970/9994], Loss: 0.0046\n",
      "Epoch [3/5], Step [9980/9994], Loss: 0.0008\n",
      "Epoch [3/5], Step [9990/9994], Loss: 0.1097\n",
      "Epoch [3/5], Average Train Loss: 0.0134\n",
      "Epoch [3/5], Validation Loss: 0.0171\n",
      "Epoch [4/5], Step [10/9994], Loss: 0.0532\n",
      "Epoch [4/5], Step [20/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [30/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [40/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [50/9994], Loss: 0.0109\n",
      "Epoch [4/5], Step [60/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [70/9994], Loss: 0.0378\n",
      "Epoch [4/5], Step [80/9994], Loss: 0.0049\n",
      "Epoch [4/5], Step [90/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [100/9994], Loss: 0.0071\n",
      "Epoch [4/5], Step [110/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [120/9994], Loss: 0.0441\n",
      "Epoch [4/5], Step [130/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [140/9994], Loss: 0.0518\n",
      "Epoch [4/5], Step [150/9994], Loss: 0.0088\n",
      "Epoch [4/5], Step [160/9994], Loss: 0.0079\n",
      "Epoch [4/5], Step [170/9994], Loss: 0.0158\n",
      "Epoch [4/5], Step [180/9994], Loss: 0.0077\n",
      "Epoch [4/5], Step [190/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [200/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [210/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [220/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [230/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [240/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [250/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [260/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [270/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [280/9994], Loss: 0.0835\n",
      "Epoch [4/5], Step [290/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [300/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [310/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [320/9994], Loss: 0.0047\n",
      "Epoch [4/5], Step [330/9994], Loss: 0.0236\n",
      "Epoch [4/5], Step [340/9994], Loss: 0.0734\n",
      "Epoch [4/5], Step [350/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [360/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [370/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [380/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [390/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [400/9994], Loss: 0.0084\n",
      "Epoch [4/5], Step [410/9994], Loss: 0.0055\n",
      "Epoch [4/5], Step [420/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [430/9994], Loss: 0.0259\n",
      "Epoch [4/5], Step [440/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [450/9994], Loss: 0.0071\n",
      "Epoch [4/5], Step [460/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [470/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [480/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [490/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [500/9994], Loss: 0.0600\n",
      "Epoch [4/5], Step [510/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [520/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [530/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [540/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [550/9994], Loss: 0.0086\n",
      "Epoch [4/5], Step [560/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [570/9994], Loss: 0.0228\n",
      "Epoch [4/5], Step [580/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [590/9994], Loss: 0.0198\n",
      "Epoch [4/5], Step [600/9994], Loss: 0.0071\n",
      "Epoch [4/5], Step [610/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [620/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [630/9994], Loss: 0.1100\n",
      "Epoch [4/5], Step [640/9994], Loss: 0.0376\n",
      "Epoch [4/5], Step [650/9994], Loss: 0.0050\n",
      "Epoch [4/5], Step [660/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [670/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [680/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [690/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [700/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [710/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [720/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [730/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [740/9994], Loss: 0.0100\n",
      "Epoch [4/5], Step [750/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [760/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [770/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [780/9994], Loss: 0.0124\n",
      "Epoch [4/5], Step [790/9994], Loss: 0.0062\n",
      "Epoch [4/5], Step [800/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [810/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [820/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [830/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [840/9994], Loss: 0.1041\n",
      "Epoch [4/5], Step [850/9994], Loss: 0.0042\n",
      "Epoch [4/5], Step [860/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [870/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [880/9994], Loss: 0.0065\n",
      "Epoch [4/5], Step [890/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [900/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [910/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [920/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [930/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [940/9994], Loss: 0.0110\n",
      "Epoch [4/5], Step [950/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [960/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [970/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [980/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [990/9994], Loss: 0.0044\n",
      "Epoch [4/5], Step [1000/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [1010/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [1020/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [1030/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [1040/9994], Loss: 0.0067\n",
      "Epoch [4/5], Step [1050/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [1060/9994], Loss: 0.0837\n",
      "Epoch [4/5], Step [1070/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [1080/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [1090/9994], Loss: 0.0075\n",
      "Epoch [4/5], Step [1100/9994], Loss: 0.0047\n",
      "Epoch [4/5], Step [1110/9994], Loss: 0.0201\n",
      "Epoch [4/5], Step [1120/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [1130/9994], Loss: 0.0049\n",
      "Epoch [4/5], Step [1140/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [1150/9994], Loss: 0.0038\n",
      "Epoch [4/5], Step [1160/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [1170/9994], Loss: 0.0576\n",
      "Epoch [4/5], Step [1180/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [1190/9994], Loss: 0.0578\n",
      "Epoch [4/5], Step [1200/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [1210/9994], Loss: 0.0189\n",
      "Epoch [4/5], Step [1220/9994], Loss: 0.0775\n",
      "Epoch [4/5], Step [1230/9994], Loss: 0.0131\n",
      "Epoch [4/5], Step [1240/9994], Loss: 0.0826\n",
      "Epoch [4/5], Step [1250/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [1260/9994], Loss: 0.0137\n",
      "Epoch [4/5], Step [1270/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1280/9994], Loss: 0.0297\n",
      "Epoch [4/5], Step [1290/9994], Loss: 0.0118\n",
      "Epoch [4/5], Step [1300/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [1310/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1320/9994], Loss: 0.0074\n",
      "Epoch [4/5], Step [1330/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [1340/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [1350/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [1360/9994], Loss: 0.0147\n",
      "Epoch [4/5], Step [1370/9994], Loss: 0.0724\n",
      "Epoch [4/5], Step [1380/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [1390/9994], Loss: 0.0120\n",
      "Epoch [4/5], Step [1400/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [1410/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [1420/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [1430/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [1440/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [1450/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [1460/9994], Loss: 0.0250\n",
      "Epoch [4/5], Step [1470/9994], Loss: 0.0512\n",
      "Epoch [4/5], Step [1480/9994], Loss: 0.0057\n",
      "Epoch [4/5], Step [1490/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1500/9994], Loss: 0.0135\n",
      "Epoch [4/5], Step [1510/9994], Loss: 0.0071\n",
      "Epoch [4/5], Step [1520/9994], Loss: 0.0092\n",
      "Epoch [4/5], Step [1530/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [1540/9994], Loss: 0.0131\n",
      "Epoch [4/5], Step [1550/9994], Loss: 0.0106\n",
      "Epoch [4/5], Step [1560/9994], Loss: 0.0137\n",
      "Epoch [4/5], Step [1570/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [1580/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [1590/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [1600/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1610/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [1620/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [1630/9994], Loss: 0.0202\n",
      "Epoch [4/5], Step [1640/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [1650/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [1660/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [1670/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1680/9994], Loss: 0.0408\n",
      "Epoch [4/5], Step [1690/9994], Loss: 0.0449\n",
      "Epoch [4/5], Step [1700/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [1710/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [1720/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [1730/9994], Loss: 0.0433\n",
      "Epoch [4/5], Step [1740/9994], Loss: 0.0477\n",
      "Epoch [4/5], Step [1750/9994], Loss: 0.0061\n",
      "Epoch [4/5], Step [1760/9994], Loss: 0.0158\n",
      "Epoch [4/5], Step [1770/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [1780/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [1790/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [1800/9994], Loss: 0.0100\n",
      "Epoch [4/5], Step [1810/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [1820/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [1830/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [1840/9994], Loss: 0.0064\n",
      "Epoch [4/5], Step [1850/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [1860/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [1870/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [1880/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [1890/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [1900/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [1910/9994], Loss: 0.0586\n",
      "Epoch [4/5], Step [1920/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [1930/9994], Loss: 0.0173\n",
      "Epoch [4/5], Step [1940/9994], Loss: 0.0396\n",
      "Epoch [4/5], Step [1950/9994], Loss: 0.0083\n",
      "Epoch [4/5], Step [1960/9994], Loss: 0.0897\n",
      "Epoch [4/5], Step [1970/9994], Loss: 0.0227\n",
      "Epoch [4/5], Step [1980/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [1990/9994], Loss: 0.0666\n",
      "Epoch [4/5], Step [2000/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [2010/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [2020/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [2030/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [2040/9994], Loss: 0.0146\n",
      "Epoch [4/5], Step [2050/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [2060/9994], Loss: 0.0509\n",
      "Epoch [4/5], Step [2070/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [2080/9994], Loss: 0.0163\n",
      "Epoch [4/5], Step [2090/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [2100/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [2110/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [2120/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [2130/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [2140/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [2150/9994], Loss: 0.0451\n",
      "Epoch [4/5], Step [2160/9994], Loss: 0.0517\n",
      "Epoch [4/5], Step [2170/9994], Loss: 0.0627\n",
      "Epoch [4/5], Step [2180/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [2190/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [2200/9994], Loss: 0.0525\n",
      "Epoch [4/5], Step [2210/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [2220/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [2230/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [2240/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [2250/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [2260/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [2270/9994], Loss: 0.0051\n",
      "Epoch [4/5], Step [2280/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [2290/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [2300/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [2310/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [2320/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [2330/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [2340/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [2350/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [2360/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [2370/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [2380/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [2390/9994], Loss: 0.0059\n",
      "Epoch [4/5], Step [2400/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [2410/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [2420/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [2430/9994], Loss: 0.0045\n",
      "Epoch [4/5], Step [2440/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [2450/9994], Loss: 0.0039\n",
      "Epoch [4/5], Step [2460/9994], Loss: 0.0559\n",
      "Epoch [4/5], Step [2470/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [2480/9994], Loss: 0.0317\n",
      "Epoch [4/5], Step [2490/9994], Loss: 0.0073\n",
      "Epoch [4/5], Step [2500/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [2510/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [2520/9994], Loss: 0.0627\n",
      "Epoch [4/5], Step [2530/9994], Loss: 0.0045\n",
      "Epoch [4/5], Step [2540/9994], Loss: 0.0039\n",
      "Epoch [4/5], Step [2550/9994], Loss: 0.1336\n",
      "Epoch [4/5], Step [2560/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [2570/9994], Loss: 0.0451\n",
      "Epoch [4/5], Step [2580/9994], Loss: 0.0719\n",
      "Epoch [4/5], Step [2590/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [2600/9994], Loss: 0.0126\n",
      "Epoch [4/5], Step [2610/9994], Loss: 0.0114\n",
      "Epoch [4/5], Step [2620/9994], Loss: 0.0172\n",
      "Epoch [4/5], Step [2630/9994], Loss: 0.0761\n",
      "Epoch [4/5], Step [2640/9994], Loss: 0.0664\n",
      "Epoch [4/5], Step [2650/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [2660/9994], Loss: 0.0212\n",
      "Epoch [4/5], Step [2670/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [2680/9994], Loss: 0.0490\n",
      "Epoch [4/5], Step [2690/9994], Loss: 0.0414\n",
      "Epoch [4/5], Step [2700/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [2710/9994], Loss: 0.0071\n",
      "Epoch [4/5], Step [2720/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [2730/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [2740/9994], Loss: 0.0051\n",
      "Epoch [4/5], Step [2750/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [2760/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [2770/9994], Loss: 0.0191\n",
      "Epoch [4/5], Step [2780/9994], Loss: 0.0227\n",
      "Epoch [4/5], Step [2790/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [2800/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [2810/9994], Loss: 0.0076\n",
      "Epoch [4/5], Step [2820/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [2830/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [2840/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [2850/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [2860/9994], Loss: 0.0402\n",
      "Epoch [4/5], Step [2870/9994], Loss: 0.0094\n",
      "Epoch [4/5], Step [2880/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [2890/9994], Loss: 0.0216\n",
      "Epoch [4/5], Step [2900/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [2910/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [2920/9994], Loss: 0.0228\n",
      "Epoch [4/5], Step [2930/9994], Loss: 0.1799\n",
      "Epoch [4/5], Step [2940/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [2950/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [2960/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [2970/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [2980/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [2990/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [3000/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [3010/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [3020/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [3030/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [3040/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [3050/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [3060/9994], Loss: 0.0023\n",
      "Epoch [4/5], Step [3070/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [3080/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [3090/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [3100/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [3110/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [3120/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [3130/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [3140/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [3150/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [3160/9994], Loss: 0.0126\n",
      "Epoch [4/5], Step [3170/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [3180/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [3190/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [3200/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [3210/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [3220/9994], Loss: 0.0235\n",
      "Epoch [4/5], Step [3230/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [3240/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [3250/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [3260/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [3270/9994], Loss: 0.0070\n",
      "Epoch [4/5], Step [3280/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [3290/9994], Loss: 0.0393\n",
      "Epoch [4/5], Step [3300/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [3310/9994], Loss: 0.0150\n",
      "Epoch [4/5], Step [3320/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [3330/9994], Loss: 0.0179\n",
      "Epoch [4/5], Step [3340/9994], Loss: 0.0055\n",
      "Epoch [4/5], Step [3350/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [3360/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [3370/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [3380/9994], Loss: 0.0046\n",
      "Epoch [4/5], Step [3390/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [3400/9994], Loss: 0.0511\n",
      "Epoch [4/5], Step [3410/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [3420/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [3430/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [3440/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [3450/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [3460/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [3470/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [3480/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [3490/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [3500/9994], Loss: 0.0098\n",
      "Epoch [4/5], Step [3510/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [3520/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [3530/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [3540/9994], Loss: 0.0114\n",
      "Epoch [4/5], Step [3550/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [3560/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [3570/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [3580/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [3590/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [3600/9994], Loss: 0.0058\n",
      "Epoch [4/5], Step [3610/9994], Loss: 0.0241\n",
      "Epoch [4/5], Step [3620/9994], Loss: 0.0122\n",
      "Epoch [4/5], Step [3630/9994], Loss: 0.0098\n",
      "Epoch [4/5], Step [3640/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [3650/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [3660/9994], Loss: 0.0639\n",
      "Epoch [4/5], Step [3670/9994], Loss: 0.0606\n",
      "Epoch [4/5], Step [3680/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [3690/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [3700/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [3710/9994], Loss: 0.0412\n",
      "Epoch [4/5], Step [3720/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [3730/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [3740/9994], Loss: 0.1959\n",
      "Epoch [4/5], Step [3750/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [3760/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [3770/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [3780/9994], Loss: 0.0086\n",
      "Epoch [4/5], Step [3790/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [3800/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [3810/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [3820/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [3830/9994], Loss: 0.1197\n",
      "Epoch [4/5], Step [3840/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [3850/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [3860/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [3870/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [3880/9994], Loss: 0.0078\n",
      "Epoch [4/5], Step [3890/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [3900/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [3910/9994], Loss: 0.0773\n",
      "Epoch [4/5], Step [3920/9994], Loss: 0.0080\n",
      "Epoch [4/5], Step [3930/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [3940/9994], Loss: 0.0399\n",
      "Epoch [4/5], Step [3950/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [3960/9994], Loss: 0.0565\n",
      "Epoch [4/5], Step [3970/9994], Loss: 0.0387\n",
      "Epoch [4/5], Step [3980/9994], Loss: 0.1145\n",
      "Epoch [4/5], Step [3990/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [4000/9994], Loss: 0.0161\n",
      "Epoch [4/5], Step [4010/9994], Loss: 0.0049\n",
      "Epoch [4/5], Step [4020/9994], Loss: 0.0151\n",
      "Epoch [4/5], Step [4030/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [4040/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [4050/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [4060/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [4070/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [4080/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [4090/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [4100/9994], Loss: 0.0073\n",
      "Epoch [4/5], Step [4110/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [4120/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [4130/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [4140/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [4150/9994], Loss: 0.0086\n",
      "Epoch [4/5], Step [4160/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [4170/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [4180/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [4190/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [4200/9994], Loss: 0.0045\n",
      "Epoch [4/5], Step [4210/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [4220/9994], Loss: 0.0046\n",
      "Epoch [4/5], Step [4230/9994], Loss: 0.0494\n",
      "Epoch [4/5], Step [4240/9994], Loss: 0.0217\n",
      "Epoch [4/5], Step [4250/9994], Loss: 0.1260\n",
      "Epoch [4/5], Step [4260/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [4270/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [4280/9994], Loss: 0.0096\n",
      "Epoch [4/5], Step [4290/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [4300/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [4310/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [4320/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [4330/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [4340/9994], Loss: 0.0122\n",
      "Epoch [4/5], Step [4350/9994], Loss: 0.0044\n",
      "Epoch [4/5], Step [4360/9994], Loss: 0.0048\n",
      "Epoch [4/5], Step [4370/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [4380/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [4390/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [4400/9994], Loss: 0.0038\n",
      "Epoch [4/5], Step [4410/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [4420/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [4430/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [4440/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [4450/9994], Loss: 0.0052\n",
      "Epoch [4/5], Step [4460/9994], Loss: 0.0414\n",
      "Epoch [4/5], Step [4470/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [4480/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4490/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [4500/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [4510/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [4520/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [4530/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [4540/9994], Loss: 0.0066\n",
      "Epoch [4/5], Step [4550/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [4560/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [4570/9994], Loss: 0.0104\n",
      "Epoch [4/5], Step [4580/9994], Loss: 0.0122\n",
      "Epoch [4/5], Step [4590/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [4600/9994], Loss: 0.0038\n",
      "Epoch [4/5], Step [4610/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [4620/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4630/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [4640/9994], Loss: 0.0109\n",
      "Epoch [4/5], Step [4650/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [4660/9994], Loss: 0.0126\n",
      "Epoch [4/5], Step [4670/9994], Loss: 0.0051\n",
      "Epoch [4/5], Step [4680/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [4690/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [4700/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [4710/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [4720/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [4730/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [4740/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [4750/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [4760/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [4770/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [4780/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [4790/9994], Loss: 0.0280\n",
      "Epoch [4/5], Step [4800/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [4810/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [4820/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [4830/9994], Loss: 0.0047\n",
      "Epoch [4/5], Step [4840/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [4850/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [4860/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4870/9994], Loss: 0.0964\n",
      "Epoch [4/5], Step [4880/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [4890/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4900/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [4910/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [4920/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [4930/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [4940/9994], Loss: 0.0065\n",
      "Epoch [4/5], Step [4950/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4960/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [4970/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [4980/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [4990/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [5000/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [5010/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5020/9994], Loss: 0.0450\n",
      "Epoch [4/5], Step [5030/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5040/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [5050/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5060/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [5070/9994], Loss: 0.0550\n",
      "Epoch [4/5], Step [5080/9994], Loss: 0.0075\n",
      "Epoch [4/5], Step [5090/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [5100/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [5110/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [5120/9994], Loss: 0.0638\n",
      "Epoch [4/5], Step [5130/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [5140/9994], Loss: 0.0510\n",
      "Epoch [4/5], Step [5150/9994], Loss: 0.0595\n",
      "Epoch [4/5], Step [5160/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [5170/9994], Loss: 0.0886\n",
      "Epoch [4/5], Step [5180/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [5190/9994], Loss: 0.0074\n",
      "Epoch [4/5], Step [5200/9994], Loss: 0.0472\n",
      "Epoch [4/5], Step [5210/9994], Loss: 0.0048\n",
      "Epoch [4/5], Step [5220/9994], Loss: 0.0102\n",
      "Epoch [4/5], Step [5230/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [5240/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [5250/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5260/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5270/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [5280/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [5290/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [5300/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5310/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [5320/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [5330/9994], Loss: 0.0634\n",
      "Epoch [4/5], Step [5340/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [5350/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5360/9994], Loss: 0.0042\n",
      "Epoch [4/5], Step [5370/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [5380/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [5390/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [5400/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [5410/9994], Loss: 0.0428\n",
      "Epoch [4/5], Step [5420/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [5430/9994], Loss: 0.0061\n",
      "Epoch [4/5], Step [5440/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [5450/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [5460/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5470/9994], Loss: 0.0066\n",
      "Epoch [4/5], Step [5480/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [5490/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [5500/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [5510/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [5520/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [5530/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [5540/9994], Loss: 0.0041\n",
      "Epoch [4/5], Step [5550/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [5560/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [5570/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [5580/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [5590/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [5600/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [5610/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [5620/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5630/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [5640/9994], Loss: 0.0292\n",
      "Epoch [4/5], Step [5650/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [5660/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [5670/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [5680/9994], Loss: 0.0647\n",
      "Epoch [4/5], Step [5690/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [5700/9994], Loss: 0.0045\n",
      "Epoch [4/5], Step [5710/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [5720/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [5730/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5740/9994], Loss: 0.0162\n",
      "Epoch [4/5], Step [5750/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [5760/9994], Loss: 0.0136\n",
      "Epoch [4/5], Step [5770/9994], Loss: 0.1910\n",
      "Epoch [4/5], Step [5780/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [5790/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [5800/9994], Loss: 0.0176\n",
      "Epoch [4/5], Step [5810/9994], Loss: 0.0041\n",
      "Epoch [4/5], Step [5820/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [5830/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [5840/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [5850/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [5860/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [5870/9994], Loss: 0.0114\n",
      "Epoch [4/5], Step [5880/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [5890/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [5900/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [5910/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [5920/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [5930/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [5940/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [5950/9994], Loss: 0.0450\n",
      "Epoch [4/5], Step [5960/9994], Loss: 0.1372\n",
      "Epoch [4/5], Step [5970/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [5980/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [5990/9994], Loss: 0.0812\n",
      "Epoch [4/5], Step [6000/9994], Loss: 0.0373\n",
      "Epoch [4/5], Step [6010/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [6020/9994], Loss: 0.0183\n",
      "Epoch [4/5], Step [6030/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [6040/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [6050/9994], Loss: 0.0080\n",
      "Epoch [4/5], Step [6060/9994], Loss: 0.0115\n",
      "Epoch [4/5], Step [6070/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [6080/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [6090/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [6100/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [6110/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [6120/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [6130/9994], Loss: 0.0483\n",
      "Epoch [4/5], Step [6140/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [6150/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [6160/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [6170/9994], Loss: 0.0389\n",
      "Epoch [4/5], Step [6180/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [6190/9994], Loss: 0.0041\n",
      "Epoch [4/5], Step [6200/9994], Loss: 0.1126\n",
      "Epoch [4/5], Step [6210/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [6220/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [6230/9994], Loss: 0.0131\n",
      "Epoch [4/5], Step [6240/9994], Loss: 0.0162\n",
      "Epoch [4/5], Step [6250/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [6260/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [6270/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [6280/9994], Loss: 0.1155\n",
      "Epoch [4/5], Step [6290/9994], Loss: 0.0121\n",
      "Epoch [4/5], Step [6300/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [6310/9994], Loss: 0.0085\n",
      "Epoch [4/5], Step [6320/9994], Loss: 0.0822\n",
      "Epoch [4/5], Step [6330/9994], Loss: 0.0166\n",
      "Epoch [4/5], Step [6340/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [6350/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [6360/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [6370/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [6380/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [6390/9994], Loss: 0.0178\n",
      "Epoch [4/5], Step [6400/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [6410/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [6420/9994], Loss: 0.0092\n",
      "Epoch [4/5], Step [6430/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [6440/9994], Loss: 0.1774\n",
      "Epoch [4/5], Step [6450/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [6460/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [6470/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [6480/9994], Loss: 0.0046\n",
      "Epoch [4/5], Step [6490/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [6500/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [6510/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [6520/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [6530/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [6540/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [6550/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [6560/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [6570/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [6580/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [6590/9994], Loss: 0.0610\n",
      "Epoch [4/5], Step [6600/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [6610/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [6620/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [6630/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [6640/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [6650/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [6660/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [6670/9994], Loss: 0.0319\n",
      "Epoch [4/5], Step [6680/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [6690/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [6700/9994], Loss: 0.0502\n",
      "Epoch [4/5], Step [6710/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [6720/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [6730/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [6740/9994], Loss: 0.0454\n",
      "Epoch [4/5], Step [6750/9994], Loss: 0.0058\n",
      "Epoch [4/5], Step [6760/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [6770/9994], Loss: 0.0091\n",
      "Epoch [4/5], Step [6780/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [6790/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [6800/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [6810/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [6820/9994], Loss: 0.0000\n",
      "Epoch [4/5], Step [6830/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [6840/9994], Loss: 0.0041\n",
      "Epoch [4/5], Step [6850/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [6860/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [6870/9994], Loss: 0.0484\n",
      "Epoch [4/5], Step [6880/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [6890/9994], Loss: 0.0472\n",
      "Epoch [4/5], Step [6900/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [6910/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [6920/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [6930/9994], Loss: 0.0261\n",
      "Epoch [4/5], Step [6940/9994], Loss: 0.0041\n",
      "Epoch [4/5], Step [6950/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [6960/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [6970/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [6980/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [6990/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [7000/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [7010/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [7020/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [7030/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [7040/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [7050/9994], Loss: 0.0123\n",
      "Epoch [4/5], Step [7060/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [7070/9994], Loss: 0.0549\n",
      "Epoch [4/5], Step [7080/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [7090/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [7100/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [7110/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [7120/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [7130/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [7140/9994], Loss: 0.0044\n",
      "Epoch [4/5], Step [7150/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [7160/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [7170/9994], Loss: 0.0023\n",
      "Epoch [4/5], Step [7180/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [7190/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [7200/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [7210/9994], Loss: 0.0050\n",
      "Epoch [4/5], Step [7220/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [7230/9994], Loss: 0.0055\n",
      "Epoch [4/5], Step [7240/9994], Loss: 0.0046\n",
      "Epoch [4/5], Step [7250/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [7260/9994], Loss: 0.0132\n",
      "Epoch [4/5], Step [7270/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [7280/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [7290/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [7300/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [7310/9994], Loss: 0.0195\n",
      "Epoch [4/5], Step [7320/9994], Loss: 0.0048\n",
      "Epoch [4/5], Step [7330/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [7340/9994], Loss: 0.0602\n",
      "Epoch [4/5], Step [7350/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [7360/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [7370/9994], Loss: 0.1083\n",
      "Epoch [4/5], Step [7380/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [7390/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [7400/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [7410/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [7420/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [7430/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [7440/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [7450/9994], Loss: 0.0072\n",
      "Epoch [4/5], Step [7460/9994], Loss: 0.0102\n",
      "Epoch [4/5], Step [7470/9994], Loss: 0.0051\n",
      "Epoch [4/5], Step [7480/9994], Loss: 0.0185\n",
      "Epoch [4/5], Step [7490/9994], Loss: 0.0546\n",
      "Epoch [4/5], Step [7500/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [7510/9994], Loss: 0.0169\n",
      "Epoch [4/5], Step [7520/9994], Loss: 0.0122\n",
      "Epoch [4/5], Step [7530/9994], Loss: 0.0688\n",
      "Epoch [4/5], Step [7540/9994], Loss: 0.0101\n",
      "Epoch [4/5], Step [7550/9994], Loss: 0.0554\n",
      "Epoch [4/5], Step [7560/9994], Loss: 0.0513\n",
      "Epoch [4/5], Step [7570/9994], Loss: 0.0117\n",
      "Epoch [4/5], Step [7580/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [7590/9994], Loss: 0.0467\n",
      "Epoch [4/5], Step [7600/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [7610/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [7620/9994], Loss: 0.0226\n",
      "Epoch [4/5], Step [7630/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [7640/9994], Loss: 0.0073\n",
      "Epoch [4/5], Step [7650/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [7660/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [7670/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [7680/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [7690/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [7700/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [7710/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [7720/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [7730/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [7740/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [7750/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [7760/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [7770/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [7780/9994], Loss: 0.0079\n",
      "Epoch [4/5], Step [7790/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [7800/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [7810/9994], Loss: 0.0277\n",
      "Epoch [4/5], Step [7820/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [7830/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [7840/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [7850/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [7860/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [7870/9994], Loss: 0.0208\n",
      "Epoch [4/5], Step [7880/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [7890/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [7900/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [7910/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [7920/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [7930/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [7940/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [7950/9994], Loss: 0.0047\n",
      "Epoch [4/5], Step [7960/9994], Loss: 0.0109\n",
      "Epoch [4/5], Step [7970/9994], Loss: 0.0918\n",
      "Epoch [4/5], Step [7980/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [7990/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [8000/9994], Loss: 0.0029\n",
      "Epoch [4/5], Step [8010/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [8020/9994], Loss: 0.0147\n",
      "Epoch [4/5], Step [8030/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [8040/9994], Loss: 0.0157\n",
      "Epoch [4/5], Step [8050/9994], Loss: 0.0233\n",
      "Epoch [4/5], Step [8060/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [8070/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [8080/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8090/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [8100/9994], Loss: 0.0190\n",
      "Epoch [4/5], Step [8110/9994], Loss: 0.0290\n",
      "Epoch [4/5], Step [8120/9994], Loss: 0.1083\n",
      "Epoch [4/5], Step [8130/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [8140/9994], Loss: 0.0206\n",
      "Epoch [4/5], Step [8150/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [8160/9994], Loss: 0.0027\n",
      "Epoch [4/5], Step [8170/9994], Loss: 0.0053\n",
      "Epoch [4/5], Step [8180/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [8190/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [8200/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8210/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8220/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [8230/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8240/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [8250/9994], Loss: 0.0676\n",
      "Epoch [4/5], Step [8260/9994], Loss: 0.0584\n",
      "Epoch [4/5], Step [8270/9994], Loss: 0.0014\n",
      "Epoch [4/5], Step [8280/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [8290/9994], Loss: 0.0032\n",
      "Epoch [4/5], Step [8300/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8310/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [8320/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [8330/9994], Loss: 0.0519\n",
      "Epoch [4/5], Step [8340/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8350/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [8360/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [8370/9994], Loss: 0.0044\n",
      "Epoch [4/5], Step [8380/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [8390/9994], Loss: 0.0030\n",
      "Epoch [4/5], Step [8400/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8410/9994], Loss: 0.0005\n",
      "Epoch [4/5], Step [8420/9994], Loss: 0.0172\n",
      "Epoch [4/5], Step [8430/9994], Loss: 0.0068\n",
      "Epoch [4/5], Step [8440/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [8450/9994], Loss: 0.0113\n",
      "Epoch [4/5], Step [8460/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [8470/9994], Loss: 0.0001\n",
      "Epoch [4/5], Step [8480/9994], Loss: 0.0347\n",
      "Epoch [4/5], Step [8490/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8500/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8510/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8520/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [8530/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8540/9994], Loss: 0.0629\n",
      "Epoch [4/5], Step [8550/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [8560/9994], Loss: 0.0082\n",
      "Epoch [4/5], Step [8570/9994], Loss: 0.0199\n",
      "Epoch [4/5], Step [8580/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [8590/9994], Loss: 0.0723\n",
      "Epoch [4/5], Step [8600/9994], Loss: 0.0119\n",
      "Epoch [4/5], Step [8610/9994], Loss: 0.0048\n",
      "Epoch [4/5], Step [8620/9994], Loss: 0.0015\n",
      "Epoch [4/5], Step [8630/9994], Loss: 0.0405\n",
      "Epoch [4/5], Step [8640/9994], Loss: 0.0199\n",
      "Epoch [4/5], Step [8650/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [8660/9994], Loss: 0.0339\n",
      "Epoch [4/5], Step [8670/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [8680/9994], Loss: 0.0035\n",
      "Epoch [4/5], Step [8690/9994], Loss: 0.0291\n",
      "Epoch [4/5], Step [8700/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [8710/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [8720/9994], Loss: 0.0108\n",
      "Epoch [4/5], Step [8730/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [8740/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [8750/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [8760/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [8770/9994], Loss: 0.0089\n",
      "Epoch [4/5], Step [8780/9994], Loss: 0.0572\n",
      "Epoch [4/5], Step [8790/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [8800/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [8810/9994], Loss: 0.0217\n",
      "Epoch [4/5], Step [8820/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [8830/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [8840/9994], Loss: 0.0039\n",
      "Epoch [4/5], Step [8850/9994], Loss: 0.0081\n",
      "Epoch [4/5], Step [8860/9994], Loss: 0.0070\n",
      "Epoch [4/5], Step [8870/9994], Loss: 0.0518\n",
      "Epoch [4/5], Step [8880/9994], Loss: 0.0627\n",
      "Epoch [4/5], Step [8890/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [8900/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [8910/9994], Loss: 0.0387\n",
      "Epoch [4/5], Step [8920/9994], Loss: 0.0010\n",
      "Epoch [4/5], Step [8930/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [8940/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8950/9994], Loss: 0.0923\n",
      "Epoch [4/5], Step [8960/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [8970/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [8980/9994], Loss: 0.0250\n",
      "Epoch [4/5], Step [8990/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [9000/9994], Loss: 0.0042\n",
      "Epoch [4/5], Step [9010/9994], Loss: 0.0427\n",
      "Epoch [4/5], Step [9020/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [9030/9994], Loss: 0.0094\n",
      "Epoch [4/5], Step [9040/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [9050/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [9060/9994], Loss: 0.0100\n",
      "Epoch [4/5], Step [9070/9994], Loss: 0.0115\n",
      "Epoch [4/5], Step [9080/9994], Loss: 0.0500\n",
      "Epoch [4/5], Step [9090/9994], Loss: 0.0139\n",
      "Epoch [4/5], Step [9100/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [9110/9994], Loss: 0.0013\n",
      "Epoch [4/5], Step [9120/9994], Loss: 0.0052\n",
      "Epoch [4/5], Step [9130/9994], Loss: 0.0042\n",
      "Epoch [4/5], Step [9140/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [9150/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [9160/9994], Loss: 0.0120\n",
      "Epoch [4/5], Step [9170/9994], Loss: 0.0379\n",
      "Epoch [4/5], Step [9180/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [9190/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [9200/9994], Loss: 0.0017\n",
      "Epoch [4/5], Step [9210/9994], Loss: 0.0122\n",
      "Epoch [4/5], Step [9220/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [9230/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [9240/9994], Loss: 0.0551\n",
      "Epoch [4/5], Step [9250/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [9260/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [9270/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [9280/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [9290/9994], Loss: 0.0004\n",
      "Epoch [4/5], Step [9300/9994], Loss: 0.0605\n",
      "Epoch [4/5], Step [9310/9994], Loss: 0.0026\n",
      "Epoch [4/5], Step [9320/9994], Loss: 0.0048\n",
      "Epoch [4/5], Step [9330/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [9340/9994], Loss: 0.0347\n",
      "Epoch [4/5], Step [9350/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [9360/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [9370/9994], Loss: 0.0119\n",
      "Epoch [4/5], Step [9380/9994], Loss: 0.0002\n",
      "Epoch [4/5], Step [9390/9994], Loss: 0.0079\n",
      "Epoch [4/5], Step [9400/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [9410/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [9420/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [9430/9994], Loss: 0.0094\n",
      "Epoch [4/5], Step [9440/9994], Loss: 0.0008\n",
      "Epoch [4/5], Step [9450/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [9460/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [9470/9994], Loss: 0.0012\n",
      "Epoch [4/5], Step [9480/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [9490/9994], Loss: 0.0033\n",
      "Epoch [4/5], Step [9500/9994], Loss: 0.0047\n",
      "Epoch [4/5], Step [9510/9994], Loss: 0.0341\n",
      "Epoch [4/5], Step [9520/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [9530/9994], Loss: 0.0006\n",
      "Epoch [4/5], Step [9540/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [9550/9994], Loss: 0.0028\n",
      "Epoch [4/5], Step [9560/9994], Loss: 0.0007\n",
      "Epoch [4/5], Step [9570/9994], Loss: 0.0018\n",
      "Epoch [4/5], Step [9580/9994], Loss: 0.0202\n",
      "Epoch [4/5], Step [9590/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [9600/9994], Loss: 0.0767\n",
      "Epoch [4/5], Step [9610/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [9620/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [9630/9994], Loss: 0.0024\n",
      "Epoch [4/5], Step [9640/9994], Loss: 0.0036\n",
      "Epoch [4/5], Step [9650/9994], Loss: 0.0588\n",
      "Epoch [4/5], Step [9660/9994], Loss: 0.0055\n",
      "Epoch [4/5], Step [9670/9994], Loss: 0.0060\n",
      "Epoch [4/5], Step [9680/9994], Loss: 0.0056\n",
      "Epoch [4/5], Step [9690/9994], Loss: 0.0850\n",
      "Epoch [4/5], Step [9700/9994], Loss: 0.0019\n",
      "Epoch [4/5], Step [9710/9994], Loss: 0.0037\n",
      "Epoch [4/5], Step [9720/9994], Loss: 0.0022\n",
      "Epoch [4/5], Step [9730/9994], Loss: 0.0039\n",
      "Epoch [4/5], Step [9740/9994], Loss: 0.0023\n",
      "Epoch [4/5], Step [9750/9994], Loss: 0.0000\n",
      "Epoch [4/5], Step [9760/9994], Loss: 0.0256\n",
      "Epoch [4/5], Step [9770/9994], Loss: 0.0074\n",
      "Epoch [4/5], Step [9780/9994], Loss: 0.0021\n",
      "Epoch [4/5], Step [9790/9994], Loss: 0.0020\n",
      "Epoch [4/5], Step [9800/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [9810/9994], Loss: 0.0083\n",
      "Epoch [4/5], Step [9820/9994], Loss: 0.0054\n",
      "Epoch [4/5], Step [9830/9994], Loss: 0.0261\n",
      "Epoch [4/5], Step [9840/9994], Loss: 0.0031\n",
      "Epoch [4/5], Step [9850/9994], Loss: 0.0045\n",
      "Epoch [4/5], Step [9860/9994], Loss: 0.0063\n",
      "Epoch [4/5], Step [9870/9994], Loss: 0.0120\n",
      "Epoch [4/5], Step [9880/9994], Loss: 0.0277\n",
      "Epoch [4/5], Step [9890/9994], Loss: 0.0009\n",
      "Epoch [4/5], Step [9900/9994], Loss: 0.0159\n",
      "Epoch [4/5], Step [9910/9994], Loss: 0.0034\n",
      "Epoch [4/5], Step [9920/9994], Loss: 0.0043\n",
      "Epoch [4/5], Step [9930/9994], Loss: 0.0003\n",
      "Epoch [4/5], Step [9940/9994], Loss: 0.0016\n",
      "Epoch [4/5], Step [9950/9994], Loss: 0.0011\n",
      "Epoch [4/5], Step [9960/9994], Loss: 0.0090\n",
      "Epoch [4/5], Step [9970/9994], Loss: 0.0025\n",
      "Epoch [4/5], Step [9980/9994], Loss: 0.0040\n",
      "Epoch [4/5], Step [9990/9994], Loss: 0.0308\n",
      "Epoch [4/5], Average Train Loss: 0.0118\n",
      "Epoch [4/5], Validation Loss: 0.0204\n",
      "Epoch [5/5], Step [10/9994], Loss: 0.0055\n",
      "Epoch [5/5], Step [20/9994], Loss: 0.0041\n",
      "Epoch [5/5], Step [30/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [40/9994], Loss: 0.0071\n",
      "Epoch [5/5], Step [50/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [60/9994], Loss: 0.0040\n",
      "Epoch [5/5], Step [70/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [80/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [90/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [100/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [110/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [120/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [130/9994], Loss: 0.0039\n",
      "Epoch [5/5], Step [140/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [150/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [160/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [170/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [180/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [190/9994], Loss: 0.0028\n",
      "Epoch [5/5], Step [200/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [210/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [220/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [230/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [240/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [250/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [260/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [270/9994], Loss: 0.0433\n",
      "Epoch [5/5], Step [280/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [290/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [300/9994], Loss: 0.0065\n",
      "Epoch [5/5], Step [310/9994], Loss: 0.0059\n",
      "Epoch [5/5], Step [320/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [330/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [340/9994], Loss: 0.0169\n",
      "Epoch [5/5], Step [350/9994], Loss: 0.0128\n",
      "Epoch [5/5], Step [360/9994], Loss: 0.0103\n",
      "Epoch [5/5], Step [370/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [380/9994], Loss: 0.0206\n",
      "Epoch [5/5], Step [390/9994], Loss: 0.0397\n",
      "Epoch [5/5], Step [400/9994], Loss: 0.0105\n",
      "Epoch [5/5], Step [410/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [420/9994], Loss: 0.0054\n",
      "Epoch [5/5], Step [430/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [440/9994], Loss: 0.0514\n",
      "Epoch [5/5], Step [450/9994], Loss: 0.0800\n",
      "Epoch [5/5], Step [460/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [470/9994], Loss: 0.0037\n",
      "Epoch [5/5], Step [480/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [490/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [500/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [510/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [520/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [530/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [540/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [550/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [560/9994], Loss: 0.0143\n",
      "Epoch [5/5], Step [570/9994], Loss: 0.0094\n",
      "Epoch [5/5], Step [580/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [590/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [600/9994], Loss: 0.0068\n",
      "Epoch [5/5], Step [610/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [620/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [630/9994], Loss: 0.0508\n",
      "Epoch [5/5], Step [640/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [650/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [660/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [670/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [680/9994], Loss: 0.0697\n",
      "Epoch [5/5], Step [690/9994], Loss: 0.0036\n",
      "Epoch [5/5], Step [700/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [710/9994], Loss: 0.0382\n",
      "Epoch [5/5], Step [720/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [730/9994], Loss: 0.0031\n",
      "Epoch [5/5], Step [740/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [750/9994], Loss: 0.0059\n",
      "Epoch [5/5], Step [760/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [770/9994], Loss: 0.0039\n",
      "Epoch [5/5], Step [780/9994], Loss: 0.0067\n",
      "Epoch [5/5], Step [790/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [800/9994], Loss: 0.0078\n",
      "Epoch [5/5], Step [810/9994], Loss: 0.0029\n",
      "Epoch [5/5], Step [820/9994], Loss: 0.0071\n",
      "Epoch [5/5], Step [830/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [840/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [850/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [860/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [870/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [880/9994], Loss: 0.0061\n",
      "Epoch [5/5], Step [890/9994], Loss: 0.0504\n",
      "Epoch [5/5], Step [900/9994], Loss: 0.0094\n",
      "Epoch [5/5], Step [910/9994], Loss: 0.0288\n",
      "Epoch [5/5], Step [920/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [930/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [940/9994], Loss: 0.0164\n",
      "Epoch [5/5], Step [950/9994], Loss: 0.0074\n",
      "Epoch [5/5], Step [960/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [970/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [980/9994], Loss: 0.0029\n",
      "Epoch [5/5], Step [990/9994], Loss: 0.0074\n",
      "Epoch [5/5], Step [1000/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [1010/9994], Loss: 0.0503\n",
      "Epoch [5/5], Step [1020/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [1030/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [1040/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [1050/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [1060/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [1070/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [1080/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [1090/9994], Loss: 0.0253\n",
      "Epoch [5/5], Step [1100/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [1110/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [1120/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [1130/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [1140/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [1150/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [1160/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [1170/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [1180/9994], Loss: 0.0551\n",
      "Epoch [5/5], Step [1190/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [1200/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [1210/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [1220/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [1230/9994], Loss: 0.0042\n",
      "Epoch [5/5], Step [1240/9994], Loss: 0.0543\n",
      "Epoch [5/5], Step [1250/9994], Loss: 0.0028\n",
      "Epoch [5/5], Step [1260/9994], Loss: 0.0036\n",
      "Epoch [5/5], Step [1270/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [1280/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [1290/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [1300/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [1310/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [1320/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [1330/9994], Loss: 0.0348\n",
      "Epoch [5/5], Step [1340/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [1350/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [1360/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [1370/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [1380/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [1390/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [1400/9994], Loss: 0.0794\n",
      "Epoch [5/5], Step [1410/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [1420/9994], Loss: 0.0115\n",
      "Epoch [5/5], Step [1430/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [1440/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [1450/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [1460/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [1470/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [1480/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [1490/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [1500/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [1510/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [1520/9994], Loss: 0.0311\n",
      "Epoch [5/5], Step [1530/9994], Loss: 0.0447\n",
      "Epoch [5/5], Step [1540/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [1550/9994], Loss: 0.0467\n",
      "Epoch [5/5], Step [1560/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [1570/9994], Loss: 0.0529\n",
      "Epoch [5/5], Step [1580/9994], Loss: 0.0997\n",
      "Epoch [5/5], Step [1590/9994], Loss: 0.0263\n",
      "Epoch [5/5], Step [1600/9994], Loss: 0.0215\n",
      "Epoch [5/5], Step [1610/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [1620/9994], Loss: 0.0079\n",
      "Epoch [5/5], Step [1630/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [1640/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [1650/9994], Loss: 0.1123\n",
      "Epoch [5/5], Step [1660/9994], Loss: 0.0510\n",
      "Epoch [5/5], Step [1670/9994], Loss: 0.0050\n",
      "Epoch [5/5], Step [1680/9994], Loss: 0.0041\n",
      "Epoch [5/5], Step [1690/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [1700/9994], Loss: 0.0042\n",
      "Epoch [5/5], Step [1710/9994], Loss: 0.0251\n",
      "Epoch [5/5], Step [1720/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [1730/9994], Loss: 0.0046\n",
      "Epoch [5/5], Step [1740/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [1750/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [1760/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [1770/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [1780/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [1790/9994], Loss: 0.0051\n",
      "Epoch [5/5], Step [1800/9994], Loss: 0.0028\n",
      "Epoch [5/5], Step [1810/9994], Loss: 0.2108\n",
      "Epoch [5/5], Step [1820/9994], Loss: 0.0033\n",
      "Epoch [5/5], Step [1830/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [1840/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [1850/9994], Loss: 0.0079\n",
      "Epoch [5/5], Step [1860/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [1870/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [1880/9994], Loss: 0.0353\n",
      "Epoch [5/5], Step [1890/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [1900/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [1910/9994], Loss: 0.0296\n",
      "Epoch [5/5], Step [1920/9994], Loss: 0.0375\n",
      "Epoch [5/5], Step [1930/9994], Loss: 0.0192\n",
      "Epoch [5/5], Step [1940/9994], Loss: 0.0393\n",
      "Epoch [5/5], Step [1950/9994], Loss: 0.0084\n",
      "Epoch [5/5], Step [1960/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [1970/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [1980/9994], Loss: 0.0093\n",
      "Epoch [5/5], Step [1990/9994], Loss: 0.1693\n",
      "Epoch [5/5], Step [2000/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [2010/9994], Loss: 0.0197\n",
      "Epoch [5/5], Step [2020/9994], Loss: 0.0103\n",
      "Epoch [5/5], Step [2030/9994], Loss: 0.0173\n",
      "Epoch [5/5], Step [2040/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [2050/9994], Loss: 0.0050\n",
      "Epoch [5/5], Step [2060/9994], Loss: 0.0050\n",
      "Epoch [5/5], Step [2070/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [2080/9994], Loss: 0.0591\n",
      "Epoch [5/5], Step [2090/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [2100/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [2110/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [2120/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [2130/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [2140/9994], Loss: 0.0580\n",
      "Epoch [5/5], Step [2150/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [2160/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [2170/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [2180/9994], Loss: 0.0117\n",
      "Epoch [5/5], Step [2190/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [2200/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [2210/9994], Loss: 0.0042\n",
      "Epoch [5/5], Step [2220/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [2230/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [2240/9994], Loss: 0.0042\n",
      "Epoch [5/5], Step [2250/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [2260/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [2270/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [2280/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [2290/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [2300/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [2310/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [2320/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [2330/9994], Loss: 0.0633\n",
      "Epoch [5/5], Step [2340/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [2350/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [2360/9994], Loss: 0.0130\n",
      "Epoch [5/5], Step [2370/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [2380/9994], Loss: 0.0395\n",
      "Epoch [5/5], Step [2390/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [2400/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [2410/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [2420/9994], Loss: 0.0031\n",
      "Epoch [5/5], Step [2430/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [2440/9994], Loss: 0.0230\n",
      "Epoch [5/5], Step [2450/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [2460/9994], Loss: 0.0675\n",
      "Epoch [5/5], Step [2470/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [2480/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [2490/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [2500/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [2510/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [2520/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [2530/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [2540/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [2550/9994], Loss: 0.0278\n",
      "Epoch [5/5], Step [2560/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [2570/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [2580/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [2590/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [2600/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [2610/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [2620/9994], Loss: 0.0029\n",
      "Epoch [5/5], Step [2630/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [2640/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [2650/9994], Loss: 0.0116\n",
      "Epoch [5/5], Step [2660/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [2670/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [2680/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [2690/9994], Loss: 0.0473\n",
      "Epoch [5/5], Step [2700/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [2710/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [2720/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [2730/9994], Loss: 0.0400\n",
      "Epoch [5/5], Step [2740/9994], Loss: 0.0380\n",
      "Epoch [5/5], Step [2750/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [2760/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [2770/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [2780/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [2790/9994], Loss: 0.0502\n",
      "Epoch [5/5], Step [2800/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [2810/9994], Loss: 0.0257\n",
      "Epoch [5/5], Step [2820/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [2830/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [2840/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [2850/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [2860/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [2870/9994], Loss: 0.0066\n",
      "Epoch [5/5], Step [2880/9994], Loss: 0.0040\n",
      "Epoch [5/5], Step [2890/9994], Loss: 0.0106\n",
      "Epoch [5/5], Step [2900/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [2910/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [2920/9994], Loss: 0.0458\n",
      "Epoch [5/5], Step [2930/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [2940/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [2950/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [2960/9994], Loss: 0.0206\n",
      "Epoch [5/5], Step [2970/9994], Loss: 0.0606\n",
      "Epoch [5/5], Step [2980/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [2990/9994], Loss: 0.0243\n",
      "Epoch [5/5], Step [3000/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [3010/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [3020/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [3030/9994], Loss: 0.0220\n",
      "Epoch [5/5], Step [3040/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [3050/9994], Loss: 0.0478\n",
      "Epoch [5/5], Step [3060/9994], Loss: 0.0196\n",
      "Epoch [5/5], Step [3070/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [3080/9994], Loss: 0.0276\n",
      "Epoch [5/5], Step [3090/9994], Loss: 0.0070\n",
      "Epoch [5/5], Step [3100/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [3110/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [3120/9994], Loss: 0.0552\n",
      "Epoch [5/5], Step [3130/9994], Loss: 0.0455\n",
      "Epoch [5/5], Step [3140/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [3150/9994], Loss: 0.0067\n",
      "Epoch [5/5], Step [3160/9994], Loss: 0.0467\n",
      "Epoch [5/5], Step [3170/9994], Loss: 0.0458\n",
      "Epoch [5/5], Step [3180/9994], Loss: 0.0106\n",
      "Epoch [5/5], Step [3190/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [3200/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [3210/9994], Loss: 0.0092\n",
      "Epoch [5/5], Step [3220/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [3230/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [3240/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [3250/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [3260/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [3270/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [3280/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [3290/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [3300/9994], Loss: 0.0160\n",
      "Epoch [5/5], Step [3310/9994], Loss: 0.0125\n",
      "Epoch [5/5], Step [3320/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [3330/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [3340/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [3350/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [3360/9994], Loss: 0.0106\n",
      "Epoch [5/5], Step [3370/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [3380/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [3390/9994], Loss: 0.1067\n",
      "Epoch [5/5], Step [3400/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [3410/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [3420/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [3430/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [3440/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [3450/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [3460/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [3470/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [3480/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [3490/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [3500/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [3510/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [3520/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [3530/9994], Loss: 0.0523\n",
      "Epoch [5/5], Step [3540/9994], Loss: 0.0072\n",
      "Epoch [5/5], Step [3550/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [3560/9994], Loss: 0.0697\n",
      "Epoch [5/5], Step [3570/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [3580/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [3590/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [3600/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [3610/9994], Loss: 0.0122\n",
      "Epoch [5/5], Step [3620/9994], Loss: 0.0066\n",
      "Epoch [5/5], Step [3630/9994], Loss: 0.0111\n",
      "Epoch [5/5], Step [3640/9994], Loss: 0.0075\n",
      "Epoch [5/5], Step [3650/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [3660/9994], Loss: 0.0118\n",
      "Epoch [5/5], Step [3670/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [3680/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [3690/9994], Loss: 0.0515\n",
      "Epoch [5/5], Step [3700/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [3710/9994], Loss: 0.0123\n",
      "Epoch [5/5], Step [3720/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [3730/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [3740/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [3750/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [3760/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [3770/9994], Loss: 0.0442\n",
      "Epoch [5/5], Step [3780/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [3790/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [3800/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [3810/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [3820/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [3830/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [3840/9994], Loss: 0.0101\n",
      "Epoch [5/5], Step [3850/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [3860/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [3870/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [3880/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [3890/9994], Loss: 0.0193\n",
      "Epoch [5/5], Step [3900/9994], Loss: 0.0063\n",
      "Epoch [5/5], Step [3910/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [3920/9994], Loss: 0.0212\n",
      "Epoch [5/5], Step [3930/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [3940/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [3950/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [3960/9994], Loss: 0.0431\n",
      "Epoch [5/5], Step [3970/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [3980/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [3990/9994], Loss: 0.0090\n",
      "Epoch [5/5], Step [4000/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [4010/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [4020/9994], Loss: 0.0085\n",
      "Epoch [5/5], Step [4030/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [4040/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [4050/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [4060/9994], Loss: 0.0092\n",
      "Epoch [5/5], Step [4070/9994], Loss: 0.0701\n",
      "Epoch [5/5], Step [4080/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [4090/9994], Loss: 0.0492\n",
      "Epoch [5/5], Step [4100/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [4110/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [4120/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [4130/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [4140/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [4150/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [4160/9994], Loss: 0.0213\n",
      "Epoch [5/5], Step [4170/9994], Loss: 0.0764\n",
      "Epoch [5/5], Step [4180/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [4190/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [4200/9994], Loss: 0.0944\n",
      "Epoch [5/5], Step [4210/9994], Loss: 0.0095\n",
      "Epoch [5/5], Step [4220/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [4230/9994], Loss: 0.0572\n",
      "Epoch [5/5], Step [4240/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [4250/9994], Loss: 0.0674\n",
      "Epoch [5/5], Step [4260/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [4270/9994], Loss: 0.0238\n",
      "Epoch [5/5], Step [4280/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [4290/9994], Loss: 0.0072\n",
      "Epoch [5/5], Step [4300/9994], Loss: 0.0092\n",
      "Epoch [5/5], Step [4310/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [4320/9994], Loss: 0.0743\n",
      "Epoch [5/5], Step [4330/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [4340/9994], Loss: 0.0545\n",
      "Epoch [5/5], Step [4350/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [4360/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [4370/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [4380/9994], Loss: 0.0094\n",
      "Epoch [5/5], Step [4390/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [4400/9994], Loss: 0.0886\n",
      "Epoch [5/5], Step [4410/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [4420/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [4430/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [4440/9994], Loss: 0.0081\n",
      "Epoch [5/5], Step [4450/9994], Loss: 0.0124\n",
      "Epoch [5/5], Step [4460/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [4470/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [4480/9994], Loss: 0.0077\n",
      "Epoch [5/5], Step [4490/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [4500/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [4510/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [4520/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [4530/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [4540/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [4550/9994], Loss: 0.0121\n",
      "Epoch [5/5], Step [4560/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [4570/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [4580/9994], Loss: 0.0624\n",
      "Epoch [5/5], Step [4590/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [4600/9994], Loss: 0.0126\n",
      "Epoch [5/5], Step [4610/9994], Loss: 0.0047\n",
      "Epoch [5/5], Step [4620/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [4630/9994], Loss: 0.0237\n",
      "Epoch [5/5], Step [4640/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [4650/9994], Loss: 0.0095\n",
      "Epoch [5/5], Step [4660/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [4670/9994], Loss: 0.0031\n",
      "Epoch [5/5], Step [4680/9994], Loss: 0.0423\n",
      "Epoch [5/5], Step [4690/9994], Loss: 0.0057\n",
      "Epoch [5/5], Step [4700/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [4710/9994], Loss: 0.1091\n",
      "Epoch [5/5], Step [4720/9994], Loss: 0.0579\n",
      "Epoch [5/5], Step [4730/9994], Loss: 0.0166\n",
      "Epoch [5/5], Step [4740/9994], Loss: 0.0199\n",
      "Epoch [5/5], Step [4750/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [4760/9994], Loss: 0.0580\n",
      "Epoch [5/5], Step [4770/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [4780/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [4790/9994], Loss: 0.0043\n",
      "Epoch [5/5], Step [4800/9994], Loss: 0.0085\n",
      "Epoch [5/5], Step [4810/9994], Loss: 0.0080\n",
      "Epoch [5/5], Step [4820/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [4830/9994], Loss: 0.0116\n",
      "Epoch [5/5], Step [4840/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [4850/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [4860/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [4870/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [4880/9994], Loss: 0.0165\n",
      "Epoch [5/5], Step [4890/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [4900/9994], Loss: 0.0036\n",
      "Epoch [5/5], Step [4910/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [4920/9994], Loss: 0.0077\n",
      "Epoch [5/5], Step [4930/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [4940/9994], Loss: 0.0041\n",
      "Epoch [5/5], Step [4950/9994], Loss: 0.0145\n",
      "Epoch [5/5], Step [4960/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [4970/9994], Loss: 0.0152\n",
      "Epoch [5/5], Step [4980/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [4990/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [5000/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [5010/9994], Loss: 0.0534\n",
      "Epoch [5/5], Step [5020/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5030/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [5040/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5050/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [5060/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [5070/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [5080/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [5090/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5100/9994], Loss: 0.0439\n",
      "Epoch [5/5], Step [5110/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [5120/9994], Loss: 0.0039\n",
      "Epoch [5/5], Step [5130/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [5140/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [5150/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [5160/9994], Loss: 0.0165\n",
      "Epoch [5/5], Step [5170/9994], Loss: 0.0153\n",
      "Epoch [5/5], Step [5180/9994], Loss: 0.0049\n",
      "Epoch [5/5], Step [5190/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [5200/9994], Loss: 0.0049\n",
      "Epoch [5/5], Step [5210/9994], Loss: 0.0077\n",
      "Epoch [5/5], Step [5220/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [5230/9994], Loss: 0.0043\n",
      "Epoch [5/5], Step [5240/9994], Loss: 0.0053\n",
      "Epoch [5/5], Step [5250/9994], Loss: 0.0029\n",
      "Epoch [5/5], Step [5260/9994], Loss: 0.0084\n",
      "Epoch [5/5], Step [5270/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [5280/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [5290/9994], Loss: 0.0089\n",
      "Epoch [5/5], Step [5300/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [5310/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [5320/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [5330/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [5340/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [5350/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [5360/9994], Loss: 0.0833\n",
      "Epoch [5/5], Step [5370/9994], Loss: 0.0042\n",
      "Epoch [5/5], Step [5380/9994], Loss: 0.0150\n",
      "Epoch [5/5], Step [5390/9994], Loss: 0.0317\n",
      "Epoch [5/5], Step [5400/9994], Loss: 0.0049\n",
      "Epoch [5/5], Step [5410/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [5420/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [5430/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [5440/9994], Loss: 0.0407\n",
      "Epoch [5/5], Step [5450/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [5460/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [5470/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [5480/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [5490/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [5500/9994], Loss: 0.0661\n",
      "Epoch [5/5], Step [5510/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [5520/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [5530/9994], Loss: 0.0080\n",
      "Epoch [5/5], Step [5540/9994], Loss: 0.0466\n",
      "Epoch [5/5], Step [5550/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [5560/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [5570/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [5580/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [5590/9994], Loss: 0.0056\n",
      "Epoch [5/5], Step [5600/9994], Loss: 0.0054\n",
      "Epoch [5/5], Step [5610/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [5620/9994], Loss: 0.0410\n",
      "Epoch [5/5], Step [5630/9994], Loss: 0.0403\n",
      "Epoch [5/5], Step [5640/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [5650/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [5660/9994], Loss: 0.0179\n",
      "Epoch [5/5], Step [5670/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [5680/9994], Loss: 0.0055\n",
      "Epoch [5/5], Step [5690/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [5700/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [5710/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [5720/9994], Loss: 0.0033\n",
      "Epoch [5/5], Step [5730/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [5740/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [5750/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [5760/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [5770/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [5780/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5790/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [5800/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [5810/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [5820/9994], Loss: 0.0676\n",
      "Epoch [5/5], Step [5830/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5840/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [5850/9994], Loss: 0.0285\n",
      "Epoch [5/5], Step [5860/9994], Loss: 0.0098\n",
      "Epoch [5/5], Step [5870/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [5880/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [5890/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [5900/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [5910/9994], Loss: 0.0036\n",
      "Epoch [5/5], Step [5920/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [5930/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [5940/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [5950/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [5960/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [5970/9994], Loss: 0.0897\n",
      "Epoch [5/5], Step [5980/9994], Loss: 0.0072\n",
      "Epoch [5/5], Step [5990/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [6000/9994], Loss: 0.0033\n",
      "Epoch [5/5], Step [6010/9994], Loss: 0.0322\n",
      "Epoch [5/5], Step [6020/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [6030/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [6040/9994], Loss: 0.0470\n",
      "Epoch [5/5], Step [6050/9994], Loss: 0.0125\n",
      "Epoch [5/5], Step [6060/9994], Loss: 0.0065\n",
      "Epoch [5/5], Step [6070/9994], Loss: 0.0030\n",
      "Epoch [5/5], Step [6080/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [6090/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [6100/9994], Loss: 0.0196\n",
      "Epoch [5/5], Step [6110/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [6120/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [6130/9994], Loss: 0.0046\n",
      "Epoch [5/5], Step [6140/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [6150/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [6160/9994], Loss: 0.0273\n",
      "Epoch [5/5], Step [6170/9994], Loss: 0.0044\n",
      "Epoch [5/5], Step [6180/9994], Loss: 0.0186\n",
      "Epoch [5/5], Step [6190/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [6200/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6210/9994], Loss: 0.0776\n",
      "Epoch [5/5], Step [6220/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [6230/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [6240/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [6250/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [6260/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [6270/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [6280/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [6290/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [6300/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [6310/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [6320/9994], Loss: 0.0784\n",
      "Epoch [5/5], Step [6330/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6340/9994], Loss: 0.0137\n",
      "Epoch [5/5], Step [6350/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [6360/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [6370/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [6380/9994], Loss: 0.0037\n",
      "Epoch [5/5], Step [6390/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [6400/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [6410/9994], Loss: 0.0043\n",
      "Epoch [5/5], Step [6420/9994], Loss: 0.0053\n",
      "Epoch [5/5], Step [6430/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [6440/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [6450/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [6460/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6470/9994], Loss: 0.0169\n",
      "Epoch [5/5], Step [6480/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [6490/9994], Loss: 0.0126\n",
      "Epoch [5/5], Step [6500/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [6510/9994], Loss: 0.0059\n",
      "Epoch [5/5], Step [6520/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [6530/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [6540/9994], Loss: 0.0081\n",
      "Epoch [5/5], Step [6550/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [6560/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [6570/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6580/9994], Loss: 0.0659\n",
      "Epoch [5/5], Step [6590/9994], Loss: 0.0084\n",
      "Epoch [5/5], Step [6600/9994], Loss: 0.0359\n",
      "Epoch [5/5], Step [6610/9994], Loss: 0.0053\n",
      "Epoch [5/5], Step [6620/9994], Loss: 0.0373\n",
      "Epoch [5/5], Step [6630/9994], Loss: 0.0082\n",
      "Epoch [5/5], Step [6640/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [6650/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [6660/9994], Loss: 0.0071\n",
      "Epoch [5/5], Step [6670/9994], Loss: 0.0387\n",
      "Epoch [5/5], Step [6680/9994], Loss: 0.0051\n",
      "Epoch [5/5], Step [6690/9994], Loss: 0.0125\n",
      "Epoch [5/5], Step [6700/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [6710/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6720/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [6730/9994], Loss: 0.0104\n",
      "Epoch [5/5], Step [6740/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [6750/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [6760/9994], Loss: 0.0194\n",
      "Epoch [5/5], Step [6770/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [6780/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [6790/9994], Loss: 0.0041\n",
      "Epoch [5/5], Step [6800/9994], Loss: 0.0502\n",
      "Epoch [5/5], Step [6810/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [6820/9994], Loss: 0.1042\n",
      "Epoch [5/5], Step [6830/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [6840/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [6850/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [6860/9994], Loss: 0.0434\n",
      "Epoch [5/5], Step [6870/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [6880/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [6890/9994], Loss: 0.0712\n",
      "Epoch [5/5], Step [6900/9994], Loss: 0.0097\n",
      "Epoch [5/5], Step [6910/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [6920/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [6930/9994], Loss: 0.0135\n",
      "Epoch [5/5], Step [6940/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [6950/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [6960/9994], Loss: 0.0284\n",
      "Epoch [5/5], Step [6970/9994], Loss: 0.0420\n",
      "Epoch [5/5], Step [6980/9994], Loss: 0.0262\n",
      "Epoch [5/5], Step [6990/9994], Loss: 0.0088\n",
      "Epoch [5/5], Step [7000/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [7010/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [7020/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [7030/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [7040/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7050/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [7060/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [7070/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [7080/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [7090/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7100/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [7110/9994], Loss: 0.0135\n",
      "Epoch [5/5], Step [7120/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [7130/9994], Loss: 0.0442\n",
      "Epoch [5/5], Step [7140/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [7150/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [7160/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [7170/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [7180/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [7190/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [7200/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7210/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [7220/9994], Loss: 0.0428\n",
      "Epoch [5/5], Step [7230/9994], Loss: 0.0203\n",
      "Epoch [5/5], Step [7240/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [7250/9994], Loss: 0.0418\n",
      "Epoch [5/5], Step [7260/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [7270/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [7280/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [7290/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [7300/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [7310/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [7320/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [7330/9994], Loss: 0.0289\n",
      "Epoch [5/5], Step [7340/9994], Loss: 0.0089\n",
      "Epoch [5/5], Step [7350/9994], Loss: 0.0193\n",
      "Epoch [5/5], Step [7360/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [7370/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [7380/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [7390/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [7400/9994], Loss: 0.0040\n",
      "Epoch [5/5], Step [7410/9994], Loss: 0.0385\n",
      "Epoch [5/5], Step [7420/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [7430/9994], Loss: 0.0384\n",
      "Epoch [5/5], Step [7440/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7450/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [7460/9994], Loss: 0.0081\n",
      "Epoch [5/5], Step [7470/9994], Loss: 0.0115\n",
      "Epoch [5/5], Step [7480/9994], Loss: 0.0044\n",
      "Epoch [5/5], Step [7490/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [7500/9994], Loss: 0.0158\n",
      "Epoch [5/5], Step [7510/9994], Loss: 0.0425\n",
      "Epoch [5/5], Step [7520/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7530/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7540/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [7550/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [7560/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7570/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [7580/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7590/9994], Loss: 0.0084\n",
      "Epoch [5/5], Step [7600/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [7610/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7620/9994], Loss: 0.0060\n",
      "Epoch [5/5], Step [7630/9994], Loss: 0.0033\n",
      "Epoch [5/5], Step [7640/9994], Loss: 0.0393\n",
      "Epoch [5/5], Step [7650/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [7660/9994], Loss: 0.0057\n",
      "Epoch [5/5], Step [7670/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [7680/9994], Loss: 0.0532\n",
      "Epoch [5/5], Step [7690/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [7700/9994], Loss: 0.0455\n",
      "Epoch [5/5], Step [7710/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [7720/9994], Loss: 0.0089\n",
      "Epoch [5/5], Step [7730/9994], Loss: 0.0069\n",
      "Epoch [5/5], Step [7740/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [7750/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [7760/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7770/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [7780/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [7790/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [7800/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [7810/9994], Loss: 0.0055\n",
      "Epoch [5/5], Step [7820/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [7830/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [7840/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [7850/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [7860/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [7870/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [7880/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [7890/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [7900/9994], Loss: 0.0570\n",
      "Epoch [5/5], Step [7910/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [7920/9994], Loss: 0.0542\n",
      "Epoch [5/5], Step [7930/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [7940/9994], Loss: 0.0049\n",
      "Epoch [5/5], Step [7950/9994], Loss: 0.0117\n",
      "Epoch [5/5], Step [7960/9994], Loss: 0.0029\n",
      "Epoch [5/5], Step [7970/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [7980/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [7990/9994], Loss: 0.0082\n",
      "Epoch [5/5], Step [8000/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [8010/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [8020/9994], Loss: 0.0748\n",
      "Epoch [5/5], Step [8030/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8040/9994], Loss: 0.0508\n",
      "Epoch [5/5], Step [8050/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [8060/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8070/9994], Loss: 0.0075\n",
      "Epoch [5/5], Step [8080/9994], Loss: 0.0610\n",
      "Epoch [5/5], Step [8090/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [8100/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [8110/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [8120/9994], Loss: 0.0044\n",
      "Epoch [5/5], Step [8130/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [8140/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [8150/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [8160/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [8170/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [8180/9994], Loss: 0.0391\n",
      "Epoch [5/5], Step [8190/9994], Loss: 0.0133\n",
      "Epoch [5/5], Step [8200/9994], Loss: 0.0336\n",
      "Epoch [5/5], Step [8210/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [8220/9994], Loss: 0.0084\n",
      "Epoch [5/5], Step [8230/9994], Loss: 0.0162\n",
      "Epoch [5/5], Step [8240/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [8250/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [8260/9994], Loss: 0.0062\n",
      "Epoch [5/5], Step [8270/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [8280/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [8290/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [8300/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [8310/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [8320/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [8330/9994], Loss: 0.0894\n",
      "Epoch [5/5], Step [8340/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [8350/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [8360/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [8370/9994], Loss: 0.0035\n",
      "Epoch [5/5], Step [8380/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8390/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [8400/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [8410/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [8420/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [8430/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [8440/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [8450/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [8460/9994], Loss: 0.0387\n",
      "Epoch [5/5], Step [8470/9994], Loss: 0.0891\n",
      "Epoch [5/5], Step [8480/9994], Loss: 0.0510\n",
      "Epoch [5/5], Step [8490/9994], Loss: 0.0049\n",
      "Epoch [5/5], Step [8500/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [8510/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [8520/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [8530/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [8540/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [8550/9994], Loss: 0.0033\n",
      "Epoch [5/5], Step [8560/9994], Loss: 0.0039\n",
      "Epoch [5/5], Step [8570/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [8580/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [8590/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8600/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [8610/9994], Loss: 0.0048\n",
      "Epoch [5/5], Step [8620/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [8630/9994], Loss: 0.0717\n",
      "Epoch [5/5], Step [8640/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [8650/9994], Loss: 0.0067\n",
      "Epoch [5/5], Step [8660/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [8670/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [8680/9994], Loss: 0.0061\n",
      "Epoch [5/5], Step [8690/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [8700/9994], Loss: 0.0149\n",
      "Epoch [5/5], Step [8710/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [8720/9994], Loss: 0.0053\n",
      "Epoch [5/5], Step [8730/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [8740/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [8750/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [8760/9994], Loss: 0.0025\n",
      "Epoch [5/5], Step [8770/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [8780/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8790/9994], Loss: 0.0184\n",
      "Epoch [5/5], Step [8800/9994], Loss: 0.0040\n",
      "Epoch [5/5], Step [8810/9994], Loss: 0.0031\n",
      "Epoch [5/5], Step [8820/9994], Loss: 0.0145\n",
      "Epoch [5/5], Step [8830/9994], Loss: 0.0125\n",
      "Epoch [5/5], Step [8840/9994], Loss: 0.0089\n",
      "Epoch [5/5], Step [8850/9994], Loss: 0.0054\n",
      "Epoch [5/5], Step [8860/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [8870/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [8880/9994], Loss: 0.0155\n",
      "Epoch [5/5], Step [8890/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [8900/9994], Loss: 0.0000\n",
      "Epoch [5/5], Step [8910/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [8920/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [8930/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [8940/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [8950/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [8960/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [8970/9994], Loss: 0.0038\n",
      "Epoch [5/5], Step [8980/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [8990/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [9000/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [9010/9994], Loss: 0.0536\n",
      "Epoch [5/5], Step [9020/9994], Loss: 0.0013\n",
      "Epoch [5/5], Step [9030/9994], Loss: 0.0015\n",
      "Epoch [5/5], Step [9040/9994], Loss: 0.0043\n",
      "Epoch [5/5], Step [9050/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [9060/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [9070/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [9080/9994], Loss: 0.0065\n",
      "Epoch [5/5], Step [9090/9994], Loss: 0.0094\n",
      "Epoch [5/5], Step [9100/9994], Loss: 0.0425\n",
      "Epoch [5/5], Step [9110/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [9120/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [9130/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [9140/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [9150/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [9160/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [9170/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [9180/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [9190/9994], Loss: 0.0070\n",
      "Epoch [5/5], Step [9200/9994], Loss: 0.0052\n",
      "Epoch [5/5], Step [9210/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [9220/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [9230/9994], Loss: 0.0676\n",
      "Epoch [5/5], Step [9240/9994], Loss: 0.0071\n",
      "Epoch [5/5], Step [9250/9994], Loss: 0.0018\n",
      "Epoch [5/5], Step [9260/9994], Loss: 0.0435\n",
      "Epoch [5/5], Step [9270/9994], Loss: 0.0061\n",
      "Epoch [5/5], Step [9280/9994], Loss: 0.0112\n",
      "Epoch [5/5], Step [9290/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [9300/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [9310/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [9320/9994], Loss: 0.0257\n",
      "Epoch [5/5], Step [9330/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [9340/9994], Loss: 0.0875\n",
      "Epoch [5/5], Step [9350/9994], Loss: 0.0004\n",
      "Epoch [5/5], Step [9360/9994], Loss: 0.0011\n",
      "Epoch [5/5], Step [9370/9994], Loss: 0.0181\n",
      "Epoch [5/5], Step [9380/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [9390/9994], Loss: 0.0007\n",
      "Epoch [5/5], Step [9400/9994], Loss: 0.0017\n",
      "Epoch [5/5], Step [9410/9994], Loss: 0.0003\n",
      "Epoch [5/5], Step [9420/9994], Loss: 0.0196\n",
      "Epoch [5/5], Step [9430/9994], Loss: 0.1081\n",
      "Epoch [5/5], Step [9440/9994], Loss: 0.0032\n",
      "Epoch [5/5], Step [9450/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [9460/9994], Loss: 0.0027\n",
      "Epoch [5/5], Step [9470/9994], Loss: 0.0066\n",
      "Epoch [5/5], Step [9480/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [9490/9994], Loss: 0.0022\n",
      "Epoch [5/5], Step [9500/9994], Loss: 0.0045\n",
      "Epoch [5/5], Step [9510/9994], Loss: 0.0325\n",
      "Epoch [5/5], Step [9520/9994], Loss: 0.0631\n",
      "Epoch [5/5], Step [9530/9994], Loss: 0.0020\n",
      "Epoch [5/5], Step [9540/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [9550/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [9560/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [9570/9994], Loss: 0.0508\n",
      "Epoch [5/5], Step [9580/9994], Loss: 0.0092\n",
      "Epoch [5/5], Step [9590/9994], Loss: 0.0205\n",
      "Epoch [5/5], Step [9600/9994], Loss: 0.0347\n",
      "Epoch [5/5], Step [9610/9994], Loss: 0.0008\n",
      "Epoch [5/5], Step [9620/9994], Loss: 0.0139\n",
      "Epoch [5/5], Step [9630/9994], Loss: 0.0097\n",
      "Epoch [5/5], Step [9640/9994], Loss: 0.0034\n",
      "Epoch [5/5], Step [9650/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [9660/9994], Loss: 0.0078\n",
      "Epoch [5/5], Step [9670/9994], Loss: 0.0039\n",
      "Epoch [5/5], Step [9680/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [9690/9994], Loss: 0.0021\n",
      "Epoch [5/5], Step [9700/9994], Loss: 0.0031\n",
      "Epoch [5/5], Step [9710/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [9720/9994], Loss: 0.0005\n",
      "Epoch [5/5], Step [9730/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [9740/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [9750/9994], Loss: 0.0001\n",
      "Epoch [5/5], Step [9760/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [9770/9994], Loss: 0.0162\n",
      "Epoch [5/5], Step [9780/9994], Loss: 0.0372\n",
      "Epoch [5/5], Step [9790/9994], Loss: 0.0046\n",
      "Epoch [5/5], Step [9800/9994], Loss: 0.0028\n",
      "Epoch [5/5], Step [9810/9994], Loss: 0.0019\n",
      "Epoch [5/5], Step [9820/9994], Loss: 0.0055\n",
      "Epoch [5/5], Step [9830/9994], Loss: 0.0009\n",
      "Epoch [5/5], Step [9840/9994], Loss: 0.0002\n",
      "Epoch [5/5], Step [9850/9994], Loss: 0.0010\n",
      "Epoch [5/5], Step [9860/9994], Loss: 0.0016\n",
      "Epoch [5/5], Step [9870/9994], Loss: 0.0024\n",
      "Epoch [5/5], Step [9880/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [9890/9994], Loss: 0.0023\n",
      "Epoch [5/5], Step [9900/9994], Loss: 0.0078\n",
      "Epoch [5/5], Step [9910/9994], Loss: 0.0101\n",
      "Epoch [5/5], Step [9920/9994], Loss: 0.0026\n",
      "Epoch [5/5], Step [9930/9994], Loss: 0.0014\n",
      "Epoch [5/5], Step [9940/9994], Loss: 0.0012\n",
      "Epoch [5/5], Step [9950/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [9960/9994], Loss: 0.0098\n",
      "Epoch [5/5], Step [9970/9994], Loss: 0.0006\n",
      "Epoch [5/5], Step [9980/9994], Loss: 0.0380\n",
      "Epoch [5/5], Step [9990/9994], Loss: 0.0008\n",
      "Epoch [5/5], Average Train Loss: 0.0111\n",
      "Epoch [5/5], Validation Loss: 0.0138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Possible overfitting detected (validation loss > training loss).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample_model = SimpleCNN(num_classes=9).to(device)\n",
    "train_model_verbose(undersample_model, undersampled_train_dataloader, val_dataloader, num_epochs=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2699194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
