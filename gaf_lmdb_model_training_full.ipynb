{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7a29fd",
   "metadata": {},
   "source": [
    "# GAF + LMDB + PyTorch Model Training Notebook\n",
    "This notebook:\n",
    "- Converts tabular network flows to GAF images (with GPU acceleration)\n",
    "- Stores GAF images and labels in LMDB\n",
    "- Loads data into PyTorch DataLoader\n",
    "- Trains a CNN on the data\n",
    "- Evaluates model and prints analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a75cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import lmdb\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Set these ====\n",
    "input_folder = './data'\n",
    "output_folder = './output/'\n",
    "lmdb_path = os.path.join(output_folder, 'gaf_images')\n",
    "pca_components = 32\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f232c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gaf_transform_torch(x, device='cpu'):\n",
    "    min_x = x.min(dim=1, keepdim=True).values\n",
    "    max_x = x.max(dim=1, keepdim=True).values\n",
    "    scaled_x = (2 * (x - min_x) / (max_x - min_x + 1e-8)) - 1\n",
    "    scaled_x = torch.clamp(scaled_x, -1, 1)\n",
    "    phi = torch.arccos(scaled_x)\n",
    "    gaf = torch.cos(phi.unsqueeze(2) + phi.unsqueeze(1))\n",
    "    return gaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be25afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA:\", torch.cuda.get_device_name(0))\n",
    "elif getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple MPS (Metal Performance Shaders)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dos_attacks = ['DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 'DoS slowloris']\n",
    "brute_force_attacks = ['FTP-Patator', 'SSH-Patator']\n",
    "web_attacks = ['Web Attack ÔøΩ Brute Force', 'Web Attack ÔøΩ Sql Injection', 'Web Attack ÔøΩ XSS']\n",
    "\n",
    "def map_to_broader_category(label):\n",
    "    if label == 'BENIGN':\n",
    "        return 'BENIGN'\n",
    "    elif label == 'DDoS':\n",
    "        return 'DDoS'\n",
    "    elif label == 'PortScan':\n",
    "        return 'PortScan'\n",
    "    elif label in dos_attacks:\n",
    "        return 'DoS'\n",
    "    elif label in brute_force_attacks:\n",
    "        return 'BruteForce'\n",
    "    elif label in web_attacks:\n",
    "        return 'WebAttack'\n",
    "    elif label == 'Bot':\n",
    "        return 'Bot'\n",
    "    elif label == 'Infiltration':\n",
    "        return 'Infiltration'\n",
    "    elif label == 'Heartbleed':\n",
    "        return 'Heartbleed'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e799c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = lmdb.open(lmdb_path, map_size=int(1e12))\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "with env.begin(write=True) as txn:\n",
    "    for csv_file in csv_files:\n",
    "        print(f\"\\nüìÑ Processing {csv_file}...\")\n",
    "        df_path = os.path.join(input_folder, csv_file)\n",
    "        df = pd.read_csv(df_path)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        if 'Label' not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è Skipping {csv_file} ‚Äî 'Label' column not found.\")\n",
    "            continue\n",
    "\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        labels = df['Label'].values\n",
    "        features = df.select_dtypes(include=[np.number])\n",
    "        features = features.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        X = features.values\n",
    "        y = labels\n",
    "\n",
    "        unique_classes = np.unique(y)\n",
    "        if len(unique_classes) > 1:\n",
    "            print(f\"Before SMOTE: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_res, y_res = smote.fit_resample(X, y)\n",
    "            print(f\"After SMOTE: {dict(zip(*np.unique(y_res, return_counts=True)))}\")\n",
    "        else:\n",
    "            print(f\"Skipping SMOTE for {csv_file} ‚Äî only found one class: {unique_classes[0]}\")\n",
    "            X_res, y_res = X, y\n",
    "\n",
    "        rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "        X_res, y_res = rus.fit_resample(X_res, y_res)\n",
    "        print(f\"After undersampling: {dict(zip(*np.unique(y_res, return_counts=True)))}\")\n",
    "\n",
    "        y_categorized = np.array([map_to_broader_category(label) for label in y_res])\n",
    "        print(f\"After category merging: {dict(zip(*np.unique(y_categorized, return_counts=True)))}\")\n",
    "        y_res = y_categorized\n",
    "\n",
    "        features_scaled = scaler.fit_transform(X_res)\n",
    "        features_reduced = pca.fit_transform(features_scaled)\n",
    "        labels_res = y_res\n",
    "\n",
    "        print(f\"Generating GAF images and storing (label, data) in LMDB...\")\n",
    "\n",
    "        flows_torch = torch.tensor(features_reduced, dtype=torch.float32, device=device)\n",
    "        gaf_images = gaf_transform_torch(flows_torch, device=device).cpu().numpy()\n",
    "\n",
    "        for idx, (gaf_image, label) in enumerate(zip(gaf_images, labels_res)):\n",
    "            try:\n",
    "                buf = io.BytesIO()\n",
    "                plt.imsave(buf, gaf_image, cmap='gray', format='png')\n",
    "                buf.seek(0)\n",
    "                image_bytes = buf.read()\n",
    "                buf.close()\n",
    "                key = f\"{os.path.splitext(csv_file)[0]}_{idx:07d}\".encode('utf-8')\n",
    "                record = {\"label\": str(label), \"data\": image_bytes}\n",
    "                txn.put(key, pickle.dumps(record))\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error on flow {idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "print(\"\\n‚úÖ GAF image generation and LMDB (label, data) storage complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7149bd",
   "metadata": {},
   "source": [
    "## Load LMDB as PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ab481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "class LMDBGAFDataset(Dataset):\n",
    "    def __init__(self, lmdb_path, transform=None):\n",
    "        self.env = lmdb.open(lmdb_path, readonly=True, lock=False)\n",
    "        self.txn = self.env.begin()\n",
    "        self.keys = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        with self.env.begin() as txn:\n",
    "            for key, value in txn.cursor():\n",
    "                record = pickle.loads(value)\n",
    "                label = record['label']\n",
    "                self.keys.append(key)\n",
    "                self.labels.append(label)\n",
    "        self.label_to_idx = {lbl: idx for idx, lbl in enumerate(sorted(set(self.labels)))}\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        value = self.txn.get(key)\n",
    "        record = pickle.loads(value)\n",
    "        label = record['label']\n",
    "        image = Image.open(io.BytesIO(record['data'])).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_idx = self.label_to_idx[label]\n",
    "        return image, label_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81568258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "lmdb_path = os.path.join(output_folder, 'gaf_images.lmdb')\n",
    "dataset = LMDBGAFDataset(lmdb_path, transform=transform)\n",
    "\n",
    "n = len(dataset)\n",
    "n_train = int(0.7 * n)\n",
    "n_val = int(0.15 * n)\n",
    "n_test = n - n_train - n_val\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "num_classes = len(dataset.label_to_idx)\n",
    "print(\"Classes:\", dataset.label_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20d0ca",
   "metadata": {},
   "source": [
    "## Define and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "# --- Option to select model type ---\n",
    "model_type = \"resnet18\"   # options: 'simple', 'resnet18', 'mobilenetv2'\n",
    "print(\"Model type:\", model_type)\n",
    "\n",
    "input_size = dataset[0][0].shape[-1]\n",
    "\n",
    "if model_type == \"simple\":\n",
    "    class SimpleGAFNet(nn.Module):\n",
    "        def __init__(self, num_classes, input_size=32):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "            self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.flatten_size = (input_size // 8) * (input_size // 8) * 64\n",
    "            self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "            self.fc2 = nn.Linear(128, num_classes)\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = self.pool(F.relu(self.conv3(x)))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            return self.fc2(x)\n",
    "    model = SimpleGAFNet(num_classes=num_classes, input_size=input_size)\n",
    "elif model_type == \"resnet18\":\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    # Modify first conv for 1-channel input (from 3 channels)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    # Change the output layer\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_type == \"mobilenetv2\":\n",
    "    model = models.mobilenet_v2(pretrained=False)\n",
    "    # Change first conv for 1-channel input (replace with 1-in channel)\n",
    "    model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "    # Change output classifier\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "else:\n",
    "    raise ValueError(\"Unknown model_type\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model ready:\", model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = out.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += imgs.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, labels)\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = out.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += imgs.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "for epoch in range(1, 11):  # 10 epochs\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f}, acc {train_acc:.3f} | Val loss {val_loss:.4f}, acc {val_acc:.3f}\")\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest loss: {test_loss:.4f}, accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c85d2",
   "metadata": {},
   "source": [
    "## Model Analysis: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        out = model(imgs)\n",
    "        _, preds = out.max(1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset.label_to_idx.keys()))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion matrix:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
